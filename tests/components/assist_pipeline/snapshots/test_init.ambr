# serializer version: 1
# name: test_pipeline_from_audio_stream_auto
  list([
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'language': 'en',
        'pipeline': <ANY>,
        'tts_output': dict({
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.RUN_START: 'run-start'>,
    }),
    dict({
      'data': dict({
        'engine': 'stt.mock_stt',
        'metadata': dict({
          'bit_rate': <AudioBitRates.BITRATE_16: 16>,
          'channel': <AudioChannels.CHANNEL_MONO: 1>,
          'codec': <AudioCodecs.PCM: 'pcm'>,
          'format': <AudioFormats.WAV: 'wav'>,
          'language': 'en-US',
          'sample_rate': <AudioSampleRates.SAMPLERATE_16000: 16000>,
        }),
      }),
      'type': <PipelineEventType.STT_START: 'stt-start'>,
    }),
    dict({
      'data': dict({
        'stt_output': dict({
          'text': 'test transcript',
        }),
      }),
      'type': <PipelineEventType.STT_END: 'stt-end'>,
    }),
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'device_id': None,
        'engine': 'conversation.home_assistant',
        'intent_input': 'test transcript',
        'language': 'en',
        'prefer_local_intents': False,
      }),
      'type': <PipelineEventType.INTENT_START: 'intent-start'>,
    }),
    dict({
      'data': dict({
        'intent_output': dict({
          'continue_conversation': False,
          'conversation_id': <ANY>,
          'response': dict({
            'card': dict({
            }),
            'data': dict({
              'code': 'no_intent_match',
            }),
            'language': 'en',
            'response_type': 'error',
            'speech': dict({
              'plain': dict({
                'extra_data': None,
                'speech': "Sorry, I couldn't understand that",
              }),
            }),
          }),
        }),
        'processed_locally': True,
      }),
      'type': <PipelineEventType.INTENT_END: 'intent-end'>,
    }),
    dict({
      'data': dict({
        'engine': 'tts.test',
        'language': 'en_US',
        'tts_input': "Sorry, I couldn't understand that",
        'voice': None,
      }),
      'type': <PipelineEventType.TTS_START: 'tts-start'>,
    }),
    dict({
      'data': dict({
        'tts_output': dict({
          'media_id': "media-source://tts/tts.test?message=Sorry,+I+couldn't+understand+that&language=en_US&tts_options=%7B%7D",
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.TTS_END: 'tts-end'>,
    }),
    dict({
      'data': None,
      'type': <PipelineEventType.RUN_END: 'run-end'>,
    }),
  ])
# ---
# name: test_pipeline_from_audio_stream_entity
  list([
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'language': 'en',
        'pipeline': <ANY>,
        'tts_output': dict({
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.RUN_START: 'run-start'>,
    }),
    dict({
      'data': dict({
        'engine': 'stt.mock_stt',
        'metadata': dict({
          'bit_rate': <AudioBitRates.BITRATE_16: 16>,
          'channel': <AudioChannels.CHANNEL_MONO: 1>,
          'codec': <AudioCodecs.PCM: 'pcm'>,
          'format': <AudioFormats.WAV: 'wav'>,
          'language': 'en-US',
          'sample_rate': <AudioSampleRates.SAMPLERATE_16000: 16000>,
        }),
      }),
      'type': <PipelineEventType.STT_START: 'stt-start'>,
    }),
    dict({
      'data': dict({
        'stt_output': dict({
          'text': 'test transcript',
        }),
      }),
      'type': <PipelineEventType.STT_END: 'stt-end'>,
    }),
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'device_id': None,
        'engine': 'conversation.home_assistant',
        'intent_input': 'test transcript',
        'language': 'en-US',
        'prefer_local_intents': False,
      }),
      'type': <PipelineEventType.INTENT_START: 'intent-start'>,
    }),
    dict({
      'data': dict({
        'intent_output': dict({
          'continue_conversation': False,
          'conversation_id': <ANY>,
          'response': dict({
            'card': dict({
            }),
            'data': dict({
              'code': 'no_intent_match',
            }),
            'language': 'en-US',
            'response_type': 'error',
            'speech': dict({
              'plain': dict({
                'extra_data': None,
                'speech': "Sorry, I couldn't understand that",
              }),
            }),
          }),
        }),
        'processed_locally': True,
      }),
      'type': <PipelineEventType.INTENT_END: 'intent-end'>,
    }),
    dict({
      'data': dict({
        'engine': 'test',
        'language': 'en-US',
        'tts_input': "Sorry, I couldn't understand that",
        'voice': 'Arnold Schwarzenegger',
      }),
      'type': <PipelineEventType.TTS_START: 'tts-start'>,
    }),
    dict({
      'data': dict({
        'tts_output': dict({
          'media_id': "media-source://tts/test?message=Sorry,+I+couldn't+understand+that&language=en-US&tts_options=%7B%22voice%22:%22Arnold+Schwarzenegger%22%7D",
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.TTS_END: 'tts-end'>,
    }),
    dict({
      'data': None,
      'type': <PipelineEventType.RUN_END: 'run-end'>,
    }),
  ])
# ---
# name: test_pipeline_from_audio_stream_legacy
  list([
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'language': 'en',
        'pipeline': <ANY>,
        'tts_output': dict({
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.RUN_START: 'run-start'>,
    }),
    dict({
      'data': dict({
        'engine': 'test',
        'metadata': dict({
          'bit_rate': <AudioBitRates.BITRATE_16: 16>,
          'channel': <AudioChannels.CHANNEL_MONO: 1>,
          'codec': <AudioCodecs.PCM: 'pcm'>,
          'format': <AudioFormats.WAV: 'wav'>,
          'language': 'en-US',
          'sample_rate': <AudioSampleRates.SAMPLERATE_16000: 16000>,
        }),
      }),
      'type': <PipelineEventType.STT_START: 'stt-start'>,
    }),
    dict({
      'data': dict({
        'stt_output': dict({
          'text': 'test transcript',
        }),
      }),
      'type': <PipelineEventType.STT_END: 'stt-end'>,
    }),
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'device_id': None,
        'engine': 'conversation.home_assistant',
        'intent_input': 'test transcript',
        'language': 'en-US',
        'prefer_local_intents': False,
      }),
      'type': <PipelineEventType.INTENT_START: 'intent-start'>,
    }),
    dict({
      'data': dict({
        'intent_output': dict({
          'continue_conversation': False,
          'conversation_id': <ANY>,
          'response': dict({
            'card': dict({
            }),
            'data': dict({
              'code': 'no_intent_match',
            }),
            'language': 'en-US',
            'response_type': 'error',
            'speech': dict({
              'plain': dict({
                'extra_data': None,
                'speech': "Sorry, I couldn't understand that",
              }),
            }),
          }),
        }),
        'processed_locally': True,
      }),
      'type': <PipelineEventType.INTENT_END: 'intent-end'>,
    }),
    dict({
      'data': dict({
        'engine': 'test',
        'language': 'en-US',
        'tts_input': "Sorry, I couldn't understand that",
        'voice': 'Arnold Schwarzenegger',
      }),
      'type': <PipelineEventType.TTS_START: 'tts-start'>,
    }),
    dict({
      'data': dict({
        'tts_output': dict({
          'media_id': "media-source://tts/test?message=Sorry,+I+couldn't+understand+that&language=en-US&tts_options=%7B%22voice%22:%22Arnold+Schwarzenegger%22%7D",
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.TTS_END: 'tts-end'>,
    }),
    dict({
      'data': None,
      'type': <PipelineEventType.RUN_END: 'run-end'>,
    }),
  ])
# ---
# name: test_pipeline_from_audio_stream_wake_word
  list([
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'language': 'en',
        'pipeline': <ANY>,
        'tts_output': dict({
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.RUN_START: 'run-start'>,
    }),
    dict({
      'data': dict({
        'entity_id': 'wake_word.test',
        'metadata': dict({
          'bit_rate': <AudioBitRates.BITRATE_16: 16>,
          'channel': <AudioChannels.CHANNEL_MONO: 1>,
          'codec': <AudioCodecs.PCM: 'pcm'>,
          'format': <AudioFormats.WAV: 'wav'>,
          'sample_rate': <AudioSampleRates.SAMPLERATE_16000: 16000>,
        }),
        'timeout': 0,
      }),
      'type': <PipelineEventType.WAKE_WORD_START: 'wake_word-start'>,
    }),
    dict({
      'data': dict({
        'wake_word_output': dict({
          'timestamp': 2000,
          'wake_word_id': 'test_ww',
          'wake_word_phrase': 'Test Wake Word',
        }),
      }),
      'type': <PipelineEventType.WAKE_WORD_END: 'wake_word-end'>,
    }),
    dict({
      'data': dict({
        'engine': 'stt.mock_stt',
        'metadata': dict({
          'bit_rate': <AudioBitRates.BITRATE_16: 16>,
          'channel': <AudioChannels.CHANNEL_MONO: 1>,
          'codec': <AudioCodecs.PCM: 'pcm'>,
          'format': <AudioFormats.WAV: 'wav'>,
          'language': 'en-US',
          'sample_rate': <AudioSampleRates.SAMPLERATE_16000: 16000>,
        }),
      }),
      'type': <PipelineEventType.STT_START: 'stt-start'>,
    }),
    dict({
      'data': dict({
        'stt_output': dict({
          'text': 'test transcript',
        }),
      }),
      'type': <PipelineEventType.STT_END: 'stt-end'>,
    }),
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'device_id': None,
        'engine': 'conversation.home_assistant',
        'intent_input': 'test transcript',
        'language': 'en',
        'prefer_local_intents': False,
      }),
      'type': <PipelineEventType.INTENT_START: 'intent-start'>,
    }),
    dict({
      'data': dict({
        'intent_output': dict({
          'continue_conversation': False,
          'conversation_id': <ANY>,
          'response': dict({
            'card': dict({
            }),
            'data': dict({
              'code': 'no_intent_match',
            }),
            'language': 'en',
            'response_type': 'error',
            'speech': dict({
              'plain': dict({
                'extra_data': None,
                'speech': "Sorry, I couldn't understand that",
              }),
            }),
          }),
        }),
        'processed_locally': True,
      }),
      'type': <PipelineEventType.INTENT_END: 'intent-end'>,
    }),
    dict({
      'data': dict({
        'engine': 'tts.test',
        'language': 'en_US',
        'tts_input': "Sorry, I couldn't understand that",
        'voice': None,
      }),
      'type': <PipelineEventType.TTS_START: 'tts-start'>,
    }),
    dict({
      'data': dict({
        'tts_output': dict({
          'media_id': "media-source://tts/tts.test?message=Sorry,+I+couldn't+understand+that&language=en_US&tts_options=%7B%7D",
          'mime_type': 'audio/mpeg',
          'token': 'test_token.mp3',
          'url': '/api/tts_proxy/test_token.mp3',
        }),
      }),
      'type': <PipelineEventType.TTS_END: 'tts-end'>,
    }),
    dict({
      'data': None,
      'type': <PipelineEventType.RUN_END: 'run-end'>,
    }),
  ])
# ---
# name: test_pipeline_from_audio_stream_with_cloud_auth_fail
  list([
    dict({
      'data': dict({
        'conversation_id': 'mock-ulid',
        'language': 'en',
        'pipeline': <ANY>,
        'tts_output': dict({
          'mime_type': 'audio/mpeg',
          'token': 'mocked-token.mp3',
          'url': '/api/tts_proxy/mocked-token.mp3',
        }),
      }),
      'type': <PipelineEventType.RUN_START: 'run-start'>,
    }),
    dict({
      'data': dict({
        'engine': 'stt.mock_stt',
        'metadata': dict({
          'bit_rate': <AudioBitRates.BITRATE_16: 16>,
          'channel': <AudioChannels.CHANNEL_MONO: 1>,
          'codec': <AudioCodecs.PCM: 'pcm'>,
          'format': <AudioFormats.WAV: 'wav'>,
          'language': 'en-US',
          'sample_rate': <AudioSampleRates.SAMPLERATE_16000: 16000>,
        }),
      }),
      'type': <PipelineEventType.STT_START: 'stt-start'>,
    }),
    dict({
      'data': dict({
        'code': 'cloud-auth-failed',
        'message': 'Home Assistant Cloud authentication failed',
      }),
      'type': <PipelineEventType.ERROR: 'error'>,
    }),
    dict({
      'data': None,
      'type': <PipelineEventType.RUN_END: 'run-end'>,
    }),
  ])
# ---
