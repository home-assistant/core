This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
service_info/
  __init__.py
  bluetooth.py
  dhcp.py
  esphome.py
  hassio.py
  mqtt.py
  ssdp.py
  usb.py
  zeroconf.py
template/
  extensions/
    __init__.py
    areas.py
    base.py
    base64.py
    collection.py
    crypto.py
    datetime.py
    devices.py
    floors.py
    issues.py
    labels.py
    math.py
    regex.py
    string.py
  __init__.py
  context.py
  helpers.py
  render_info.py
__init__.py
aiohttp_client.py
area_registry.py
automation.py
category_registry.py
chat_session.py
check_config.py
collection.py
condition.py
config_entry_flow.py
config_entry_oauth2_flow.py
config_validation.py
data_entry_flow.py
debounce.py
deprecation.py
device_registry.py
device.py
discovery_flow.py
discovery.py
dispatcher.py
entity_component.py
entity_platform.py
entity_registry.py
entity_values.py
entity.py
entityfilter.py
event.py
floor_registry.py
frame.py
group.py
hassio.py
helper_integration.py
http.py
httpx_client.py
icon.py
importlib.py
instance_id.py
integration_platform.py
intent.py
issue_registry.py
json.py
label_registry.py
llm.py
location.py
network.py
normalized_name_base_registry.py
ratelimit.py
recorder.py
redact.py
registry.py
reload.py
restore_state.py
schema_config_entry_flow.py
script_variables.py
script.py
selector.py
sensor.py
service.py
signal.py
significant_change.py
singleton.py
start.py
state.py
storage.py
sun.py
system_info.py
target.py
temperature.py
trace.py
translation.py
trigger_template_entity.py
trigger.py
typing.py
update_coordinator.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="service_info/__init__.py">
"""Service info helpers."""
</file>

<file path="service_info/bluetooth.py">
"""The bluetooth integration service info."""

from home_assistant_bluetooth import BluetoothServiceInfo

__all__ = ["BluetoothServiceInfo"]
</file>

<file path="service_info/dhcp.py">
"""DHCP discovery data."""

from dataclasses import dataclass

from homeassistant.data_entry_flow import BaseServiceInfo


@dataclass(slots=True)
class DhcpServiceInfo(BaseServiceInfo):
    """Prepared info from dhcp entries."""

    ip: str
    hostname: str
    macaddress: str
    """The MAC address of the device.

    Please note that for historical reason the DHCP service will always format it
    as a lowercase string without colons.
    eg. "AA:BB:CC:12:34:56" is stored as "aabbcc123456"
    """
</file>

<file path="service_info/esphome.py">
"""ESPHome discovery data."""

from dataclasses import dataclass

from yarl import URL

from homeassistant.data_entry_flow import BaseServiceInfo


@dataclass(slots=True)
class ESPHomeServiceInfo(BaseServiceInfo):
    """Prepared info from ESPHome entries."""

    name: str
    zwave_home_id: int | None
    ip_address: str
    port: int
    noise_psk: str | None = None

    @property
    def socket_path(self) -> str:
        """Return the socket path to connect to the ESPHome device."""
        url = URL.build(scheme="esphome", host=self.ip_address, port=self.port)
        if self.noise_psk:
            url = url.with_user(self.noise_psk)
        return str(url)
</file>

<file path="service_info/hassio.py">
"""Hassio Discovery data."""

from dataclasses import dataclass
from typing import Any

from homeassistant.data_entry_flow import BaseServiceInfo


@dataclass(slots=True)
class HassioServiceInfo(BaseServiceInfo):
    """Prepared info from hassio entries."""

    config: dict[str, Any]
    name: str
    slug: str
    uuid: str
</file>

<file path="service_info/mqtt.py">
"""MQTT Discovery data."""

from dataclasses import dataclass

from homeassistant.data_entry_flow import BaseServiceInfo

type ReceivePayloadType = str | bytes | bytearray


@dataclass(slots=True)
class MqttServiceInfo(BaseServiceInfo):
    """Prepared info from mqtt entries."""

    topic: str
    payload: ReceivePayloadType
    qos: int
    retain: bool
    subscribed_topic: str
    timestamp: float
</file>

<file path="service_info/ssdp.py">
"""SSDP discovery data."""

from collections.abc import Mapping
from dataclasses import dataclass, field
from typing import Any, Final

from homeassistant.data_entry_flow import BaseServiceInfo

# Attributes for accessing info from retrieved UPnP device description
ATTR_ST: Final = "st"
ATTR_NT: Final = "nt"
ATTR_UPNP_DEVICE_TYPE: Final = "deviceType"
ATTR_UPNP_FRIENDLY_NAME: Final = "friendlyName"
ATTR_UPNP_MANUFACTURER: Final = "manufacturer"
ATTR_UPNP_MANUFACTURER_URL: Final = "manufacturerURL"
ATTR_UPNP_MODEL_DESCRIPTION: Final = "modelDescription"
ATTR_UPNP_MODEL_NAME: Final = "modelName"
ATTR_UPNP_MODEL_NUMBER: Final = "modelNumber"
ATTR_UPNP_MODEL_URL: Final = "modelURL"
ATTR_UPNP_SERIAL: Final = "serialNumber"
ATTR_UPNP_SERVICE_LIST: Final = "serviceList"
ATTR_UPNP_UDN: Final = "UDN"
ATTR_UPNP_UPC: Final = "UPC"
ATTR_UPNP_PRESENTATION_URL: Final = "presentationURL"


@dataclass(slots=True)
class SsdpServiceInfo(BaseServiceInfo):
    """Prepared info from ssdp/upnp entries."""

    ssdp_usn: str
    ssdp_st: str
    upnp: Mapping[str, Any]
    ssdp_location: str | None = None
    ssdp_nt: str | None = None
    ssdp_udn: str | None = None
    ssdp_ext: str | None = None
    ssdp_server: str | None = None
    ssdp_headers: Mapping[str, Any] = field(default_factory=dict)
    ssdp_all_locations: set[str] = field(default_factory=set)
    x_homeassistant_matching_domains: set[str] = field(default_factory=set)
</file>

<file path="service_info/usb.py">
"""USB discovery data."""

from dataclasses import dataclass

from homeassistant.data_entry_flow import BaseServiceInfo


@dataclass(slots=True)
class UsbServiceInfo(BaseServiceInfo):
    """Prepared info from usb entries."""

    device: str
    vid: str
    pid: str
    serial_number: str | None
    manufacturer: str | None
    description: str | None
</file>

<file path="service_info/zeroconf.py">
"""Zeroconf discovery data."""

from dataclasses import dataclass
from ipaddress import IPv4Address, IPv6Address
from typing import Any, Final

from homeassistant.data_entry_flow import BaseServiceInfo

# Attributes for ZeroconfServiceInfo[ATTR_PROPERTIES]
ATTR_PROPERTIES_ID: Final = "id"


@dataclass(slots=True)
class ZeroconfServiceInfo(BaseServiceInfo):
    """Prepared info from mDNS entries.

    The ip_address is the most recently updated address
    that is not a link local or unspecified address.

    The ip_addresses are all addresses in order of most
    recently updated to least recently updated.

    The host is the string representation of the ip_address.

    The addresses are the string representations of the
    ip_addresses.

    It is recommended to use the ip_address to determine
    the address to connect to as it will be the most
    recently updated address that is not a link local
    or unspecified address.
    """

    ip_address: IPv4Address | IPv6Address
    ip_addresses: list[IPv4Address | IPv6Address]
    port: int | None
    hostname: str
    type: str
    name: str
    properties: dict[str, Any]

    @property
    def host(self) -> str:
        """Return the host."""
        return str(self.ip_address)

    @property
    def addresses(self) -> list[str]:
        """Return the addresses."""
        return [str(ip_address) for ip_address in self.ip_addresses]
</file>

<file path="template/extensions/__init__.py">
"""Home Assistant template extensions."""

from .areas import AreaExtension
from .base64 import Base64Extension
from .collection import CollectionExtension
from .crypto import CryptoExtension
from .datetime import DateTimeExtension
from .devices import DeviceExtension
from .floors import FloorExtension
from .issues import IssuesExtension
from .labels import LabelExtension
from .math import MathExtension
from .regex import RegexExtension
from .string import StringExtension

__all__ = [
    "AreaExtension",
    "Base64Extension",
    "CollectionExtension",
    "CryptoExtension",
    "DateTimeExtension",
    "DeviceExtension",
    "FloorExtension",
    "IssuesExtension",
    "LabelExtension",
    "MathExtension",
    "RegexExtension",
    "StringExtension",
]
</file>

<file path="template/extensions/areas.py">
"""Area functions for Home Assistant templates."""

from __future__ import annotations

from collections.abc import Iterable
from typing import TYPE_CHECKING

import voluptuous as vol

from homeassistant.helpers import (
    area_registry as ar,
    device_registry as dr,
    entity_registry as er,
)
from homeassistant.helpers.template.helpers import resolve_area_id

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class AreaExtension(BaseTemplateExtension):
    """Extension for area-related template functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the area extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "areas",
                    self.areas,
                    as_global=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "area_id",
                    self.area_id,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "area_name",
                    self.area_name,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "area_entities",
                    self.area_entities,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "area_devices",
                    self.area_devices,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
            ],
        )

    def areas(self) -> Iterable[str | None]:
        """Return all areas."""
        return list(ar.async_get(self.hass).areas)

    def area_id(self, lookup_value: str) -> str | None:
        """Get the area ID from an area name, alias, device id, or entity id."""
        return resolve_area_id(self.hass, lookup_value)

    def _get_area_name(self, area_reg: ar.AreaRegistry, valid_area_id: str) -> str:
        """Get area name from valid area ID."""
        area = area_reg.async_get_area(valid_area_id)
        assert area
        return area.name

    def area_name(self, lookup_value: str) -> str | None:
        """Get the area name from an area id, device id, or entity id."""
        area_reg = ar.async_get(self.hass)
        if area := area_reg.async_get_area(lookup_value):
            return area.name

        dev_reg = dr.async_get(self.hass)
        ent_reg = er.async_get(self.hass)
        # Import here, not at top-level to avoid circular import
        from homeassistant.helpers import config_validation as cv  # noqa: PLC0415

        try:
            cv.entity_id(lookup_value)
        except vol.Invalid:
            pass
        else:
            if entity := ent_reg.async_get(lookup_value):
                # If entity has an area ID, get the area name for that
                if entity.area_id:
                    return self._get_area_name(area_reg, entity.area_id)
                # If entity has a device ID and the device exists with an area ID, get the
                # area name for that
                if (
                    entity.device_id
                    and (device := dev_reg.async_get(entity.device_id))
                    and device.area_id
                ):
                    return self._get_area_name(area_reg, device.area_id)

        if (device := dev_reg.async_get(lookup_value)) and device.area_id:
            return self._get_area_name(area_reg, device.area_id)

        return None

    def area_entities(self, area_id_or_name: str) -> Iterable[str]:
        """Return entities for a given area ID or name."""
        _area_id: str | None
        # if area_name returns a value, we know the input was an ID, otherwise we
        # assume it's a name, and if it's neither, we return early
        if self.area_name(area_id_or_name) is None:
            _area_id = self.area_id(area_id_or_name)
        else:
            _area_id = area_id_or_name
        if _area_id is None:
            return []
        ent_reg = er.async_get(self.hass)
        entity_ids = [
            entry.entity_id for entry in er.async_entries_for_area(ent_reg, _area_id)
        ]
        dev_reg = dr.async_get(self.hass)
        # We also need to add entities tied to a device in the area that don't themselves
        # have an area specified since they inherit the area from the device.
        entity_ids.extend(
            [
                entity.entity_id
                for device in dr.async_entries_for_area(dev_reg, _area_id)
                for entity in er.async_entries_for_device(ent_reg, device.id)
                if entity.area_id is None
            ]
        )
        return entity_ids

    def area_devices(self, area_id_or_name: str) -> Iterable[str]:
        """Return device IDs for a given area ID or name."""
        _area_id: str | None
        # if area_name returns a value, we know the input was an ID, otherwise we
        # assume it's a name, and if it's neither, we return early
        if self.area_name(area_id_or_name) is not None:
            _area_id = area_id_or_name
        else:
            _area_id = self.area_id(area_id_or_name)
        if _area_id is None:
            return []
        dev_reg = dr.async_get(self.hass)
        entries = dr.async_entries_for_area(dev_reg, _area_id)
        return [entry.id for entry in entries]
</file>

<file path="template/extensions/base.py">
"""Base extension class for Home Assistant template extensions."""

from __future__ import annotations

from collections.abc import Callable
from dataclasses import dataclass
from functools import wraps
from typing import TYPE_CHECKING, Any, Concatenate, NoReturn

from jinja2 import pass_context
from jinja2.ext import Extension
from jinja2.nodes import Node
from jinja2.parser import Parser

from homeassistant.exceptions import TemplateError

if TYPE_CHECKING:
    from homeassistant.core import HomeAssistant
    from homeassistant.helpers.template import TemplateEnvironment


@dataclass
class TemplateFunction:
    """Definition for a template function, filter, or test."""

    name: str
    func: Callable[..., Any] | Any
    as_global: bool = False
    as_filter: bool = False
    as_test: bool = False
    limited_ok: bool = (
        True  # Whether this function is available in limited environments
    )
    requires_hass: bool = False  # Whether this function requires hass to be available


def _pass_context[**_P, _R](
    func: Callable[Concatenate[Any, _P], _R],
    jinja_context: Callable[
        [Callable[Concatenate[Any, _P], _R]],
        Callable[Concatenate[Any, _P], _R],
    ] = pass_context,
) -> Callable[Concatenate[Any, _P], _R]:
    """Wrap function to pass context.

    We mark these as a context functions to ensure they get
    evaluated fresh with every execution, rather than executed
    at compile time and the value stored. The context itself
    can be discarded.
    """

    @wraps(func)
    def wrapper(_: Any, *args: _P.args, **kwargs: _P.kwargs) -> _R:
        return func(*args, **kwargs)

    return jinja_context(wrapper)


class BaseTemplateExtension(Extension):
    """Base class for Home Assistant template extensions."""

    environment: TemplateEnvironment

    def __init__(
        self,
        environment: TemplateEnvironment,
        *,
        functions: list[TemplateFunction] | None = None,
    ) -> None:
        """Initialize the extension with a list of template functions."""
        super().__init__(environment)

        if functions:
            for template_func in functions:
                # Skip functions that require hass when hass is not available
                if template_func.requires_hass and self.environment.hass is None:
                    continue

                # Register unsupported stub for functions not allowed in limited environments
                if self.environment.limited and not template_func.limited_ok:
                    unsupported_func = self._create_unsupported_function(
                        template_func.name
                    )
                    if template_func.as_global:
                        environment.globals[template_func.name] = unsupported_func
                    if template_func.as_filter:
                        environment.filters[template_func.name] = unsupported_func
                    if template_func.as_test:
                        environment.tests[template_func.name] = unsupported_func
                    continue

                func = template_func.func

                if template_func.requires_hass:
                    # We wrap these as a context functions to ensure they get
                    # evaluated fresh with every execution, rather than executed
                    # at compile time and the value stored.
                    func = _pass_context(func)

                if template_func.as_global:
                    environment.globals[template_func.name] = func
                if template_func.as_filter:
                    environment.filters[template_func.name] = func
                if template_func.as_test:
                    environment.tests[template_func.name] = func

    @staticmethod
    def _create_unsupported_function(name: str) -> Callable[[], NoReturn]:
        """Create a function that raises an error for unsupported functions in limited templates."""

        def unsupported(*args: Any, **kwargs: Any) -> NoReturn:
            raise TemplateError(
                f"Use of '{name}' is not supported in limited templates"
            )

        return unsupported

    @property
    def hass(self) -> HomeAssistant:
        """Return the Home Assistant instance.

        This property should only be used in extensions that have functions
        marked with requires_hass=True, as it assumes hass is not None.

        Raises:
            RuntimeError: If hass is not available in the environment.
        """
        if self.environment.hass is None:
            raise RuntimeError(
                "Home Assistant instance is not available. "
                "This property should only be used in extensions with "
                "functions marked requires_hass=True."
            )
        return self.environment.hass

    def parse(self, parser: Parser) -> Node | list[Node]:
        """Required by Jinja2 Extension base class."""
        return []
</file>

<file path="template/extensions/base64.py">
"""Base64 encoding and decoding functions for Home Assistant templates."""

from __future__ import annotations

import base64
from typing import TYPE_CHECKING

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class Base64Extension(BaseTemplateExtension):
    """Jinja2 extension for base64 encoding and decoding functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the base64 extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "base64_encode",
                    self.base64_encode,
                    as_filter=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "base64_decode",
                    self.base64_decode,
                    as_filter=True,
                    limited_ok=False,
                ),
            ],
        )

    @staticmethod
    def base64_encode(value: str | bytes) -> str:
        """Encode a string or bytes to base64."""
        if isinstance(value, str):
            value = value.encode("utf-8")
        return base64.b64encode(value).decode("utf-8")

    @staticmethod
    def base64_decode(value: str, encoding: str | None = "utf-8") -> str | bytes:
        """Decode a base64 string."""
        decoded = base64.b64decode(value)
        if encoding is None:
            return decoded
        return decoded.decode(encoding)
</file>

<file path="template/extensions/collection.py">
"""Collection and data structure functions for Home Assistant templates."""

from __future__ import annotations

from collections.abc import Iterable, MutableSequence
import random
from typing import TYPE_CHECKING, Any

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class CollectionExtension(BaseTemplateExtension):
    """Extension for collection and data structure operations."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the collection extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "flatten",
                    self.flatten,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "shuffle",
                    self.shuffle,
                    as_global=True,
                    as_filter=True,
                ),
                # Set operations
                TemplateFunction(
                    "intersect",
                    self.intersect,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "difference",
                    self.difference,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "union",
                    self.union,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "symmetric_difference",
                    self.symmetric_difference,
                    as_global=True,
                    as_filter=True,
                ),
                # Type conversion functions
                TemplateFunction(
                    "set",
                    self.to_set,
                    as_global=True,
                ),
                TemplateFunction(
                    "tuple",
                    self.to_tuple,
                    as_global=True,
                ),
                # Type checking functions (tests)
                TemplateFunction(
                    "list",
                    self.is_list,
                    as_test=True,
                ),
                TemplateFunction(
                    "set",
                    self.is_set,
                    as_test=True,
                ),
                TemplateFunction(
                    "tuple",
                    self.is_tuple,
                    as_test=True,
                ),
            ],
        )

    def flatten(self, value: Iterable[Any], levels: int | None = None) -> list[Any]:
        """Flatten list of lists."""
        if not isinstance(value, Iterable) or isinstance(value, str):
            raise TypeError(f"flatten expected a list, got {type(value).__name__}")

        flattened: list[Any] = []
        for item in value:
            if isinstance(item, Iterable) and not isinstance(item, str):
                if levels is None:
                    flattened.extend(self.flatten(item))
                elif levels >= 1:
                    flattened.extend(self.flatten(item, levels=(levels - 1)))
                else:
                    flattened.append(item)
            else:
                flattened.append(item)
        return flattened

    def shuffle(self, *args: Any, seed: Any = None) -> MutableSequence[Any]:
        """Shuffle a list, either with a seed or without."""
        if not args:
            raise TypeError("shuffle expected at least 1 argument, got 0")

        # If first argument is iterable and more than 1 argument provided
        # but not a named seed, then use 2nd argument as seed.
        if isinstance(args[0], Iterable) and not isinstance(args[0], str):
            items = list(args[0])
            if len(args) > 1 and seed is None:
                seed = args[1]
        elif len(args) == 1:
            raise TypeError(f"'{type(args[0]).__name__}' object is not iterable")
        else:
            items = list(args)

        if seed:
            r = random.Random(seed)
            r.shuffle(items)
        else:
            random.shuffle(items)
        return items

    def intersect(self, value: Iterable[Any], other: Iterable[Any]) -> list[Any]:
        """Return the common elements between two lists."""
        if not isinstance(value, Iterable) or isinstance(value, str):
            raise TypeError(f"intersect expected a list, got {type(value).__name__}")
        if not isinstance(other, Iterable) or isinstance(other, str):
            raise TypeError(f"intersect expected a list, got {type(other).__name__}")

        return list(set(value) & set(other))

    def difference(self, value: Iterable[Any], other: Iterable[Any]) -> list[Any]:
        """Return elements in first list that are not in second list."""
        if not isinstance(value, Iterable) or isinstance(value, str):
            raise TypeError(f"difference expected a list, got {type(value).__name__}")
        if not isinstance(other, Iterable) or isinstance(other, str):
            raise TypeError(f"difference expected a list, got {type(other).__name__}")

        return list(set(value) - set(other))

    def union(self, value: Iterable[Any], other: Iterable[Any]) -> list[Any]:
        """Return all unique elements from both lists combined."""
        if not isinstance(value, Iterable) or isinstance(value, str):
            raise TypeError(f"union expected a list, got {type(value).__name__}")
        if not isinstance(other, Iterable) or isinstance(other, str):
            raise TypeError(f"union expected a list, got {type(other).__name__}")

        return list(set(value) | set(other))

    def symmetric_difference(
        self, value: Iterable[Any], other: Iterable[Any]
    ) -> list[Any]:
        """Return elements that are in either list but not in both."""
        if not isinstance(value, Iterable) or isinstance(value, str):
            raise TypeError(
                f"symmetric_difference expected a list, got {type(value).__name__}"
            )
        if not isinstance(other, Iterable) or isinstance(other, str):
            raise TypeError(
                f"symmetric_difference expected a list, got {type(other).__name__}"
            )

        return list(set(value) ^ set(other))

    def to_set(self, value: Any) -> set[Any]:
        """Convert value to set."""
        return set(value)

    def to_tuple(self, value: Any) -> tuple[Any, ...]:
        """Convert value to tuple."""
        return tuple(value)

    def is_list(self, value: Any) -> bool:
        """Return whether a value is a list."""
        return isinstance(value, list)

    def is_set(self, value: Any) -> bool:
        """Return whether a value is a set."""
        return isinstance(value, set)

    def is_tuple(self, value: Any) -> bool:
        """Return whether a value is a tuple."""
        return isinstance(value, tuple)
</file>

<file path="template/extensions/crypto.py">
"""Cryptographic hash functions for Home Assistant templates."""

from __future__ import annotations

import hashlib
from typing import TYPE_CHECKING

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class CryptoExtension(BaseTemplateExtension):
    """Jinja2 extension for cryptographic hash functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the crypto extension."""
        super().__init__(
            environment,
            functions=[
                # Hash functions (as globals and filters)
                TemplateFunction(
                    "md5", self.md5, as_global=True, as_filter=True, limited_ok=False
                ),
                TemplateFunction(
                    "sha1", self.sha1, as_global=True, as_filter=True, limited_ok=False
                ),
                TemplateFunction(
                    "sha256",
                    self.sha256,
                    as_global=True,
                    as_filter=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "sha512",
                    self.sha512,
                    as_global=True,
                    as_filter=True,
                    limited_ok=False,
                ),
            ],
        )

    @staticmethod
    def md5(value: str) -> str:
        """Generate md5 hash from a string."""
        return hashlib.md5(value.encode()).hexdigest()

    @staticmethod
    def sha1(value: str) -> str:
        """Generate sha1 hash from a string."""
        return hashlib.sha1(value.encode()).hexdigest()

    @staticmethod
    def sha256(value: str) -> str:
        """Generate sha256 hash from a string."""
        return hashlib.sha256(value.encode()).hexdigest()

    @staticmethod
    def sha512(value: str) -> str:
        """Generate sha512 hash from a string."""
        return hashlib.sha512(value.encode()).hexdigest()
</file>

<file path="template/extensions/datetime.py">
"""DateTime functions for Home Assistant templates."""

from __future__ import annotations

from datetime import date, datetime, time, timedelta
from typing import TYPE_CHECKING, Any

from homeassistant.helpers.template.helpers import raise_no_default
from homeassistant.helpers.template.render_info import render_info_cv
from homeassistant.util import dt as dt_util

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment

_SENTINEL = object()
DATE_STR_FORMAT = "%Y-%m-%d %H:%M:%S"


class DateTimeExtension(BaseTemplateExtension):
    """Extension for datetime-related template functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the datetime extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "as_datetime",
                    self.as_datetime,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "as_local",
                    self.as_local,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "as_timedelta",
                    self.as_timedelta,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "as_timestamp",
                    self.as_timestamp,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "strptime",
                    self.strptime,
                    as_global=True,
                ),
                TemplateFunction(
                    "timedelta",
                    timedelta,
                    as_global=True,
                ),
                TemplateFunction(
                    "timestamp_custom",
                    self.timestamp_custom,
                    as_filter=True,
                ),
                TemplateFunction(
                    "timestamp_local",
                    self.timestamp_local,
                    as_filter=True,
                ),
                TemplateFunction(
                    "timestamp_utc",
                    self.timestamp_utc,
                    as_filter=True,
                ),
                TemplateFunction(
                    "datetime",
                    self.is_datetime,
                    as_test=True,
                ),
                # Functions that require hass
                TemplateFunction(
                    "now",
                    self.now,
                    as_global=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "utcnow",
                    self.utcnow,
                    as_global=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "relative_time",
                    self.relative_time,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "time_since",
                    self.time_since,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "time_until",
                    self.time_until,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "today_at",
                    self.today_at,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
            ],
        )

    def timestamp_custom(
        self,
        value: Any,
        date_format: str = DATE_STR_FORMAT,
        local: bool = True,
        default: Any = _SENTINEL,
    ) -> Any:
        """Filter to convert given timestamp to format."""
        try:
            result = dt_util.utc_from_timestamp(value)

            if local:
                result = dt_util.as_local(result)

            return result.strftime(date_format)
        except (ValueError, TypeError):
            # If timestamp can't be converted
            if default is _SENTINEL:
                raise_no_default("timestamp_custom", value)
            return default

    def timestamp_local(self, value: Any, default: Any = _SENTINEL) -> Any:
        """Filter to convert given timestamp to local date/time."""
        try:
            return dt_util.as_local(dt_util.utc_from_timestamp(value)).isoformat()
        except (ValueError, TypeError):
            # If timestamp can't be converted
            if default is _SENTINEL:
                raise_no_default("timestamp_local", value)
            return default

    def timestamp_utc(self, value: Any, default: Any = _SENTINEL) -> Any:
        """Filter to convert given timestamp to UTC date/time."""
        try:
            return dt_util.utc_from_timestamp(value).isoformat()
        except (ValueError, TypeError):
            # If timestamp can't be converted
            if default is _SENTINEL:
                raise_no_default("timestamp_utc", value)
            return default

    def as_timestamp(self, value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function which tries to convert value to timestamp."""
        try:
            return dt_util.as_timestamp(value)
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("as_timestamp", value)
            return default

    def as_datetime(self, value: Any, default: Any = _SENTINEL) -> Any:
        """Filter to convert a time string or UNIX timestamp to datetime object."""
        # Return datetime.datetime object without changes
        if type(value) is datetime:
            return value
        # Add midnight to datetime.date object
        if type(value) is date:
            return datetime.combine(value, time(0, 0, 0))
        try:
            # Check for a valid UNIX timestamp string, int or float
            timestamp = float(value)
            return dt_util.utc_from_timestamp(timestamp)
        except (ValueError, TypeError):
            # Try to parse datetime string to datetime object
            try:
                return dt_util.parse_datetime(value, raise_on_error=True)
            except (ValueError, TypeError):
                if default is _SENTINEL:
                    # Return None on string input
                    # to ensure backwards compatibility with HA Core 2024.1 and before.
                    if isinstance(value, str):
                        return None
                    raise_no_default("as_datetime", value)
                return default

    def as_timedelta(self, value: str) -> timedelta | None:
        """Parse a ISO8601 duration like 'PT10M' to a timedelta."""
        return dt_util.parse_duration(value)

    def strptime(self, string: str, fmt: str, default: Any = _SENTINEL) -> Any:
        """Parse a time string to datetime."""
        try:
            return datetime.strptime(string, fmt)
        except (ValueError, AttributeError, TypeError):
            if default is _SENTINEL:
                raise_no_default("strptime", string)
            return default

    def as_local(self, value: datetime) -> datetime:
        """Filter and function to convert time to local."""
        return dt_util.as_local(value)

    def is_datetime(self, value: Any) -> bool:
        """Return whether a value is a datetime."""
        return isinstance(value, datetime)

    def now(self) -> datetime:
        """Record fetching now."""
        if (render_info := render_info_cv.get()) is not None:
            render_info.has_time = True

        return dt_util.now()

    def utcnow(self) -> datetime:
        """Record fetching utcnow."""
        if (render_info := render_info_cv.get()) is not None:
            render_info.has_time = True

        return dt_util.utcnow()

    def today_at(self, time_str: str = "") -> datetime:
        """Record fetching now where the time has been replaced with value."""
        if (render_info := render_info_cv.get()) is not None:
            render_info.has_time = True

        today = dt_util.start_of_local_day()
        if not time_str:
            return today

        if (time_today := dt_util.parse_time(time_str)) is None:
            raise ValueError(
                f"could not convert {type(time_str).__name__} to datetime: '{time_str}'"
            )

        return datetime.combine(today, time_today, today.tzinfo)

    def relative_time(self, value: Any) -> Any:
        """Take a datetime and return its "age" as a string.

        The age can be in second, minute, hour, day, month or year. Only the
        biggest unit is considered, e.g. if it's 2 days and 3 hours, "2 days" will
        be returned.
        If the input datetime is in the future,
        the input datetime will be returned.

        If the input are not a datetime object the input will be returned unmodified.

        Note: This template function is deprecated in favor of `time_until`, but is still
        supported so as not to break old templates.
        """
        if (render_info := render_info_cv.get()) is not None:
            render_info.has_time = True

        if not isinstance(value, datetime):
            return value
        if not value.tzinfo:
            value = dt_util.as_local(value)
        if dt_util.now() < value:
            return value
        return dt_util.get_age(value)

    def time_since(self, value: Any | datetime, precision: int = 1) -> Any:
        """Take a datetime and return its "age" as a string.

        The age can be in seconds, minutes, hours, days, months and year.

        precision is the number of units to return, with the last unit rounded.

        If the value not a datetime object the input will be returned unmodified.
        """
        if (render_info := render_info_cv.get()) is not None:
            render_info.has_time = True

        if not isinstance(value, datetime):
            return value
        if not value.tzinfo:
            value = dt_util.as_local(value)
        if dt_util.now() < value:
            return value

        return dt_util.get_age(value, precision)

    def time_until(self, value: Any | datetime, precision: int = 1) -> Any:
        """Take a datetime and return the amount of time until that time as a string.

        The time until can be in seconds, minutes, hours, days, months and years.

        precision is the number of units to return, with the last unit rounded.

        If the value not a datetime object the input will be returned unmodified.
        """
        if (render_info := render_info_cv.get()) is not None:
            render_info.has_time = True

        if not isinstance(value, datetime):
            return value
        if not value.tzinfo:
            value = dt_util.as_local(value)
        if dt_util.now() > value:
            return value

        return dt_util.get_time_remaining(value, precision)
</file>

<file path="template/extensions/devices.py">
"""Device functions for Home Assistant templates."""

from __future__ import annotations

from collections.abc import Iterable
from typing import TYPE_CHECKING, Any

import voluptuous as vol

from homeassistant.exceptions import TemplateError
from homeassistant.helpers import (
    config_validation as cv,
    device_registry as dr,
    entity_registry as er,
)

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class DeviceExtension(BaseTemplateExtension):
    """Extension for device-related template functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the device extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "device_entities",
                    self.device_entities,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "device_id",
                    self.device_id,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "device_name",
                    self.device_name,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "device_attr",
                    self.device_attr,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "is_device_attr",
                    self.is_device_attr,
                    as_global=True,
                    as_test=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
            ],
        )

    def device_entities(self, _device_id: str) -> Iterable[str]:
        """Get entity ids for entities tied to a device."""
        entity_reg = er.async_get(self.hass)
        entries = er.async_entries_for_device(entity_reg, _device_id)
        return [entry.entity_id for entry in entries]

    def device_id(self, entity_id_or_device_name: str) -> str | None:
        """Get a device ID from an entity ID or device name."""
        entity_reg = er.async_get(self.hass)
        entity = entity_reg.async_get(entity_id_or_device_name)
        if entity is not None:
            return entity.device_id

        dev_reg = dr.async_get(self.hass)
        return next(
            (
                device_id
                for device_id, device in dev_reg.devices.items()
                if (name := device.name_by_user or device.name)
                and (str(entity_id_or_device_name) == name)
            ),
            None,
        )

    def device_name(self, lookup_value: str) -> str | None:
        """Get the device name from an device id, or entity id."""
        device_reg = dr.async_get(self.hass)
        if device := device_reg.async_get(lookup_value):
            return device.name_by_user or device.name

        ent_reg = er.async_get(self.hass)

        try:
            cv.entity_id(lookup_value)
        except vol.Invalid:
            pass
        else:
            if entity := ent_reg.async_get(lookup_value):
                if entity.device_id and (
                    device := device_reg.async_get(entity.device_id)
                ):
                    return device.name_by_user or device.name

        return None

    def device_attr(self, device_or_entity_id: str, attr_name: str) -> Any:
        """Get the device specific attribute."""
        device_reg = dr.async_get(self.hass)
        if not isinstance(device_or_entity_id, str):
            raise TemplateError("Must provide a device or entity ID")
        device = None
        if (
            "." in device_or_entity_id
            and (_device_id := self.device_id(device_or_entity_id)) is not None
        ):
            device = device_reg.async_get(_device_id)
        elif "." not in device_or_entity_id:
            device = device_reg.async_get(device_or_entity_id)
        if device is None or not hasattr(device, attr_name):
            return None
        return getattr(device, attr_name)

    def is_device_attr(
        self, device_or_entity_id: str, attr_name: str, attr_value: Any
    ) -> bool:
        """Test if a device's attribute is a specific value."""
        return bool(self.device_attr(device_or_entity_id, attr_name) == attr_value)
</file>

<file path="template/extensions/floors.py">
"""Floor functions for Home Assistant templates."""

from __future__ import annotations

from collections.abc import Iterable
from typing import TYPE_CHECKING, Any

from homeassistant.helpers import (
    area_registry as ar,
    device_registry as dr,
    entity_registry as er,
    floor_registry as fr,
)
from homeassistant.helpers.template.helpers import resolve_area_id

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class FloorExtension(BaseTemplateExtension):
    """Extension for floor-related template functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the floor extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "floors",
                    self.floors,
                    as_global=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "floor_id",
                    self.floor_id,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "floor_name",
                    self.floor_name,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "floor_areas",
                    self.floor_areas,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "floor_entities",
                    self.floor_entities,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
            ],
        )

    def floors(self) -> Iterable[str | None]:
        """Return all floors."""
        floor_registry = fr.async_get(self.hass)
        return [floor.floor_id for floor in floor_registry.async_list_floors()]

    def floor_id(self, lookup_value: Any) -> str | None:
        """Get the floor ID from a floor or area name, alias, device id, or entity id."""
        floor_registry = fr.async_get(self.hass)
        lookup_str = str(lookup_value)

        # Check if it's a floor name or alias
        if floor := floor_registry.async_get_floor_by_name(lookup_str):
            return floor.floor_id
        floors_list = floor_registry.async_get_floors_by_alias(lookup_str)
        if floors_list:
            return floors_list[0].floor_id

        # Resolve to area ID and get floor from area
        if aid := resolve_area_id(self.hass, lookup_value):
            area_reg = ar.async_get(self.hass)
            if area := area_reg.async_get_area(aid):
                return area.floor_id

        return None

    def floor_name(self, lookup_value: str) -> str | None:
        """Get the floor name from a floor id."""
        floor_registry = fr.async_get(self.hass)

        # Check if it's a floor ID
        if floor := floor_registry.async_get_floor(lookup_value):
            return floor.name

        # Resolve to area ID and get floor name from area's floor
        if aid := resolve_area_id(self.hass, lookup_value):
            area_reg = ar.async_get(self.hass)
            if (
                (area := area_reg.async_get_area(aid))
                and area.floor_id
                and (floor := floor_registry.async_get_floor(area.floor_id))
            ):
                return floor.name

        return None

    def _floor_id_or_name(self, floor_id_or_name: str) -> str | None:
        """Get the floor ID from a floor name or ID."""
        # If floor_name returns a value, we know the input was an ID, otherwise we
        # assume it's a name, and if it's neither, we return early.
        if self.floor_name(floor_id_or_name) is not None:
            return floor_id_or_name
        return self.floor_id(floor_id_or_name)

    def floor_areas(self, floor_id_or_name: str) -> Iterable[str]:
        """Return area IDs for a given floor ID or name."""
        if (_floor_id := self._floor_id_or_name(floor_id_or_name)) is None:
            return []

        area_reg = ar.async_get(self.hass)
        entries = ar.async_entries_for_floor(area_reg, _floor_id)
        return [entry.id for entry in entries if entry.id]

    def floor_entities(self, floor_id_or_name: str) -> Iterable[str]:
        """Return entity_ids for a given floor ID or name."""
        ent_reg = er.async_get(self.hass)
        dev_reg = dr.async_get(self.hass)
        entity_ids = []

        for area_id in self.floor_areas(floor_id_or_name):
            # Get entities directly assigned to the area
            entity_ids.extend(
                [
                    entry.entity_id
                    for entry in er.async_entries_for_area(ent_reg, area_id)
                ]
            )

            # Also add entities tied to a device in the area that don't themselves
            # have an area specified since they inherit the area from the device
            entity_ids.extend(
                [
                    entity.entity_id
                    for device in dr.async_entries_for_area(dev_reg, area_id)
                    for entity in er.async_entries_for_device(ent_reg, device.id)
                    if entity.area_id is None
                ]
            )

        return entity_ids
</file>

<file path="template/extensions/issues.py">
"""Issue functions for Home Assistant templates."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

from homeassistant.helpers import issue_registry as ir

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class IssuesExtension(BaseTemplateExtension):
    """Extension for issue-related template functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the issues extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "issues",
                    self.issues,
                    as_global=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "issue",
                    self.issue,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
            ],
        )

    def issues(self) -> dict[tuple[str, str], dict[str, Any]]:
        """Return all open issues."""
        current_issues = ir.async_get(self.hass).issues
        # Use JSON for safe representation
        return {
            key: issue_entry.to_json()
            for (key, issue_entry) in current_issues.items()
            if issue_entry.active
        }

    def issue(self, domain: str, issue_id: str) -> dict[str, Any] | None:
        """Get issue by domain and issue_id."""
        result = ir.async_get(self.hass).async_get_issue(domain, issue_id)
        if result:
            return result.to_json()
        return None
</file>

<file path="template/extensions/labels.py">
"""Label functions for Home Assistant templates."""

from __future__ import annotations

from collections.abc import Iterable
from typing import TYPE_CHECKING, Any

import voluptuous as vol

from homeassistant.helpers import (
    area_registry as ar,
    device_registry as dr,
    entity_registry as er,
    label_registry as lr,
)

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class LabelExtension(BaseTemplateExtension):
    """Extension for label-related template functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the label extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "labels",
                    self.labels,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "label_id",
                    self.label_id,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "label_name",
                    self.label_name,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                    limited_ok=False,
                ),
                TemplateFunction(
                    "label_description",
                    self.label_description,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "label_areas",
                    self.label_areas,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "label_devices",
                    self.label_devices,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
                TemplateFunction(
                    "label_entities",
                    self.label_entities,
                    as_global=True,
                    as_filter=True,
                    requires_hass=True,
                ),
            ],
        )

    def labels(self, lookup_value: Any = None) -> Iterable[str | None]:
        """Return all labels, or those from a area ID, device ID, or entity ID."""
        label_reg = lr.async_get(self.hass)
        if lookup_value is None:
            return list(label_reg.labels)

        ent_reg = er.async_get(self.hass)

        # Import here, not at top-level to avoid circular import
        from homeassistant.helpers import config_validation as cv  # noqa: PLC0415

        lookup_value = str(lookup_value)

        try:
            cv.entity_id(lookup_value)
        except vol.Invalid:
            pass
        else:
            if entity := ent_reg.async_get(lookup_value):
                return list(entity.labels)

        # Check if this could be a device ID
        dev_reg = dr.async_get(self.hass)
        if device := dev_reg.async_get(lookup_value):
            return list(device.labels)

        # Check if this could be a area ID
        area_reg = ar.async_get(self.hass)
        if area := area_reg.async_get_area(lookup_value):
            return list(area.labels)

        return []

    def label_id(self, lookup_value: Any) -> str | None:
        """Get the label ID from a label name."""
        label_reg = lr.async_get(self.hass)
        if label := label_reg.async_get_label_by_name(str(lookup_value)):
            return label.label_id
        return None

    def label_name(self, lookup_value: str) -> str | None:
        """Get the label name from a label ID."""
        label_reg = lr.async_get(self.hass)
        if label := label_reg.async_get_label(lookup_value):
            return label.name
        return None

    def label_description(self, lookup_value: str) -> str | None:
        """Get the label description from a label ID."""
        label_reg = lr.async_get(self.hass)
        if label := label_reg.async_get_label(lookup_value):
            return label.description
        return None

    def _label_id_or_name(self, label_id_or_name: str) -> str | None:
        """Get the label ID from a label name or ID."""
        # If label_name returns a value, we know the input was an ID, otherwise we
        # assume it's a name, and if it's neither, we return early.
        if self.label_name(label_id_or_name) is not None:
            return label_id_or_name
        return self.label_id(label_id_or_name)

    def label_areas(self, label_id_or_name: str) -> Iterable[str]:
        """Return areas for a given label ID or name."""
        if (_label_id := self._label_id_or_name(label_id_or_name)) is None:
            return []
        area_reg = ar.async_get(self.hass)
        entries = ar.async_entries_for_label(area_reg, _label_id)
        return [entry.id for entry in entries]

    def label_devices(self, label_id_or_name: str) -> Iterable[str]:
        """Return device IDs for a given label ID or name."""
        if (_label_id := self._label_id_or_name(label_id_or_name)) is None:
            return []
        dev_reg = dr.async_get(self.hass)
        entries = dr.async_entries_for_label(dev_reg, _label_id)
        return [entry.id for entry in entries]

    def label_entities(self, label_id_or_name: str) -> Iterable[str]:
        """Return entities for a given label ID or name."""
        if (_label_id := self._label_id_or_name(label_id_or_name)) is None:
            return []
        ent_reg = er.async_get(self.hass)
        entries = er.async_entries_for_label(ent_reg, _label_id)
        return [entry.entity_id for entry in entries]
</file>

<file path="template/extensions/math.py">
"""Mathematical and statistical functions for Home Assistant templates."""

from __future__ import annotations

from collections.abc import Iterable
from functools import wraps
import math
import statistics
from typing import TYPE_CHECKING, Any, Literal

import jinja2
from jinja2 import pass_environment

from homeassistant.helpers.template.helpers import raise_no_default

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment

# Sentinel object for default parameter
_SENTINEL = object()


class MathExtension(BaseTemplateExtension):
    """Jinja2 extension for mathematical and statistical functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the math extension."""
        super().__init__(
            environment,
            functions=[
                # Math constants (as globals only) - these are values, not functions
                TemplateFunction("e", math.e, as_global=True),
                TemplateFunction("pi", math.pi, as_global=True),
                TemplateFunction("tau", math.pi * 2, as_global=True),
                # Trigonometric functions (as globals and filters)
                TemplateFunction("sin", self.sine, as_global=True, as_filter=True),
                TemplateFunction("cos", self.cosine, as_global=True, as_filter=True),
                TemplateFunction("tan", self.tangent, as_global=True, as_filter=True),
                TemplateFunction("asin", self.arc_sine, as_global=True, as_filter=True),
                TemplateFunction(
                    "acos", self.arc_cosine, as_global=True, as_filter=True
                ),
                TemplateFunction(
                    "atan", self.arc_tangent, as_global=True, as_filter=True
                ),
                TemplateFunction(
                    "atan2", self.arc_tangent2, as_global=True, as_filter=True
                ),
                # Advanced math functions (as globals and filters)
                TemplateFunction("log", self.logarithm, as_global=True, as_filter=True),
                TemplateFunction(
                    "sqrt", self.square_root, as_global=True, as_filter=True
                ),
                # Statistical functions (as globals and filters)
                TemplateFunction(
                    "average", self.average, as_global=True, as_filter=True
                ),
                TemplateFunction("median", self.median, as_global=True, as_filter=True),
                TemplateFunction(
                    "statistical_mode",
                    self.statistical_mode,
                    as_global=True,
                    as_filter=True,
                ),
                # Min/Max functions (as globals only)
                TemplateFunction("min", self.min_max_min, as_global=True),
                TemplateFunction("max", self.min_max_max, as_global=True),
                # Bitwise operations (as globals and filters)
                TemplateFunction(
                    "bitwise_and", self.bitwise_and, as_global=True, as_filter=True
                ),
                TemplateFunction(
                    "bitwise_or", self.bitwise_or, as_global=True, as_filter=True
                ),
                TemplateFunction(
                    "bitwise_xor", self.bitwise_xor, as_global=True, as_filter=True
                ),
                # Value constraint functions (as globals and filters)
                TemplateFunction("clamp", self.clamp, as_global=True, as_filter=True),
                TemplateFunction("wrap", self.wrap, as_global=True, as_filter=True),
                TemplateFunction("remap", self.remap, as_global=True, as_filter=True),
            ],
        )

    @staticmethod
    def logarithm(value: Any, base: Any = math.e, default: Any = _SENTINEL) -> Any:
        """Filter and function to get logarithm of the value with a specific base."""
        try:
            base_float = float(base)
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("log", base)
            return default
        try:
            value_float = float(value)
            return math.log(value_float, base_float)
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("log", value)
            return default

    @staticmethod
    def sine(value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to get sine of the value."""
        try:
            return math.sin(float(value))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("sin", value)
            return default

    @staticmethod
    def cosine(value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to get cosine of the value."""
        try:
            return math.cos(float(value))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("cos", value)
            return default

    @staticmethod
    def tangent(value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to get tangent of the value."""
        try:
            return math.tan(float(value))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("tan", value)
            return default

    @staticmethod
    def arc_sine(value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to get arc sine of the value."""
        try:
            return math.asin(float(value))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("asin", value)
            return default

    @staticmethod
    def arc_cosine(value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to get arc cosine of the value."""
        try:
            return math.acos(float(value))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("acos", value)
            return default

    @staticmethod
    def arc_tangent(value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to get arc tangent of the value."""
        try:
            return math.atan(float(value))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("atan", value)
            return default

    @staticmethod
    def arc_tangent2(*args: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to calculate four quadrant arc tangent of y / x.

        The parameters to atan2 may be passed either in an iterable or as separate arguments
        The default value may be passed either as a positional or in a keyword argument
        """
        try:
            if 1 <= len(args) <= 2 and isinstance(args[0], (list, tuple)):
                if len(args) == 2 and default is _SENTINEL:
                    # Default value passed as a positional argument
                    default = args[1]
                args = tuple(args[0])
            elif len(args) == 3 and default is _SENTINEL:
                # Default value passed as a positional argument
                default = args[2]

            return math.atan2(float(args[0]), float(args[1]))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("atan2", args)
            return default

    @staticmethod
    def square_root(value: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to get square root of the value."""
        try:
            return math.sqrt(float(value))
        except (ValueError, TypeError):
            if default is _SENTINEL:
                raise_no_default("sqrt", value)
            return default

    @staticmethod
    def average(*args: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to calculate the arithmetic mean.

        Calculates of an iterable or of two or more arguments.

        The parameters may be passed as an iterable or as separate arguments.
        """
        if len(args) == 0:
            raise TypeError("average expected at least 1 argument, got 0")

        # If first argument is iterable and more than 1 argument provided but not a named
        # default, then use 2nd argument as default.
        if isinstance(args[0], Iterable):
            average_list = args[0]
            if len(args) > 1 and default is _SENTINEL:
                default = args[1]
        elif len(args) == 1:
            raise TypeError(f"'{type(args[0]).__name__}' object is not iterable")
        else:
            average_list = args

        try:
            return statistics.fmean(average_list)
        except (TypeError, statistics.StatisticsError):
            if default is _SENTINEL:
                raise_no_default("average", args)
            return default

    @staticmethod
    def median(*args: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to calculate the median.

        Calculates median of an iterable of two or more arguments.

        The parameters may be passed as an iterable or as separate arguments.
        """
        if len(args) == 0:
            raise TypeError("median expected at least 1 argument, got 0")

        # If first argument is a list or tuple and more than 1 argument provided but not a named
        # default, then use 2nd argument as default.
        if isinstance(args[0], Iterable):
            median_list = args[0]
            if len(args) > 1 and default is _SENTINEL:
                default = args[1]
        elif len(args) == 1:
            raise TypeError(f"'{type(args[0]).__name__}' object is not iterable")
        else:
            median_list = args

        try:
            return statistics.median(median_list)
        except (TypeError, statistics.StatisticsError):
            if default is _SENTINEL:
                raise_no_default("median", args)
            return default

    @staticmethod
    def statistical_mode(*args: Any, default: Any = _SENTINEL) -> Any:
        """Filter and function to calculate the statistical mode.

        Calculates mode of an iterable of two or more arguments.

        The parameters may be passed as an iterable or as separate arguments.
        """
        if not args:
            raise TypeError("statistical_mode expected at least 1 argument, got 0")

        # If first argument is a list or tuple and more than 1 argument provided but not a named
        # default, then use 2nd argument as default.
        if len(args) == 1 and isinstance(args[0], Iterable):
            mode_list = args[0]
        elif isinstance(args[0], list | tuple):
            mode_list = args[0]
            if len(args) > 1 and default is _SENTINEL:
                default = args[1]
        elif len(args) == 1:
            raise TypeError(f"'{type(args[0]).__name__}' object is not iterable")
        else:
            mode_list = args

        try:
            return statistics.mode(mode_list)
        except (TypeError, statistics.StatisticsError):
            if default is _SENTINEL:
                raise_no_default("statistical_mode", args)
            return default

    def min_max_from_filter(self, builtin_filter: Any, name: str) -> Any:
        """Convert a built-in min/max Jinja filter to a global function.

        The parameters may be passed as an iterable or as separate arguments.
        """

        @pass_environment
        @wraps(builtin_filter)
        def wrapper(environment: jinja2.Environment, *args: Any, **kwargs: Any) -> Any:
            if len(args) == 0:
                raise TypeError(f"{name} expected at least 1 argument, got 0")

            if len(args) == 1:
                if isinstance(args[0], Iterable):
                    return builtin_filter(environment, args[0], **kwargs)

                raise TypeError(f"'{type(args[0]).__name__}' object is not iterable")

            return builtin_filter(environment, args, **kwargs)

        return pass_environment(wrapper)

    def min_max_min(self, *args: Any, **kwargs: Any) -> Any:
        """Min function using built-in filter."""
        return self.min_max_from_filter(self.environment.filters["min"], "min")(
            self.environment, *args, **kwargs
        )

    def min_max_max(self, *args: Any, **kwargs: Any) -> Any:
        """Max function using built-in filter."""
        return self.min_max_from_filter(self.environment.filters["max"], "max")(
            self.environment, *args, **kwargs
        )

    @staticmethod
    def bitwise_and(first_value: Any, second_value: Any) -> Any:
        """Perform a bitwise and operation."""
        return first_value & second_value

    @staticmethod
    def bitwise_or(first_value: Any, second_value: Any) -> Any:
        """Perform a bitwise or operation."""
        return first_value | second_value

    @staticmethod
    def bitwise_xor(first_value: Any, second_value: Any) -> Any:
        """Perform a bitwise xor operation."""
        return first_value ^ second_value

    @staticmethod
    def clamp(value: Any, min_value: Any, max_value: Any) -> Any:
        """Filter and function to clamp a value between min and max bounds.

        Constrains value to the range [min_value, max_value] (inclusive).
        """
        try:
            value_num = float(value)
            min_value_num = float(min_value)
            max_value_num = float(max_value)
        except (ValueError, TypeError) as err:
            raise ValueError(
                f"function requires numeric arguments, "
                f"got {value=}, {min_value=}, {max_value=}"
            ) from err
        return max(min_value_num, min(max_value_num, value_num))

    @staticmethod
    def wrap(value: Any, min_value: Any, max_value: Any) -> Any:
        """Filter and function to wrap a value within a range.

        Wraps value cyclically within [min_value, max_value) (inclusive min, exclusive max).
        """
        try:
            value_num = float(value)
            min_value_num = float(min_value)
            max_value_num = float(max_value)
        except (ValueError, TypeError) as err:
            raise ValueError(
                f"function requires numeric arguments, "
                f"got {value=}, {min_value=}, {max_value=}"
            ) from err
        try:
            range_size = max_value_num - min_value_num
            return ((value_num - min_value_num) % range_size) + min_value_num
        except ZeroDivisionError:  # be lenient: if the range is empty, just clamp
            return min_value_num

    @staticmethod
    def remap(
        value: Any,
        in_min: Any,
        in_max: Any,
        out_min: Any,
        out_max: Any,
        *,
        steps: int = 0,
        edges: Literal["none", "clamp", "wrap", "mirror"] = "none",
    ) -> Any:
        """Filter and function to remap a value from one range to another.

        Maps value from input range [in_min, in_max] to output range [out_min, out_max].

        The steps parameter, if greater than 0, quantizes the output into
        the specified number of discrete steps.

        The edges parameter controls how out-of-bounds input values are handled:
        - "none": No special handling; values outside the input range are extrapolated into the output range.
        - "clamp": Values outside the input range are clamped to the nearest boundary.
        - "wrap": Values outside the input range are wrapped around cyclically.
        - "mirror": Values outside the input range are mirrored back into the range.
        """
        try:
            value_num = float(value)
            in_min_num = float(in_min)
            in_max_num = float(in_max)
            out_min_num = float(out_min)
            out_max_num = float(out_max)
        except (ValueError, TypeError) as err:
            raise ValueError(
                f"function requires numeric arguments, "
                f"got {value=}, {in_min=}, {in_max=}, {out_min=}, {out_max=}"
            ) from err

        # Apply edge behavior in original space for accuracy.
        if edges == "clamp":
            value_num = max(in_min_num, min(in_max_num, value_num))
        elif edges == "wrap":
            if in_min_num == in_max_num:
                raise ValueError(f"{in_min=} must not equal {in_max=}")

            range_size = in_max_num - in_min_num  # Validated against div0 above.
            value_num = ((value_num - in_min_num) % range_size) + in_min_num
        elif edges == "mirror":
            if in_min_num == in_max_num:
                raise ValueError(f"{in_min=} must not equal {in_max=}")

            range_size = in_max_num - in_min_num  # Validated against div0 above.
            # Determine which period we're in and whether it should be mirrored
            offset = value_num - in_min_num
            period = math.floor(offset / range_size)
            position_in_period = offset - (period * range_size)

            if (period < 0) or (period % 2 != 0):
                position_in_period = range_size - position_in_period

            value_num = in_min_num + position_in_period
        # Unknown "edges" values are left as-is; no use throwing an error.

        steps = max(steps, 0)

        if not steps and (in_min_num == out_min_num and in_max_num == out_max_num):
            return value_num  # No remapping needed. Save some cycles and floating-point precision.

        normalized = (value_num - in_min_num) / (in_max_num - in_min_num)

        if steps:
            normalized = round(normalized * steps) / steps

        return out_min_num + (normalized * (out_max_num - out_min_num))
</file>

<file path="template/extensions/regex.py">
"""Jinja2 extension for regular expression functions."""

from __future__ import annotations

from functools import lru_cache
import re
from typing import TYPE_CHECKING, Any

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment

# Module-level regex cache shared across all instances
_regex_cache = lru_cache(maxsize=128)(re.compile)


class RegexExtension(BaseTemplateExtension):
    """Jinja2 extension for regular expression functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the regex extension."""

        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "regex_match",
                    self.regex_match,
                    as_filter=True,
                ),
                TemplateFunction(
                    "regex_search",
                    self.regex_search,
                    as_filter=True,
                ),
                # Register tests with different names
                TemplateFunction(
                    "match",
                    self.regex_match,
                    as_test=True,
                ),
                TemplateFunction(
                    "search",
                    self.regex_search,
                    as_test=True,
                ),
                TemplateFunction(
                    "regex_replace",
                    self.regex_replace,
                    as_filter=True,
                ),
                TemplateFunction(
                    "regex_findall",
                    self.regex_findall,
                    as_filter=True,
                ),
                TemplateFunction(
                    "regex_findall_index",
                    self.regex_findall_index,
                    as_filter=True,
                ),
            ],
        )

    def regex_match(self, value: Any, find: str = "", ignorecase: bool = False) -> bool:
        """Match value using regex."""
        if not isinstance(value, str):
            value = str(value)
        flags = re.IGNORECASE if ignorecase else 0
        return bool(_regex_cache(find, flags).match(value))

    def regex_replace(
        self,
        value: Any = "",
        find: str = "",
        replace: str = "",
        ignorecase: bool = False,
    ) -> str:
        """Replace using regex."""
        if not isinstance(value, str):
            value = str(value)
        flags = re.IGNORECASE if ignorecase else 0
        result = _regex_cache(find, flags).sub(replace, value)
        return str(result)

    def regex_search(
        self, value: Any, find: str = "", ignorecase: bool = False
    ) -> bool:
        """Search using regex."""
        if not isinstance(value, str):
            value = str(value)
        flags = re.IGNORECASE if ignorecase else 0
        return bool(_regex_cache(find, flags).search(value))

    def regex_findall_index(
        self, value: Any, find: str = "", index: int = 0, ignorecase: bool = False
    ) -> str:
        """Find all matches using regex and then pick specific match index."""
        return self.regex_findall(value, find, ignorecase)[index]

    def regex_findall(
        self, value: Any, find: str = "", ignorecase: bool = False
    ) -> list[str]:
        """Find all matches using regex."""
        if not isinstance(value, str):
            value = str(value)
        flags = re.IGNORECASE if ignorecase else 0
        return _regex_cache(find, flags).findall(value)
</file>

<file path="template/extensions/string.py">
"""Jinja2 extension for string processing functions."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any
from urllib.parse import urlencode as urllib_urlencode

from homeassistant.util import slugify as slugify_util

from .base import BaseTemplateExtension, TemplateFunction

if TYPE_CHECKING:
    from homeassistant.helpers.template import TemplateEnvironment


class StringExtension(BaseTemplateExtension):
    """Jinja2 extension for string processing functions."""

    def __init__(self, environment: TemplateEnvironment) -> None:
        """Initialize the string extension."""
        super().__init__(
            environment,
            functions=[
                TemplateFunction(
                    "ordinal",
                    self.ordinal,
                    as_filter=True,
                ),
                TemplateFunction(
                    "slugify",
                    self.slugify,
                    as_global=True,
                    as_filter=True,
                ),
                TemplateFunction(
                    "urlencode",
                    self.urlencode,
                    as_global=True,
                ),
            ],
        )

    def ordinal(self, value: Any) -> str:
        """Perform ordinal conversion."""
        suffixes = ["th", "st", "nd", "rd"] + ["th"] * 6  # codespell:ignore nd
        return str(value) + (
            suffixes[(int(str(value)[-1])) % 10]
            if int(str(value)[-2:]) % 100 not in range(11, 14)
            else "th"
        )

    def slugify(self, value: Any, separator: str = "_") -> str:
        """Convert a string into a slug, such as what is used for entity ids."""
        return slugify_util(str(value), separator=separator)

    def urlencode(self, value: Any) -> bytes:
        """Urlencode dictionary and return as UTF-8 string."""
        return urllib_urlencode(value).encode("utf-8")
</file>

<file path="template/__init__.py">
"""Template helper methods for rendering strings with Home Assistant data."""

from __future__ import annotations

from ast import literal_eval
import asyncio
import collections.abc
from collections.abc import Callable, Generator, Iterable
from copy import deepcopy
from datetime import datetime, timedelta
from functools import cache, lru_cache, partial, wraps
import json
import logging
import math
from operator import contains
import pathlib
import random
import re
from struct import error as StructError, pack, unpack_from
import sys
from types import CodeType
from typing import TYPE_CHECKING, Any, Concatenate, Literal, NoReturn, Self, overload
import weakref

from awesomeversion import AwesomeVersion
import jinja2
from jinja2 import pass_context, pass_eval_context
from jinja2.runtime import AsyncLoopContext, LoopContext
from jinja2.sandbox import ImmutableSandboxedEnvironment
from jinja2.utils import Namespace
from lru import LRU
import orjson
from propcache.api import under_cached_property
import voluptuous as vol

from homeassistant.const import (
    ATTR_ENTITY_ID,
    ATTR_LATITUDE,
    ATTR_LONGITUDE,
    ATTR_PERSONS,
    ATTR_UNIT_OF_MEASUREMENT,
    EVENT_HOMEASSISTANT_START,
    EVENT_HOMEASSISTANT_STOP,
    STATE_UNAVAILABLE,
    STATE_UNKNOWN,
    UnitOfLength,
)
from homeassistant.core import (
    Context,
    HomeAssistant,
    ServiceResponse,
    State,
    callback,
    valid_domain,
    valid_entity_id,
)
from homeassistant.exceptions import TemplateError
from homeassistant.helpers import entity_registry as er, location as loc_helper
from homeassistant.helpers.singleton import singleton
from homeassistant.helpers.translation import async_translate_state
from homeassistant.helpers.typing import TemplateVarsType
from homeassistant.util import convert, location as location_util
from homeassistant.util.async_ import run_callback_threadsafe
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.json import JSON_DECODE_EXCEPTIONS, json_loads
from homeassistant.util.read_only_dict import ReadOnlyDict
from homeassistant.util.thread import ThreadWithException

from .context import (
    TemplateContextManager as TemplateContextManager,
    render_with_context,
    template_context_manager,
    template_cv,
)
from .helpers import raise_no_default
from .render_info import RenderInfo, render_info_cv

if TYPE_CHECKING:
    from _typeshed import OptExcInfo

# mypy: allow-untyped-defs, no-check-untyped-defs

_LOGGER = logging.getLogger(__name__)
_SENTINEL = object()
DATE_STR_FORMAT = "%Y-%m-%d %H:%M:%S"

_ENVIRONMENT: HassKey[TemplateEnvironment] = HassKey("template.environment")
_ENVIRONMENT_LIMITED: HassKey[TemplateEnvironment] = HassKey(
    "template.environment_limited"
)
_ENVIRONMENT_STRICT: HassKey[TemplateEnvironment] = HassKey(
    "template.environment_strict"
)
_HASS_LOADER = "template.hass_loader"

# Match "simple" ints and floats. -1.0, 1, +5, 5.0
_IS_NUMERIC = re.compile(r"^[+-]?(?!0\d)\d*(?:\.\d*)?$")

_RESERVED_NAMES = {
    "contextfunction",
    "evalcontextfunction",
    "environmentfunction",
    "jinja_pass_arg",
}

_COLLECTABLE_STATE_ATTRIBUTES = {
    "state",
    "attributes",
    "last_changed",
    "last_updated",
    "context",
    "domain",
    "object_id",
    "name",
}


#
# CACHED_TEMPLATE_STATES is a rough estimate of the number of entities
# on a typical system. It is used as the initial size of the LRU cache
# for TemplateState objects.
#
# If the cache is too small we will end up creating and destroying
# TemplateState objects too often which will cause a lot of GC activity
# and slow down the system. For systems with a lot of entities and
# templates, this can reach 100000s of object creations and destructions
# per minute.
#
# Since entity counts may grow over time, we will increase
# the size if the number of entities grows via _async_adjust_lru_sizes
# at the start of the system and every 10 minutes if needed.
#
CACHED_TEMPLATE_STATES = 512
EVAL_CACHE_SIZE = 512

MAX_CUSTOM_TEMPLATE_SIZE = 5 * 1024 * 1024
MAX_TEMPLATE_OUTPUT = 256 * 1024  # 256KiB

CACHED_TEMPLATE_LRU: LRU[State, TemplateState] = LRU(CACHED_TEMPLATE_STATES)
CACHED_TEMPLATE_NO_COLLECT_LRU: LRU[State, TemplateState] = LRU(CACHED_TEMPLATE_STATES)
ENTITY_COUNT_GROWTH_FACTOR = 1.2

ORJSON_PASSTHROUGH_OPTIONS = (
    orjson.OPT_PASSTHROUGH_DATACLASS | orjson.OPT_PASSTHROUGH_DATETIME
)


def _template_state_no_collect(hass: HomeAssistant, state: State) -> TemplateState:
    """Return a TemplateState for a state without collecting."""
    if template_state := CACHED_TEMPLATE_NO_COLLECT_LRU.get(state):
        return template_state
    template_state = _create_template_state_no_collect(hass, state)
    CACHED_TEMPLATE_NO_COLLECT_LRU[state] = template_state
    return template_state


def _template_state(hass: HomeAssistant, state: State) -> TemplateState:
    """Return a TemplateState for a state that collects."""
    if template_state := CACHED_TEMPLATE_LRU.get(state):
        return template_state
    template_state = TemplateState(hass, state)
    CACHED_TEMPLATE_LRU[state] = template_state
    return template_state


def async_setup(hass: HomeAssistant) -> bool:
    """Set up tracking the template LRUs."""

    @callback
    def _async_adjust_lru_sizes(_: Any) -> None:
        """Adjust the lru cache sizes."""
        new_size = int(
            round(hass.states.async_entity_ids_count() * ENTITY_COUNT_GROWTH_FACTOR)
        )
        for lru in (CACHED_TEMPLATE_LRU, CACHED_TEMPLATE_NO_COLLECT_LRU):
            # There is no typing for LRU
            current_size = lru.get_size()
            if new_size > current_size:
                lru.set_size(new_size)

    from homeassistant.helpers.event import async_track_time_interval  # noqa: PLC0415

    cancel = async_track_time_interval(
        hass, _async_adjust_lru_sizes, timedelta(minutes=10)
    )
    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_START, _async_adjust_lru_sizes)
    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, callback(lambda _: cancel()))
    return True


def render_complex(
    value: Any,
    variables: TemplateVarsType = None,
    limited: bool = False,
    parse_result: bool = True,
) -> Any:
    """Recursive template creator helper function."""
    if isinstance(value, list):
        return [
            render_complex(item, variables, limited, parse_result) for item in value
        ]
    if isinstance(value, collections.abc.Mapping):
        return {
            render_complex(key, variables, limited, parse_result): render_complex(
                item, variables, limited, parse_result
            )
            for key, item in value.items()
        }
    if isinstance(value, Template):
        return value.async_render(variables, limited=limited, parse_result=parse_result)

    return value


def is_complex(value: Any) -> bool:
    """Test if data structure is a complex template."""
    if isinstance(value, Template):
        return True
    if isinstance(value, list):
        return any(is_complex(val) for val in value)
    if isinstance(value, collections.abc.Mapping):
        return any(is_complex(val) for val in value) or any(
            is_complex(val) for val in value.values()
        )
    return False


def is_template_string(maybe_template: str) -> bool:
    """Check if the input is a Jinja2 template."""
    return "{" in maybe_template and (
        "{%" in maybe_template or "{{" in maybe_template or "{#" in maybe_template
    )


class ResultWrapper:
    """Result wrapper class to store render result."""

    render_result: str | None


def gen_result_wrapper(kls: type[dict | list | set]) -> type:
    """Generate a result wrapper."""

    class Wrapper(kls, ResultWrapper):  # type: ignore[valid-type,misc]
        """Wrapper of a kls that can store render_result."""

        def __init__(self, *args: Any, render_result: str | None = None) -> None:
            super().__init__(*args)
            self.render_result = render_result

        def __str__(self) -> str:
            if self.render_result is None:
                # Can't get set repr to work
                if kls is set:
                    return str(set(self))

                return kls.__str__(self)

            return self.render_result

    return Wrapper


class TupleWrapper(tuple, ResultWrapper):
    """Wrap a tuple."""

    __slots__ = ()

    # This is all magic to be allowed to subclass a tuple.

    def __new__(cls, value: tuple, *, render_result: str | None = None) -> Self:
        """Create a new tuple class."""
        return super().__new__(cls, tuple(value))

    def __init__(self, value: tuple, *, render_result: str | None = None) -> None:
        """Initialize a new tuple class."""
        self.render_result = render_result

    def __str__(self) -> str:
        """Return string representation."""
        if self.render_result is None:
            return super().__str__()

        return self.render_result


_types: tuple[type[dict | list | set], ...] = (dict, list, set)
RESULT_WRAPPERS: dict[type, type] = {kls: gen_result_wrapper(kls) for kls in _types}
RESULT_WRAPPERS[tuple] = TupleWrapper


@lru_cache(maxsize=EVAL_CACHE_SIZE)
def _cached_parse_result(render_result: str) -> Any:
    """Parse a result and cache the result."""
    result = literal_eval(render_result)
    if type(result) in RESULT_WRAPPERS:
        result = RESULT_WRAPPERS[type(result)](result, render_result=render_result)

    # If the literal_eval result is a string, use the original
    # render, by not returning right here. The evaluation of strings
    # resulting in strings impacts quotes, to avoid unexpected
    # output; use the original render instead of the evaluated one.
    # Complex and scientific values are also unexpected. Filter them out.
    if (
        # Filter out string and complex numbers
        not isinstance(result, (str, complex))
        and (
            # Pass if not numeric and not a boolean
            not isinstance(result, (int, float))
            # Or it's a boolean (inherit from int)
            or isinstance(result, bool)
            # Or if it's a digit
            or _IS_NUMERIC.match(render_result) is not None
        )
    ):
        return result

    return render_result


class Template:
    """Class to hold a template and manage caching and rendering."""

    __slots__ = (
        "__weakref__",
        "_compiled",
        "_compiled_code",
        "_exc_info",
        "_hash_cache",
        "_limited",
        "_log_fn",
        "_renders",
        "_strict",
        "hass",
        "is_static",
        "template",
    )

    def __init__(self, template: str, hass: HomeAssistant | None = None) -> None:
        """Instantiate a template.

        Note: A valid hass instance should always be passed in. The hass parameter
        will be non optional in Home Assistant Core 2025.10.
        """
        from homeassistant.helpers.frame import (  # noqa: PLC0415
            ReportBehavior,
            report_usage,
        )

        if not isinstance(template, str):
            raise TypeError("Expected template to be a string")

        if not hass:
            report_usage(
                "creates a template object without passing hass",
                core_behavior=ReportBehavior.LOG,
                breaks_in_ha_version="2025.10",
            )

        self.template: str = template.strip()
        self._compiled_code: CodeType | None = None
        self._compiled: jinja2.Template | None = None
        self.hass = hass
        self.is_static = not is_template_string(template)
        self._exc_info: OptExcInfo | None = None
        self._limited: bool | None = None
        self._strict: bool | None = None
        self._log_fn: Callable[[int, str], None] | None = None
        self._hash_cache: int = hash(self.template)
        self._renders: int = 0

    @property
    def _env(self) -> TemplateEnvironment:
        if self.hass is None:
            return _NO_HASS_ENV
        # Bypass cache if a custom log function is specified
        if self._log_fn is not None:
            return TemplateEnvironment(
                self.hass, self._limited, self._strict, self._log_fn
            )
        if self._limited:
            wanted_env = _ENVIRONMENT_LIMITED
        elif self._strict:
            wanted_env = _ENVIRONMENT_STRICT
        else:
            wanted_env = _ENVIRONMENT
        if (ret := self.hass.data.get(wanted_env)) is None:
            ret = self.hass.data[wanted_env] = TemplateEnvironment(
                self.hass, self._limited, self._strict, self._log_fn
            )
        return ret

    def ensure_valid(self) -> None:
        """Return if template is valid."""
        if self.is_static or self._compiled_code is not None:
            return

        if compiled := self._env.template_cache.get(self.template):
            self._compiled_code = compiled
            return

        with template_context_manager as cm:
            cm.set_template(self.template, "compiling")
            try:
                self._compiled_code = self._env.compile(self.template)
            except jinja2.TemplateError as err:
                raise TemplateError(err) from err

    def render(
        self,
        variables: TemplateVarsType = None,
        parse_result: bool = True,
        limited: bool = False,
        **kwargs: Any,
    ) -> Any:
        """Render given template.

        If limited is True, the template is not allowed to access any function
        or filter depending on hass or the state machine.
        """
        if self.is_static:
            if not parse_result or (self.hass and self.hass.config.legacy_templates):
                return self.template
            return self._parse_result(self.template)
        assert self.hass is not None, "hass variable not set on template"
        return run_callback_threadsafe(
            self.hass.loop,
            partial(self.async_render, variables, parse_result, limited, **kwargs),
        ).result()

    @callback
    def async_render(
        self,
        variables: TemplateVarsType = None,
        parse_result: bool = True,
        limited: bool = False,
        strict: bool = False,
        log_fn: Callable[[int, str], None] | None = None,
        **kwargs: Any,
    ) -> Any:
        """Render given template.

        This method must be run in the event loop.

        If limited is True, the template is not allowed to access any function
        or filter depending on hass or the state machine.
        """
        self._renders += 1

        if self.is_static:
            if not parse_result or (self.hass and self.hass.config.legacy_templates):
                return self.template
            return self._parse_result(self.template)

        compiled = self._compiled or self._ensure_compiled(limited, strict, log_fn)

        if variables is not None:
            kwargs.update(variables)

        try:
            render_result = render_with_context(self.template, compiled, **kwargs)
        except Exception as err:
            raise TemplateError(err) from err

        if len(render_result) > MAX_TEMPLATE_OUTPUT:
            raise TemplateError(
                f"Template output exceeded maximum size of {MAX_TEMPLATE_OUTPUT} characters"
            )

        render_result = render_result.strip()

        if not parse_result or (self.hass and self.hass.config.legacy_templates):
            return render_result

        return self._parse_result(render_result)

    def _parse_result(self, render_result: str) -> Any:
        """Parse the result."""
        try:
            return _cached_parse_result(render_result)
        except (ValueError, TypeError, SyntaxError, MemoryError):
            pass

        return render_result

    async def async_render_will_timeout(
        self,
        timeout: float,
        variables: TemplateVarsType = None,
        strict: bool = False,
        log_fn: Callable[[int, str], None] | None = None,
        **kwargs: Any,
    ) -> bool:
        """Check to see if rendering a template will timeout during render.

        This is intended to check for expensive templates
        that will make the system unstable.  The template
        is rendered in the executor to ensure it does not
        tie up the event loop.

        This function is not a security control and is only
        intended to be used as a safety check when testing
        templates.

        This method must be run in the event loop.
        """
        self._renders += 1

        if self.is_static:
            return False

        compiled = self._compiled or self._ensure_compiled(strict=strict, log_fn=log_fn)

        if variables is not None:
            kwargs.update(variables)

        self._exc_info = None
        finish_event = asyncio.Event()

        def _render_template() -> None:
            assert self.hass is not None, "hass variable not set on template"
            try:
                render_with_context(self.template, compiled, **kwargs)
            except TimeoutError:
                pass
            except Exception:  # noqa: BLE001
                self._exc_info = sys.exc_info()
            finally:
                self.hass.loop.call_soon_threadsafe(finish_event.set)

        template_render_thread = ThreadWithException(target=_render_template)
        try:
            template_render_thread.start()
            async with asyncio.timeout(timeout):
                await finish_event.wait()
            if self._exc_info:
                raise TemplateError(self._exc_info[1].with_traceback(self._exc_info[2]))
        except TimeoutError:
            if template_render_thread.is_alive():
                template_render_thread.raise_exc(TimeoutError)
            return True
        finally:
            template_render_thread.join()

        return False

    @callback
    def async_render_to_info(
        self,
        variables: TemplateVarsType = None,
        strict: bool = False,
        log_fn: Callable[[int, str], None] | None = None,
        **kwargs: Any,
    ) -> RenderInfo:
        """Render the template and collect an entity filter."""
        if self.hass and self.hass.config.debug:
            self.hass.verify_event_loop_thread("async_render_to_info")
        self._renders += 1

        render_info = RenderInfo(self)

        if not self.hass:
            raise RuntimeError(f"hass not set while rendering {self}")

        if render_info_cv.get() is not None:
            raise RuntimeError(
                f"RenderInfo already set while rendering {self}, "
                "this usually indicates the template is being rendered "
                "in the wrong thread"
            )

        if self.is_static:
            render_info._result = self.template.strip()  # noqa: SLF001
            render_info._freeze_static()  # noqa: SLF001
            return render_info

        token = render_info_cv.set(render_info)
        try:
            render_info._result = self.async_render(  # noqa: SLF001
                variables, strict=strict, log_fn=log_fn, **kwargs
            )
        except TemplateError as ex:
            render_info.exception = ex
        finally:
            render_info_cv.reset(token)

        render_info._freeze()  # noqa: SLF001
        return render_info

    def render_with_possible_json_value(self, value, error_value=_SENTINEL):
        """Render template with value exposed.

        If valid JSON will expose value_json too.
        """
        if self.is_static:
            return self.template

        return run_callback_threadsafe(
            self.hass.loop,
            self.async_render_with_possible_json_value,
            value,
            error_value,
        ).result()

    @callback
    def async_render_with_possible_json_value(
        self,
        value: Any,
        error_value: Any = _SENTINEL,
        variables: dict[str, Any] | None = None,
        parse_result: bool = False,
    ) -> Any:
        """Render template with value exposed.

        If valid JSON will expose value_json too.

        This method must be run in the event loop.
        """
        self._renders += 1

        if self.is_static:
            return self.template

        compiled = self._compiled or self._ensure_compiled()

        variables = dict(variables or {})
        variables["value"] = value

        try:  # noqa: SIM105 - suppress is much slower
            variables["value_json"] = json_loads(value)
        except JSON_DECODE_EXCEPTIONS:
            pass

        try:
            render_result = render_with_context(
                self.template, compiled, **variables
            ).strip()
        except jinja2.TemplateError as ex:
            if error_value is _SENTINEL:
                _LOGGER.error(
                    "Error parsing value: %s (value: %s, template: %s)",
                    ex,
                    value,
                    self.template,
                )
            return value if error_value is _SENTINEL else error_value

        if not parse_result or (self.hass and self.hass.config.legacy_templates):
            return render_result

        return self._parse_result(render_result)

    def _ensure_compiled(
        self,
        limited: bool = False,
        strict: bool = False,
        log_fn: Callable[[int, str], None] | None = None,
    ) -> jinja2.Template:
        """Bind a template to a specific hass instance."""
        self.ensure_valid()

        assert self.hass is not None, "hass variable not set on template"
        assert self._limited is None or self._limited == limited, (
            "can't change between limited and non limited template"
        )
        assert self._strict is None or self._strict == strict, (
            "can't change between strict and non strict template"
        )
        assert not (strict and limited), "can't combine strict and limited template"
        assert self._log_fn is None or self._log_fn == log_fn, (
            "can't change custom log function"
        )
        assert self._compiled_code is not None, "template code was not compiled"

        self._limited = limited
        self._strict = strict
        self._log_fn = log_fn
        env = self._env

        self._compiled = jinja2.Template.from_code(
            env, self._compiled_code, env.globals, None
        )

        return self._compiled

    def __eq__(self, other):
        """Compare template with another."""
        return (
            self.__class__ == other.__class__
            and self.template == other.template
            and self.hass == other.hass
        )

    def __hash__(self) -> int:
        """Hash code for template."""
        return self._hash_cache

    def __repr__(self) -> str:
        """Representation of Template."""
        return f"Template<template=({self.template}) renders={self._renders}>"


@cache
def _domain_states(hass: HomeAssistant, name: str) -> DomainStates:
    return DomainStates(hass, name)


def _readonly(*args: Any, **kwargs: Any) -> Any:
    """Raise an exception when a states object is modified."""
    raise RuntimeError(f"Cannot modify template States object: {args} {kwargs}")


class AllStates:
    """Class to expose all HA states as attributes."""

    __setitem__ = _readonly
    __delitem__ = _readonly
    __slots__ = ("_hass",)

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize all states."""
        self._hass = hass

    def __getattr__(self, name):
        """Return the domain state."""
        if "." in name:
            return _get_state_if_valid(self._hass, name)

        if name in _RESERVED_NAMES:
            return None

        if not valid_domain(name):
            raise TemplateError(f"Invalid domain name '{name}'")

        return _domain_states(self._hass, name)

    # Jinja will try __getitem__ first and it avoids the need
    # to call is_safe_attribute
    __getitem__ = __getattr__

    def _collect_all(self) -> None:
        if (render_info := render_info_cv.get()) is not None:
            render_info.all_states = True

    def _collect_all_lifecycle(self) -> None:
        if (render_info := render_info_cv.get()) is not None:
            render_info.all_states_lifecycle = True

    def __iter__(self) -> Generator[TemplateState]:
        """Return all states."""
        self._collect_all()
        return _state_generator(self._hass, None)

    def __len__(self) -> int:
        """Return number of states."""
        self._collect_all_lifecycle()
        return self._hass.states.async_entity_ids_count()

    def __call__(
        self,
        entity_id: str,
        rounded: bool | object = _SENTINEL,
        with_unit: bool = False,
    ) -> str:
        """Return the states."""
        state = _get_state(self._hass, entity_id)
        if state is None:
            return STATE_UNKNOWN
        if rounded is _SENTINEL:
            rounded = with_unit
        if rounded or with_unit:
            return state.format_state(rounded, with_unit)  # type: ignore[arg-type]
        return state.state

    def __repr__(self) -> str:
        """Representation of All States."""
        return "<template AllStates>"


class StateTranslated:
    """Class to represent a translated state in a template."""

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize all states."""
        self._hass = hass

    def __call__(self, entity_id: str) -> str | None:
        """Retrieve translated state if available."""
        state = _get_state_if_valid(self._hass, entity_id)

        if state is None:
            return STATE_UNKNOWN

        state_value = state.state
        domain = state.domain
        device_class = state.attributes.get("device_class")
        entry = er.async_get(self._hass).async_get(entity_id)
        platform = None if entry is None else entry.platform
        translation_key = None if entry is None else entry.translation_key

        return async_translate_state(
            self._hass, state_value, domain, platform, translation_key, device_class
        )

    def __repr__(self) -> str:
        """Representation of Translated state."""
        return "<template StateTranslated>"


class DomainStates:
    """Class to expose a specific HA domain as attributes."""

    __slots__ = ("_domain", "_hass")

    __setitem__ = _readonly
    __delitem__ = _readonly

    def __init__(self, hass: HomeAssistant, domain: str) -> None:
        """Initialize the domain states."""
        self._hass = hass
        self._domain = domain

    def __getattr__(self, name: str) -> TemplateState | None:
        """Return the states."""
        return _get_state_if_valid(self._hass, f"{self._domain}.{name}")

    # Jinja will try __getitem__ first and it avoids the need
    # to call is_safe_attribute
    __getitem__ = __getattr__

    def _collect_domain(self) -> None:
        if (entity_collect := render_info_cv.get()) is not None:
            entity_collect.domains.add(self._domain)  # type: ignore[attr-defined]

    def _collect_domain_lifecycle(self) -> None:
        if (entity_collect := render_info_cv.get()) is not None:
            entity_collect.domains_lifecycle.add(self._domain)  # type: ignore[attr-defined]

    def __iter__(self) -> Generator[TemplateState]:
        """Return the iteration over all the states."""
        self._collect_domain()
        return _state_generator(self._hass, self._domain)

    def __len__(self) -> int:
        """Return number of states."""
        self._collect_domain_lifecycle()
        return self._hass.states.async_entity_ids_count(self._domain)

    def __repr__(self) -> str:
        """Representation of Domain States."""
        return f"<template DomainStates('{self._domain}')>"


class TemplateStateBase(State):
    """Class to represent a state object in a template."""

    __slots__ = ("_collect", "_entity_id", "_hass", "_state")

    _state: State

    __setitem__ = _readonly
    __delitem__ = _readonly

    # Inheritance is done so functions that check against State keep working
    # pylint: disable-next=super-init-not-called
    def __init__(self, hass: HomeAssistant, collect: bool, entity_id: str) -> None:
        """Initialize template state."""
        self._hass = hass
        self._collect = collect
        self._entity_id = entity_id
        self._cache: dict[str, Any] = {}

    def _collect_state(self) -> None:
        if self._collect and (render_info := render_info_cv.get()):
            render_info.entities.add(self._entity_id)  # type: ignore[attr-defined]

    # Jinja will try __getitem__ first and it avoids the need
    # to call is_safe_attribute
    def __getitem__(self, item: str) -> Any:
        """Return a property as an attribute for jinja."""
        if item in _COLLECTABLE_STATE_ATTRIBUTES:
            # _collect_state inlined here for performance
            if self._collect and (render_info := render_info_cv.get()):
                render_info.entities.add(self._entity_id)  # type: ignore[attr-defined]
            return getattr(self._state, item)
        if item == "entity_id":
            return self._entity_id
        if item == "state_with_unit":
            return self.state_with_unit
        raise KeyError

    @under_cached_property
    def entity_id(self) -> str:
        """Wrap State.entity_id.

        Intentionally does not collect state
        """
        return self._entity_id

    @property
    def state(self) -> str:  # type: ignore[override]
        """Wrap State.state."""
        self._collect_state()
        return self._state.state

    @property
    def attributes(self) -> ReadOnlyDict[str, Any]:  # type: ignore[override]
        """Wrap State.attributes."""
        self._collect_state()
        return self._state.attributes

    @property
    def last_changed(self) -> datetime:  # type: ignore[override]
        """Wrap State.last_changed."""
        self._collect_state()
        return self._state.last_changed

    @property
    def last_reported(self) -> datetime:  # type: ignore[override]
        """Wrap State.last_reported."""
        self._collect_state()
        return self._state.last_reported

    @property
    def last_updated(self) -> datetime:  # type: ignore[override]
        """Wrap State.last_updated."""
        self._collect_state()
        return self._state.last_updated

    @property
    def context(self) -> Context:  # type: ignore[override]
        """Wrap State.context."""
        self._collect_state()
        return self._state.context

    @property
    def domain(self) -> str:  # type: ignore[override]
        """Wrap State.domain."""
        self._collect_state()
        return self._state.domain

    @property
    def object_id(self) -> str:  # type: ignore[override]
        """Wrap State.object_id."""
        self._collect_state()
        return self._state.object_id

    @property
    def name(self) -> str:
        """Wrap State.name."""
        self._collect_state()
        return self._state.name

    @property
    def state_with_unit(self) -> str:
        """Return the state concatenated with the unit if available."""
        return self.format_state(rounded=True, with_unit=True)

    def format_state(self, rounded: bool, with_unit: bool) -> str:
        """Return a formatted version of the state."""
        # Import here, not at top-level, to avoid circular import
        from homeassistant.components.sensor import (  # noqa: PLC0415
            DOMAIN as SENSOR_DOMAIN,
            async_rounded_state,
        )

        self._collect_state()
        if rounded and self._state.domain == SENSOR_DOMAIN:
            state = async_rounded_state(self._hass, self._entity_id, self._state)
        else:
            state = self._state.state
        if with_unit and (unit := self._state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)):
            return f"{state} {unit}"
        return state

    def __eq__(self, other: object) -> bool:
        """Ensure we collect on equality check."""
        self._collect_state()
        return self._state.__eq__(other)


class TemplateState(TemplateStateBase):
    """Class to represent a state object in a template."""

    __slots__ = ()

    # Inheritance is done so functions that check against State keep working
    def __init__(self, hass: HomeAssistant, state: State, collect: bool = True) -> None:
        """Initialize template state."""
        super().__init__(hass, collect, state.entity_id)
        self._state = state

    def __repr__(self) -> str:
        """Representation of Template State."""
        return f"<template TemplateState({self._state!r})>"


class TemplateStateFromEntityId(TemplateStateBase):
    """Class to represent a state object in a template."""

    __slots__ = ()

    def __init__(
        self, hass: HomeAssistant, entity_id: str, collect: bool = True
    ) -> None:
        """Initialize template state."""
        super().__init__(hass, collect, entity_id)

    @property
    def _state(self) -> State:  # type: ignore[override]
        state = self._hass.states.get(self._entity_id)
        if not state:
            state = State(self._entity_id, STATE_UNKNOWN)
        return state

    def __repr__(self) -> str:
        """Representation of Template State."""
        return f"<template TemplateStateFromEntityId({self._entity_id})>"


_create_template_state_no_collect = partial(TemplateState, collect=False)


def _collect_state(hass: HomeAssistant, entity_id: str) -> None:
    if (entity_collect := render_info_cv.get()) is not None:
        entity_collect.entities.add(entity_id)  # type: ignore[attr-defined]


def _state_generator(
    hass: HomeAssistant, domain: str | None
) -> Generator[TemplateState]:
    """State generator for a domain or all states."""
    states = hass.states
    # If domain is None, we want to iterate over all states, but making
    # a copy of the dict is expensive. So we iterate over the protected
    # _states dict instead. This is safe because we're not modifying it
    # and everything is happening in the same thread (MainThread).
    #
    # We do not want to expose this method in the public API though to
    # ensure it does not get misused.
    #
    container: Iterable[State]
    if domain is None:
        container = states._states.values()  # noqa: SLF001
    else:
        container = states.async_all(domain)
    for state in container:
        yield _template_state_no_collect(hass, state)


def _get_state_if_valid(hass: HomeAssistant, entity_id: str) -> TemplateState | None:
    state = hass.states.get(entity_id)
    if state is None and not valid_entity_id(entity_id):
        raise TemplateError(f"Invalid entity ID '{entity_id}'")
    return _get_template_state_from_state(hass, entity_id, state)


def _get_state(hass: HomeAssistant, entity_id: str) -> TemplateState | None:
    return _get_template_state_from_state(hass, entity_id, hass.states.get(entity_id))


def _get_template_state_from_state(
    hass: HomeAssistant, entity_id: str, state: State | None
) -> TemplateState | None:
    if state is None:
        # Only need to collect if none, if not none collect first actual
        # access to the state properties in the state wrapper.
        _collect_state(hass, entity_id)
        return None
    return _template_state(hass, state)


def _resolve_state(
    hass: HomeAssistant, entity_id_or_state: Any
) -> State | TemplateState | None:
    """Return state or entity_id if given."""
    if isinstance(entity_id_or_state, State):
        return entity_id_or_state
    if isinstance(entity_id_or_state, str):
        return _get_state(hass, entity_id_or_state)
    return None


@overload
def forgiving_boolean(value: Any) -> bool | object: ...


@overload
def forgiving_boolean[_T](value: Any, default: _T) -> bool | _T: ...


def forgiving_boolean[_T](
    value: Any, default: _T | object = _SENTINEL
) -> bool | _T | object:
    """Try to convert value to a boolean."""
    try:
        # Import here, not at top-level to avoid circular import
        from homeassistant.helpers import config_validation as cv  # noqa: PLC0415

        return cv.boolean(value)
    except vol.Invalid:
        if default is _SENTINEL:
            raise_no_default("bool", value)
        return default


def result_as_boolean(template_result: Any | None) -> bool:
    """Convert the template result to a boolean.

    True/not 0/'1'/'true'/'yes'/'on'/'enable' are considered truthy
    False/0/None/'0'/'false'/'no'/'off'/'disable' are considered falsy
    All other values are falsy
    """
    if template_result is None:
        return False

    return forgiving_boolean(template_result, default=False)


def expand(hass: HomeAssistant, *args: Any) -> Iterable[State]:
    """Expand out any groups and zones into entity states."""
    # circular import.
    from homeassistant.helpers import entity as entity_helper  # noqa: PLC0415

    search = list(args)
    found = {}
    sources = entity_helper.entity_sources(hass)
    while search:
        entity = search.pop()
        if isinstance(entity, str):
            entity_id = entity
            if (entity := _get_state(hass, entity)) is None:
                continue
        elif isinstance(entity, State):
            entity_id = entity.entity_id
        elif isinstance(entity, collections.abc.Iterable):
            search += entity
            continue
        else:
            # ignore other types
            continue

        if entity_id in found:
            continue

        domain = entity.domain
        if domain == "group" or (
            (source := sources.get(entity_id)) and source["domain"] == "group"
        ):
            # Collect state will be called in here since it's wrapped
            if group_entities := entity.attributes.get(ATTR_ENTITY_ID):
                search += group_entities
        elif domain == "zone":
            if zone_entities := entity.attributes.get(ATTR_PERSONS):
                search += zone_entities
        else:
            _collect_state(hass, entity_id)
            found[entity_id] = entity

    return list(found.values())


def integration_entities(hass: HomeAssistant, entry_name: str) -> Iterable[str]:
    """Get entity ids for entities tied to an integration/domain.

    Provide entry_name as domain to get all entity id's for a integration/domain
    or provide a config entry title for filtering between instances of the same
    integration.
    """

    # Don't allow searching for config entries without title
    if not entry_name:
        return []

    # first try if there are any config entries with a matching title
    entities: list[str] = []
    ent_reg = er.async_get(hass)
    for entry in hass.config_entries.async_entries():
        if entry.title != entry_name:
            continue
        entries = er.async_entries_for_config_entry(ent_reg, entry.entry_id)
        entities.extend(entry.entity_id for entry in entries)
    if entities:
        return entities

    # fallback to just returning all entities for a domain
    from homeassistant.helpers.entity import entity_sources  # noqa: PLC0415

    return [
        entity_id
        for entity_id, info in entity_sources(hass).items()
        if info["domain"] == entry_name
    ]


def config_entry_id(hass: HomeAssistant, entity_id: str) -> str | None:
    """Get an config entry ID from an entity ID."""
    entity_reg = er.async_get(hass)
    if entity := entity_reg.async_get(entity_id):
        return entity.config_entry_id
    return None


def config_entry_attr(
    hass: HomeAssistant, config_entry_id_: str, attr_name: str
) -> Any:
    """Get config entry specific attribute."""
    if not isinstance(config_entry_id_, str):
        raise TemplateError("Must provide a config entry ID")

    if attr_name not in (
        "domain",
        "title",
        "state",
        "source",
        "disabled_by",
        "pref_disable_polling",
    ):
        raise TemplateError("Invalid config entry attribute")

    config_entry = hass.config_entries.async_get_entry(config_entry_id_)

    if config_entry is None:
        return None

    return getattr(config_entry, attr_name)


def closest(hass: HomeAssistant, *args: Any) -> State | None:
    """Find closest entity.

    Closest to home:
        closest(states)
        closest(states.device_tracker)
        closest('group.children')
        closest(states.group.children)

    Closest to a point:
        closest(23.456, 23.456, 'group.children')
        closest('zone.school', 'group.children')
        closest(states.zone.school, 'group.children')

    As a filter:
        states | closest
        states.device_tracker | closest
        ['group.children', states.device_tracker] | closest
        'group.children' | closest(23.456, 23.456)
        states.device_tracker | closest('zone.school')
        'group.children' | closest(states.zone.school)

    """
    if len(args) == 1:
        latitude = hass.config.latitude
        longitude = hass.config.longitude
        entities = args[0]

    elif len(args) == 2:
        point_state = _resolve_state(hass, args[0])

        if point_state is None:
            _LOGGER.warning("Closest:Unable to find state %s", args[0])
            return None
        if not loc_helper.has_location(point_state):
            _LOGGER.warning(
                "Closest:State does not contain valid location: %s", point_state
            )
            return None

        latitude = point_state.attributes[ATTR_LATITUDE]
        longitude = point_state.attributes[ATTR_LONGITUDE]

        entities = args[1]

    else:
        latitude_arg = convert(args[0], float)
        longitude_arg = convert(args[1], float)

        if latitude_arg is None or longitude_arg is None:
            _LOGGER.warning(
                "Closest:Received invalid coordinates: %s, %s", args[0], args[1]
            )
            return None

        latitude = latitude_arg
        longitude = longitude_arg

        entities = args[2]

    states = expand(hass, entities)

    # state will already be wrapped here
    return loc_helper.closest(latitude, longitude, states)


def closest_filter(hass: HomeAssistant, *args: Any) -> State | None:
    """Call closest as a filter. Need to reorder arguments."""
    new_args = list(args[1:])
    new_args.append(args[0])
    return closest(hass, *new_args)


def distance(hass: HomeAssistant, *args: Any) -> float | None:
    """Calculate distance.

    Will calculate distance from home to a point or between points.
    Points can be passed in using state objects or lat/lng coordinates.
    """
    locations: list[tuple[float, float]] = []

    to_process = list(args)

    while to_process:
        value = to_process.pop(0)
        if isinstance(value, str) and not valid_entity_id(value):
            point_state = None
        else:
            point_state = _resolve_state(hass, value)

        if point_state is None:
            # We expect this and next value to be lat&lng
            if not to_process:
                _LOGGER.warning(
                    "Distance:Expected latitude and longitude, got %s", value
                )
                return None

            value_2 = to_process.pop(0)
            latitude_to_process = convert(value, float)
            longitude_to_process = convert(value_2, float)

            if latitude_to_process is None or longitude_to_process is None:
                _LOGGER.warning(
                    "Distance:Unable to process latitude and longitude: %s, %s",
                    value,
                    value_2,
                )
                return None

            latitude = latitude_to_process
            longitude = longitude_to_process

        else:
            if not loc_helper.has_location(point_state):
                _LOGGER.warning(
                    "Distance:State does not contain valid location: %s", point_state
                )
                return None

            latitude = point_state.attributes[ATTR_LATITUDE]
            longitude = point_state.attributes[ATTR_LONGITUDE]

        locations.append((latitude, longitude))

    if len(locations) == 1:
        return hass.config.distance(*locations[0])

    return hass.config.units.length(
        location_util.distance(*locations[0] + locations[1]), UnitOfLength.METERS
    )


def is_hidden_entity(hass: HomeAssistant, entity_id: str) -> bool:
    """Test if an entity is hidden."""
    entity_reg = er.async_get(hass)
    entry = entity_reg.async_get(entity_id)
    return entry is not None and entry.hidden


def is_state(hass: HomeAssistant, entity_id: str, state: str | list[str]) -> bool:
    """Test if a state is a specific value."""
    state_obj = _get_state(hass, entity_id)
    return state_obj is not None and (
        state_obj.state == state
        or (isinstance(state, list) and state_obj.state in state)
    )


def is_state_attr(hass: HomeAssistant, entity_id: str, name: str, value: Any) -> bool:
    """Test if a state's attribute is a specific value."""
    if (state_obj := _get_state(hass, entity_id)) is not None:
        attr = state_obj.attributes.get(name, _SENTINEL)
        if attr is _SENTINEL:
            return False
        return bool(attr == value)
    return False


def state_attr(hass: HomeAssistant, entity_id: str, name: str) -> Any:
    """Get a specific attribute from a state."""
    if (state_obj := _get_state(hass, entity_id)) is not None:
        return state_obj.attributes.get(name)
    return None


def has_value(hass: HomeAssistant, entity_id: str) -> bool:
    """Test if an entity has a valid value."""
    state_obj = _get_state(hass, entity_id)

    return state_obj is not None and (
        state_obj.state not in [STATE_UNAVAILABLE, STATE_UNKNOWN]
    )


def forgiving_round(value, precision=0, method="common", default=_SENTINEL):
    """Filter to round a value."""
    try:
        # support rounding methods like jinja
        multiplier = float(10**precision)
        if method == "ceil":
            value = math.ceil(float(value) * multiplier) / multiplier
        elif method == "floor":
            value = math.floor(float(value) * multiplier) / multiplier
        elif method == "half":
            value = round(float(value) * 2) / 2
        else:
            # if method is common or something else, use common rounding
            value = round(float(value), precision)
        return int(value) if precision == 0 else value
    except (ValueError, TypeError):
        # If value can't be converted to float
        if default is _SENTINEL:
            raise_no_default("round", value)
        return default


def multiply(value, amount, default=_SENTINEL):
    """Filter to convert value to float and multiply it."""
    try:
        return float(value) * amount
    except (ValueError, TypeError):
        # If value can't be converted to float
        if default is _SENTINEL:
            raise_no_default("multiply", value)
        return default


def add(value, amount, default=_SENTINEL):
    """Filter to convert value to float and add it."""
    try:
        return float(value) + amount
    except (ValueError, TypeError):
        # If value can't be converted to float
        if default is _SENTINEL:
            raise_no_default("add", value)
        return default


def apply(value, fn, *args, **kwargs):
    """Call the given callable with the provided arguments and keyword arguments."""
    return fn(value, *args, **kwargs)


def as_function(macro: jinja2.runtime.Macro) -> Callable[..., Any]:
    """Turn a macro with a 'returns' keyword argument into a function that returns what that argument is called with."""

    def wrapper(*args, **kwargs):
        return_value = None

        def returns(value):
            nonlocal return_value
            return_value = value
            return value

        # Call the callable with the value and other args
        macro(*args, **kwargs, returns=returns)
        return return_value

    # Remove "macro_" from the macro's name to avoid confusion in the wrapper's name
    trimmed_name = macro.name.removeprefix("macro_")

    wrapper.__name__ = trimmed_name
    wrapper.__qualname__ = trimmed_name
    return wrapper


def version(value):
    """Filter and function to get version object of the value."""
    return AwesomeVersion(value)


def merge_response(value: ServiceResponse) -> list[Any]:
    """Merge action responses into single list.

    Checks that the input is a correct service response:
    {
        "entity_id": {str: dict[str, Any]},
    }
    If response is a single list, it will extend the list with the items
        and add the entity_id and value_key to each dictionary for reference.
    If response is a dictionary or multiple lists,
        it will append the dictionary/lists to the list
        and add the entity_id to each dictionary for reference.
    """
    if not isinstance(value, dict):
        raise TypeError("Response is not a dictionary")
    if not value:
        # Bail out early if response is an empty dictionary
        return []

    is_single_list = False
    response_items: list = []
    input_service_response = deepcopy(value)
    for entity_id, entity_response in input_service_response.items():  # pylint: disable=too-many-nested-blocks
        if not isinstance(entity_response, dict):
            raise TypeError("Response is not a dictionary")
        for value_key, type_response in entity_response.items():
            if len(entity_response) == 1 and isinstance(type_response, list):
                # Provides special handling for responses such as calendar events
                # and weather forecasts where the response contains a single list with multiple
                # dictionaries inside.
                is_single_list = True
                for dict_in_list in type_response:
                    if isinstance(dict_in_list, dict):
                        if ATTR_ENTITY_ID in dict_in_list:
                            raise ValueError(
                                f"Response dictionary already contains key '{ATTR_ENTITY_ID}'"
                            )
                        dict_in_list[ATTR_ENTITY_ID] = entity_id
                        dict_in_list["value_key"] = value_key
                response_items.extend(type_response)
            else:
                # Break the loop if not a single list as the logic is then managed in the outer loop
                # which handles both dictionaries and in the case of multiple lists.
                break

        if not is_single_list:
            _response = entity_response.copy()
            if ATTR_ENTITY_ID in _response:
                raise ValueError(
                    f"Response dictionary already contains key '{ATTR_ENTITY_ID}'"
                )
            _response[ATTR_ENTITY_ID] = entity_id
            response_items.append(_response)

    return response_items


def fail_when_undefined(value):
    """Filter to force a failure when the value is undefined."""
    if isinstance(value, jinja2.Undefined):
        value()
    return value


def forgiving_float(value, default=_SENTINEL):
    """Try to convert value to a float."""
    try:
        return float(value)
    except (ValueError, TypeError):
        if default is _SENTINEL:
            raise_no_default("float", value)
        return default


def forgiving_float_filter(value, default=_SENTINEL):
    """Try to convert value to a float."""
    try:
        return float(value)
    except (ValueError, TypeError):
        if default is _SENTINEL:
            raise_no_default("float", value)
        return default


def forgiving_int(value, default=_SENTINEL, base=10):
    """Try to convert value to an int, and raise if it fails."""
    result = jinja2.filters.do_int(value, default=default, base=base)
    if result is _SENTINEL:
        raise_no_default("int", value)
    return result


def forgiving_int_filter(value, default=_SENTINEL, base=10):
    """Try to convert value to an int, and raise if it fails."""
    result = jinja2.filters.do_int(value, default=default, base=base)
    if result is _SENTINEL:
        raise_no_default("int", value)
    return result


def is_number(value):
    """Try to convert value to a float."""
    try:
        fvalue = float(value)
    except (ValueError, TypeError):
        return False
    if not math.isfinite(fvalue):
        return False
    return True


def _is_string_like(value: Any) -> bool:
    """Return whether a value is a string or string like object."""
    return isinstance(value, (str, bytes, bytearray))


def struct_pack(value: Any | None, format_string: str) -> bytes | None:
    """Pack an object into a bytes object."""
    try:
        return pack(format_string, value)
    except StructError:
        _LOGGER.warning(
            (
                "Template warning: 'pack' unable to pack object '%s' with type '%s' and"
                " format_string '%s' see https://docs.python.org/3/library/struct.html"
                " for more information"
            ),
            str(value),
            type(value).__name__,
            format_string,
        )
        return None


def struct_unpack(value: bytes, format_string: str, offset: int = 0) -> Any | None:
    """Unpack an object from bytes an return the first native object."""
    try:
        return unpack_from(format_string, value, offset)[0]
    except StructError:
        _LOGGER.warning(
            (
                "Template warning: 'unpack' unable to unpack object '%s' with"
                " format_string '%s' and offset %s see"
                " https://docs.python.org/3/library/struct.html for more information"
            ),
            value,
            format_string,
            offset,
        )
        return None


def from_hex(value: str) -> bytes:
    """Perform hex string decode."""
    return bytes.fromhex(value)


def from_json(value, default=_SENTINEL):
    """Convert a JSON string to an object."""
    try:
        return json_loads(value)
    except JSON_DECODE_EXCEPTIONS:
        if default is _SENTINEL:
            raise_no_default("from_json", value)
        return default


def _to_json_default(obj: Any) -> None:
    """Disable custom types in json serialization."""
    raise TypeError(f"Object of type {type(obj).__name__} is not JSON serializable")


def to_json(
    value: Any,
    ensure_ascii: bool = False,
    pretty_print: bool = False,
    sort_keys: bool = False,
) -> str:
    """Convert an object to a JSON string."""
    if ensure_ascii:
        # For those who need ascii, we can't use orjson, so we fall back to the json library.
        return json.dumps(
            value,
            ensure_ascii=ensure_ascii,
            indent=2 if pretty_print else None,
            sort_keys=sort_keys,
        )

    option = (
        ORJSON_PASSTHROUGH_OPTIONS
        # OPT_NON_STR_KEYS is added as a workaround to
        # ensure subclasses of str are allowed as dict keys
        # See: https://github.com/ijl/orjson/issues/445
        | orjson.OPT_NON_STR_KEYS
        | (orjson.OPT_INDENT_2 if pretty_print else 0)
        | (orjson.OPT_SORT_KEYS if sort_keys else 0)
    )

    return orjson.dumps(
        value,
        option=option,
        default=_to_json_default,
    ).decode("utf-8")


@pass_context
def random_every_time(context, values):
    """Choose a random value.

    Unlike Jinja's random filter,
    this is context-dependent to avoid caching the chosen value.
    """
    return random.choice(values)


def iif(
    value: Any, if_true: Any = True, if_false: Any = False, if_none: Any = _SENTINEL
) -> Any:
    """Immediate if function/filter that allow for common if/else constructs.

    https://en.wikipedia.org/wiki/IIf

    Examples:
        {{ is_state("device_tracker.frenck", "home") | iif("yes", "no") }}
        {{ iif(1==2, "yes", "no") }}
        {{ (1 == 1) | iif("yes", "no") }}

    """
    if value is None and if_none is not _SENTINEL:
        return if_none
    if bool(value):
        return if_true
    return if_false


def typeof(value: Any) -> Any:
    """Return the type of value passed to debug types."""
    return value.__class__.__name__


def combine(*args: Any, recursive: bool = False) -> dict[Any, Any]:
    """Combine multiple dictionaries into one."""
    if not args:
        raise TypeError("combine expected at least 1 argument, got 0")

    result: dict[Any, Any] = {}
    for arg in args:
        if not isinstance(arg, dict):
            raise TypeError(f"combine expected a dict, got {type(arg).__name__}")

        if recursive:
            for key, value in arg.items():
                if (
                    key in result
                    and isinstance(result[key], dict)
                    and isinstance(value, dict)
                ):
                    result[key] = combine(result[key], value, recursive=True)
                else:
                    result[key] = value
        else:
            result |= arg

    return result


def make_logging_undefined(
    strict: bool | None, log_fn: Callable[[int, str], None] | None
) -> type[jinja2.Undefined]:
    """Log on undefined variables."""

    if strict:
        return jinja2.StrictUndefined

    def _log_with_logger(level: int, msg: str) -> None:
        template, action = template_cv.get() or ("", "rendering or compiling")
        _LOGGER.log(
            level,
            "Template variable %s: %s when %s '%s'",
            logging.getLevelName(level).lower(),
            msg,
            action,
            template,
        )

    _log_fn = log_fn or _log_with_logger

    class LoggingUndefined(jinja2.Undefined):
        """Log on undefined variables."""

        def _log_message(self) -> None:
            _log_fn(logging.WARNING, self._undefined_message)

        def _fail_with_undefined_error(self, *args, **kwargs):
            try:
                return super()._fail_with_undefined_error(*args, **kwargs)
            except self._undefined_exception:
                _log_fn(logging.ERROR, self._undefined_message)
                raise

        def __str__(self) -> str:
            """Log undefined __str___."""
            self._log_message()
            return super().__str__()

        def __iter__(self):
            """Log undefined __iter___."""
            self._log_message()
            return super().__iter__()

        def __bool__(self) -> bool:
            """Log undefined __bool___."""
            self._log_message()
            return super().__bool__()

    return LoggingUndefined


async def async_load_custom_templates(hass: HomeAssistant) -> None:
    """Load all custom jinja files under 5MiB into memory."""
    custom_templates = await hass.async_add_executor_job(_load_custom_templates, hass)
    _get_hass_loader(hass).sources = custom_templates


def _load_custom_templates(hass: HomeAssistant) -> dict[str, str]:
    result = {}
    jinja_path = hass.config.path("custom_templates")
    all_files = [
        item
        for item in pathlib.Path(jinja_path).rglob("*.jinja")
        if item.is_file() and item.stat().st_size <= MAX_CUSTOM_TEMPLATE_SIZE
    ]
    for file in all_files:
        content = file.read_text()
        path = str(file.relative_to(jinja_path))
        result[path] = content
    return result


@singleton(_HASS_LOADER)
def _get_hass_loader(hass: HomeAssistant) -> HassLoader:
    return HassLoader({})


class HassLoader(jinja2.BaseLoader):
    """An in-memory jinja loader that keeps track of templates that need to be reloaded."""

    def __init__(self, sources: dict[str, str]) -> None:
        """Initialize an empty HassLoader."""
        self._sources = sources
        self._reload = 0

    @property
    def sources(self) -> dict[str, str]:
        """Map filename to jinja source."""
        return self._sources

    @sources.setter
    def sources(self, value: dict[str, str]) -> None:
        self._sources = value
        self._reload += 1

    def get_source(
        self, environment: jinja2.Environment, template: str
    ) -> tuple[str, str | None, Callable[[], bool] | None]:
        """Get in-memory sources."""
        if template not in self._sources:
            raise jinja2.TemplateNotFound(template)
        cur_reload = self._reload
        return self._sources[template], template, lambda: cur_reload == self._reload


class TemplateEnvironment(ImmutableSandboxedEnvironment):
    """The Home Assistant template environment."""

    def __init__(
        self,
        hass: HomeAssistant | None,
        limited: bool | None = False,
        strict: bool | None = False,
        log_fn: Callable[[int, str], None] | None = None,
    ) -> None:
        """Initialise template environment."""
        super().__init__(undefined=make_logging_undefined(strict, log_fn))
        self.hass = hass
        self.limited = limited
        self.template_cache: weakref.WeakValueDictionary[
            str | jinja2.nodes.Template, CodeType | None
        ] = weakref.WeakValueDictionary()
        self.add_extension("jinja2.ext.loopcontrols")
        self.add_extension("jinja2.ext.do")
        self.add_extension("homeassistant.helpers.template.extensions.AreaExtension")
        self.add_extension("homeassistant.helpers.template.extensions.Base64Extension")
        self.add_extension(
            "homeassistant.helpers.template.extensions.CollectionExtension"
        )
        self.add_extension("homeassistant.helpers.template.extensions.CryptoExtension")
        self.add_extension(
            "homeassistant.helpers.template.extensions.DateTimeExtension"
        )
        self.add_extension("homeassistant.helpers.template.extensions.DeviceExtension")
        self.add_extension("homeassistant.helpers.template.extensions.FloorExtension")
        self.add_extension("homeassistant.helpers.template.extensions.IssuesExtension")
        self.add_extension("homeassistant.helpers.template.extensions.LabelExtension")
        self.add_extension("homeassistant.helpers.template.extensions.MathExtension")
        self.add_extension("homeassistant.helpers.template.extensions.RegexExtension")
        self.add_extension("homeassistant.helpers.template.extensions.StringExtension")

        self.globals["apply"] = apply
        self.globals["as_function"] = as_function
        self.globals["bool"] = forgiving_boolean
        self.globals["combine"] = combine
        self.globals["float"] = forgiving_float
        self.globals["iif"] = iif
        self.globals["int"] = forgiving_int
        self.globals["is_number"] = is_number
        self.globals["merge_response"] = merge_response
        self.globals["pack"] = struct_pack
        self.globals["typeof"] = typeof
        self.globals["unpack"] = struct_unpack
        self.globals["version"] = version
        self.globals["zip"] = zip

        self.filters["add"] = add
        self.filters["apply"] = apply
        self.filters["as_function"] = as_function
        self.filters["bool"] = forgiving_boolean
        self.filters["combine"] = combine
        self.filters["contains"] = contains
        self.filters["float"] = forgiving_float_filter
        self.filters["from_json"] = from_json
        self.filters["from_hex"] = from_hex
        self.filters["iif"] = iif
        self.filters["int"] = forgiving_int_filter
        self.filters["is_defined"] = fail_when_undefined
        self.filters["is_number"] = is_number
        self.filters["multiply"] = multiply
        self.filters["ord"] = ord
        self.filters["pack"] = struct_pack
        self.filters["random"] = random_every_time
        self.filters["round"] = forgiving_round
        self.filters["to_json"] = to_json
        self.filters["typeof"] = typeof
        self.filters["unpack"] = struct_unpack
        self.filters["version"] = version

        self.tests["apply"] = apply
        self.tests["contains"] = contains
        self.tests["is_number"] = is_number
        self.tests["string_like"] = _is_string_like

        if hass is None:
            return

        # This environment has access to hass, attach its loader to enable imports.
        self.loader = _get_hass_loader(hass)

        # We mark these as a context functions to ensure they get
        # evaluated fresh with every execution, rather than executed
        # at compile time and the value stored. The context itself
        # can be discarded, we only need to get at the hass object.
        def hassfunction[**_P, _R](
            func: Callable[Concatenate[HomeAssistant, _P], _R],
            jinja_context: Callable[
                [Callable[Concatenate[Any, _P], _R]],
                Callable[Concatenate[Any, _P], _R],
            ] = pass_context,
        ) -> Callable[Concatenate[Any, _P], _R]:
            """Wrap function that depend on hass."""

            @wraps(func)
            def wrapper(_: Any, *args: _P.args, **kwargs: _P.kwargs) -> _R:
                return func(hass, *args, **kwargs)

            return jinja_context(wrapper)

        # Integration extensions

        self.globals["integration_entities"] = hassfunction(integration_entities)
        self.filters["integration_entities"] = self.globals["integration_entities"]

        # Config entry extensions

        self.globals["config_entry_attr"] = hassfunction(config_entry_attr)
        self.filters["config_entry_attr"] = self.globals["config_entry_attr"]

        self.globals["config_entry_id"] = hassfunction(config_entry_id)
        self.filters["config_entry_id"] = self.globals["config_entry_id"]

        if limited:
            # Only device_entities is available to limited templates, mark other
            # functions and filters as unsupported.
            def unsupported(name: str) -> Callable[[], NoReturn]:
                def warn_unsupported(*args: Any, **kwargs: Any) -> NoReturn:
                    raise TemplateError(
                        f"Use of '{name}' is not supported in limited templates"
                    )

                return warn_unsupported

            hass_globals = [
                "area_id",
                "area_name",
                "closest",
                "distance",
                "expand",
                "has_value",
                "is_hidden_entity",
                "is_state_attr",
                "is_state",
                "state_attr",
                "state_translated",
                "states",
            ]
            hass_filters = [
                "area_id",
                "area_name",
                "closest",
                "expand",
                "has_value",
            ]
            hass_tests = [
                "has_value",
                "is_hidden_entity",
                "is_state_attr",
                "is_state",
            ]
            for glob in hass_globals:
                self.globals[glob] = unsupported(glob)
            for filt in hass_filters:
                self.filters[filt] = unsupported(filt)
            for test in hass_tests:
                self.filters[test] = unsupported(test)
            return

        self.globals["closest"] = hassfunction(closest)
        self.globals["distance"] = hassfunction(distance)
        self.globals["expand"] = hassfunction(expand)
        self.globals["has_value"] = hassfunction(has_value)

        self.filters["closest"] = hassfunction(closest_filter)
        self.filters["expand"] = self.globals["expand"]
        self.filters["has_value"] = self.globals["has_value"]

        self.tests["has_value"] = hassfunction(has_value, pass_eval_context)

        # Entity extensions

        self.globals["is_hidden_entity"] = hassfunction(is_hidden_entity)
        self.tests["is_hidden_entity"] = hassfunction(
            is_hidden_entity, pass_eval_context
        )

        # State extensions

        self.globals["is_state_attr"] = hassfunction(is_state_attr)
        self.globals["is_state"] = hassfunction(is_state)
        self.globals["state_attr"] = hassfunction(state_attr)
        self.globals["state_translated"] = StateTranslated(hass)
        self.globals["states"] = AllStates(hass)
        self.filters["state_attr"] = self.globals["state_attr"]
        self.filters["state_translated"] = self.globals["state_translated"]
        self.filters["states"] = self.globals["states"]
        self.tests["is_state_attr"] = hassfunction(is_state_attr, pass_eval_context)
        self.tests["is_state"] = hassfunction(is_state, pass_eval_context)

    def is_safe_callable(self, obj):
        """Test if callback is safe."""
        return isinstance(
            obj, (AllStates, StateTranslated)
        ) or super().is_safe_callable(obj)

    def is_safe_attribute(self, obj, attr, value):
        """Test if attribute is safe."""
        if isinstance(
            obj, (AllStates, DomainStates, TemplateState, LoopContext, AsyncLoopContext)
        ):
            return attr[0] != "_"

        if isinstance(obj, Namespace):
            return True

        return super().is_safe_attribute(obj, attr, value)

    @overload
    def compile(
        self,
        source: str | jinja2.nodes.Template,
        name: str | None = None,
        filename: str | None = None,
        raw: Literal[False] = False,
        defer_init: bool = False,
    ) -> CodeType: ...

    @overload
    def compile(
        self,
        source: str | jinja2.nodes.Template,
        name: str | None = None,
        filename: str | None = None,
        raw: Literal[True] = ...,
        defer_init: bool = False,
    ) -> str: ...

    def compile(
        self,
        source: str | jinja2.nodes.Template,
        name: str | None = None,
        filename: str | None = None,
        raw: bool = False,
        defer_init: bool = False,
    ) -> CodeType | str:
        """Compile the template."""
        if (
            name is not None
            or filename is not None
            or raw is not False
            or defer_init is not False
        ):
            # If there are any non-default keywords args, we do
            # not cache.  In prodution we currently do not have
            # any instance of this.
            return super().compile(  # type: ignore[no-any-return,call-overload]
                source,
                name,
                filename,
                raw,
                defer_init,
            )

        compiled = super().compile(source)
        self.template_cache[source] = compiled
        return compiled


_NO_HASS_ENV = TemplateEnvironment(None)
</file>

<file path="template/context.py">
"""Template context management for Home Assistant."""

from __future__ import annotations

from contextlib import AbstractContextManager
from contextvars import ContextVar
from types import TracebackType
from typing import Any

import jinja2

# Context variable for template string tracking
template_cv: ContextVar[tuple[str, str] | None] = ContextVar(
    "template_cv", default=None
)


class TemplateContextManager(AbstractContextManager):
    """Context manager to store template being parsed or rendered in a ContextVar."""

    def set_template(self, template_str: str, action: str) -> None:
        """Store template being parsed or rendered in a Contextvar to aid error handling."""
        template_cv.set((template_str, action))

    def __exit__(
        self,
        exc_type: type[BaseException] | None,
        exc_value: BaseException | None,
        traceback: TracebackType | None,
    ) -> None:
        """Raise any exception triggered within the runtime context."""
        template_cv.set(None)


# Global context manager instance
template_context_manager = TemplateContextManager()


def render_with_context(
    template_str: str, template: jinja2.Template, **kwargs: Any
) -> str:
    """Store template being rendered in a ContextVar to aid error handling."""
    with template_context_manager as cm:
        cm.set_template(template_str, "rendering")
        return template.render(**kwargs)
</file>

<file path="template/helpers.py">
"""Template helper functions for Home Assistant."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any, NoReturn

import voluptuous as vol

from homeassistant.helpers import (
    area_registry as ar,
    device_registry as dr,
    entity_registry as er,
)

from .context import template_cv

if TYPE_CHECKING:
    from homeassistant.core import HomeAssistant


def raise_no_default(function: str, value: Any) -> NoReturn:
    """Raise ValueError when no default is specified for template functions."""
    template, action = template_cv.get() or ("", "rendering or compiling")
    raise ValueError(
        f"Template error: {function} got invalid input '{value}' when {action} template"
        f" '{template}' but no default was specified"
    )


def resolve_area_id(hass: HomeAssistant, lookup_value: Any) -> str | None:
    """Resolve lookup value to an area ID.

    Accepts area name, area alias, device ID, or entity ID.
    Returns the area ID or None if not found.
    """
    area_reg = ar.async_get(hass)
    dev_reg = dr.async_get(hass)
    ent_reg = er.async_get(hass)
    lookup_str = str(lookup_value)

    # Check if it's an area name
    if area := area_reg.async_get_area_by_name(lookup_str):
        return area.id

    # Check if it's an area alias
    areas_list = area_reg.async_get_areas_by_alias(lookup_str)
    if areas_list:
        return areas_list[0].id

    # Import here, not at top-level to avoid circular import
    from homeassistant.helpers import config_validation as cv  # noqa: PLC0415

    # Check if it's an entity ID
    try:
        cv.entity_id(lookup_value)
    except vol.Invalid:
        pass
    else:
        if entity := ent_reg.async_get(lookup_value):
            # If entity has an area ID, return that
            if entity.area_id:
                return entity.area_id
            # If entity has a device ID, return the area ID for the device
            if entity.device_id and (device := dev_reg.async_get(entity.device_id)):
                return device.area_id

    # Check if it's a device ID
    if device := dev_reg.async_get(lookup_value):
        return device.area_id

    return None
</file>

<file path="template/render_info.py">
"""Template render information tracking for Home Assistant."""

from __future__ import annotations

import collections.abc
from collections.abc import Callable
from contextvars import ContextVar
from typing import TYPE_CHECKING, cast

from homeassistant.core import split_entity_id

if TYPE_CHECKING:
    from homeassistant.exceptions import TemplateError

    from . import Template

# Rate limiting constants
ALL_STATES_RATE_LIMIT = 60  # seconds
DOMAIN_STATES_RATE_LIMIT = 1  # seconds

# Context variable for render information tracking
render_info_cv: ContextVar[RenderInfo | None] = ContextVar(
    "render_info_cv", default=None
)


# Filter functions for efficiency
def _true(entity_id: str) -> bool:
    """Return True for all entity IDs."""
    return True


def _false(entity_id: str) -> bool:
    """Return False for all entity IDs."""
    return False


class RenderInfo:
    """Holds information about a template render."""

    __slots__ = (
        "_result",
        "all_states",
        "all_states_lifecycle",
        "domains",
        "domains_lifecycle",
        "entities",
        "exception",
        "filter",
        "filter_lifecycle",
        "has_time",
        "is_static",
        "rate_limit",
        "template",
    )

    def __init__(self, template: Template) -> None:
        """Initialise."""
        self.template = template
        # Will be set sensibly once frozen.
        self.filter_lifecycle: Callable[[str], bool] = _true
        self.filter: Callable[[str], bool] = _true
        self._result: str | None = None
        self.is_static = False
        self.exception: TemplateError | None = None
        self.all_states = False
        self.all_states_lifecycle = False
        self.domains: collections.abc.Set[str] = set()
        self.domains_lifecycle: collections.abc.Set[str] = set()
        self.entities: collections.abc.Set[str] = set()
        self.rate_limit: float | None = None
        self.has_time = False

    def __repr__(self) -> str:
        """Representation of RenderInfo."""
        return (
            f"<RenderInfo {self.template}"
            f" all_states={self.all_states}"
            f" all_states_lifecycle={self.all_states_lifecycle}"
            f" domains={self.domains}"
            f" domains_lifecycle={self.domains_lifecycle}"
            f" entities={self.entities}"
            f" rate_limit={self.rate_limit}"
            f" has_time={self.has_time}"
            f" exception={self.exception}"
            f" is_static={self.is_static}"
            ">"
        )

    def _filter_domains_and_entities(self, entity_id: str) -> bool:
        """Template should re-render if the entity state changes.

        Only when we match specific domains or entities.
        """
        return (
            split_entity_id(entity_id)[0] in self.domains or entity_id in self.entities
        )

    def _filter_entities(self, entity_id: str) -> bool:
        """Template should re-render if the entity state changes.

        Only when we match specific entities.
        """
        return entity_id in self.entities

    def _filter_lifecycle_domains(self, entity_id: str) -> bool:
        """Template should re-render if the entity is added or removed.

        Only with domains watched.
        """
        return split_entity_id(entity_id)[0] in self.domains_lifecycle

    def result(self) -> str:
        """Results of the template computation."""
        if self.exception is not None:
            raise self.exception
        return cast(str, self._result)

    def _freeze_static(self) -> None:
        self.is_static = True
        self._freeze_sets()
        self.all_states = False

    def _freeze_sets(self) -> None:
        self.entities = frozenset(self.entities)
        self.domains = frozenset(self.domains)
        self.domains_lifecycle = frozenset(self.domains_lifecycle)

    def _freeze(self) -> None:
        self._freeze_sets()

        if self.rate_limit is None:
            if self.all_states or self.exception:
                self.rate_limit = ALL_STATES_RATE_LIMIT
            elif self.domains or self.domains_lifecycle:
                self.rate_limit = DOMAIN_STATES_RATE_LIMIT

        if self.exception:
            return

        if not self.all_states_lifecycle:
            if self.domains_lifecycle:
                self.filter_lifecycle = self._filter_lifecycle_domains
            else:
                self.filter_lifecycle = _false

        if self.all_states:
            return

        if self.domains:
            self.filter = self._filter_domains_and_entities
        elif self.entities:
            self.filter = self._filter_entities
        else:
            self.filter = _false
</file>

<file path="__init__.py">
"""Helper methods for components within Home Assistant."""
</file>

<file path="aiohttp_client.py">
"""Helper for aiohttp webclient stuff."""

from __future__ import annotations

import asyncio
from collections.abc import Awaitable, Callable
from contextlib import suppress
import socket
from ssl import SSLContext
import sys
from types import MappingProxyType
from typing import TYPE_CHECKING, Any, Self

import aiohttp
from aiohttp import web
from aiohttp.hdrs import CONTENT_TYPE, USER_AGENT
from aiohttp.web_exceptions import HTTPBadGateway, HTTPGatewayTimeout
from aiohttp_asyncmdnsresolver.api import AsyncDualMDNSResolver

from homeassistant import config_entries
from homeassistant.components import zeroconf
from homeassistant.const import APPLICATION_NAME, EVENT_HOMEASSISTANT_CLOSE, __version__
from homeassistant.core import Event, HomeAssistant, callback
from homeassistant.loader import bind_hass
from homeassistant.util import ssl as ssl_util
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.json import json_loads

from .frame import warn_use
from .json import json_dumps
from .singleton import singleton

if TYPE_CHECKING:
    from aiohttp.typedefs import JSONDecoder


DATA_CONNECTOR: HassKey[dict[tuple[bool, int, str], aiohttp.BaseConnector]] = HassKey(
    "aiohttp_connector"
)
DATA_CLIENTSESSION: HassKey[dict[tuple[bool, int, str], aiohttp.ClientSession]] = (
    HassKey("aiohttp_clientsession")
)
DATA_RESOLVER: HassKey[HassAsyncDNSResolver] = HassKey("aiohttp_resolver")

SERVER_SOFTWARE = (
    f"{APPLICATION_NAME}/{__version__} "
    f"aiohttp/{aiohttp.__version__} Python/{sys.version_info[0]}.{sys.version_info[1]}"
)

WARN_CLOSE_MSG = "closes the Home Assistant aiohttp session"

#
# The default connection limit of 100 meant that you could only have
# 100 concurrent connections.
#
# This was effectively a limit of 100 devices and than
# the supervisor API would fail as soon as it was hit.
#
# We now apply the 100 limit per host, so that we can have 100 connections
# to a single host, but can have more than 4096 connections in total to
# prevent a single host from using all available connections.
#
MAXIMUM_CONNECTIONS = 4096
MAXIMUM_CONNECTIONS_PER_HOST = 100


class HassAsyncDNSResolver(AsyncDualMDNSResolver):
    """Home Assistant AsyncDNSResolver.

    This is a wrapper around the AsyncDualMDNSResolver to only
    close the resolver when the Home Assistant instance is closed.
    """

    async def real_close(self) -> None:
        """Close the resolver."""
        await super().close()

    async def close(self) -> None:
        """Close the resolver."""


class HassClientResponse(aiohttp.ClientResponse):
    """aiohttp.ClientResponse with a json method that uses json_loads by default."""

    async def json(
        self,
        *args: Any,
        loads: JSONDecoder = json_loads,
        **kwargs: Any,
    ) -> Any:
        """Send a json request and parse the json response."""
        return await super().json(*args, loads=loads, **kwargs)


class ChunkAsyncStreamIterator:
    """Async iterator for chunked streams.

    Based on aiohttp.streams.ChunkTupleAsyncStreamIterator, but yields
    bytes instead of tuple[bytes, bool].
    """

    __slots__ = ("_stream",)

    def __init__(self, stream: aiohttp.StreamReader) -> None:
        """Initialize."""
        self._stream = stream

    def __aiter__(self) -> Self:
        """Iterate."""
        return self

    async def __anext__(self) -> bytes:
        """Yield next chunk."""
        rv = await self._stream.readchunk()
        if rv == (b"", False):
            raise StopAsyncIteration
        return rv[0]


@callback
@bind_hass
def async_get_clientsession(
    hass: HomeAssistant,
    verify_ssl: bool = True,
    family: socket.AddressFamily = socket.AF_UNSPEC,
    ssl_cipher: ssl_util.SSLCipherList = ssl_util.SSLCipherList.PYTHON_DEFAULT,
) -> aiohttp.ClientSession:
    """Return default aiohttp ClientSession.

    This method must be run in the event loop.
    """
    session_key = _make_key(verify_ssl, family, ssl_cipher)
    sessions = hass.data.setdefault(DATA_CLIENTSESSION, {})

    if session_key not in sessions:
        session = _async_create_clientsession(
            hass,
            verify_ssl,
            auto_cleanup_method=_async_register_default_clientsession_shutdown,
            family=family,
            ssl_cipher=ssl_cipher,
        )
        sessions[session_key] = session
    else:
        session = sessions[session_key]

    return session


@callback
@bind_hass
def async_create_clientsession(
    hass: HomeAssistant,
    verify_ssl: bool = True,
    auto_cleanup: bool = True,
    family: socket.AddressFamily = socket.AF_UNSPEC,
    ssl_cipher: ssl_util.SSLCipherList = ssl_util.SSLCipherList.PYTHON_DEFAULT,
    **kwargs: Any,
) -> aiohttp.ClientSession:
    """Create a new ClientSession with kwargs, i.e. for cookies.

    If auto_cleanup is False, you need to call detach() after the session
    returned is no longer used. Default is True, the session will be
    automatically detached on homeassistant_stop or when being created
    in config entry setup, the config entry is unloaded.

    This method must be run in the event loop.
    """
    auto_cleanup_method = None
    if auto_cleanup:
        auto_cleanup_method = _async_register_clientsession_shutdown

    return _async_create_clientsession(
        hass,
        verify_ssl,
        auto_cleanup_method=auto_cleanup_method,
        family=family,
        ssl_cipher=ssl_cipher,
        **kwargs,
    )


@callback
def _async_create_clientsession(
    hass: HomeAssistant,
    verify_ssl: bool = True,
    auto_cleanup_method: Callable[[HomeAssistant, aiohttp.ClientSession], None]
    | None = None,
    family: socket.AddressFamily = socket.AF_UNSPEC,
    ssl_cipher: ssl_util.SSLCipherList = ssl_util.SSLCipherList.PYTHON_DEFAULT,
    **kwargs: Any,
) -> aiohttp.ClientSession:
    """Create a new ClientSession with kwargs, i.e. for cookies."""
    clientsession = aiohttp.ClientSession(
        connector=_async_get_connector(hass, verify_ssl, family, ssl_cipher),
        json_serialize=json_dumps,
        response_class=HassClientResponse,
        **kwargs,
    )
    # Prevent packages accidentally overriding our default headers
    # It's important that we identify as Home Assistant
    # If a package requires a different user agent, override it by passing a headers
    # dictionary to the request method.
    clientsession._default_headers = MappingProxyType(  # type: ignore[assignment]  # noqa: SLF001
        {USER_AGENT: SERVER_SOFTWARE},
    )

    clientsession.close = warn_use(  # type: ignore[method-assign]
        clientsession.close,
        WARN_CLOSE_MSG,
    )

    if auto_cleanup_method:
        auto_cleanup_method(hass, clientsession)

    return clientsession


@bind_hass
async def async_aiohttp_proxy_web(
    hass: HomeAssistant,
    request: web.BaseRequest,
    web_coro: Awaitable[aiohttp.ClientResponse],
    buffer_size: int = 102400,
    timeout: int = 10,
) -> web.StreamResponse | None:
    """Stream websession request to aiohttp web response."""
    try:
        async with asyncio.timeout(timeout):
            req = await web_coro

    except asyncio.CancelledError:
        # The user cancelled the request
        return None

    except TimeoutError as err:
        # Timeout trying to start the web request
        raise HTTPGatewayTimeout from err

    except aiohttp.ClientError as err:
        # Something went wrong with the connection
        raise HTTPBadGateway from err

    try:
        return await async_aiohttp_proxy_stream(
            hass, request, req.content, req.headers.get(CONTENT_TYPE)
        )
    finally:
        req.close()


@bind_hass
async def async_aiohttp_proxy_stream(
    hass: HomeAssistant,
    request: web.BaseRequest,
    stream: aiohttp.StreamReader,
    content_type: str | None,
    buffer_size: int = 102400,
    timeout: int = 10,
) -> web.StreamResponse:
    """Stream a stream to aiohttp web response."""
    response = web.StreamResponse()
    if content_type is not None:
        response.content_type = content_type
    await response.prepare(request)

    # Suppressing something went wrong fetching data, closed connection
    with suppress(TimeoutError, aiohttp.ClientError):
        while hass.is_running:
            async with asyncio.timeout(timeout):
                data = await stream.read(buffer_size)

            if not data:
                break
            await response.write(data)

    return response


@callback
def _async_register_clientsession_shutdown(
    hass: HomeAssistant, clientsession: aiohttp.ClientSession
) -> None:
    """Register ClientSession close on Home Assistant shutdown or config entry unload.

    This method must be run in the event loop.
    """

    @callback
    def _async_close_websession(*_: Any) -> None:
        """Close websession."""
        clientsession.detach()

    unsub = hass.bus.async_listen_once(
        EVENT_HOMEASSISTANT_CLOSE, _async_close_websession
    )

    if not (config_entry := config_entries.current_entry.get()):
        return

    config_entry.async_on_unload(unsub)
    config_entry.async_on_unload(_async_close_websession)


@callback
def _async_register_default_clientsession_shutdown(
    hass: HomeAssistant, clientsession: aiohttp.ClientSession
) -> None:
    """Register default ClientSession close on Home Assistant shutdown.

    This method must be run in the event loop.
    """

    @callback
    def _async_close_websession(event: Event) -> None:
        """Close websession."""
        clientsession.detach()

    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_CLOSE, _async_close_websession)


@callback
def _make_key(
    verify_ssl: bool = True,
    family: socket.AddressFamily = socket.AF_UNSPEC,
    ssl_cipher: ssl_util.SSLCipherList = ssl_util.SSLCipherList.PYTHON_DEFAULT,
) -> tuple[bool, socket.AddressFamily, ssl_util.SSLCipherList]:
    """Make a key for connector or session pool."""
    return (verify_ssl, family, ssl_cipher)


class HomeAssistantTCPConnector(aiohttp.TCPConnector):
    """Home Assistant TCP Connector.

    Same as aiohttp.TCPConnector but with a longer cleanup_closed timeout.

    By default the cleanup_closed timeout is 2 seconds. This is too short
    for Home Assistant since we churn through a lot of connections. We set
    it to 60 seconds to reduce the overhead of aborting TLS connections
    that are likely already closed.
    """

    # abort transport after 60 seconds (cleanup broken connections)
    _cleanup_closed_period = 60.0


@callback
def _async_get_connector(
    hass: HomeAssistant,
    verify_ssl: bool = True,
    family: socket.AddressFamily = socket.AF_UNSPEC,
    ssl_cipher: ssl_util.SSLCipherList = ssl_util.SSLCipherList.PYTHON_DEFAULT,
) -> aiohttp.BaseConnector:
    """Return the connector pool for aiohttp.

    This method must be run in the event loop.
    """
    connector_key = _make_key(verify_ssl, family, ssl_cipher)
    connectors = hass.data.setdefault(DATA_CONNECTOR, {})

    if connector_key in connectors:
        return connectors[connector_key]

    if verify_ssl:
        ssl_context: SSLContext = ssl_util.client_context(
            ssl_cipher, ssl_util.SSL_ALPN_HTTP11
        )
    else:
        ssl_context = ssl_util.client_context_no_verify(
            ssl_cipher, ssl_util.SSL_ALPN_HTTP11
        )

    connector = HomeAssistantTCPConnector(
        family=family,
        ssl=ssl_context,
        limit=MAXIMUM_CONNECTIONS,
        limit_per_host=MAXIMUM_CONNECTIONS_PER_HOST,
        resolver=_async_get_or_create_resolver(hass),
    )
    connectors[connector_key] = connector

    async def _async_close_connector(event: Event) -> None:
        """Close connector pool."""
        await connector.close()

    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_CLOSE, _async_close_connector)

    return connector


@singleton(DATA_RESOLVER)
@callback
def _async_get_or_create_resolver(hass: HomeAssistant) -> HassAsyncDNSResolver:
    """Return the HassAsyncDNSResolver."""
    resolver = _async_make_resolver(hass)

    async def _async_close_resolver(event: Event) -> None:
        await resolver.real_close()

    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_CLOSE, _async_close_resolver)
    return resolver


@callback
def _async_make_resolver(hass: HomeAssistant) -> HassAsyncDNSResolver:
    return HassAsyncDNSResolver(async_zeroconf=zeroconf.async_get_async_zeroconf(hass))
</file>

<file path="area_registry.py">
"""Provide a way to connect devices to one physical location."""

from __future__ import annotations

from collections import defaultdict
from collections.abc import Iterable
import dataclasses
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any, Literal, TypedDict

from homeassistant.const import ATTR_DEVICE_CLASS
from homeassistant.core import HomeAssistant, callback
from homeassistant.util.dt import utc_from_timestamp, utcnow
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey

from . import device_registry as dr, entity_registry as er
from .json import json_bytes, json_fragment
from .normalized_name_base_registry import (
    NormalizedNameBaseRegistryEntry,
    NormalizedNameBaseRegistryItems,
    normalize_name,
)
from .registry import BaseRegistry, RegistryIndexType
from .singleton import singleton
from .storage import Store
from .typing import UNDEFINED, UndefinedType

if TYPE_CHECKING:
    # mypy cannot workout _cache Protocol with dataclasses
    from propcache.api import cached_property as under_cached_property
else:
    from propcache.api import under_cached_property


DATA_REGISTRY: HassKey[AreaRegistry] = HassKey("area_registry")
EVENT_AREA_REGISTRY_UPDATED: EventType[EventAreaRegistryUpdatedData] = EventType(
    "area_registry_updated"
)
STORAGE_KEY = "core.area_registry"
STORAGE_VERSION_MAJOR = 1
STORAGE_VERSION_MINOR = 9


class _AreaStoreData(TypedDict):
    """Data type for individual area. Used in AreasRegistryStoreData."""

    aliases: list[str]
    floor_id: str | None
    humidity_entity_id: str | None
    icon: str | None
    id: str
    labels: list[str]
    name: str
    picture: str | None
    temperature_entity_id: str | None
    created_at: str
    modified_at: str


class AreasRegistryStoreData(TypedDict):
    """Store data type for AreaRegistry."""

    areas: list[_AreaStoreData]


class EventAreaRegistryUpdatedData(TypedDict):
    """EventAreaRegistryUpdated data."""

    action: Literal["create", "remove", "update", "reorder"]
    area_id: str | None


@dataclass(frozen=True, kw_only=True, slots=True)
class AreaEntry(NormalizedNameBaseRegistryEntry):
    """Area Registry Entry."""

    aliases: set[str]
    floor_id: str | None
    humidity_entity_id: str | None
    icon: str | None
    id: str
    labels: set[str] = field(default_factory=set)
    picture: str | None
    temperature_entity_id: str | None
    _cache: dict[str, Any] = field(default_factory=dict, compare=False, init=False)

    @under_cached_property
    def json_fragment(self) -> json_fragment:
        """Return a JSON representation of this AreaEntry."""
        return json_fragment(
            json_bytes(
                {
                    "aliases": list(self.aliases),
                    "area_id": self.id,
                    "floor_id": self.floor_id,
                    "humidity_entity_id": self.humidity_entity_id,
                    "icon": self.icon,
                    "labels": list(self.labels),
                    "name": self.name,
                    "picture": self.picture,
                    "temperature_entity_id": self.temperature_entity_id,
                    "created_at": self.created_at.timestamp(),
                    "modified_at": self.modified_at.timestamp(),
                }
            )
        )


class AreaRegistryStore(Store[AreasRegistryStoreData]):
    """Store area registry data."""

    async def _async_migrate_func(
        self,
        old_major_version: int,
        old_minor_version: int,
        old_data: dict[str, list[dict[str, Any]]],
    ) -> AreasRegistryStoreData:
        """Migrate to the new version."""
        if old_major_version < 2:
            if old_minor_version < 2:
                # Version 1.2 implements migration and freezes the available keys
                for area in old_data["areas"]:
                    # Populate keys which were introduced before version 1.2
                    area.setdefault("picture", None)

            if old_minor_version < 3:
                # Version 1.3 adds aliases
                for area in old_data["areas"]:
                    area["aliases"] = []

            if old_minor_version < 4:
                # Version 1.4 adds icon
                for area in old_data["areas"]:
                    area["icon"] = None

            if old_minor_version < 5:
                # Version 1.5 adds floor_id
                for area in old_data["areas"]:
                    area["floor_id"] = None

            if old_minor_version < 6:
                # Version 1.6 adds labels
                for area in old_data["areas"]:
                    area["labels"] = []

            if old_minor_version < 7:
                # Version 1.7 adds created_at and modified_at
                created_at = utc_from_timestamp(0).isoformat()
                for area in old_data["areas"]:
                    area["created_at"] = area["modified_at"] = created_at

            if old_minor_version < 8:
                # Version 1.8 adds humidity_entity_id and temperature_entity_id
                for area in old_data["areas"]:
                    area["humidity_entity_id"] = None
                    area["temperature_entity_id"] = None

            if old_minor_version < 9:
                # Version 1.9 sorts the areas by name
                old_data["areas"] = sorted(
                    old_data["areas"],
                    key=lambda area: area["name"].casefold(),
                )

        if old_major_version > 1:
            raise NotImplementedError
        return old_data  # type: ignore[return-value]


class AreaRegistryItems(NormalizedNameBaseRegistryItems[AreaEntry]):
    """Class to hold area registry items."""

    def __init__(self) -> None:
        """Initialize the area registry items."""
        super().__init__()
        self._labels_index: RegistryIndexType = defaultdict(dict)
        self._floors_index: RegistryIndexType = defaultdict(dict)
        self._aliases_index: RegistryIndexType = defaultdict(dict)

    def _index_entry(self, key: str, entry: AreaEntry) -> None:
        """Index an entry."""
        super()._index_entry(key, entry)
        if entry.floor_id is not None:
            self._floors_index[entry.floor_id][key] = True
        for label in entry.labels:
            self._labels_index[label][key] = True
        for normalized_alias in {normalize_name(alias) for alias in entry.aliases}:
            self._aliases_index[normalized_alias][key] = True

    def _unindex_entry(
        self, key: str, replacement_entry: AreaEntry | None = None
    ) -> None:
        # always call base class before other indices
        super()._unindex_entry(key, replacement_entry)
        entry = self.data[key]
        if aliases := entry.aliases:
            for normalized_alias in {normalize_name(alias) for alias in aliases}:
                self._unindex_entry_value(key, normalized_alias, self._aliases_index)
        if labels := entry.labels:
            for label in labels:
                self._unindex_entry_value(key, label, self._labels_index)
        if floor_id := entry.floor_id:
            self._unindex_entry_value(key, floor_id, self._floors_index)

    def get_areas_for_label(self, label: str) -> list[AreaEntry]:
        """Get areas for label."""
        data = self.data
        return [data[key] for key in self._labels_index.get(label, ())]

    def get_areas_for_floor(self, floor: str) -> list[AreaEntry]:
        """Get areas for floor."""
        data = self.data
        return [data[key] for key in self._floors_index.get(floor, ())]

    def get_areas_for_alias(self, alias: str) -> list[AreaEntry]:
        """Get areas for alias."""
        data = self.data
        normalized_alias = normalize_name(alias)
        return [data[key] for key in self._aliases_index.get(normalized_alias, ())]


class AreaRegistry(BaseRegistry[AreasRegistryStoreData]):
    """Class to hold a registry of areas."""

    areas: AreaRegistryItems
    _area_data: dict[str, AreaEntry]

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the area registry."""
        self.hass = hass
        self._store = AreaRegistryStore(
            hass,
            STORAGE_VERSION_MAJOR,
            STORAGE_KEY,
            atomic_writes=True,
            minor_version=STORAGE_VERSION_MINOR,
        )

    @callback
    def async_get_area(self, area_id: str) -> AreaEntry | None:
        """Get area by id.

        We retrieve the DeviceEntry from the underlying dict to avoid
        the overhead of the UserDict __getitem__.
        """
        return self._area_data.get(area_id)

    @callback
    def async_get_area_by_name(self, name: str) -> AreaEntry | None:
        """Get area by name."""
        return self.areas.get_by_name(name)

    @callback
    def async_get_areas_by_alias(self, alias: str) -> list[AreaEntry]:
        """Get areas by alias."""
        return self.areas.get_areas_for_alias(alias)

    @callback
    def async_list_areas(self) -> Iterable[AreaEntry]:
        """Get all areas."""
        return self.areas.values()

    @callback
    def async_get_or_create(self, name: str) -> AreaEntry:
        """Get or create an area."""
        if area := self.async_get_area_by_name(name):
            return area
        return self.async_create(name)

    def _generate_id(self, name: str) -> str:
        """Generate area ID."""
        return self.areas.generate_id_from_name(name)

    @callback
    def async_create(
        self,
        name: str,
        *,
        aliases: set[str] | None = None,
        floor_id: str | None = None,
        humidity_entity_id: str | None = None,
        icon: str | None = None,
        labels: set[str] | None = None,
        picture: str | None = None,
        temperature_entity_id: str | None = None,
    ) -> AreaEntry:
        """Create a new area."""

        self.hass.verify_event_loop_thread("area_registry.async_create")

        if area := self.async_get_area_by_name(name):
            raise ValueError(
                f"The name {name} ({area.normalized_name}) is already in use"
            )

        if humidity_entity_id is not None:
            _validate_humidity_entity(self.hass, humidity_entity_id)

        if temperature_entity_id is not None:
            _validate_temperature_entity(self.hass, temperature_entity_id)

        area = AreaEntry(
            aliases=aliases or set(),
            floor_id=floor_id,
            humidity_entity_id=humidity_entity_id,
            icon=icon,
            id=self._generate_id(name),
            labels=labels or set(),
            name=name,
            picture=picture,
            temperature_entity_id=temperature_entity_id,
        )
        area_id = area.id
        self.areas[area_id] = area
        self.async_schedule_save()

        self.hass.bus.async_fire_internal(
            EVENT_AREA_REGISTRY_UPDATED,
            EventAreaRegistryUpdatedData(action="create", area_id=area_id),
        )
        return area

    @callback
    def async_delete(self, area_id: str) -> None:
        """Delete area."""
        self.hass.verify_event_loop_thread("area_registry.async_delete")
        device_registry = dr.async_get(self.hass)
        entity_registry = er.async_get(self.hass)
        device_registry.async_clear_area_id(area_id)
        entity_registry.async_clear_area_id(area_id)

        del self.areas[area_id]

        self.hass.bus.async_fire_internal(
            EVENT_AREA_REGISTRY_UPDATED,
            EventAreaRegistryUpdatedData(action="remove", area_id=area_id),
        )

        self.async_schedule_save()

    @callback
    def async_update(
        self,
        area_id: str,
        *,
        aliases: set[str] | UndefinedType = UNDEFINED,
        floor_id: str | None | UndefinedType = UNDEFINED,
        humidity_entity_id: str | None | UndefinedType = UNDEFINED,
        icon: str | None | UndefinedType = UNDEFINED,
        labels: set[str] | UndefinedType = UNDEFINED,
        name: str | UndefinedType = UNDEFINED,
        picture: str | None | UndefinedType = UNDEFINED,
        temperature_entity_id: str | None | UndefinedType = UNDEFINED,
    ) -> AreaEntry:
        """Update name of area."""
        updated = self._async_update(
            area_id,
            aliases=aliases,
            floor_id=floor_id,
            humidity_entity_id=humidity_entity_id,
            icon=icon,
            labels=labels,
            name=name,
            picture=picture,
            temperature_entity_id=temperature_entity_id,
        )
        # Since updated may be the old or the new and we always fire
        # an event even if nothing has changed we cannot use async_fire_internal
        # here because we do not know if the thread safety check already
        # happened or not in _async_update.
        self.hass.bus.async_fire(
            EVENT_AREA_REGISTRY_UPDATED,
            EventAreaRegistryUpdatedData(action="update", area_id=area_id),
        )
        return updated

    @callback
    def _async_update(
        self,
        area_id: str,
        *,
        aliases: set[str] | UndefinedType = UNDEFINED,
        floor_id: str | None | UndefinedType = UNDEFINED,
        humidity_entity_id: str | None | UndefinedType = UNDEFINED,
        icon: str | None | UndefinedType = UNDEFINED,
        labels: set[str] | UndefinedType = UNDEFINED,
        name: str | UndefinedType = UNDEFINED,
        picture: str | None | UndefinedType = UNDEFINED,
        temperature_entity_id: str | None | UndefinedType = UNDEFINED,
    ) -> AreaEntry:
        """Update name of area."""
        old = self.areas[area_id]

        new_values: dict[str, Any] = {
            attr_name: value
            for attr_name, value in (
                ("aliases", aliases),
                ("floor_id", floor_id),
                ("humidity_entity_id", humidity_entity_id),
                ("icon", icon),
                ("labels", labels),
                ("picture", picture),
                ("temperature_entity_id", temperature_entity_id),
            )
            if value is not UNDEFINED and value != getattr(old, attr_name)
        }

        if "humidity_entity_id" in new_values and humidity_entity_id is not None:
            _validate_humidity_entity(self.hass, new_values["humidity_entity_id"])

        if "temperature_entity_id" in new_values and temperature_entity_id is not None:
            _validate_temperature_entity(self.hass, new_values["temperature_entity_id"])

        if name is not UNDEFINED and name != old.name:
            new_values["name"] = name

        if not new_values:
            return old

        new_values["modified_at"] = utcnow()

        self.hass.verify_event_loop_thread("area_registry.async_update")
        new = self.areas[area_id] = dataclasses.replace(old, **new_values)

        self.async_schedule_save()
        return new

    @callback
    def async_reorder(self, area_ids: list[str]) -> None:
        """Reorder areas."""
        self.hass.verify_event_loop_thread("area_registry.async_reorder")

        if set(area_ids) != set(self.areas.data.keys()):
            raise ValueError(
                "The area_ids list must contain all existing area IDs exactly once"
            )

        reordered_data = {area_id: self.areas.data[area_id] for area_id in area_ids}
        self.areas.data.clear()
        self.areas.data.update(reordered_data)

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_AREA_REGISTRY_UPDATED,
            EventAreaRegistryUpdatedData(action="reorder", area_id=None),
        )

    async def async_load(self) -> None:
        """Load the area registry."""
        self._async_setup_cleanup()

        data = await self._store.async_load()

        areas = AreaRegistryItems()

        if data is not None:
            for area in data["areas"]:
                assert area["name"] is not None and area["id"] is not None
                areas[area["id"]] = AreaEntry(
                    aliases=set(area["aliases"]),
                    floor_id=area["floor_id"],
                    humidity_entity_id=area["humidity_entity_id"],
                    icon=area["icon"],
                    id=area["id"],
                    labels=set(area["labels"]),
                    name=area["name"],
                    picture=area["picture"],
                    temperature_entity_id=area["temperature_entity_id"],
                    created_at=datetime.fromisoformat(area["created_at"]),
                    modified_at=datetime.fromisoformat(area["modified_at"]),
                )

        self.areas = areas
        self._area_data = areas.data

    @callback
    def _data_to_save(self) -> AreasRegistryStoreData:
        """Return data of area registry to store in a file."""
        return {
            "areas": [
                {
                    "aliases": list(entry.aliases),
                    "floor_id": entry.floor_id,
                    "humidity_entity_id": entry.humidity_entity_id,
                    "icon": entry.icon,
                    "id": entry.id,
                    "labels": list(entry.labels),
                    "name": entry.name,
                    "picture": entry.picture,
                    "temperature_entity_id": entry.temperature_entity_id,
                    "created_at": entry.created_at.isoformat(),
                    "modified_at": entry.modified_at.isoformat(),
                }
                for entry in self.areas.values()
            ]
        }

    @callback
    def _async_setup_cleanup(self) -> None:
        """Set up the area registry cleanup."""
        from . import (  # Circular dependencies  # noqa: PLC0415
            floor_registry as fr,
            label_registry as lr,
        )

        @callback
        def _removed_from_registry_filter(
            event_data: fr.EventFloorRegistryUpdatedData
            | lr.EventLabelRegistryUpdatedData,
        ) -> bool:
            """Filter all except for the item removed from registry events."""
            return event_data["action"] == "remove"

        @callback
        def _handle_floor_registry_update(event: fr.EventFloorRegistryUpdated) -> None:
            """Update areas that are associated with a floor that has been removed."""
            if TYPE_CHECKING:
                assert event.data["action"] == "remove"
            floor_id = event.data["floor_id"]
            for area in self.areas.get_areas_for_floor(floor_id):
                self.async_update(area.id, floor_id=None)

        self.hass.bus.async_listen(
            event_type=fr.EVENT_FLOOR_REGISTRY_UPDATED,
            event_filter=_removed_from_registry_filter,
            listener=_handle_floor_registry_update,
        )

        @callback
        def _handle_label_registry_update(event: lr.EventLabelRegistryUpdated) -> None:
            """Update areas that have a label that has been removed."""
            label_id = event.data["label_id"]
            for area in self.areas.get_areas_for_label(label_id):
                self.async_update(area.id, labels=area.labels - {label_id})

        self.hass.bus.async_listen(
            event_type=lr.EVENT_LABEL_REGISTRY_UPDATED,
            event_filter=_removed_from_registry_filter,
            listener=_handle_label_registry_update,
        )


@callback
@singleton(DATA_REGISTRY)
def async_get(hass: HomeAssistant) -> AreaRegistry:
    """Get area registry."""
    return AreaRegistry(hass)


async def async_load(hass: HomeAssistant) -> None:
    """Load area registry."""
    assert DATA_REGISTRY not in hass.data
    await async_get(hass).async_load()


@callback
def async_entries_for_floor(registry: AreaRegistry, floor_id: str) -> list[AreaEntry]:
    """Return entries that match a floor."""
    return registry.areas.get_areas_for_floor(floor_id)


@callback
def async_entries_for_label(registry: AreaRegistry, label_id: str) -> list[AreaEntry]:
    """Return entries that match a label."""
    return registry.areas.get_areas_for_label(label_id)


def _validate_temperature_entity(hass: HomeAssistant, entity_id: str) -> None:
    """Validate temperature entity."""
    from homeassistant.components.sensor import SensorDeviceClass  # noqa: PLC0415

    if not (state := hass.states.get(entity_id)):
        raise ValueError(f"Entity {entity_id} does not exist")

    if (
        state.domain != "sensor"
        or state.attributes.get(ATTR_DEVICE_CLASS) != SensorDeviceClass.TEMPERATURE
    ):
        raise ValueError(f"Entity {entity_id} is not a temperature sensor")


def _validate_humidity_entity(hass: HomeAssistant, entity_id: str) -> None:
    """Validate humidity entity."""
    from homeassistant.components.sensor import SensorDeviceClass  # noqa: PLC0415

    if not (state := hass.states.get(entity_id)):
        raise ValueError(f"Entity {entity_id} does not exist")

    if (
        state.domain != "sensor"
        or state.attributes.get(ATTR_DEVICE_CLASS) != SensorDeviceClass.HUMIDITY
    ):
        raise ValueError(f"Entity {entity_id} is not a humidity sensor")
</file>

<file path="automation.py">
"""Helpers for automation."""

from typing import Any

import voluptuous as vol

from homeassistant.const import CONF_OPTIONS

from .typing import ConfigType


def get_absolute_description_key(domain: str, key: str) -> str:
    """Return the absolute description key."""
    if not key.startswith("_"):
        return f"{domain}.{key}"
    key = key[1:]  # Remove leading underscore
    if not key:
        return domain
    return key


def get_relative_description_key(domain: str, key: str) -> str:
    """Return the relative description key."""
    platform, *subtype = key.split(".", 1)
    if platform != domain:
        return f"_{key}"
    if not subtype:
        return "_"
    return subtype[0]


def move_top_level_schema_fields_to_options(
    config: ConfigType, options_schema_dict: dict[vol.Marker, Any]
) -> ConfigType:
    """Move top-level fields to options.

    This function is used to help migrating old-style configs to new-style configs
    for triggers and conditions.
    If options is already present, the config is returned as-is.
    """
    if CONF_OPTIONS in config:
        return config

    config = config.copy()
    options = config.setdefault(CONF_OPTIONS, {})

    # Move top-level fields to options
    for key_marked in options_schema_dict:
        key = key_marked.schema
        if key in config:
            options[key] = config.pop(key)

    return config


def move_options_fields_to_top_level(
    config: ConfigType, base_schema: vol.Schema
) -> ConfigType:
    """Move options fields to top-level.

    This function is used to provide backwards compatibility for new-style configs
    for triggers and conditions.

    The config is returned as-is, if any of the following is true:
    - options is not present
    - options is not a dict
    - the config with options field removed fails the base_schema validation (most
    likely due to additional keys being present)

    Those conditions are checked to make it so that only configs that have the structure
    of the new-style are modified, whereas valid old-style configs are preserved.
    """
    options = config.get(CONF_OPTIONS)

    if not isinstance(options, dict):
        return config

    new_config: ConfigType = config.copy()
    new_config.pop(CONF_OPTIONS)

    try:
        new_config = base_schema(new_config)
    except vol.Invalid:
        return config

    new_config.update(options)

    return new_config
</file>

<file path="category_registry.py">
"""Provide a way to categorize things within a defined scope."""

from __future__ import annotations

from collections.abc import Iterable
import dataclasses
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Literal, TypedDict

from homeassistant.core import Event, HomeAssistant, callback
from homeassistant.util.dt import utc_from_timestamp, utcnow
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.ulid import ulid_now

from .registry import BaseRegistry
from .singleton import singleton
from .storage import Store
from .typing import UNDEFINED, UndefinedType

DATA_REGISTRY: HassKey[CategoryRegistry] = HassKey("category_registry")
EVENT_CATEGORY_REGISTRY_UPDATED: EventType[EventCategoryRegistryUpdatedData] = (
    EventType("category_registry_updated")
)
STORAGE_KEY = "core.category_registry"
STORAGE_VERSION_MAJOR = 1
STORAGE_VERSION_MINOR = 2


class _CategoryStoreData(TypedDict):
    """Data type for individual category. Used in CategoryRegistryStoreData."""

    category_id: str
    created_at: str
    icon: str | None
    modified_at: str
    name: str


class CategoryRegistryStoreData(TypedDict):
    """Store data type for CategoryRegistry."""

    categories: dict[str, list[_CategoryStoreData]]


class EventCategoryRegistryUpdatedData(TypedDict):
    """Event data for when the category registry is updated."""

    action: Literal["create", "remove", "update"]
    scope: str
    category_id: str


type EventCategoryRegistryUpdated = Event[EventCategoryRegistryUpdatedData]


@dataclass(slots=True, kw_only=True, frozen=True)
class CategoryEntry:
    """Category registry entry."""

    category_id: str = field(default_factory=ulid_now)
    created_at: datetime = field(default_factory=utcnow)
    icon: str | None = None
    modified_at: datetime = field(default_factory=utcnow)
    name: str


class CategoryRegistryStore(Store[CategoryRegistryStoreData]):
    """Store category registry data."""

    async def _async_migrate_func(
        self,
        old_major_version: int,
        old_minor_version: int,
        old_data: dict[str, dict[str, list[dict[str, Any]]]],
    ) -> CategoryRegistryStoreData:
        """Migrate to the new version."""
        if old_major_version > STORAGE_VERSION_MAJOR:
            raise ValueError("Can't migrate to future version")

        if old_major_version == 1:
            if old_minor_version < 2:
                # Version 1.2 implements migration and adds created_at and modified_at
                created_at = utc_from_timestamp(0).isoformat()
                for categories in old_data["categories"].values():
                    for category in categories:
                        category["created_at"] = category["modified_at"] = created_at

        return old_data  # type: ignore[return-value]


class CategoryRegistry(BaseRegistry[CategoryRegistryStoreData]):
    """Class to hold a registry of categories by scope."""

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the category registry."""
        self.hass = hass
        self.categories: dict[str, dict[str, CategoryEntry]] = {}
        self._store = CategoryRegistryStore(
            hass,
            STORAGE_VERSION_MAJOR,
            STORAGE_KEY,
            atomic_writes=True,
            minor_version=STORAGE_VERSION_MINOR,
        )

    @callback
    def async_get_category(
        self, *, scope: str, category_id: str
    ) -> CategoryEntry | None:
        """Get category by ID."""
        if scope not in self.categories:
            return None
        return self.categories[scope].get(category_id)

    @callback
    def async_list_categories(self, *, scope: str) -> Iterable[CategoryEntry]:
        """Get all categories."""
        if scope not in self.categories:
            return []
        return self.categories[scope].values()

    @callback
    def async_create(
        self,
        *,
        name: str,
        scope: str,
        icon: str | None = None,
    ) -> CategoryEntry:
        """Create a new category."""
        self.hass.verify_event_loop_thread("category_registry.async_create")
        self._async_ensure_name_is_available(scope, name)
        category = CategoryEntry(
            icon=icon,
            name=name,
        )

        if scope not in self.categories:
            self.categories[scope] = {}

        self.categories[scope][category.category_id] = category

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_CATEGORY_REGISTRY_UPDATED,
            EventCategoryRegistryUpdatedData(
                action="create", scope=scope, category_id=category.category_id
            ),
        )
        return category

    @callback
    def async_delete(self, *, scope: str, category_id: str) -> None:
        """Delete category."""
        self.hass.verify_event_loop_thread("category_registry.async_delete")
        del self.categories[scope][category_id]
        self.hass.bus.async_fire_internal(
            EVENT_CATEGORY_REGISTRY_UPDATED,
            EventCategoryRegistryUpdatedData(
                action="remove",
                scope=scope,
                category_id=category_id,
            ),
        )
        self.async_schedule_save()

    @callback
    def async_update(
        self,
        *,
        scope: str,
        category_id: str,
        icon: str | None | UndefinedType = UNDEFINED,
        name: str | UndefinedType = UNDEFINED,
    ) -> CategoryEntry:
        """Update name or icon of the category."""
        old = self.categories[scope][category_id]
        changes: dict[str, Any] = {}

        if icon is not UNDEFINED and icon != old.icon:
            changes["icon"] = icon

        if name is not UNDEFINED and name != old.name:
            changes["name"] = name
            self._async_ensure_name_is_available(scope, name, category_id)

        if not changes:
            return old

        changes["modified_at"] = utcnow()

        self.hass.verify_event_loop_thread("category_registry.async_update")
        new = self.categories[scope][category_id] = dataclasses.replace(old, **changes)

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_CATEGORY_REGISTRY_UPDATED,
            EventCategoryRegistryUpdatedData(
                action="update", scope=scope, category_id=category_id
            ),
        )

        return new

    async def async_load(self) -> None:
        """Load the category registry."""
        data = await self._store.async_load()
        category_entries: dict[str, dict[str, CategoryEntry]] = {}

        if data is not None:
            for scope, categories in data["categories"].items():
                category_entries[scope] = {
                    category["category_id"]: CategoryEntry(
                        category_id=category["category_id"],
                        created_at=datetime.fromisoformat(category["created_at"]),
                        icon=category["icon"],
                        modified_at=datetime.fromisoformat(category["modified_at"]),
                        name=category["name"],
                    )
                    for category in categories
                }

        self.categories = category_entries

    @callback
    def _data_to_save(self) -> CategoryRegistryStoreData:
        """Return data of category registry to store in a file."""
        return {
            "categories": {
                scope: [
                    {
                        "category_id": entry.category_id,
                        "created_at": entry.created_at.isoformat(),
                        "icon": entry.icon,
                        "modified_at": entry.modified_at.isoformat(),
                        "name": entry.name,
                    }
                    for entry in entries.values()
                ]
                for scope, entries in self.categories.items()
            }
        }

    @callback
    def _async_ensure_name_is_available(
        self, scope: str, name: str, category_id: str | None = None
    ) -> None:
        """Ensure name is available within the scope."""
        if scope not in self.categories:
            return
        for category in self.categories[scope].values():
            if (
                category.name.casefold() == name.casefold()
                and category.category_id != category_id
            ):
                raise ValueError(f"The name '{name}' is already in use")


@callback
@singleton(DATA_REGISTRY)
def async_get(hass: HomeAssistant) -> CategoryRegistry:
    """Get category registry."""
    return CategoryRegistry(hass)


async def async_load(hass: HomeAssistant) -> None:
    """Load category registry."""
    assert DATA_REGISTRY not in hass.data
    await async_get(hass).async_load()
</file>

<file path="chat_session.py">
"""Helper to organize chat sessions between integrations."""

from __future__ import annotations

from collections.abc import Generator
from contextlib import contextmanager
from contextvars import ContextVar
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import logging

from homeassistant.const import EVENT_HOMEASSISTANT_STOP
from homeassistant.core import (
    CALLBACK_TYPE,
    Event,
    HassJob,
    HassJobType,
    HomeAssistant,
    callback,
)
from homeassistant.util import dt as dt_util
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.ulid import ulid_now, ulid_to_bytes

from .event import async_call_later

DATA_CHAT_SESSION: HassKey[dict[str, ChatSession]] = HassKey("chat_session")
DATA_CHAT_SESSION_CLEANUP: HassKey[SessionCleanup] = HassKey("chat_session_cleanup")

CONVERSATION_TIMEOUT = timedelta(minutes=5)
LOGGER = logging.getLogger(__name__)

current_session: ContextVar[ChatSession | None] = ContextVar(
    "current_session", default=None
)


@dataclass
class ChatSession:
    """Represent a chat session."""

    conversation_id: str
    last_updated: datetime = field(default_factory=dt_util.utcnow)
    _cleanup_callbacks: list[CALLBACK_TYPE] = field(default_factory=list)

    @callback
    def async_updated(self) -> None:
        """Update the last updated time."""
        self.last_updated = dt_util.utcnow()

    @callback
    def async_on_cleanup(self, cb: CALLBACK_TYPE) -> None:
        """Register a callback to clean up the session."""
        self._cleanup_callbacks.append(cb)

    @callback
    def async_cleanup(self) -> None:
        """Call all clean up callbacks."""
        for cb in self._cleanup_callbacks:
            cb()
        self._cleanup_callbacks.clear()


class SessionCleanup:
    """Helper to clean up the stale sessions."""

    unsub: CALLBACK_TYPE | None = None

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the session cleanup."""
        self.hass = hass
        hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, self._on_hass_stop)
        self.cleanup_job = HassJob(
            self._cleanup, "chat_session_cleanup", job_type=HassJobType.Callback
        )

    @callback
    def schedule(self) -> None:
        """Schedule the cleanup."""
        if self.unsub:
            return
        self.unsub = async_call_later(
            self.hass,
            CONVERSATION_TIMEOUT.total_seconds() + 1,
            self.cleanup_job,
        )

    @callback
    def _on_hass_stop(self, event: Event) -> None:
        """Cancel the cleanup on shutdown."""
        if self.unsub:
            self.unsub()
        self.unsub = None

    @callback
    def _cleanup(self, now: datetime) -> None:
        """Clean up the history and schedule follow-up if necessary."""
        self.unsub = None
        all_sessions = self.hass.data[DATA_CHAT_SESSION]

        # We mutate original object because current commands could be
        # yielding session based on it.
        for conversation_id, session in list(all_sessions.items()):
            if session.last_updated + CONVERSATION_TIMEOUT < now:
                LOGGER.debug("Cleaning up session %s", conversation_id)
                del all_sessions[conversation_id]
                session.async_cleanup()

        # Still conversations left, check again in timeout time.
        if all_sessions:
            self.schedule()


@contextmanager
def async_get_chat_session(
    hass: HomeAssistant,
    conversation_id: str | None = None,
) -> Generator[ChatSession]:
    """Return a chat session."""
    if session := current_session.get():
        # If a session is already active and it's the requested conversation ID,
        # return that. We won't update the last updated time in this case.
        if session.conversation_id == conversation_id:
            yield session
            return

        # If it's not the same conversation ID, we will create a new session
        # because it might be a conversation agent calling a tool that is talking
        # to another LLM.
        session = None

    all_sessions = hass.data.get(DATA_CHAT_SESSION)
    if all_sessions is None:
        all_sessions = {}
        hass.data[DATA_CHAT_SESSION] = all_sessions
        hass.data[DATA_CHAT_SESSION_CLEANUP] = SessionCleanup(hass)

    if conversation_id is None:
        conversation_id = ulid_now()

    elif conversation_id in all_sessions:
        session = all_sessions[conversation_id]

    else:
        # Conversation IDs are ULIDs. We generate a new one if not provided.
        # If an old ULID is passed in, we will generate a new one to indicate
        # a new conversation was started. If the user picks their own, they
        # want to track a conversation and we respect it.
        try:
            ulid_to_bytes(conversation_id)
            conversation_id = ulid_now()
        except ValueError:
            pass

    if session is None:
        LOGGER.debug("Creating new session %s", conversation_id)
        session = ChatSession(conversation_id)

    current_session.set(session)
    yield session
    current_session.set(None)

    session.last_updated = dt_util.utcnow()
    all_sessions[conversation_id] = session
    hass.data[DATA_CHAT_SESSION_CLEANUP].schedule()
</file>

<file path="check_config.py">
"""Helper to check the configuration file."""

from __future__ import annotations

from collections import OrderedDict
import logging
import os
from pathlib import Path
from typing import NamedTuple, Self

from annotatedyaml import loader as yaml_loader
import voluptuous as vol

from homeassistant import loader
from homeassistant.config import (  # type: ignore[attr-defined]
    CONF_PACKAGES,
    YAML_CONFIG_FILE,
    config_per_platform,
    extract_domain_configs,
    format_homeassistant_error,
    format_schema_error,
    load_yaml_config_file,
    merge_packages_config,
)
from homeassistant.core import DOMAIN as HOMEASSISTANT_DOMAIN, HomeAssistant
from homeassistant.core_config import CORE_CONFIG_SCHEMA
from homeassistant.exceptions import HomeAssistantError
from homeassistant.requirements import (
    RequirementsNotFound,
    async_clear_install_history,
    async_get_integration_with_requirements,
)

from . import config_validation as cv
from .typing import ConfigType


class CheckConfigError(NamedTuple):
    """Configuration check error."""

    message: str
    domain: str | None
    config: ConfigType | None


class HomeAssistantConfig(OrderedDict):
    """Configuration result with errors attribute."""

    def __init__(self) -> None:
        """Initialize HA config."""
        super().__init__()
        self.errors: list[CheckConfigError] = []
        self.warnings: list[CheckConfigError] = []

    def add_error(
        self,
        message: str,
        domain: str | None = None,
        config: ConfigType | None = None,
    ) -> Self:
        """Add an error."""
        self.errors.append(CheckConfigError(str(message), domain, config))
        return self

    @property
    def error_str(self) -> str:
        """Concatenate all errors to a string."""
        return "\n".join([err.message for err in self.errors])

    def add_warning(
        self,
        message: str,
        domain: str | None = None,
        config: ConfigType | None = None,
    ) -> Self:
        """Add a warning."""
        self.warnings.append(CheckConfigError(str(message), domain, config))
        return self

    @property
    def warning_str(self) -> str:
        """Concatenate all warnings to a string."""
        return "\n".join([err.message for err in self.warnings])


async def async_check_ha_config_file(  # noqa: C901
    hass: HomeAssistant,
) -> HomeAssistantConfig:
    """Load and check if Home Assistant configuration file is valid.

    This method is a coroutine.
    """
    result = HomeAssistantConfig()
    async_clear_install_history(hass)

    def _pack_error(
        hass: HomeAssistant,
        package: str,
        component: str | None,
        config: ConfigType,
        message: str,
    ) -> None:
        """Handle errors from packages."""
        message = f"Setup of package '{package}' failed: {message}"
        domain = f"homeassistant.packages.{package}{'.' + component if component is not None else ''}"
        pack_config = core_config[CONF_PACKAGES].get(package, config)
        result.add_warning(message, domain, pack_config)

    def _comp_error(
        ex: vol.Invalid | HomeAssistantError,
        domain: str,
        component_config: ConfigType,
        config_to_attach: ConfigType,
    ) -> None:
        """Handle errors from components."""
        if isinstance(ex, vol.Invalid):
            message = format_schema_error(hass, ex, domain, component_config)
        else:
            message = format_homeassistant_error(hass, ex, domain, component_config)
        if domain in frontend_dependencies:
            result.add_error(message, domain, config_to_attach)
        else:
            result.add_warning(message, domain, config_to_attach)

    async def _get_integration(
        hass: HomeAssistant, domain: str
    ) -> loader.Integration | None:
        """Get an integration."""
        integration: loader.Integration | None = None
        try:
            integration = await async_get_integration_with_requirements(hass, domain)
        except loader.IntegrationNotFound as ex:
            # We get this error if an integration is not found. In recovery mode and
            # safe mode, this currently happens for all custom integrations. Don't
            # show errors for a missing integration in recovery mode or safe mode to
            # not confuse the user.
            if not hass.config.recovery_mode and not hass.config.safe_mode:
                result.add_warning(f"Integration error: {domain} - {ex}")
        except RequirementsNotFound as ex:
            result.add_warning(f"Integration error: {domain} - {ex}")
        return integration

    # Load configuration.yaml
    config_path = hass.config.path(YAML_CONFIG_FILE)
    try:
        if not await hass.async_add_executor_job(os.path.isfile, config_path):
            return result.add_error("File configuration.yaml not found.")

        config = await hass.async_add_executor_job(
            load_yaml_config_file,
            config_path,
            yaml_loader.Secrets(Path(hass.config.config_dir)),
        )
    except FileNotFoundError:
        return result.add_error(f"File not found: {config_path}")
    except HomeAssistantError as err:
        return result.add_error(f"Error loading {config_path}: {err}")

    # Extract and validate core [homeassistant] config
    core_config = config.pop(HOMEASSISTANT_DOMAIN, {})
    try:
        core_config = CORE_CONFIG_SCHEMA(core_config)
        result[HOMEASSISTANT_DOMAIN] = core_config

        # Merge packages
        await merge_packages_config(
            hass, config, core_config.get(CONF_PACKAGES, {}), _pack_error
        )
    except vol.Invalid as err:
        result.add_error(
            format_schema_error(hass, err, HOMEASSISTANT_DOMAIN, core_config),
            HOMEASSISTANT_DOMAIN,
            core_config,
        )
        core_config = {}
    core_config.pop(CONF_PACKAGES, None)

    # Filter out repeating config sections
    components = {cv.domain_key(key) for key in config}

    frontend_dependencies: set[str] = set()
    if "frontend" in components or "default_config" in components:
        frontend = await _get_integration(hass, "frontend")
        if frontend:
            await frontend.resolve_dependencies()
            frontend_dependencies = frontend.all_dependencies | {"frontend"}

    # Process and validate config
    for domain in components:
        if not (integration := await _get_integration(hass, domain)):
            continue

        try:
            component = await integration.async_get_component()
        except ImportError as ex:
            result.add_warning(f"Component error: {domain} - {ex}")
            continue

        # Check if the integration has a custom config validator
        config_validator = None
        if integration.platforms_exists(("config",)):
            try:
                config_validator = await integration.async_get_platform("config")
            except ImportError as err:
                # Filter out import error of the config platform.
                # If the config platform contains bad imports, make sure
                # that still fails.
                if err.name != f"{integration.pkg_path}.config":
                    result.add_error(f"Error importing config platform {domain}: {err}")
                    continue

        if config_validator is not None and hasattr(
            config_validator, "async_validate_config"
        ):
            try:
                result[domain] = (
                    await config_validator.async_validate_config(hass, config)
                )[domain]
                continue
            except (vol.Invalid, HomeAssistantError) as ex:
                _comp_error(ex, domain, config, config[domain])
                continue
            except Exception as err:
                logging.getLogger(__name__).exception(
                    "Unexpected error validating config"
                )
                result.add_error(
                    f"Unexpected error calling config validator: {err}",
                    domain,
                    config.get(domain),
                )
                continue

        config_schema = getattr(component, "CONFIG_SCHEMA", None)
        if config_schema is not None:
            try:
                validated_config = await cv.async_validate(hass, config_schema, config)
                # Don't fail if the validator removed the domain from the config
                if domain in validated_config:
                    result[domain] = validated_config[domain]
            except vol.Invalid as ex:
                _comp_error(ex, domain, config, config[domain])
                continue

        component_platform_schema = getattr(
            component,
            "PLATFORM_SCHEMA_BASE",
            getattr(component, "PLATFORM_SCHEMA", None),
        )

        if component_platform_schema is None:
            continue

        platforms = []
        for p_name, p_config in config_per_platform(config, domain):
            # Validate component specific platform schema
            try:
                p_validated = await cv.async_validate(
                    hass, component_platform_schema, p_config
                )
            except vol.Invalid as ex:
                _comp_error(ex, domain, p_config, p_config)
                continue

            # Not all platform components follow same pattern for platforms
            # So if p_name is None we are not going to validate platform
            # (the automation component is one of them)
            if p_name is None:
                platforms.append(p_validated)
                continue

            try:
                p_integration = await async_get_integration_with_requirements(
                    hass, p_name
                )
                platform = await p_integration.async_get_platform(domain)
            except loader.IntegrationNotFound as ex:
                # We get this error if an integration is not found. In recovery mode and
                # safe mode, this currently happens for all custom integrations. Don't
                # show errors for a missing integration in recovery mode or safe mode to
                # not confuse the user.
                if not hass.config.recovery_mode and not hass.config.safe_mode:
                    result.add_warning(
                        f"Platform error '{domain}' from integration '{p_name}' - {ex}"
                    )
                continue
            except (
                RequirementsNotFound,
                ImportError,
            ) as ex:
                result.add_warning(
                    f"Platform error '{domain}' from integration '{p_name}' - {ex}"
                )
                continue

            # Validate platform specific schema
            platform_schema = getattr(platform, "PLATFORM_SCHEMA", None)
            if platform_schema is not None:
                try:
                    p_validated = platform_schema(p_validated)
                except vol.Invalid as ex:
                    _comp_error(ex, f"{domain}.{p_name}", p_config, p_config)
                    continue

            platforms.append(p_validated)

        # Remove config for current component and add validated config back in.
        for filter_comp in extract_domain_configs(config, domain):
            del config[filter_comp]
        result[domain] = platforms

    return result
</file>

<file path="collection.py">
"""Helper to deal with YAML + storage."""

from __future__ import annotations

from abc import abstractmethod
import asyncio
from collections.abc import Awaitable, Callable, Coroutine, Iterable
from dataclasses import dataclass
from functools import partial
from hashlib import md5
from itertools import groupby
import logging
from operator import attrgetter
from typing import Any, TypedDict

import voluptuous as vol
from voluptuous.humanize import humanize_error

from homeassistant.components import websocket_api
from homeassistant.const import CONF_ID
from homeassistant.core import CALLBACK_TYPE, HomeAssistant, callback
from homeassistant.exceptions import HomeAssistantError
from homeassistant.util import slugify

from . import entity_registry
from .entity import Entity
from .entity_component import EntityComponent
from .json import json_bytes
from .storage import Store
from .typing import ConfigType, VolDictType

STORAGE_VERSION = 1
SAVE_DELAY = 10

CHANGE_ADDED = "added"
CHANGE_UPDATED = "updated"
CHANGE_REMOVED = "removed"


@dataclass(slots=True)
class CollectionChange:
    """Class to represent an item in a change set.

    change_type: One of CHANGE_*
    item_id: The id of the item
    item: The item
    """

    change_type: str
    item_id: str
    item: Any
    item_hash: str | None = None


type ChangeListener = Callable[
    [
        # Change type
        str,
        # Item ID
        str,
        # New or removed config
        dict,
    ],
    Awaitable[None],
]

type ChangeSetListener = Callable[[Iterable[CollectionChange]], Awaitable[None]]


class CollectionError(HomeAssistantError):
    """Base class for collection related errors."""


class ItemNotFound(CollectionError):
    """Raised when an item is not found."""

    def __init__(self, item_id: str) -> None:
        """Initialize item not found error."""
        super().__init__(f"Item {item_id} not found.")
        self.item_id = item_id


class IDManager:
    """Keep track of IDs across different collections."""

    def __init__(self) -> None:
        """Initiate the ID manager."""
        self.collections: list[dict[str, Any]] = []

    def add_collection(self, collection: dict[str, Any]) -> None:
        """Add a collection to check for ID usage."""
        self.collections.append(collection)

    def has_id(self, item_id: str) -> bool:
        """Test if the ID exists."""
        return any(item_id in collection for collection in self.collections)

    def generate_id(self, suggestion: str) -> str:
        """Generate an ID."""
        base = slugify(suggestion)
        proposal = base
        attempt = 1

        while self.has_id(proposal):
            attempt += 1
            proposal = f"{base}_{attempt}"

        return proposal


class CollectionEntity(Entity):
    """Mixin class for entities managed by an ObservableCollection."""

    @classmethod
    @abstractmethod
    def from_storage(cls, config: ConfigType) -> CollectionEntity:
        """Create instance from storage."""

    @classmethod
    @abstractmethod
    def from_yaml(cls, config: ConfigType) -> CollectionEntity:
        """Create instance from yaml config."""

    @abstractmethod
    async def async_update_config(self, config: ConfigType) -> None:
        """Handle updated configuration."""


class ObservableCollection[_ItemT]:
    """Base collection type that can be observed."""

    def __init__(self, id_manager: IDManager | None) -> None:
        """Initialize the base collection."""
        self.id_manager = id_manager or IDManager()
        self.data: dict[str, _ItemT] = {}
        self.listeners: list[ChangeListener] = []
        self.change_set_listeners: list[ChangeSetListener] = []

        self.id_manager.add_collection(self.data)

    @callback
    def async_items(self) -> list[_ItemT]:
        """Return list of items in collection."""
        return list(self.data.values())

    @callback
    def async_add_listener(self, listener: ChangeListener) -> Callable[[], None]:
        """Add a listener.

        Will be called with (change_type, item_id, updated_config).
        """
        self.listeners.append(listener)
        return partial(self.listeners.remove, listener)

    @callback
    def async_add_change_set_listener(
        self, listener: ChangeSetListener
    ) -> Callable[[], None]:
        """Add a listener for a full change set.

        Will be called with [(change_type, item_id, updated_config), ...]
        """
        self.change_set_listeners.append(listener)
        return partial(self.change_set_listeners.remove, listener)

    async def notify_changes(self, change_set: Iterable[CollectionChange]) -> None:
        """Notify listeners of a change."""
        await asyncio.gather(
            *(
                listener(change.change_type, change.item_id, change.item)
                for listener in self.listeners
                for change in change_set
            ),
            *(
                change_set_listener(change_set)
                for change_set_listener in self.change_set_listeners
            ),
        )


class YamlCollection(ObservableCollection[dict]):
    """Offer a collection based on static data."""

    def __init__(
        self,
        logger: logging.Logger,
        id_manager: IDManager | None = None,
    ) -> None:
        """Initialize the storage collection."""
        super().__init__(id_manager)
        self.logger = logger

    @staticmethod
    def create_entity(
        entity_class: type[CollectionEntity], config: ConfigType
    ) -> CollectionEntity:
        """Create a CollectionEntity instance."""
        return entity_class.from_yaml(config)

    async def async_load(self, data: list[dict]) -> None:
        """Load the YAML collection. Overrides existing data."""
        old_ids = set(self.data)

        change_set = []

        for item in data:
            item_id = item[CONF_ID]

            if item_id in old_ids:
                old_ids.remove(item_id)
                event = CHANGE_UPDATED
            elif self.id_manager.has_id(item_id):
                self.logger.warning("Duplicate ID '%s' detected, skipping", item_id)
                continue
            else:
                event = CHANGE_ADDED

            self.data[item_id] = item
            change_set.append(CollectionChange(event, item_id, item))

        change_set.extend(
            CollectionChange(CHANGE_REMOVED, item_id, self.data.pop(item_id))
            for item_id in old_ids
        )

        if change_set:
            await self.notify_changes(change_set)


class SerializedStorageCollection(TypedDict):
    """Serialized storage collection."""

    items: list[dict[str, Any]]


class StorageCollection[_ItemT, _StoreT: SerializedStorageCollection](
    ObservableCollection[_ItemT]
):
    """Offer a CRUD interface on top of JSON storage."""

    def __init__(
        self,
        store: Store[_StoreT],
        id_manager: IDManager | None = None,
    ) -> None:
        """Initialize the storage collection."""
        super().__init__(id_manager)
        self.store = store

    @staticmethod
    def create_entity(
        entity_class: type[CollectionEntity], config: ConfigType
    ) -> CollectionEntity:
        """Create a CollectionEntity instance."""
        return entity_class.from_storage(config)

    @property
    def hass(self) -> HomeAssistant:
        """Home Assistant object."""
        return self.store.hass

    async def _async_load_data(self) -> _StoreT | None:
        """Load the data."""
        return await self.store.async_load()

    async def async_load(self) -> None:
        """Load the storage Manager."""
        if not (raw_storage := await self._async_load_data()):
            return

        for item in raw_storage["items"]:
            self.data[item[CONF_ID]] = self._deserialize_item(item)

        await self.notify_changes(
            [
                CollectionChange(
                    CHANGE_ADDED, item[CONF_ID], item, self._hash_item(item)
                )
                for item in raw_storage["items"]
            ]
        )

    @abstractmethod
    async def _process_create_data(self, data: dict) -> dict:
        """Validate the config is valid."""

    @callback
    @abstractmethod
    def _get_suggested_id(self, info: dict) -> str:
        """Suggest an ID based on the config."""

    @abstractmethod
    async def _update_data(self, item: _ItemT, update_data: dict) -> _ItemT:
        """Return a new updated item."""

    @abstractmethod
    def _create_item(self, item_id: str, data: dict) -> _ItemT:
        """Create an item from validated config."""

    @abstractmethod
    def _deserialize_item(self, data: dict) -> _ItemT:
        """Create an item from its serialized representation."""

    @abstractmethod
    def _serialize_item(self, item_id: str, item: _ItemT) -> dict:
        """Return the serialized representation of an item for storing.

        The serialized representation must include the item_id in the "id" key.
        """

    async def async_create_item(self, data: dict) -> _ItemT:
        """Create a new item."""
        validated_data = await self._process_create_data(data)
        item_id = self.id_manager.generate_id(self._get_suggested_id(validated_data))
        item = self._create_item(item_id, validated_data)
        self.data[item_id] = item
        self._async_schedule_save()
        await self.notify_changes(
            [
                CollectionChange(
                    CHANGE_ADDED,
                    item_id,
                    item,
                    self._hash_item(self._serialize_item(item_id, item)),
                )
            ]
        )
        return item

    async def async_update_item(self, item_id: str, updates: dict) -> _ItemT:
        """Update item."""
        if item_id not in self.data:
            raise ItemNotFound(item_id)

        if CONF_ID in updates:
            raise ValueError("Cannot update ID")

        current = self.data[item_id]

        updated = await self._update_data(current, updates)

        self.data[item_id] = updated
        self._async_schedule_save()

        await self.notify_changes(
            [
                CollectionChange(
                    CHANGE_UPDATED,
                    item_id,
                    updated,
                    self._hash_item(self._serialize_item(item_id, updated)),
                )
            ]
        )

        return self.data[item_id]

    async def async_delete_item(self, item_id: str) -> None:
        """Delete item."""
        if item_id not in self.data:
            raise ItemNotFound(item_id)

        item = self.data.pop(item_id)
        self._async_schedule_save()

        await self.notify_changes([CollectionChange(CHANGE_REMOVED, item_id, item)])

    @callback
    def _async_schedule_save(self) -> None:
        """Schedule saving the collection."""
        self.store.async_delay_save(self._data_to_save, SAVE_DELAY)

    @callback
    def _base_data_to_save(self) -> SerializedStorageCollection:
        """Return JSON-compatible data for storing to file."""
        return {
            "items": [
                self._serialize_item(item_id, item)
                for item_id, item in self.data.items()
            ]
        }

    @abstractmethod
    @callback
    def _data_to_save(self) -> _StoreT:
        """Return JSON-compatible date for storing to file."""

    def _hash_item(self, item: dict) -> str:
        """Return a hash of the item."""
        return md5(json_bytes(item)).hexdigest()


class DictStorageCollection(StorageCollection[dict, SerializedStorageCollection]):
    """A specialized StorageCollection where the items are untyped dicts."""

    def _create_item(self, item_id: str, data: dict) -> dict:
        """Create an item from its validated, serialized representation."""
        return {CONF_ID: item_id} | data

    def _deserialize_item(self, data: dict) -> dict:
        """Create an item from its validated, serialized representation."""
        return data

    def _serialize_item(self, item_id: str, item: dict) -> dict:
        """Return the serialized representation of an item for storing."""
        return item

    @callback
    def _data_to_save(self) -> SerializedStorageCollection:
        """Return JSON-compatible date for storing to file."""
        return self._base_data_to_save()


class IDLessCollection(YamlCollection):
    """A collection without IDs."""

    counter = 0

    async def async_load(self, data: list[dict]) -> None:
        """Load the collection. Overrides existing data."""
        await self.notify_changes(
            [
                CollectionChange(CHANGE_REMOVED, item_id, item)
                for item_id, item in list(self.data.items())
            ]
        )

        self.data.clear()

        for item in data:
            self.counter += 1
            item_id = f"fakeid-{self.counter}"

            self.data[item_id] = item

        await self.notify_changes(
            [
                CollectionChange(CHANGE_ADDED, item_id, item)
                for item_id, item in self.data.items()
            ]
        )


_GROUP_BY_KEY = attrgetter("change_type")


@dataclass(slots=True, frozen=True)
class _CollectionLifeCycle[_EntityT: Entity = Entity]:
    """Life cycle for a collection of entities."""

    domain: str
    platform: str
    entity_component: EntityComponent[_EntityT]
    collection: StorageCollection | YamlCollection
    entity_class: type[CollectionEntity]
    ent_reg: entity_registry.EntityRegistry
    entities: dict[str, CollectionEntity]

    @callback
    def async_setup(self) -> None:
        """Set up the collection life cycle."""
        self.collection.async_add_change_set_listener(self._collection_changed)

    def _entity_removed(self, item_id: str) -> None:
        """Remove entity from entities if it's removed or not added."""
        self.entities.pop(item_id, None)

    @callback
    def _add_entity(self, change_set: CollectionChange) -> CollectionEntity:
        item_id = change_set.item_id
        entity = self.collection.create_entity(self.entity_class, change_set.item)
        self.entities[item_id] = entity
        entity.async_on_remove(partial(self._entity_removed, item_id))
        return entity

    async def _remove_entity(self, change_set: CollectionChange) -> None:
        item_id = change_set.item_id
        ent_reg = self.ent_reg
        entities = self.entities
        ent_to_remove = ent_reg.async_get_entity_id(self.domain, self.platform, item_id)
        if ent_to_remove is not None:
            ent_reg.async_remove(ent_to_remove)
        elif entity := entities.get(item_id):
            await entity.async_remove(force_remove=True)
        # Unconditionally pop the entity from the entity list to avoid racing against
        # the entity registry event handled by Entity._async_registry_updated
        entities.pop(item_id, None)

    async def _update_entity(self, change_set: CollectionChange) -> None:
        if entity := self.entities.get(change_set.item_id):
            if change_set.item_hash:
                self.ent_reg.async_update_entity_options(
                    entity.entity_id, "collection", {"hash": change_set.item_hash}
                )
            await entity.async_update_config(change_set.item)

    async def _collection_changed(self, change_set: Iterable[CollectionChange]) -> None:
        """Handle a collection change."""
        # Create a new bucket every time we have a different change type
        # to ensure operations happen in order. We only group
        # the same change type.
        new_entities: list[CollectionEntity] = []
        coros: list[Coroutine[Any, Any, CollectionEntity | None]] = []
        grouped: Iterable[CollectionChange]
        for _, grouped in groupby(change_set, _GROUP_BY_KEY):
            for change in grouped:
                change_type = change.change_type
                if change_type == CHANGE_ADDED:
                    new_entities.append(self._add_entity(change))
                elif change_type == CHANGE_REMOVED:
                    coros.append(self._remove_entity(change))
                elif change_type == CHANGE_UPDATED:
                    coros.append(self._update_entity(change))

        if coros:
            await asyncio.gather(*coros)

        if new_entities:
            await self.entity_component.async_add_entities(new_entities)


@callback
def sync_entity_lifecycle[_EntityT: Entity = Entity](
    hass: HomeAssistant,
    domain: str,
    platform: str,
    entity_component: EntityComponent[_EntityT],
    collection: StorageCollection | YamlCollection,
    entity_class: type[CollectionEntity],
) -> None:
    """Map a collection to an entity component."""
    ent_reg = entity_registry.async_get(hass)
    _CollectionLifeCycle(
        domain, platform, entity_component, collection, entity_class, ent_reg, {}
    ).async_setup()


class StorageCollectionWebsocket[_StorageCollectionT: StorageCollection]:
    """Class to expose storage collection management over websocket."""

    def __init__(
        self,
        storage_collection: _StorageCollectionT,
        api_prefix: str,
        model_name: str,
        create_schema: VolDictType,
        update_schema: VolDictType,
    ) -> None:
        """Initialize a websocket CRUD."""
        self.storage_collection = storage_collection
        self.api_prefix = api_prefix
        self.model_name = model_name
        self.create_schema = create_schema
        self.update_schema = update_schema

        self._remove_subscription: CALLBACK_TYPE | None = None
        self._subscribers: set[tuple[websocket_api.ActiveConnection, int]] = set()

        assert self.api_prefix[-1] != "/", "API prefix should not end in /"

    @property
    def item_id_key(self) -> str:
        """Return item ID key."""
        return f"{self.model_name}_id"

    @callback
    def async_setup(self, hass: HomeAssistant) -> None:
        """Set up the websocket commands."""
        websocket_api.async_register_command(
            hass,
            f"{self.api_prefix}/list",
            self.ws_list_item,
            websocket_api.BASE_COMMAND_MESSAGE_SCHEMA.extend(
                {vol.Required("type"): f"{self.api_prefix}/list"}
            ),
        )

        websocket_api.async_register_command(
            hass,
            f"{self.api_prefix}/create",
            websocket_api.require_admin(
                websocket_api.async_response(self.ws_create_item)
            ),
            websocket_api.BASE_COMMAND_MESSAGE_SCHEMA.extend(
                {
                    **self.create_schema,
                    vol.Required("type"): f"{self.api_prefix}/create",
                }
            ),
        )

        websocket_api.async_register_command(
            hass,
            f"{self.api_prefix}/subscribe",
            self._ws_subscribe,
            websocket_api.BASE_COMMAND_MESSAGE_SCHEMA.extend(
                {vol.Required("type"): f"{self.api_prefix}/subscribe"}
            ),
        )

        websocket_api.async_register_command(
            hass,
            f"{self.api_prefix}/update",
            websocket_api.require_admin(
                websocket_api.async_response(self.ws_update_item)
            ),
            websocket_api.BASE_COMMAND_MESSAGE_SCHEMA.extend(
                {
                    **self.update_schema,
                    vol.Required("type"): f"{self.api_prefix}/update",
                    vol.Required(self.item_id_key): str,
                }
            ),
        )

        websocket_api.async_register_command(
            hass,
            f"{self.api_prefix}/delete",
            websocket_api.require_admin(
                websocket_api.async_response(self.ws_delete_item)
            ),
            websocket_api.BASE_COMMAND_MESSAGE_SCHEMA.extend(
                {
                    vol.Required("type"): f"{self.api_prefix}/delete",
                    vol.Required(self.item_id_key): str,
                }
            ),
        )

    @callback
    def ws_list_item(
        self, hass: HomeAssistant, connection: websocket_api.ActiveConnection, msg: dict
    ) -> None:
        """List items."""
        connection.send_result(msg["id"], self.storage_collection.async_items())

    async def ws_create_item(
        self, hass: HomeAssistant, connection: websocket_api.ActiveConnection, msg: dict
    ) -> None:
        """Create an item."""
        try:
            data = dict(msg)
            data.pop("id")
            data.pop("type")
            item = await self.storage_collection.async_create_item(data)
            connection.send_result(msg["id"], item)
        except vol.Invalid as err:
            connection.send_error(
                msg["id"],
                websocket_api.ERR_INVALID_FORMAT,
                humanize_error(data, err),
            )
        except ValueError as err:
            connection.send_error(msg["id"], websocket_api.ERR_INVALID_FORMAT, str(err))

    @callback
    def _ws_subscribe(
        self, hass: HomeAssistant, connection: websocket_api.ActiveConnection, msg: dict
    ) -> None:
        """Subscribe to collection updates."""

        async def async_change_listener(
            change_set: Iterable[CollectionChange],
        ) -> None:
            json_msg = [
                {
                    "change_type": change.change_type,
                    self.item_id_key: change.item_id,
                    "item": change.item,
                }
                for change in change_set
            ]
            for conn, msg_id in self._subscribers:
                conn.send_message(websocket_api.event_message(msg_id, json_msg))

        if not self._subscribers:
            self._remove_subscription = (
                self.storage_collection.async_add_change_set_listener(
                    async_change_listener
                )
            )

        self._subscribers.add((connection, msg["id"]))

        @callback
        def cancel_subscription() -> None:
            self._subscribers.remove((connection, msg["id"]))
            if not self._subscribers and self._remove_subscription:
                self._remove_subscription()
                self._remove_subscription = None

        connection.subscriptions[msg["id"]] = cancel_subscription

        connection.send_message(websocket_api.result_message(msg["id"]))

        json_msg = [
            {
                "change_type": CHANGE_ADDED,
                self.item_id_key: item_id,
                "item": item,
            }
            for item_id, item in self.storage_collection.data.items()
        ]
        connection.send_message(websocket_api.event_message(msg["id"], json_msg))

    async def ws_update_item(
        self, hass: HomeAssistant, connection: websocket_api.ActiveConnection, msg: dict
    ) -> None:
        """Update an item."""
        data = dict(msg)
        msg_id = data.pop("id")
        item_id = data.pop(self.item_id_key)
        data.pop("type")

        try:
            item = await self.storage_collection.async_update_item(item_id, data)
            connection.send_result(msg_id, item)
        except ItemNotFound:
            connection.send_error(
                msg["id"],
                websocket_api.ERR_NOT_FOUND,
                f"Unable to find {self.item_id_key} {item_id}",
            )
        except vol.Invalid as err:
            connection.send_error(
                msg["id"],
                websocket_api.ERR_INVALID_FORMAT,
                humanize_error(data, err),
            )
        except ValueError as err:
            connection.send_error(msg_id, websocket_api.ERR_INVALID_FORMAT, str(err))

    async def ws_delete_item(
        self, hass: HomeAssistant, connection: websocket_api.ActiveConnection, msg: dict
    ) -> None:
        """Delete an item."""
        try:
            await self.storage_collection.async_delete_item(msg[self.item_id_key])
        except ItemNotFound:
            connection.send_error(
                msg["id"],
                websocket_api.ERR_NOT_FOUND,
                f"Unable to find {self.item_id_key} {msg[self.item_id_key]}",
            )

        connection.send_result(msg["id"])


class DictStorageCollectionWebsocket(StorageCollectionWebsocket[DictStorageCollection]):
    """Class to expose storage collection management over websocket."""
</file>

<file path="condition.py">
"""Offer reusable conditions."""

from __future__ import annotations

import abc
from collections import deque
from collections.abc import Callable, Container, Coroutine, Generator, Iterable
from contextlib import contextmanager
from dataclasses import dataclass
from datetime import datetime, time as dt_time, timedelta
import functools as ft
import inspect
import logging
import re
import sys
from typing import (
    TYPE_CHECKING,
    Any,
    Final,
    Literal,
    Protocol,
    TypedDict,
    Unpack,
    cast,
    overload,
    override,
)

import voluptuous as vol

from homeassistant.const import (
    ATTR_DEVICE_CLASS,
    CONF_ABOVE,
    CONF_AFTER,
    CONF_ATTRIBUTE,
    CONF_BEFORE,
    CONF_BELOW,
    CONF_CONDITION,
    CONF_DEVICE_ID,
    CONF_ENABLED,
    CONF_ENTITY_ID,
    CONF_FOR,
    CONF_ID,
    CONF_MATCH,
    CONF_OPTIONS,
    CONF_SELECTOR,
    CONF_STATE,
    CONF_TARGET,
    CONF_VALUE_TEMPLATE,
    CONF_WEEKDAY,
    ENTITY_MATCH_ALL,
    ENTITY_MATCH_ANY,
    STATE_UNAVAILABLE,
    STATE_UNKNOWN,
    WEEKDAYS,
)
from homeassistant.core import HomeAssistant, State, callback, split_entity_id
from homeassistant.exceptions import (
    ConditionError,
    ConditionErrorContainer,
    ConditionErrorIndex,
    ConditionErrorMessage,
    HomeAssistantError,
    TemplateError,
)
from homeassistant.loader import (
    Integration,
    IntegrationNotFound,
    async_get_integration,
    async_get_integrations,
)
from homeassistant.util import dt as dt_util
from homeassistant.util.async_ import run_callback_threadsafe
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.yaml import load_yaml_dict

from . import config_validation as cv, entity_registry as er, selector
from .automation import (
    get_absolute_description_key,
    get_relative_description_key,
    move_options_fields_to_top_level,
)
from .integration_platform import async_process_integration_platforms
from .selector import TargetSelector
from .target import TargetSelection, async_extract_referenced_entity_ids
from .template import Template, render_complex
from .trace import (
    TraceElement,
    trace_append_element,
    trace_path,
    trace_path_get,
    trace_stack_cv,
    trace_stack_pop,
    trace_stack_push,
    trace_stack_top,
)
from .typing import ConfigType, TemplateVarsType

ASYNC_FROM_CONFIG_FORMAT = "async_{}_from_config"
FROM_CONFIG_FORMAT = "{}_from_config"
VALIDATE_CONFIG_FORMAT = "{}_validate_config"

_LOGGER = logging.getLogger(__name__)

_PLATFORM_ALIASES: dict[str | None, str | None] = {
    "and": None,
    "device": "device_automation",
    "not": None,
    "numeric_state": None,
    "or": None,
    "state": None,
    "template": None,
    "time": None,
    "trigger": None,
}

INPUT_ENTITY_ID = re.compile(
    r"^input_(?:select|text|number|boolean|datetime)\.(?!.+__)(?!_)[\da-z_]+(?<!_)$"
)


CONDITION_DESCRIPTION_CACHE: HassKey[dict[str, dict[str, Any] | None]] = HassKey(
    "condition_description_cache"
)
CONDITION_DISABLED_CONDITIONS: HassKey[set[str]] = HassKey(
    "condition_disabled_conditions"
)
CONDITION_PLATFORM_SUBSCRIPTIONS: HassKey[
    list[Callable[[set[str]], Coroutine[Any, Any, None]]]
] = HassKey("condition_platform_subscriptions")
CONDITIONS: HassKey[dict[str, str]] = HassKey("conditions")


# Basic schemas to sanity check the condition descriptions,
# full validation is done by hassfest.conditions
_FIELD_DESCRIPTION_SCHEMA = vol.Schema(
    {
        vol.Optional(CONF_SELECTOR): selector.validate_selector,
    },
    extra=vol.ALLOW_EXTRA,
)

_CONDITION_DESCRIPTION_SCHEMA = vol.Schema(
    {
        vol.Optional("target"): TargetSelector.CONFIG_SCHEMA,
        vol.Optional("fields"): vol.Schema({str: _FIELD_DESCRIPTION_SCHEMA}),
    },
    extra=vol.ALLOW_EXTRA,
)


def starts_with_dot(key: str) -> str:
    """Check if key starts with dot."""
    if not key.startswith("."):
        raise vol.Invalid("Key does not start with .")
    return key


_CONDITIONS_DESCRIPTION_SCHEMA = vol.Schema(
    {
        vol.Remove(vol.All(str, starts_with_dot)): object,
        cv.underscore_slug: vol.Any(None, _CONDITION_DESCRIPTION_SCHEMA),
    }
)


async def async_setup(hass: HomeAssistant) -> None:
    """Set up the condition helper."""
    from homeassistant.components import automation, labs  # noqa: PLC0415

    hass.data[CONDITION_DESCRIPTION_CACHE] = {}
    hass.data[CONDITION_DISABLED_CONDITIONS] = set()
    hass.data[CONDITION_PLATFORM_SUBSCRIPTIONS] = []
    hass.data[CONDITIONS] = {}

    @callback
    def new_triggers_conditions_listener() -> None:
        """Handle new_triggers_conditions flag change."""
        # Invalidate the cache
        hass.data[CONDITION_DESCRIPTION_CACHE] = {}
        hass.data[CONDITION_DISABLED_CONDITIONS] = set()

    labs.async_listen(
        hass,
        automation.DOMAIN,
        automation.NEW_TRIGGERS_CONDITIONS_FEATURE_FLAG,
        new_triggers_conditions_listener,
    )

    await async_process_integration_platforms(
        hass, "condition", _register_condition_platform, wait_for_platforms=True
    )


@callback
def async_subscribe_platform_events(
    hass: HomeAssistant,
    on_event: Callable[[set[str]], Coroutine[Any, Any, None]],
) -> Callable[[], None]:
    """Subscribe to condition platform events."""
    condition_platform_event_subscriptions = hass.data[CONDITION_PLATFORM_SUBSCRIPTIONS]

    def remove_subscription() -> None:
        condition_platform_event_subscriptions.remove(on_event)

    condition_platform_event_subscriptions.append(on_event)
    return remove_subscription


async def _register_condition_platform(
    hass: HomeAssistant, integration_domain: str, platform: ConditionProtocol
) -> None:
    """Register a condition platform and notify listeners.

    If the condition platform does not provide any conditions, or it is disabled,
    listeners will not be notified.
    """
    from homeassistant.components import automation  # noqa: PLC0415

    new_conditions: set[str] = set()

    if hasattr(platform, "async_get_conditions"):
        for condition_key in await platform.async_get_conditions(hass):
            condition_key = get_absolute_description_key(
                integration_domain, condition_key
            )
            hass.data[CONDITIONS][condition_key] = integration_domain
            new_conditions.add(condition_key)
        if not new_conditions:
            _LOGGER.debug(
                "Integration %s returned no conditions in async_get_conditions",
                integration_domain,
            )
            return
    else:
        _LOGGER.debug(
            "Integration %s does not provide condition support, skipping",
            integration_domain,
        )
        return

    if automation.is_disabled_experimental_condition(hass, integration_domain):
        _LOGGER.debug("Conditions for integration %s are disabled", integration_domain)
        return

    # We don't use gather here because gather adds additional overhead
    # when wrapping each coroutine in a task, and we expect our listeners
    # to call condition.async_get_all_descriptions which will only yield
    # the first time it's called, after that it returns cached data.
    for listener in hass.data[CONDITION_PLATFORM_SUBSCRIPTIONS]:
        try:
            await listener(new_conditions)
        except Exception:
            _LOGGER.exception("Error while notifying condition platform listener")


_CONDITION_BASE_SCHEMA = vol.Schema(
    {
        **cv.CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): str,
    }
)
_CONDITION_SCHEMA = _CONDITION_BASE_SCHEMA.extend(
    {
        vol.Optional(CONF_OPTIONS): object,
        vol.Optional(CONF_TARGET): cv.TARGET_FIELDS,
    }
)


class Condition(abc.ABC):
    """Condition class."""

    _hass: HomeAssistant

    @classmethod
    async def async_validate_complete_config(
        cls, hass: HomeAssistant, complete_config: ConfigType
    ) -> ConfigType:
        """Validate complete config.

        The complete config includes fields that are generic to all conditions,
        such as the alias.
        This method should be overridden by conditions that need to migrate
        from the old-style config.
        """
        complete_config = _CONDITION_SCHEMA(complete_config)

        specific_config: ConfigType = {}
        for key in (CONF_OPTIONS, CONF_TARGET):
            if key in complete_config:
                specific_config[key] = complete_config.pop(key)
        specific_config = await cls.async_validate_config(hass, specific_config)

        for key in (CONF_OPTIONS, CONF_TARGET):
            if key in specific_config:
                complete_config[key] = specific_config[key]

        return complete_config

    @classmethod
    @abc.abstractmethod
    async def async_validate_config(
        cls, hass: HomeAssistant, config: ConfigType
    ) -> ConfigType:
        """Validate config."""

    def __init__(self, hass: HomeAssistant, config: ConditionConfig) -> None:
        """Initialize condition."""
        self._hass = hass

    @abc.abstractmethod
    async def async_get_checker(self) -> ConditionChecker:
        """Get the condition checker."""


ATTR_BEHAVIOR: Final = "behavior"
BEHAVIOR_ANY: Final = "any"
BEHAVIOR_ALL: Final = "all"

STATE_CONDITION_OPTIONS_SCHEMA: dict[vol.Marker, Any] = {
    vol.Required(ATTR_BEHAVIOR, default=BEHAVIOR_ANY): vol.In(
        [BEHAVIOR_ANY, BEHAVIOR_ALL]
    ),
}
ENTITY_STATE_CONDITION_SCHEMA_ANY_ALL = vol.Schema(
    {
        vol.Required(CONF_TARGET): cv.TARGET_FIELDS,
        vol.Required(CONF_OPTIONS): STATE_CONDITION_OPTIONS_SCHEMA,
    }
)


class EntityStateConditionBase(Condition):
    """State condition."""

    _domain: str
    _schema: vol.Schema = ENTITY_STATE_CONDITION_SCHEMA_ANY_ALL
    _states: set[str]

    @override
    @classmethod
    async def async_validate_config(
        cls, hass: HomeAssistant, config: ConfigType
    ) -> ConfigType:
        """Validate config."""
        return cast(ConfigType, cls._schema(config))

    def __init__(self, hass: HomeAssistant, config: ConditionConfig) -> None:
        """Initialize condition."""
        super().__init__(hass, config)
        if TYPE_CHECKING:
            assert config.target
            assert config.options
        self._target_selection = TargetSelection(config.target)
        self._behavior = config.options[ATTR_BEHAVIOR]

    def entity_filter(self, entities: set[str]) -> set[str]:
        """Filter entities of this domain."""
        return {
            entity_id
            for entity_id in entities
            if split_entity_id(entity_id)[0] == self._domain
        }

    @override
    async def async_get_checker(self) -> ConditionChecker:
        """Get the condition checker."""

        def check_any_match_state(states: list[str]) -> bool:
            """Test if any entity match the state."""
            return any(state in self._states for state in states)

        def check_all_match_state(states: list[str]) -> bool:
            """Test if all entities match the state."""
            return all(state in self._states for state in states)

        matcher: Callable[[list[str]], bool]
        if self._behavior == BEHAVIOR_ANY:
            matcher = check_any_match_state
        elif self._behavior == BEHAVIOR_ALL:
            matcher = check_all_match_state

        def test_state(**kwargs: Unpack[ConditionCheckParams]) -> bool:
            """Test state condition."""
            targeted_entities = async_extract_referenced_entity_ids(
                self._hass, self._target_selection, expand_group=False
            )
            referenced_entity_ids = targeted_entities.referenced.union(
                targeted_entities.indirectly_referenced
            )
            filtered_entity_ids = self.entity_filter(referenced_entity_ids)
            entity_states = [
                _state.state
                for entity_id in filtered_entity_ids
                if (_state := self._hass.states.get(entity_id))
                and _state.state not in (STATE_UNAVAILABLE, STATE_UNKNOWN)
            ]
            return matcher(entity_states)

        return test_state


def make_entity_state_condition(
    domain: str, states: str | set[str]
) -> type[EntityStateConditionBase]:
    """Create a condition for entity state changes to specific state(s)."""

    if isinstance(states, str):
        states_set = {states}
    else:
        states_set = states

    class CustomCondition(EntityStateConditionBase):
        """Condition for entity state."""

        _domain = domain
        _states = states_set

    return CustomCondition


class ConditionProtocol(Protocol):
    """Define the format of condition modules."""

    async def async_get_conditions(
        self, hass: HomeAssistant
    ) -> dict[str, type[Condition]]:
        """Return the conditions provided by this integration."""


@dataclass(slots=True)
class ConditionConfig:
    """Condition config."""

    options: dict[str, Any] | None = None
    target: dict[str, Any] | None = None


class ConditionCheckParams(TypedDict, total=False):
    """Condition check params."""

    variables: TemplateVarsType


class ConditionChecker(Protocol):
    """Protocol for condition checker callable with typed kwargs."""

    def __call__(self, **kwargs: Unpack[ConditionCheckParams]) -> bool:
        """Check the condition."""


type ConditionCheckerType = Callable[[HomeAssistant, TemplateVarsType], bool]
type ConditionCheckerTypeOptional = Callable[
    [HomeAssistant, TemplateVarsType], bool | None
]


def condition_trace_append(variables: TemplateVarsType, path: str) -> TraceElement:
    """Append a TraceElement to trace[path]."""
    trace_element = TraceElement(variables, path)
    trace_append_element(trace_element)
    return trace_element


def condition_trace_set_result(result: bool, **kwargs: Any) -> None:
    """Set the result of TraceElement at the top of the stack."""
    node = trace_stack_top(trace_stack_cv)

    # The condition function may be called directly, in which case tracing
    # is not setup
    if not node:
        return

    node.set_result(result=result, **kwargs)


def condition_trace_update_result(**kwargs: Any) -> None:
    """Update the result of TraceElement at the top of the stack."""
    node = trace_stack_top(trace_stack_cv)

    # The condition function may be called directly, in which case tracing
    # is not setup
    if not node:
        return

    node.update_result(**kwargs)


@contextmanager
def trace_condition(variables: TemplateVarsType) -> Generator[TraceElement]:
    """Trace condition evaluation."""
    should_pop = True
    trace_element = trace_stack_top(trace_stack_cv)
    if trace_element and trace_element.reuse_by_child:
        should_pop = False
        trace_element.reuse_by_child = False
    else:
        trace_element = condition_trace_append(variables, trace_path_get())
        trace_stack_push(trace_stack_cv, trace_element)
    try:
        yield trace_element
    except Exception as ex:
        trace_element.set_error(ex)
        raise
    finally:
        if should_pop:
            trace_stack_pop(trace_stack_cv)


@overload
def trace_condition_function(
    condition: ConditionCheckerType,
) -> ConditionCheckerType: ...


@overload
def trace_condition_function(
    condition: ConditionCheckerTypeOptional,
) -> ConditionCheckerTypeOptional: ...


def trace_condition_function(
    condition: ConditionCheckerType | ConditionCheckerTypeOptional,
) -> ConditionCheckerType | ConditionCheckerTypeOptional:
    """Wrap a condition function to enable basic tracing."""

    @ft.wraps(condition)
    def wrapper(hass: HomeAssistant, variables: TemplateVarsType = None) -> bool | None:
        """Trace condition."""
        with trace_condition(variables):
            result = condition(hass, variables)
            condition_trace_update_result(result=result)
            return result

    return wrapper


async def _async_get_condition_platform(
    hass: HomeAssistant, condition_key: str
) -> tuple[str, ConditionProtocol | None]:
    from homeassistant.components import automation  # noqa: PLC0415

    platform_and_sub_type = condition_key.split(".")
    platform: str | None = platform_and_sub_type[0]
    platform = _PLATFORM_ALIASES.get(platform, platform)
    if platform is None:
        return "", None

    if automation.is_disabled_experimental_condition(hass, platform):
        raise vol.Invalid(
            f"Condition '{condition_key}' requires the experimental 'New triggers and "
            "conditions' feature to be enabled in Home Assistant Labs settings "
            f"(feature flag: '{automation.NEW_TRIGGERS_CONDITIONS_FEATURE_FLAG}')"
        )

    try:
        integration = await async_get_integration(hass, platform)
    except IntegrationNotFound:
        raise HomeAssistantError(
            f'Invalid condition "{condition_key}" specified'
        ) from None
    try:
        return platform, await integration.async_get_platform("condition")
    except ImportError:
        raise HomeAssistantError(
            f"Integration '{platform}' does not provide condition support"
        ) from None


async def _async_get_checker(condition: Condition) -> ConditionCheckerType:
    new_checker = await condition.async_get_checker()

    @trace_condition_function
    def checker(hass: HomeAssistant, variables: TemplateVarsType = None) -> bool:
        return new_checker(variables=variables)

    return checker


async def async_from_config(
    hass: HomeAssistant,
    config: ConfigType,
) -> ConditionCheckerTypeOptional:
    """Turn a condition configuration into a method.

    Should be run on the event loop.
    """
    # Check if condition is not enabled
    if CONF_ENABLED in config:
        enabled = config[CONF_ENABLED]
        if isinstance(enabled, Template):
            try:
                enabled = enabled.async_render(limited=True)
            except TemplateError as err:
                raise HomeAssistantError(
                    f"Error rendering condition enabled template: {err}"
                ) from err
        if not enabled:

            @trace_condition_function
            def disabled_condition(
                hass: HomeAssistant, variables: TemplateVarsType = None
            ) -> bool | None:
                """Condition not enabled, will act as if it didn't exist."""
                return None

            return disabled_condition

    condition_key: str = config[CONF_CONDITION]
    factory: Any = None
    platform_domain, platform = await _async_get_condition_platform(hass, condition_key)

    if platform is not None:
        condition_descriptors = await platform.async_get_conditions(hass)
        relative_condition_key = get_relative_description_key(
            platform_domain, condition_key
        )
        condition_cls = condition_descriptors[relative_condition_key]
        condition = condition_cls(
            hass,
            ConditionConfig(
                options=config.get(CONF_OPTIONS),
                target=config.get(CONF_TARGET),
            ),
        )
        return await _async_get_checker(condition)

    for fmt in (ASYNC_FROM_CONFIG_FORMAT, FROM_CONFIG_FORMAT):
        factory = getattr(sys.modules[__name__], fmt.format(condition_key), None)

        if factory:
            break

    # Check for partials to properly determine if coroutine function
    check_factory = factory
    while isinstance(check_factory, ft.partial):
        check_factory = check_factory.func

    if inspect.iscoroutinefunction(check_factory):
        return cast(ConditionCheckerType, await factory(hass, config))
    return cast(ConditionCheckerType, factory(config))


async def async_and_from_config(
    hass: HomeAssistant, config: ConfigType
) -> ConditionCheckerType:
    """Create multi condition matcher using 'AND'."""
    checks = [await async_from_config(hass, entry) for entry in config["conditions"]]

    @trace_condition_function
    def if_and_condition(
        hass: HomeAssistant, variables: TemplateVarsType = None
    ) -> bool:
        """Test and condition."""
        errors = []
        for index, check in enumerate(checks):
            try:
                with trace_path(["conditions", str(index)]):
                    if check(hass, variables) is False:
                        return False
            except ConditionError as ex:
                errors.append(
                    ConditionErrorIndex("and", index=index, total=len(checks), error=ex)
                )

        # Raise the errors if no check was false
        if errors:
            raise ConditionErrorContainer("and", errors=errors)

        return True

    return if_and_condition


async def async_or_from_config(
    hass: HomeAssistant, config: ConfigType
) -> ConditionCheckerType:
    """Create multi condition matcher using 'OR'."""
    checks = [await async_from_config(hass, entry) for entry in config["conditions"]]

    @trace_condition_function
    def if_or_condition(
        hass: HomeAssistant, variables: TemplateVarsType = None
    ) -> bool:
        """Test or condition."""
        errors = []
        for index, check in enumerate(checks):
            try:
                with trace_path(["conditions", str(index)]):
                    if check(hass, variables) is True:
                        return True
            except ConditionError as ex:
                errors.append(
                    ConditionErrorIndex("or", index=index, total=len(checks), error=ex)
                )

        # Raise the errors if no check was true
        if errors:
            raise ConditionErrorContainer("or", errors=errors)

        return False

    return if_or_condition


async def async_not_from_config(
    hass: HomeAssistant, config: ConfigType
) -> ConditionCheckerType:
    """Create multi condition matcher using 'NOT'."""
    checks = [await async_from_config(hass, entry) for entry in config["conditions"]]

    @trace_condition_function
    def if_not_condition(
        hass: HomeAssistant, variables: TemplateVarsType = None
    ) -> bool:
        """Test not condition."""
        errors = []
        for index, check in enumerate(checks):
            try:
                with trace_path(["conditions", str(index)]):
                    if check(hass, variables):
                        return False
            except ConditionError as ex:
                errors.append(
                    ConditionErrorIndex("not", index=index, total=len(checks), error=ex)
                )

        # Raise the errors if no check was true
        if errors:
            raise ConditionErrorContainer("not", errors=errors)

        return True

    return if_not_condition


def numeric_state(
    hass: HomeAssistant,
    entity: str | State | None,
    below: float | str | None = None,
    above: float | str | None = None,
    value_template: Template | None = None,
    variables: TemplateVarsType = None,
) -> bool:
    """Test a numeric state condition."""
    return run_callback_threadsafe(
        hass.loop,
        async_numeric_state,
        hass,
        entity,
        below,
        above,
        value_template,
        variables,
    ).result()


def async_numeric_state(
    hass: HomeAssistant,
    entity: str | State | None,
    below: float | str | None = None,
    above: float | str | None = None,
    value_template: Template | None = None,
    variables: TemplateVarsType = None,
    attribute: str | None = None,
) -> bool:
    """Test a numeric state condition."""
    if entity is None:
        raise ConditionErrorMessage("numeric_state", "no entity specified")

    if isinstance(entity, str):
        entity_id = entity

        if (entity := hass.states.get(entity)) is None:
            raise ConditionErrorMessage("numeric_state", f"unknown entity {entity_id}")
    else:
        entity_id = entity.entity_id

    if attribute is not None and attribute not in entity.attributes:
        condition_trace_set_result(
            False,
            message=f"attribute '{attribute}' of entity {entity_id} does not exist",
        )
        return False

    value: Any = None
    if value_template is None:
        if attribute is None:
            value = entity.state
        else:
            value = entity.attributes.get(attribute)
    else:
        variables = dict(variables or {})
        variables["state"] = entity
        try:
            value = value_template.async_render(variables)
        except TemplateError as ex:
            raise ConditionErrorMessage(
                "numeric_state", f"template error: {ex}"
            ) from ex

    # Known states or attribute values that never match the numeric condition
    if value in (None, STATE_UNAVAILABLE, STATE_UNKNOWN):
        condition_trace_set_result(
            False,
            message=f"value '{value}' is non-numeric and treated as False",
        )
        return False

    try:
        fvalue = float(value)
    except (ValueError, TypeError) as ex:
        raise ConditionErrorMessage(
            "numeric_state",
            f"entity {entity_id} state '{value}' cannot be processed as a number",
        ) from ex

    if below is not None:
        if isinstance(below, str):
            if not (below_entity := hass.states.get(below)):
                raise ConditionErrorMessage(
                    "numeric_state", f"unknown 'below' entity {below}"
                )
            if below_entity.state in (
                STATE_UNAVAILABLE,
                STATE_UNKNOWN,
            ):
                return False
            try:
                if fvalue >= float(below_entity.state):
                    condition_trace_set_result(
                        False,
                        state=fvalue,
                        wanted_state_below=float(below_entity.state),
                    )
                    return False
            except (ValueError, TypeError) as ex:
                raise ConditionErrorMessage(
                    "numeric_state",
                    (
                        f"the 'below' entity {below} state '{below_entity.state}'"
                        " cannot be processed as a number"
                    ),
                ) from ex
        elif fvalue >= below:
            condition_trace_set_result(False, state=fvalue, wanted_state_below=below)
            return False

    if above is not None:
        if isinstance(above, str):
            if not (above_entity := hass.states.get(above)):
                raise ConditionErrorMessage(
                    "numeric_state", f"unknown 'above' entity {above}"
                )
            if above_entity.state in (
                STATE_UNAVAILABLE,
                STATE_UNKNOWN,
            ):
                return False
            try:
                if fvalue <= float(above_entity.state):
                    condition_trace_set_result(
                        False,
                        state=fvalue,
                        wanted_state_above=float(above_entity.state),
                    )
                    return False
            except (ValueError, TypeError) as ex:
                raise ConditionErrorMessage(
                    "numeric_state",
                    (
                        f"the 'above' entity {above} state '{above_entity.state}'"
                        " cannot be processed as a number"
                    ),
                ) from ex
        elif fvalue <= above:
            condition_trace_set_result(False, state=fvalue, wanted_state_above=above)
            return False

    condition_trace_set_result(True, state=fvalue)
    return True


def async_numeric_state_from_config(config: ConfigType) -> ConditionCheckerType:
    """Wrap action method with state based condition."""
    entity_ids = config.get(CONF_ENTITY_ID, [])
    attribute = config.get(CONF_ATTRIBUTE)
    below = config.get(CONF_BELOW)
    above = config.get(CONF_ABOVE)
    value_template = config.get(CONF_VALUE_TEMPLATE)

    @trace_condition_function
    def if_numeric_state(
        hass: HomeAssistant, variables: TemplateVarsType = None
    ) -> bool:
        """Test numeric state condition."""
        errors = []
        for index, entity_id in enumerate(entity_ids):
            try:
                with trace_path(["entity_id", str(index)]), trace_condition(variables):
                    if not async_numeric_state(
                        hass,
                        entity_id,
                        below,
                        above,
                        value_template,
                        variables,
                        attribute,
                    ):
                        return False
            except ConditionError as ex:
                errors.append(
                    ConditionErrorIndex(
                        "numeric_state", index=index, total=len(entity_ids), error=ex
                    )
                )

        # Raise the errors if no check was false
        if errors:
            raise ConditionErrorContainer("numeric_state", errors=errors)

        return True

    return if_numeric_state


def state(
    hass: HomeAssistant,
    entity: str | State | None,
    req_state: Any,
    for_period: timedelta | None = None,
    attribute: str | None = None,
    variables: TemplateVarsType = None,
) -> bool:
    """Test if state matches requirements.

    Async friendly.
    """
    if entity is None:
        raise ConditionErrorMessage("state", "no entity specified")

    if isinstance(entity, str):
        entity_id = entity

        if (entity := hass.states.get(entity)) is None:
            raise ConditionErrorMessage("state", f"unknown entity {entity_id}")
    else:
        entity_id = entity.entity_id

    if attribute is not None and attribute not in entity.attributes:
        condition_trace_set_result(
            False,
            message=f"attribute '{attribute}' of entity {entity_id} does not exist",
        )
        return False

    assert isinstance(entity, State)

    if attribute is None:
        value: Any = entity.state
    else:
        value = entity.attributes.get(attribute)

    if not isinstance(req_state, list):
        req_state = [req_state]

    is_state = False
    for req_state_value in req_state:
        state_value = req_state_value
        if (
            isinstance(req_state_value, str)
            and INPUT_ENTITY_ID.match(req_state_value) is not None
        ):
            if not (state_entity := hass.states.get(req_state_value)):
                raise ConditionErrorMessage(
                    "state", f"the 'state' entity {req_state_value} is unavailable"
                )
            state_value = state_entity.state
        is_state = value == state_value
        if is_state:
            break

    if for_period is None or not is_state:
        condition_trace_set_result(is_state, state=value, wanted_state=state_value)
        return is_state

    try:
        for_period = cv.positive_time_period(render_complex(for_period, variables))
    except TemplateError as ex:
        raise ConditionErrorMessage("state", f"template error: {ex}") from ex
    except vol.Invalid as ex:
        raise ConditionErrorMessage("state", f"schema error: {ex}") from ex

    duration = dt_util.utcnow() - cast(timedelta, for_period)
    duration_ok = duration > entity.last_changed
    condition_trace_set_result(duration_ok, state=value, duration=duration)
    return duration_ok


def state_from_config(config: ConfigType) -> ConditionCheckerType:
    """Wrap action method with state based condition."""
    entity_ids = config.get(CONF_ENTITY_ID, [])
    req_states: str | list[str] = config.get(CONF_STATE, [])
    for_period = config.get(CONF_FOR)
    attribute = config.get(CONF_ATTRIBUTE)
    match = config.get(CONF_MATCH, ENTITY_MATCH_ALL)

    if not isinstance(req_states, list):
        req_states = [req_states]

    @trace_condition_function
    def if_state(hass: HomeAssistant, variables: TemplateVarsType = None) -> bool:
        """Test if condition."""
        errors = []
        result: bool = match != ENTITY_MATCH_ANY
        for index, entity_id in enumerate(entity_ids):
            try:
                with trace_path(["entity_id", str(index)]), trace_condition(variables):
                    if state(
                        hass, entity_id, req_states, for_period, attribute, variables
                    ):
                        result = True
                    elif match == ENTITY_MATCH_ALL:
                        return False
            except ConditionError as ex:
                errors.append(
                    ConditionErrorIndex(
                        "state", index=index, total=len(entity_ids), error=ex
                    )
                )

        # Raise the errors if no check was false
        if errors:
            raise ConditionErrorContainer("state", errors=errors)

        return result

    return if_state


def template(
    hass: HomeAssistant, value_template: Template, variables: TemplateVarsType = None
) -> bool:
    """Test if template condition matches."""
    return run_callback_threadsafe(
        hass.loop, async_template, hass, value_template, variables
    ).result()


def async_template(
    hass: HomeAssistant,
    value_template: Template,
    variables: TemplateVarsType = None,
    trace_result: bool = True,
) -> bool:
    """Test if template condition matches."""
    try:
        info = value_template.async_render_to_info(variables, parse_result=False)
        value = info.result()
    except TemplateError as ex:
        raise ConditionErrorMessage("template", str(ex)) from ex

    result = value.lower() == "true"
    if trace_result:
        condition_trace_set_result(result, entities=list(info.entities))
    return result


def async_template_from_config(config: ConfigType) -> ConditionCheckerType:
    """Wrap action method with state based condition."""
    value_template = cast(Template, config.get(CONF_VALUE_TEMPLATE))

    @trace_condition_function
    def template_if(hass: HomeAssistant, variables: TemplateVarsType = None) -> bool:
        """Validate template based if-condition."""
        return async_template(hass, value_template, variables)

    return template_if


def time(
    hass: HomeAssistant,
    before: dt_time | str | None = None,
    after: dt_time | str | None = None,
    weekday: str | Container[str] | None = None,
) -> bool:
    """Test if local time condition matches.

    Handle the fact that time is continuous and we may be testing for
    a period that crosses midnight. In that case it is easier to test
    for the opposite. "(23:59 <= now < 00:01)" would be the same as
    "not (00:01 <= now < 23:59)".
    """
    from homeassistant.components.sensor import SensorDeviceClass  # noqa: PLC0415

    now = dt_util.now()
    now_time = now.time()

    if after is None:
        after = dt_time(0)
    elif isinstance(after, str):
        if not (after_entity := hass.states.get(after)):
            raise ConditionErrorMessage("time", f"unknown 'after' entity {after}")
        if after_entity.domain == "input_datetime":
            after = dt_time(
                after_entity.attributes.get("hour", 23),
                after_entity.attributes.get("minute", 59),
                after_entity.attributes.get("second", 59),
            )
        elif after_entity.domain == "time" and after_entity.state not in (
            STATE_UNAVAILABLE,
            STATE_UNKNOWN,
        ):
            after = datetime.strptime(after_entity.state, "%H:%M:%S").time()
        elif (
            after_entity.attributes.get(ATTR_DEVICE_CLASS)
            == SensorDeviceClass.TIMESTAMP
        ) and after_entity.state not in (
            STATE_UNAVAILABLE,
            STATE_UNKNOWN,
        ):
            after_datetime = dt_util.parse_datetime(after_entity.state)
            if after_datetime is None:
                return False
            after = dt_util.as_local(after_datetime).time()
        else:
            return False

    if before is None:
        before = dt_time(23, 59, 59, 999999)
    elif isinstance(before, str):
        if not (before_entity := hass.states.get(before)):
            raise ConditionErrorMessage("time", f"unknown 'before' entity {before}")
        if before_entity.domain == "input_datetime":
            before = dt_time(
                before_entity.attributes.get("hour", 23),
                before_entity.attributes.get("minute", 59),
                before_entity.attributes.get("second", 59),
            )
        elif before_entity.domain == "time":
            try:
                before = datetime.strptime(before_entity.state, "%H:%M:%S").time()
            except ValueError:
                return False
        elif (
            before_entity.attributes.get(ATTR_DEVICE_CLASS)
            == SensorDeviceClass.TIMESTAMP
        ) and before_entity.state not in (
            STATE_UNAVAILABLE,
            STATE_UNKNOWN,
        ):
            before_timedatime = dt_util.parse_datetime(before_entity.state)
            if before_timedatime is None:
                return False
            before = dt_util.as_local(before_timedatime).time()
        else:
            return False

    if after < before:
        condition_trace_update_result(after=after, now_time=now_time, before=before)
        if not after <= now_time < before:
            return False
    else:
        condition_trace_update_result(after=after, now_time=now_time, before=before)
        if before <= now_time < after:
            return False

    if weekday is not None:
        now_weekday = WEEKDAYS[now.weekday()]

        condition_trace_update_result(weekday=weekday, now_weekday=now_weekday)
        if (
            isinstance(weekday, str) and weekday != now_weekday
        ) or now_weekday not in weekday:
            return False

    return True


def time_from_config(config: ConfigType) -> ConditionCheckerType:
    """Wrap action method with time based condition."""
    before = config.get(CONF_BEFORE)
    after = config.get(CONF_AFTER)
    weekday = config.get(CONF_WEEKDAY)

    @trace_condition_function
    def time_if(hass: HomeAssistant, variables: TemplateVarsType = None) -> bool:
        """Validate time based if-condition."""
        return time(hass, before, after, weekday)

    return time_if


async def async_trigger_from_config(
    hass: HomeAssistant, config: ConfigType
) -> ConditionCheckerType:
    """Test a trigger condition."""
    trigger_id = config[CONF_ID]

    @trace_condition_function
    def trigger_if(hass: HomeAssistant, variables: TemplateVarsType = None) -> bool:
        """Validate trigger based if-condition."""
        return (
            variables is not None
            and "trigger" in variables
            and variables["trigger"].get("id") in trigger_id
        )

    return trigger_if


def numeric_state_validate_config(
    hass: HomeAssistant, config: ConfigType
) -> ConfigType:
    """Validate numeric_state condition config."""

    registry = er.async_get(hass)
    config = dict(config)
    config[CONF_ENTITY_ID] = er.async_validate_entity_ids(
        registry, cv.entity_ids_or_uuids(config[CONF_ENTITY_ID])
    )
    return config


def state_validate_config(hass: HomeAssistant, config: ConfigType) -> ConfigType:
    """Validate state condition config."""

    registry = er.async_get(hass)
    config = dict(config)
    config[CONF_ENTITY_ID] = er.async_validate_entity_ids(
        registry, cv.entity_ids_or_uuids(config[CONF_ENTITY_ID])
    )
    return config


async def async_validate_condition_config(
    hass: HomeAssistant, config: ConfigType
) -> ConfigType:
    """Validate config."""
    condition_key: str = config[CONF_CONDITION]

    if condition_key in ("and", "not", "or"):
        conditions = []
        for sub_cond in config["conditions"]:
            sub_cond = await async_validate_condition_config(hass, sub_cond)
            conditions.append(sub_cond)
        config["conditions"] = conditions
        return config

    platform_domain, platform = await _async_get_condition_platform(hass, condition_key)

    if platform is not None:
        condition_descriptors = await platform.async_get_conditions(hass)
        relative_condition_key = get_relative_description_key(
            platform_domain, condition_key
        )
        if not (condition_class := condition_descriptors.get(relative_condition_key)):
            raise vol.Invalid(f"Invalid condition '{condition_key}' specified")
        return await condition_class.async_validate_complete_config(hass, config)

    config = move_options_fields_to_top_level(config, _CONDITION_BASE_SCHEMA)

    if condition_key in ("numeric_state", "state"):
        validator = cast(
            Callable[[HomeAssistant, ConfigType], ConfigType],
            getattr(
                sys.modules[__name__], VALIDATE_CONFIG_FORMAT.format(condition_key)
            ),
        )
        return validator(hass, config)

    return config


async def async_validate_conditions_config(
    hass: HomeAssistant, conditions: list[ConfigType]
) -> list[ConfigType | Template]:
    """Validate config."""
    # No gather here because async_validate_condition_config is unlikely
    # to suspend and the overhead of creating many tasks is not worth it
    return [await async_validate_condition_config(hass, cond) for cond in conditions]


async def async_conditions_from_config(
    hass: HomeAssistant,
    condition_configs: list[ConfigType],
    logger: logging.Logger,
    name: str,
) -> Callable[[TemplateVarsType], bool]:
    """AND all conditions."""
    checks = [
        await async_from_config(hass, condition_config)
        for condition_config in condition_configs
    ]

    def check_conditions(variables: TemplateVarsType = None) -> bool:
        """AND all conditions."""
        errors: list[ConditionErrorIndex] = []
        for index, check in enumerate(checks):
            try:
                with trace_path(["condition", str(index)]):
                    if check(hass, variables) is False:
                        return False
            except ConditionError as ex:
                errors.append(
                    ConditionErrorIndex(
                        "condition", index=index, total=len(checks), error=ex
                    )
                )

        if errors:
            logger.warning(
                "Error evaluating condition in '%s':\n%s",
                name,
                ConditionErrorContainer("condition", errors=errors),
            )
            return False

        return True

    return check_conditions


@callback
def async_extract_entities(config: ConfigType | Template) -> set[str]:
    """Extract entities from a condition."""
    referenced: set[str] = set()
    to_process = deque([config])

    while to_process:
        config = to_process.popleft()
        if isinstance(config, Template):
            continue

        condition = config[CONF_CONDITION]

        if condition in ("and", "not", "or"):
            to_process.extend(config["conditions"])
            continue

        entity_ids = config.get(CONF_ENTITY_ID)

        if isinstance(entity_ids, str):
            entity_ids = [entity_ids]

        if entity_ids is not None:
            referenced.update(entity_ids)

        if target_entities := _get_targets_from_condition_config(
            config, CONF_ENTITY_ID
        ):
            referenced.update(target_entities)

    return referenced


@callback
def async_extract_devices(config: ConfigType | Template) -> set[str]:
    """Extract devices from a condition."""
    referenced: set[str] = set()
    to_process = deque([config])

    while to_process:
        config = to_process.popleft()
        if isinstance(config, Template):
            continue

        condition = config[CONF_CONDITION]

        if condition in ("and", "not", "or"):
            to_process.extend(config["conditions"])
            continue

        if condition == "device":
            if (device_id := config.get(CONF_DEVICE_ID)) is not None:
                referenced.add(device_id)
            continue

        if target_devices := _get_targets_from_condition_config(config, CONF_DEVICE_ID):
            referenced.update(target_devices)

    return referenced


@callback
def async_extract_targets(
    config: ConfigType | Template,
    target_type: Literal["area_id", "floor_id", "label_id"],
) -> set[str]:
    """Extract targets from a condition."""
    referenced: set[str] = set()
    to_process = deque([config])

    while to_process:
        config = to_process.popleft()
        if isinstance(config, Template):
            continue

        condition = config[CONF_CONDITION]

        if condition in ("and", "not", "or"):
            to_process.extend(config["conditions"])
            continue

        if targets := _get_targets_from_condition_config(config, target_type):
            referenced.update(targets)

    return referenced


@callback
def _get_targets_from_condition_config(
    config: ConfigType,
    target: Literal["entity_id", "device_id", "area_id", "floor_id", "label_id"],
) -> list[str]:
    """Extract targets from a condition target config."""
    if not (target_conf := config.get(CONF_TARGET)):
        return []
    if not (targets := target_conf.get(target)):
        return []

    return [targets] if isinstance(targets, str) else targets


def _load_conditions_file(integration: Integration) -> dict[str, Any]:
    """Load conditions file for an integration."""
    try:
        return cast(
            dict[str, Any],
            _CONDITIONS_DESCRIPTION_SCHEMA(
                load_yaml_dict(str(integration.file_path / "conditions.yaml"))
            ),
        )
    except FileNotFoundError:
        _LOGGER.warning(
            "Unable to find conditions.yaml for the %s integration", integration.domain
        )
        return {}
    except (HomeAssistantError, vol.Invalid) as ex:
        _LOGGER.warning(
            "Unable to parse conditions.yaml for the %s integration: %s",
            integration.domain,
            ex,
        )
        return {}


def _load_conditions_files(
    integrations: Iterable[Integration],
) -> dict[str, dict[str, Any]]:
    """Load condition files for multiple integrations."""
    return {
        integration.domain: {
            get_absolute_description_key(integration.domain, key): value
            for key, value in _load_conditions_file(integration).items()
        }
        for integration in integrations
    }


async def async_get_all_descriptions(
    hass: HomeAssistant,
) -> dict[str, dict[str, Any] | None]:
    """Return descriptions (i.e. user documentation) for all conditions."""
    from homeassistant.components import automation  # noqa: PLC0415

    descriptions_cache = hass.data[CONDITION_DESCRIPTION_CACHE]

    conditions = hass.data[CONDITIONS]
    # See if there are new conditions not seen before.
    # Any condition that we saw before already has an entry in description_cache.
    all_conditions = set(conditions)
    previous_all_conditions = set(descriptions_cache)
    # If the conditions are the same, we can return the cache

    # mypy complains: Invalid index type "HassKey[set[str]]" for "HassDict"
    if (
        previous_all_conditions | hass.data[CONDITION_DISABLED_CONDITIONS]  # type: ignore[index]
        == all_conditions
    ):
        return descriptions_cache

    # Files we loaded for missing descriptions
    new_conditions_descriptions: dict[str, dict[str, Any]] = {}
    # We try to avoid making a copy in the event the cache is good,
    # but now we must make a copy in case new conditions get added
    # while we are loading the missing ones so we do not
    # add the new ones to the cache without their descriptions
    conditions = conditions.copy()

    if missing_conditions := all_conditions.difference(descriptions_cache):
        domains_with_missing_conditions = {
            conditions[missing_condition] for missing_condition in missing_conditions
        }
        ints_or_excs = await async_get_integrations(
            hass, domains_with_missing_conditions
        )
        integrations: list[Integration] = []
        for domain, int_or_exc in ints_or_excs.items():
            if type(int_or_exc) is Integration and int_or_exc.has_conditions:
                integrations.append(int_or_exc)
                continue
            if TYPE_CHECKING:
                assert isinstance(int_or_exc, Exception)
            _LOGGER.debug(
                "Failed to load conditions.yaml for integration: %s",
                domain,
                exc_info=int_or_exc,
            )

        if integrations:
            new_conditions_descriptions = await hass.async_add_executor_job(
                _load_conditions_files, integrations
            )

    # Make a copy of the old cache and add missing descriptions to it
    new_descriptions_cache = descriptions_cache.copy()
    for missing_condition in missing_conditions:
        domain = conditions[missing_condition]
        if automation.is_disabled_experimental_condition(hass, domain):
            hass.data[CONDITION_DISABLED_CONDITIONS].add(missing_condition)
            continue

        if (
            yaml_description := new_conditions_descriptions.get(domain, {}).get(
                missing_condition
            )
        ) is None:
            _LOGGER.debug(
                "No condition descriptions found for condition %s, skipping",
                missing_condition,
            )
            new_descriptions_cache[missing_condition] = None
            continue

        description = {"fields": yaml_description.get("fields", {})}
        if (target := yaml_description.get("target")) is not None:
            description["target"] = target

        new_descriptions_cache[missing_condition] = description

    hass.data[CONDITION_DESCRIPTION_CACHE] = new_descriptions_cache
    return new_descriptions_cache
</file>

<file path="config_entry_flow.py">
"""Helpers for data entry flows for config entries."""

from __future__ import annotations

from collections.abc import Awaitable, Callable
import logging
from typing import TYPE_CHECKING, Any, cast

from homeassistant import config_entries
from homeassistant.components import onboarding
from homeassistant.core import HomeAssistant

from .typing import DiscoveryInfoType

if TYPE_CHECKING:
    import asyncio

    from homeassistant.components.bluetooth import BluetoothServiceInfoBleak

    from .service_info.dhcp import DhcpServiceInfo
    from .service_info.mqtt import MqttServiceInfo
    from .service_info.ssdp import SsdpServiceInfo
    from .service_info.zeroconf import ZeroconfServiceInfo

type DiscoveryFunctionType[_R] = Callable[[HomeAssistant], _R]

_LOGGER = logging.getLogger(__name__)


class DiscoveryFlowHandler[_R: Awaitable[bool] | bool](config_entries.ConfigFlow):
    """Handle a discovery config flow."""

    VERSION = 1

    def __init__(
        self,
        domain: str,
        title: str,
        discovery_function: DiscoveryFunctionType[_R],
    ) -> None:
        """Initialize the discovery config flow."""
        self._domain = domain
        self._title = title
        self._discovery_function = discovery_function

    async def async_step_user(
        self, user_input: dict[str, Any] | None = None
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by the user."""
        if self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain, raise_on_progress=False)

        return await self.async_step_confirm()

    async def async_step_confirm(
        self, user_input: dict[str, Any] | None = None
    ) -> config_entries.ConfigFlowResult:
        """Confirm setup."""
        if user_input is None and onboarding.async_is_onboarded(self.hass):
            self._set_confirm_only()
            return self.async_show_form(step_id="confirm")

        if self.source == config_entries.SOURCE_USER:
            # Get current discovered entries.
            in_progress = self._async_in_progress()

            if not (has_devices := bool(in_progress)):
                discovery_result = self._discovery_function(self.hass)
                if isinstance(discovery_result, bool):
                    has_devices = discovery_result
                else:
                    has_devices = await cast("asyncio.Future[bool]", discovery_result)

            if not has_devices:
                return self.async_abort(reason="no_devices_found")

            # Cancel the discovered one.
            for flow in in_progress:
                self.hass.config_entries.flow.async_abort(flow["flow_id"])

        if self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        return self.async_create_entry(title=self._title, data={})

    async def async_step_discovery(
        self, discovery_info: DiscoveryInfoType
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by discovery."""
        if self._async_in_progress() or self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain)

        return await self.async_step_confirm()

    async def async_step_bluetooth(
        self, discovery_info: BluetoothServiceInfoBleak
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by bluetooth discovery."""
        if self._async_in_progress() or self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain)

        return await self.async_step_confirm()

    async def async_step_dhcp(
        self, discovery_info: DhcpServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by dhcp discovery."""
        if self._async_in_progress() or self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain)

        return await self.async_step_confirm()

    async def async_step_homekit(
        self, discovery_info: ZeroconfServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by Homekit discovery."""
        if self._async_in_progress() or self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain)

        return await self.async_step_confirm()

    async def async_step_mqtt(
        self, discovery_info: MqttServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by mqtt discovery."""
        if self._async_in_progress() or self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain)

        return await self.async_step_confirm()

    async def async_step_zeroconf(
        self, discovery_info: ZeroconfServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by Zeroconf discovery."""
        if self._async_in_progress() or self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain)

        return await self.async_step_confirm()

    async def async_step_ssdp(
        self, discovery_info: SsdpServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by Ssdp discovery."""
        if self._async_in_progress() or self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        await self.async_set_unique_id(self._domain)

        return await self.async_step_confirm()

    async def async_step_import(
        self, _: dict[str, Any] | None
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by import."""
        if self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        # Cancel other flows.
        in_progress = self._async_in_progress()
        for flow in in_progress:
            self.hass.config_entries.flow.async_abort(flow["flow_id"])

        return self.async_create_entry(title=self._title, data={})


def register_discovery_flow(
    domain: str,
    title: str,
    discovery_function: DiscoveryFunctionType[Awaitable[bool] | bool],
) -> None:
    """Register flow for discovered integrations that not require auth."""

    class DiscoveryFlow(DiscoveryFlowHandler[Awaitable[bool] | bool]):
        """Discovery flow handler."""

        def __init__(self) -> None:
            super().__init__(domain, title, discovery_function)

    config_entries.HANDLERS.register(domain)(DiscoveryFlow)


class WebhookFlowHandler(config_entries.ConfigFlow):
    """Handle a webhook config flow."""

    VERSION = 1

    def __init__(
        self,
        domain: str,
        title: str,
        description_placeholder: dict,
        allow_multiple: bool,
    ) -> None:
        """Initialize the discovery config flow."""
        self._domain = domain
        self._title = title
        self._description_placeholder = description_placeholder
        self._allow_multiple = allow_multiple

    async def async_step_user(
        self, user_input: dict[str, Any] | None = None
    ) -> config_entries.ConfigFlowResult:
        """Handle a user initiated set up flow to create a webhook."""
        if not self._allow_multiple and self._async_current_entries():
            return self.async_abort(reason="single_instance_allowed")

        if user_input is None:
            return self.async_show_form(step_id="user")

        # Local import to be sure cloud is loaded and setup
        from homeassistant.components.cloud import (  # noqa: PLC0415
            async_active_subscription,
            async_create_cloudhook,
            async_is_connected,
        )

        # Local import to be sure webhook is loaded and setup
        from homeassistant.components.webhook import (  # noqa: PLC0415
            async_generate_id,
            async_generate_url,
        )

        webhook_id = async_generate_id()

        if "cloud" in self.hass.config.components and async_active_subscription(
            self.hass
        ):
            if not async_is_connected(self.hass):
                return self.async_abort(reason="cloud_not_connected")

            webhook_url = await async_create_cloudhook(self.hass, webhook_id)
            cloudhook = True
        else:
            webhook_url = async_generate_url(self.hass, webhook_id)
            cloudhook = False

        self._description_placeholder["webhook_url"] = webhook_url

        return self.async_create_entry(
            title=self._title,
            data={"webhook_id": webhook_id, "cloudhook": cloudhook},
            description_placeholders=self._description_placeholder,
        )


def register_webhook_flow(
    domain: str, title: str, description_placeholder: dict, allow_multiple: bool = False
) -> None:
    """Register flow for webhook integrations."""

    class WebhookFlow(WebhookFlowHandler):
        """Webhook flow handler."""

        def __init__(self) -> None:
            super().__init__(domain, title, description_placeholder, allow_multiple)

    config_entries.HANDLERS.register(domain)(WebhookFlow)


async def webhook_async_remove_entry(
    hass: HomeAssistant, entry: config_entries.ConfigEntry
) -> None:
    """Remove a webhook config entry."""
    if not entry.data.get("cloudhook") or "cloud" not in hass.config.components:
        return

    # Local import to be sure cloud is loaded and setup
    from homeassistant.components.cloud import async_delete_cloudhook  # noqa: PLC0415

    await async_delete_cloudhook(hass, entry.data["webhook_id"])
</file>

<file path="config_entry_oauth2_flow.py">
"""Config Flow using OAuth2.

This module exists of the following parts:
 - OAuth2 config flow which supports multiple OAuth2 implementations
 - OAuth2 implementation that works with local provided client ID/secret

"""

from __future__ import annotations

from abc import ABC, ABCMeta, abstractmethod
import asyncio
from asyncio import Lock
import base64
from collections.abc import Awaitable, Callable
import hashlib
from http import HTTPStatus
from json import JSONDecodeError
import logging
import secrets
import time
from typing import Any, cast

from aiohttp import ClientError, ClientResponseError, client, web
from habluetooth import BluetoothServiceInfoBleak
import jwt
import voluptuous as vol
from yarl import URL

from homeassistant import config_entries
from homeassistant.core import HomeAssistant, callback
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import async_get_application_credentials
from homeassistant.util.hass_dict import HassKey

from . import http
from .aiohttp_client import async_get_clientsession
from .network import NoURLAvailableError
from .service_info.dhcp import DhcpServiceInfo
from .service_info.ssdp import SsdpServiceInfo
from .service_info.zeroconf import ZeroconfServiceInfo

_LOGGER = logging.getLogger(__name__)

DATA_JWT_SECRET = "oauth2_jwt_secret"
DATA_IMPLEMENTATIONS: HassKey[dict[str, dict[str, AbstractOAuth2Implementation]]] = (
    HassKey("oauth2_impl")
)
DATA_PROVIDERS: HassKey[
    dict[
        str,
        Callable[[HomeAssistant, str], Awaitable[list[AbstractOAuth2Implementation]]],
    ]
] = HassKey("oauth2_providers")
AUTH_CALLBACK_PATH = "/auth/external/callback"
HEADER_FRONTEND_BASE = "HA-Frontend-Base"
MY_AUTH_CALLBACK_PATH = "https://my.home-assistant.io/redirect/oauth"

CLOCK_OUT_OF_SYNC_MAX_SEC = 20

OAUTH_AUTHORIZE_URL_TIMEOUT_SEC = 30
OAUTH_TOKEN_TIMEOUT_SEC = 30


class ImplementationUnavailableError(HomeAssistantError):
    """Raised when an underlying implementation is unavailable."""


@callback
def async_get_redirect_uri(hass: HomeAssistant) -> str:
    """Return the redirect uri."""
    if "my" in hass.config.components:
        return MY_AUTH_CALLBACK_PATH

    if (req := http.current_request.get()) is None:
        raise RuntimeError("No current request in context")

    if (ha_host := req.headers.get(HEADER_FRONTEND_BASE)) is None:
        raise RuntimeError("No header in request")

    return f"{ha_host}{AUTH_CALLBACK_PATH}"


class AbstractOAuth2Implementation(ABC):
    """Base class to abstract OAuth2 authentication."""

    @property
    @abstractmethod
    def name(self) -> str:
        """Name of the implementation."""

    @property
    @abstractmethod
    def domain(self) -> str:
        """Domain that is providing the implementation."""

    @abstractmethod
    async def async_generate_authorize_url(self, flow_id: str) -> str:
        """Generate a url for the user to authorize.

        This step is called when a config flow is initialized. It should redirect the
        user to the vendor website where they can authorize Home Assistant.

        The implementation is responsible to get notified when the user is authorized
        and pass this to the specified config flow. Do as little work as possible once
        notified. You can do the work inside async_resolve_external_data. This will
        give the best UX.

        Pass external data in with:

        await hass.config_entries.flow.async_configure(
            flow_id=flow_id, user_input={'code': 'abcd', 'state':  }

        )

        """

    @abstractmethod
    async def async_resolve_external_data(self, external_data: Any) -> dict:
        """Resolve external data to tokens.

        Turn the data that the implementation passed to the config flow as external
        step data into tokens. These tokens will be stored as 'token' in the
        config entry data.
        """

    async def async_refresh_token(self, token: dict) -> dict:
        """Refresh a token and update expires info."""
        new_token = await self._async_refresh_token(token)
        # Force int for non-compliant oauth2 providers
        new_token["expires_in"] = int(new_token["expires_in"])
        new_token["expires_at"] = time.time() + new_token["expires_in"]
        return new_token

    @abstractmethod
    async def _async_refresh_token(self, token: dict) -> dict:
        """Refresh a token."""


class LocalOAuth2Implementation(AbstractOAuth2Implementation):
    """Local OAuth2 implementation."""

    def __init__(
        self,
        hass: HomeAssistant,
        domain: str,
        client_id: str,
        client_secret: str,
        authorize_url: str,
        token_url: str,
    ) -> None:
        """Initialize local auth implementation."""
        self.hass = hass
        self._domain = domain
        self.client_id = client_id
        self.client_secret = client_secret
        self.authorize_url = authorize_url
        self.token_url = token_url

    @property
    def name(self) -> str:
        """Name of the implementation."""
        return "Local application credentials"

    @property
    def domain(self) -> str:
        """Domain providing the implementation."""
        return self._domain

    @property
    def redirect_uri(self) -> str:
        """Return the redirect uri."""
        return async_get_redirect_uri(self.hass)

    @property
    def extra_authorize_data(self) -> dict:
        """Extra data that needs to be appended to the authorize url."""
        return {}

    @property
    def extra_token_resolve_data(self) -> dict:
        """Extra data for the token resolve request."""
        return {}

    async def async_generate_authorize_url(self, flow_id: str) -> str:
        """Generate a url for the user to authorize."""
        redirect_uri = self.redirect_uri
        return str(
            URL(self.authorize_url)
            .with_query(
                {
                    "response_type": "code",
                    "client_id": self.client_id,
                    "redirect_uri": redirect_uri,
                    "state": _encode_jwt(
                        self.hass, {"flow_id": flow_id, "redirect_uri": redirect_uri}
                    ),
                }
            )
            .update_query(self.extra_authorize_data)
        )

    async def async_resolve_external_data(self, external_data: Any) -> dict:
        """Resolve the authorization code to tokens."""
        request_data: dict = {
            "grant_type": "authorization_code",
            "code": external_data["code"],
            "redirect_uri": external_data["state"]["redirect_uri"],
        }
        request_data.update(self.extra_token_resolve_data)
        return await self._token_request(request_data)

    async def _async_refresh_token(self, token: dict) -> dict:
        """Refresh tokens."""
        new_token = await self._token_request(
            {
                "grant_type": "refresh_token",
                "client_id": self.client_id,
                "refresh_token": token["refresh_token"],
            }
        )
        return {**token, **new_token}

    async def _token_request(self, data: dict) -> dict:
        """Make a token request."""
        session = async_get_clientsession(self.hass)

        data["client_id"] = self.client_id

        if self.client_secret:
            data["client_secret"] = self.client_secret

        _LOGGER.debug("Sending token request to %s", self.token_url)
        resp = await session.post(self.token_url, data=data)
        if resp.status >= 400:
            try:
                error_response = await resp.json()
            except (ClientError, JSONDecodeError):
                error_response = {}
            error_code = error_response.get("error", "unknown")
            error_description = error_response.get("error_description", "unknown error")
            _LOGGER.error(
                "Token request for %s failed (%s): %s",
                self.domain,
                error_code,
                error_description,
            )
        resp.raise_for_status()
        return cast(dict, await resp.json())


class LocalOAuth2ImplementationWithPkce(LocalOAuth2Implementation):
    """Local OAuth2 implementation with PKCE."""

    def __init__(
        self,
        hass: HomeAssistant,
        domain: str,
        client_id: str,
        authorize_url: str,
        token_url: str,
        client_secret: str = "",
        code_verifier_length: int = 128,
    ) -> None:
        """Initialize local auth implementation."""
        super().__init__(
            hass,
            domain,
            client_id,
            client_secret,
            authorize_url,
            token_url,
        )

        # Generate code verifier
        self.code_verifier = LocalOAuth2ImplementationWithPkce.generate_code_verifier(
            code_verifier_length
        )

    @property
    def extra_authorize_data(self) -> dict:
        """Extra data that needs to be appended to the authorize url.

        If you want to override this method,
        calling super is mandatory (for adding scopes):
        ```
        @def extra_authorize_data(self) -> dict:
            data: dict = {
                "scope": "openid profile email",
            }
            data.update(super().extra_authorize_data)
            return data
        ```
        """
        return {
            "code_challenge": LocalOAuth2ImplementationWithPkce.compute_code_challenge(
                self.code_verifier
            ),
            "code_challenge_method": "S256",
        }

    @property
    def extra_token_resolve_data(self) -> dict:
        """Extra data that needs to be included in the token resolve request.

        If you want to override this method,
        calling super is mandatory (for adding `someKey`):
        ```
        @def extra_token_resolve_data(self) -> dict:
            data: dict = {
                "someKey": "someValue",
            }
            data.update(super().extra_token_resolve_data)
            return data
        ```
        """

        return {"code_verifier": self.code_verifier}

    @staticmethod
    def generate_code_verifier(code_verifier_length: int = 128) -> str:
        """Generate a code verifier."""
        if not 43 <= code_verifier_length <= 128:
            msg = (
                "Parameter `code_verifier_length` must validate"
                "`43 <= code_verifier_length <= 128`."
            )
            raise ValueError(msg)
        return secrets.token_urlsafe(96)[:code_verifier_length]

    @staticmethod
    def compute_code_challenge(code_verifier: str) -> str:
        """Compute the code challenge."""
        if not 43 <= len(code_verifier) <= 128:
            msg = (
                "Parameter `code_verifier` must validate "
                "`43 <= len(code_verifier) <= 128`."
            )
            raise ValueError(msg)

        hashed = hashlib.sha256(code_verifier.encode("ascii")).digest()
        encoded = base64.urlsafe_b64encode(hashed)
        return encoded.decode("ascii").replace("=", "")


class AbstractOAuth2FlowHandler(config_entries.ConfigFlow, metaclass=ABCMeta):
    """Handle a config flow."""

    DOMAIN = ""

    VERSION = 1

    def __init__(self) -> None:
        """Instantiate config flow."""
        if self.DOMAIN == "":
            raise TypeError(
                f"Can't instantiate class {self.__class__.__name__} without DOMAIN"
                " being set"
            )

        self.external_data: Any = None
        self.flow_impl: AbstractOAuth2Implementation = None  # type: ignore[assignment]

    @property
    @abstractmethod
    def logger(self) -> logging.Logger:
        """Return logger."""

    @property
    def extra_authorize_data(self) -> dict:
        """Extra data that needs to be appended to the authorize url."""
        return {}

    async def async_generate_authorize_url(self) -> str:
        """Generate a url for the user to authorize."""
        url = await self.flow_impl.async_generate_authorize_url(self.flow_id)
        return str(URL(url).update_query(self.extra_authorize_data))

    async def async_step_pick_implementation(
        self, user_input: dict | None = None
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow start."""
        implementations = await async_get_implementations(self.hass, self.DOMAIN)

        if user_input is not None:
            self.flow_impl = implementations[user_input["implementation"]]
            return await self.async_step_auth()

        if not implementations:
            if self.DOMAIN in await async_get_application_credentials(self.hass):
                return self.async_abort(reason="missing_credentials")
            return self.async_abort(reason="missing_configuration")

        req = http.current_request.get()
        if len(implementations) == 1 and req is not None:
            # Pick first implementation if we have only one, but only
            # if this is triggered by a user interaction (request).
            self.flow_impl = list(implementations.values())[0]
            return await self.async_step_auth()

        return self.async_show_form(
            step_id="pick_implementation",
            data_schema=vol.Schema(
                {
                    vol.Required(
                        "implementation", default=list(implementations)[0]
                    ): vol.In({key: impl.name for key, impl in implementations.items()})
                }
            ),
        )

    async def async_step_auth(
        self, user_input: dict[str, Any] | None = None
    ) -> config_entries.ConfigFlowResult:
        """Create an entry for auth."""
        # Flow has been triggered by external data
        if user_input is not None:
            self.external_data = user_input
            next_step = "authorize_rejected" if "error" in user_input else "creation"
            return self.async_external_step_done(next_step_id=next_step)

        try:
            async with asyncio.timeout(OAUTH_AUTHORIZE_URL_TIMEOUT_SEC):
                url = await self.async_generate_authorize_url()
        except TimeoutError as err:
            _LOGGER.error("Timeout generating authorize url: %s", err)
            return self.async_abort(reason="authorize_url_timeout")
        except NoURLAvailableError:
            return self.async_abort(
                reason="no_url_available",
                description_placeholders={
                    "docs_url": (
                        "https://www.home-assistant.io/more-info/no-url-available"
                    )
                },
            )

        return self.async_external_step(step_id="auth", url=url)

    async def async_step_creation(
        self, user_input: dict[str, Any] | None = None
    ) -> config_entries.ConfigFlowResult:
        """Create config entry from external data."""
        _LOGGER.debug("Creating config entry from external data")

        try:
            async with asyncio.timeout(OAUTH_TOKEN_TIMEOUT_SEC):
                token = await self.flow_impl.async_resolve_external_data(
                    self.external_data
                )
        except TimeoutError as err:
            _LOGGER.error("Timeout resolving OAuth token: %s", err)
            return self.async_abort(reason="oauth_timeout")
        except (ClientResponseError, ClientError) as err:
            _LOGGER.error("Error resolving OAuth token: %s", err)
            if (
                isinstance(err, ClientResponseError)
                and err.status == HTTPStatus.UNAUTHORIZED
            ):
                return self.async_abort(reason="oauth_unauthorized")
            return self.async_abort(reason="oauth_failed")

        if "expires_in" not in token:
            _LOGGER.warning("Invalid token: %s", token)
            return self.async_abort(reason="oauth_error")

        # Force int for non-compliant oauth2 providers
        try:
            token["expires_in"] = int(token["expires_in"])
        except ValueError as err:
            _LOGGER.warning("Error converting expires_in to int: %s", err)
            return self.async_abort(reason="oauth_error")
        token["expires_at"] = time.time() + token["expires_in"]

        self.logger.info("Successfully authenticated")

        return await self.async_oauth_create_entry(
            {"auth_implementation": self.flow_impl.domain, "token": token}
        )

    async def async_step_authorize_rejected(
        self, data: None = None
    ) -> config_entries.ConfigFlowResult:
        """Step to handle flow rejection."""
        return self.async_abort(
            reason="user_rejected_authorize",
            description_placeholders={"error": self.external_data["error"]},
        )

    async def async_oauth_create_entry(
        self, data: dict
    ) -> config_entries.ConfigFlowResult:
        """Create an entry for the flow.

        Ok to override if you want to fetch extra info or even add another step.
        """
        return self.async_create_entry(title=self.flow_impl.name, data=data)

    async def async_step_user(
        self, user_input: dict[str, Any] | None = None
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow start."""
        return await self.async_step_pick_implementation(user_input)

    async def async_step_bluetooth(
        self, discovery_info: BluetoothServiceInfoBleak
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by Bluetooth discovery."""
        return await self.async_step_oauth_discovery()

    async def async_step_dhcp(
        self, discovery_info: DhcpServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by DHCP discovery."""
        return await self.async_step_oauth_discovery()

    async def async_step_homekit(
        self, discovery_info: ZeroconfServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by Homekit discovery."""
        return await self.async_step_oauth_discovery()

    async def async_step_ssdp(
        self, discovery_info: SsdpServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by SSDP discovery."""
        return await self.async_step_oauth_discovery()

    async def async_step_zeroconf(
        self, discovery_info: ZeroconfServiceInfo
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by Zeroconf discovery."""
        return await self.async_step_oauth_discovery()

    async def async_step_oauth_discovery(
        self, user_input: dict[str, Any] | None = None
    ) -> config_entries.ConfigFlowResult:
        """Handle a flow initialized by a discovery method."""
        if user_input is not None:
            return await self.async_step_user()
        await self._async_handle_discovery_without_unique_id()
        return self.async_show_form(step_id="oauth_discovery")

    @classmethod
    def async_register_implementation(
        cls, hass: HomeAssistant, local_impl: LocalOAuth2Implementation
    ) -> None:
        """Register a local implementation."""
        async_register_implementation(hass, cls.DOMAIN, local_impl)


@callback
def async_register_implementation(
    hass: HomeAssistant, domain: str, implementation: AbstractOAuth2Implementation
) -> None:
    """Register an OAuth2 flow implementation for an integration."""
    implementations = hass.data.setdefault(DATA_IMPLEMENTATIONS, {})
    implementations.setdefault(domain, {})[implementation.domain] = implementation


async def async_get_implementations(
    hass: HomeAssistant, domain: str
) -> dict[str, AbstractOAuth2Implementation]:
    """Return OAuth2 implementations for specified domain."""
    registered = hass.data.setdefault(DATA_IMPLEMENTATIONS, {}).get(domain, {})

    if DATA_PROVIDERS not in hass.data:
        return registered

    registered = dict(registered)
    exceptions = []
    for get_impl in list(hass.data[DATA_PROVIDERS].values()):
        try:
            for impl in await get_impl(hass, domain):
                registered[impl.domain] = impl
        except ImplementationUnavailableError as err:
            exceptions.append(err)

    if not registered and exceptions:
        raise ImplementationUnavailableError(*exceptions)

    return registered


async def async_get_config_entry_implementation(
    hass: HomeAssistant, config_entry: config_entries.ConfigEntry
) -> AbstractOAuth2Implementation:
    """Return the implementation for this config entry."""
    implementations = await async_get_implementations(hass, config_entry.domain)
    implementation = implementations.get(config_entry.data["auth_implementation"])

    if implementation is None:
        raise ValueError("Implementation not available")

    return implementation


@callback
def async_add_implementation_provider(
    hass: HomeAssistant,
    provider_domain: str,
    async_provide_implementation: Callable[
        [HomeAssistant, str], Awaitable[list[AbstractOAuth2Implementation]]
    ],
) -> None:
    """Add an implementation provider.

    If no implementation found, return None.
    """
    hass.data.setdefault(DATA_PROVIDERS, {})[provider_domain] = (
        async_provide_implementation
    )


class OAuth2AuthorizeCallbackView(http.HomeAssistantView):
    """OAuth2 Authorization Callback View."""

    requires_auth = False
    url = AUTH_CALLBACK_PATH
    name = "auth:external:callback"

    async def get(self, request: web.Request) -> web.Response:
        """Receive authorization code."""
        if "state" not in request.query:
            return web.Response(text="Missing state parameter")

        hass = request.app[http.KEY_HASS]

        state = _decode_jwt(hass, request.query["state"])

        if state is None:
            return web.Response(
                text=(
                    "Invalid state. Is My Home Assistant configured "
                    "to go to the right instance?"
                ),
                status=400,
            )

        user_input: dict[str, Any] = {"state": state}

        if "code" in request.query:
            user_input["code"] = request.query["code"]
        elif "error" in request.query:
            user_input["error"] = request.query["error"]
        else:
            return web.Response(text="Missing code or error parameter")

        await hass.config_entries.flow.async_configure(
            flow_id=state["flow_id"], user_input=user_input
        )
        _LOGGER.debug("Resumed OAuth configuration flow")
        return web.Response(
            headers={"content-type": "text/html"},
            text="<script>window.close()</script>",
        )


class OAuth2Session:
    """Session to make requests authenticated with OAuth2."""

    def __init__(
        self,
        hass: HomeAssistant,
        config_entry: config_entries.ConfigEntry,
        implementation: AbstractOAuth2Implementation,
    ) -> None:
        """Initialize an OAuth2 session."""
        self.hass = hass
        self.config_entry = config_entry
        self.implementation = implementation
        self._token_lock = Lock()

    @property
    def token(self) -> dict:
        """Return the token."""
        return cast(dict, self.config_entry.data["token"])

    @property
    def valid_token(self) -> bool:
        """Return if token is still valid."""
        return (
            cast(float, self.token["expires_at"])
            > time.time() + CLOCK_OUT_OF_SYNC_MAX_SEC
        )

    async def async_ensure_token_valid(self) -> None:
        """Ensure that the current token is valid."""
        async with self._token_lock:
            if self.valid_token:
                return

            new_token = await self.implementation.async_refresh_token(self.token)

            self.hass.config_entries.async_update_entry(
                self.config_entry, data={**self.config_entry.data, "token": new_token}
            )

    async def async_request(
        self, method: str, url: str, **kwargs: Any
    ) -> client.ClientResponse:
        """Make a request."""
        await self.async_ensure_token_valid()
        return await async_oauth2_request(
            self.hass, self.config_entry.data["token"], method, url, **kwargs
        )


async def async_oauth2_request(
    hass: HomeAssistant, token: dict, method: str, url: str, **kwargs: Any
) -> client.ClientResponse:
    """Make an OAuth2 authenticated request.

    This method will not refresh tokens. Use OAuth2 session for that.
    """
    session = async_get_clientsession(hass)
    headers = kwargs.pop("headers", {})
    return await session.request(
        method,
        url,
        **kwargs,
        headers={
            **headers,
            "authorization": f"Bearer {token['access_token']}",
        },
    )


@callback
def _encode_jwt(hass: HomeAssistant, data: dict) -> str:
    """JWT encode data."""
    if (secret := hass.data.get(DATA_JWT_SECRET)) is None:
        secret = hass.data[DATA_JWT_SECRET] = secrets.token_hex()

    return jwt.encode(data, secret, algorithm="HS256")


@callback
def _decode_jwt(hass: HomeAssistant, encoded: str) -> dict[str, Any] | None:
    """JWT encode data."""
    secret: str | None = hass.data.get(DATA_JWT_SECRET)

    if secret is None:
        return None

    try:
        return jwt.decode(encoded, secret, algorithms=["HS256"])  # type: ignore[no-any-return]
    except jwt.InvalidTokenError:
        return None
</file>

<file path="config_validation.py">
"""Helpers for config validation using voluptuous."""

from __future__ import annotations

from collections.abc import Callable, Hashable, Mapping
import contextlib
from contextvars import ContextVar
from datetime import (
    date as date_sys,
    datetime as datetime_sys,
    time as time_sys,
    timedelta,
)
from enum import Enum, StrEnum
import functools
import logging
from numbers import Number
import os
import re
from socket import (  # type: ignore[attr-defined]  # private, not in typeshed
    _GLOBAL_DEFAULT_TIMEOUT,
)
import threading
from typing import TYPE_CHECKING, Any, cast, overload
from urllib.parse import urlparse
from uuid import UUID

import voluptuous as vol
import voluptuous_serialize

from homeassistant.const import (
    ATTR_AREA_ID,
    ATTR_DEVICE_ID,
    ATTR_ENTITY_ID,
    ATTR_FLOOR_ID,
    ATTR_LABEL_ID,
    CONF_ABOVE,
    CONF_ACTION,
    CONF_ALIAS,
    CONF_ATTRIBUTE,
    CONF_BELOW,
    CONF_CHOOSE,
    CONF_CONDITION,
    CONF_CONDITIONS,
    CONF_CONTINUE_ON_ERROR,
    CONF_CONTINUE_ON_TIMEOUT,
    CONF_COUNT,
    CONF_DEFAULT,
    CONF_DELAY,
    CONF_DEVICE_ID,
    CONF_DOMAIN,
    CONF_ELSE,
    CONF_ENABLED,
    CONF_ENTITY_ID,
    CONF_ENTITY_NAMESPACE,
    CONF_ERROR,
    CONF_EVENT,
    CONF_EVENT_DATA,
    CONF_EVENT_DATA_TEMPLATE,
    CONF_FOR,
    CONF_FOR_EACH,
    CONF_ID,
    CONF_IF,
    CONF_MATCH,
    CONF_PARALLEL,
    CONF_PLATFORM,
    CONF_REPEAT,
    CONF_RESPONSE_VARIABLE,
    CONF_SCAN_INTERVAL,
    CONF_SCENE,
    CONF_SEQUENCE,
    CONF_SERVICE,
    CONF_SERVICE_DATA,
    CONF_SERVICE_DATA_TEMPLATE,
    CONF_SERVICE_TEMPLATE,
    CONF_SET_CONVERSATION_RESPONSE,
    CONF_STATE,
    CONF_STOP,
    CONF_TARGET,
    CONF_THEN,
    CONF_TIMEOUT,
    CONF_TRIGGER,
    CONF_TRIGGERS,
    CONF_UNTIL,
    CONF_VALUE_TEMPLATE,
    CONF_VARIABLES,
    CONF_WAIT_FOR_TRIGGER,
    CONF_WAIT_TEMPLATE,
    CONF_WHILE,
    ENTITY_MATCH_ALL,
    ENTITY_MATCH_ANY,
    ENTITY_MATCH_NONE,
    SUN_EVENT_SUNRISE,
    SUN_EVENT_SUNSET,
    WEEKDAYS,
    UnitOfTemperature,
)
from homeassistant.core import (
    DOMAIN as HOMEASSISTANT_DOMAIN,
    HomeAssistant,
    async_get_hass,
    async_get_hass_or_none,
    split_entity_id,
    valid_entity_id,
)
from homeassistant.exceptions import HomeAssistantError, TemplateError
from homeassistant.generated import currencies
from homeassistant.generated.countries import COUNTRIES
from homeassistant.generated.languages import LANGUAGES
from homeassistant.util import (
    dt as dt_util,
    raise_if_invalid_path,
    slugify as util_slugify,
)
from homeassistant.util.yaml.objects import NodeStrClass

from . import script_variables as script_variables_helper, template as template_helper
from .frame import get_integration_logger
from .typing import VolDictType, VolSchemaType

TIME_PERIOD_ERROR = "offset {} should be format 'HH:MM', 'HH:MM:SS' or 'HH:MM:SS.F'"


class MustValidateInExecutor(HomeAssistantError):
    """Raised when validation must happen in an executor thread."""


class _Hass(threading.local):
    """Container which makes a HomeAssistant instance available to validators."""

    hass: HomeAssistant | None = None


_hass = _Hass()
"""Set when doing async friendly schema validation."""


def _async_get_hass_or_none() -> HomeAssistant | None:
    """Return the HomeAssistant instance or None.

    First tries core.async_get_hass_or_none, then _hass which is
    set when doing async friendly schema validation.
    """
    return async_get_hass_or_none() or _hass.hass


_validating_async: ContextVar[bool] = ContextVar("_validating_async", default=False)
"""Set to True when doing async friendly schema validation."""


def not_async_friendly[**_P, _R](validator: Callable[_P, _R]) -> Callable[_P, _R]:
    """Mark a validator as not async friendly.

    This makes validation happen in an executor thread if validation is done by
    async_validate, otherwise does nothing.
    """

    @functools.wraps(validator)
    def _not_async_friendly(*args: _P.args, **kwargs: _P.kwargs) -> _R:
        if _validating_async.get() and async_get_hass_or_none():
            # Raise if doing async friendly validation and validation
            # is happening in the event loop
            raise MustValidateInExecutor
        return validator(*args, **kwargs)

    return _not_async_friendly


class UrlProtocolSchema(StrEnum):
    """Valid URL protocol schema values."""

    HTTP = "http"
    HTTPS = "https"
    HOMEASSISTANT = "homeassistant"


EXTERNAL_URL_PROTOCOL_SCHEMA_LIST = frozenset(
    {UrlProtocolSchema.HTTP, UrlProtocolSchema.HTTPS}
)
CONFIGURATION_URL_PROTOCOL_SCHEMA_LIST = frozenset(
    {UrlProtocolSchema.HOMEASSISTANT, UrlProtocolSchema.HTTP, UrlProtocolSchema.HTTPS}
)

# Home Assistant types
byte = vol.All(vol.Coerce(int), vol.Range(min=0, max=255))
small_float = vol.All(vol.Coerce(float), vol.Range(min=0, max=1))
positive_int = vol.All(vol.Coerce(int), vol.Range(min=0))
positive_float = vol.All(vol.Coerce(float), vol.Range(min=0))
latitude = vol.All(
    vol.Coerce(float), vol.Range(min=-90, max=90), msg="invalid latitude"
)
longitude = vol.All(
    vol.Coerce(float), vol.Range(min=-180, max=180), msg="invalid longitude"
)
gps = vol.ExactSequence([latitude, longitude])
sun_event = vol.All(vol.Lower, vol.Any(SUN_EVENT_SUNSET, SUN_EVENT_SUNRISE))
port = vol.All(vol.Coerce(int), vol.Range(min=1, max=65535))


def path(value: Any) -> str:
    """Validate it's a safe path."""
    if not isinstance(value, str):
        raise vol.Invalid("Expected a string")

    try:
        raise_if_invalid_path(value)
    except ValueError as err:
        raise vol.Invalid("Invalid path") from err

    return value


# Adapted from:
# https://github.com/alecthomas/voluptuous/issues/115#issuecomment-144464666
def has_at_least_one_key(*keys: Any) -> Callable[[dict], dict]:
    """Validate that at least one key exists."""
    key_set = set(keys)

    def validate(obj: dict) -> dict:
        """Test keys exist in dict."""
        if not isinstance(obj, dict):
            raise vol.Invalid("expected dictionary")

        if not key_set.isdisjoint(obj):
            return obj
        expected = ", ".join(str(k) for k in keys)
        raise vol.Invalid(f"must contain at least one of {expected}.")

    return validate


def has_at_most_one_key(*keys: Any) -> Callable[[dict], dict]:
    """Validate that zero keys exist or one key exists."""

    def validate(obj: dict) -> dict:
        """Test zero keys exist or one key exists in dict."""
        if not isinstance(obj, dict):
            raise vol.Invalid("expected dictionary")

        if len(set(keys) & set(obj)) > 1:
            expected = ", ".join(str(k) for k in keys)
            raise vol.Invalid(f"must contain at most one of {expected}.")
        return obj

    return validate


def boolean(value: Any) -> bool:
    """Validate and coerce a boolean value."""
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        value = value.lower().strip()
        if value in ("1", "true", "yes", "on", "enable"):
            return True
        if value in ("0", "false", "no", "off", "disable"):
            return False
    elif isinstance(value, Number):
        # type ignore: https://github.com/python/mypy/issues/3186
        return value != 0  # type: ignore[comparison-overlap]
    raise vol.Invalid(f"invalid boolean value {value}")


def whitespace(value: Any) -> str:
    """Validate result contains only whitespace."""
    if isinstance(value, str) and (value == "" or value.isspace()):
        return value

    raise vol.Invalid(f"contains non-whitespace: {value}")


@not_async_friendly
def isdevice(value: Any) -> str:
    """Validate that value is a real device."""
    try:
        os.stat(value)
        return str(value)
    except OSError as err:
        raise vol.Invalid(f"No device at {value} found") from err


def matches_regex(regex: str) -> Callable[[Any], str]:
    """Validate that the value is a string that matches a regex."""
    compiled = re.compile(regex)

    def validator(value: Any) -> str:
        """Validate that value matches the given regex."""
        if not isinstance(value, str):
            raise vol.Invalid(f"not a string value: {value}")

        if not compiled.match(value):
            raise vol.Invalid(
                f"value {value} does not match regular expression {compiled.pattern}"
            )

        return value

    return validator


def is_regex(value: Any) -> re.Pattern[Any]:
    """Validate that a string is a valid regular expression."""
    try:
        r = re.compile(value)
    except TypeError as err:
        raise vol.Invalid(
            f"value {value} is of the wrong type for a regular expression"
        ) from err
    except re.error as err:
        raise vol.Invalid(f"value {value} is not a valid regular expression") from err
    return r


@not_async_friendly
def isfile(value: Any) -> str:
    """Validate that the value is an existing file."""
    if value is None:
        raise vol.Invalid("None is not file")
    file_in = os.path.expanduser(str(value))

    if not os.path.isfile(file_in):
        raise vol.Invalid("not a file")
    if not os.access(file_in, os.R_OK):
        raise vol.Invalid("file not readable")
    return file_in


@not_async_friendly
def isdir(value: Any) -> str:
    """Validate that the value is an existing dir."""
    if value is None:
        raise vol.Invalid("not a directory")
    dir_in = os.path.expanduser(str(value))

    if not os.path.isdir(dir_in):
        raise vol.Invalid("not a directory")
    if not os.access(dir_in, os.R_OK):
        raise vol.Invalid("directory not readable")
    return dir_in


@overload
def ensure_list(value: None) -> list[Any]: ...


@overload
def ensure_list[_T](value: list[_T]) -> list[_T]: ...


@overload
def ensure_list[_T](value: list[_T] | _T) -> list[_T]: ...


def ensure_list[_T](value: _T | None) -> list[_T] | list[Any]:
    """Wrap value in list if it is not one."""
    if value is None:
        return []
    if isinstance(value, list):
        if TYPE_CHECKING:
            # https://github.com/home-assistant/core/pull/71960
            # cast with a type variable is still slow.
            return cast(list[_T], value)
        return value  # type: ignore[unreachable]
    return [value]


def entity_id(value: Any) -> str:
    """Validate Entity ID."""
    str_value = string(value).lower()
    if valid_entity_id(str_value):
        return str_value

    raise vol.Invalid(f"Entity ID {value} is an invalid entity ID")


def strict_entity_id(value: Any) -> str:
    """Validate Entity ID, strictly."""
    if not isinstance(value, str):
        raise vol.Invalid(f"Entity ID {value} is not a string")

    if valid_entity_id(value):
        return value

    raise vol.Invalid(f"Entity ID {value} is not a valid entity ID")


def entity_id_or_uuid(value: Any) -> str:
    """Validate Entity specified by entity_id or uuid."""
    with contextlib.suppress(vol.Invalid):
        return entity_id(value)
    with contextlib.suppress(vol.Invalid):
        return fake_uuid4_hex(value)
    raise vol.Invalid(f"Entity {value} is neither a valid entity ID nor a valid UUID")


def _entity_ids(value: str | list, allow_uuid: bool) -> list[str]:
    """Help validate entity IDs or UUIDs."""
    if value is None:
        raise vol.Invalid("Entity IDs cannot be None")
    if isinstance(value, str):
        value = [ent_id.strip() for ent_id in value.split(",")]

    validator = entity_id_or_uuid if allow_uuid else entity_id
    return [validator(ent_id) for ent_id in value]


def entity_ids(value: str | list) -> list[str]:
    """Validate Entity IDs."""
    return _entity_ids(value, False)


def entity_ids_or_uuids(value: str | list) -> list[str]:
    """Validate entities specified by entity IDs or UUIDs."""
    return _entity_ids(value, True)


comp_entity_ids = vol.Any(
    vol.All(vol.Lower, vol.Any(ENTITY_MATCH_ALL, ENTITY_MATCH_NONE)), entity_ids
)


comp_entity_ids_or_uuids = vol.Any(
    vol.All(vol.Lower, vol.Any(ENTITY_MATCH_ALL, ENTITY_MATCH_NONE)),
    entity_ids_or_uuids,
)


def domain_key(config_key: Any) -> str:
    """Validate a top level config key with an optional label and return the domain.

    A domain is separated from a label by one or more spaces, empty labels are not
    allowed.

    Examples:
    'hue' returns 'hue'
    'hue 1' returns 'hue'
    'hue  1' returns 'hue'
    'hue ' raises
    'hue  ' raises

    """
    if not isinstance(config_key, str):
        raise vol.Invalid("invalid domain", path=[config_key])

    parts = config_key.partition(" ")
    _domain = parts[0] if parts[2].strip(" ") else config_key
    if not _domain or _domain.strip(" ") != _domain:
        raise vol.Invalid("invalid domain", path=[config_key])

    return _domain


def entity_domain(domain: str | list[str]) -> Callable[[Any], str]:
    """Validate that entity belong to domain."""
    ent_domain = entities_domain(domain)

    def validate(value: str) -> str:
        """Test if entity domain is domain."""
        validated = ent_domain(value)
        if len(validated) != 1:
            raise vol.Invalid(f"Expected exactly 1 entity, got {len(validated)}")
        return validated[0]

    return validate


def entities_domain(domain: str | list[str]) -> Callable[[str | list], list[str]]:
    """Validate that entities belong to domain."""
    if isinstance(domain, str):

        def check_invalid(val: str) -> bool:
            return val != domain

    else:

        def check_invalid(val: str) -> bool:
            return val not in domain

    def validate(values: str | list) -> list[str]:
        """Test if entity domain is domain."""
        values = entity_ids(values)
        for ent_id in values:
            if check_invalid(split_entity_id(ent_id)[0]):
                raise vol.Invalid(
                    f"Entity ID '{ent_id}' does not belong to domain '{domain}'"
                )
        return values

    return validate


def enum(enumClass: type[Enum]) -> vol.All:
    """Create validator for specified enum."""
    return vol.All(vol.In(enumClass.__members__), enumClass.__getitem__)


def icon(value: Any) -> str:
    """Validate icon."""
    str_value = str(value)

    if ":" in str_value:
        return str_value

    raise vol.Invalid('Icons should be specified in the form "prefix:name"')


_COLOR_HEX = re.compile(r"^#[0-9A-F]{6}$", re.IGNORECASE)


def color_hex(value: Any) -> str:
    """Validate a hex color code."""
    str_value = str(value)

    if not _COLOR_HEX.match(str_value):
        raise vol.Invalid("Color should be in the format #RRGGBB")

    return str_value


_TIME_PERIOD_DICT_KEYS = ("days", "hours", "minutes", "seconds", "milliseconds")

time_period_dict = vol.All(
    dict,
    vol.Schema(
        {
            "days": vol.Coerce(float),
            "hours": vol.Coerce(float),
            "minutes": vol.Coerce(float),
            "seconds": vol.Coerce(float),
            "milliseconds": vol.Coerce(float),
        }
    ),
    has_at_least_one_key(*_TIME_PERIOD_DICT_KEYS),
    lambda value: timedelta(**value),
)


def time(value: Any) -> time_sys:
    """Validate and transform a time."""
    if isinstance(value, time_sys):
        return value

    try:
        time_val = dt_util.parse_time(value)
    except TypeError as err:
        raise vol.Invalid("Not a parseable type") from err

    if time_val is None:
        raise vol.Invalid(f"Invalid time specified: {value}")

    return time_val


def date(value: Any) -> date_sys:
    """Validate and transform a date."""
    if isinstance(value, date_sys):
        return value

    try:
        date_val = dt_util.parse_date(value)
    except TypeError as err:
        raise vol.Invalid("Not a parseable type") from err

    if date_val is None:
        raise vol.Invalid("Could not parse date")

    return date_val


def time_period_str(value: str) -> timedelta:
    """Validate and transform time offset."""
    if isinstance(value, int):  # type: ignore[unreachable]
        raise vol.Invalid("Make sure you wrap time values in quotes")
    if not isinstance(value, str):
        raise vol.Invalid(TIME_PERIOD_ERROR.format(value))

    negative_offset = False
    if value.startswith("-"):
        negative_offset = True
        value = value[1:]
    elif value.startswith("+"):
        value = value[1:]

    parsed = value.split(":")
    if len(parsed) not in (2, 3):
        raise vol.Invalid(TIME_PERIOD_ERROR.format(value))
    try:
        hour = int(parsed[0])
        minute = int(parsed[1])
        try:
            second = float(parsed[2])
        except IndexError:
            second = 0
    except ValueError as err:
        raise vol.Invalid(TIME_PERIOD_ERROR.format(value)) from err

    offset = timedelta(hours=hour, minutes=minute, seconds=second)

    if negative_offset:
        offset *= -1

    return offset


def time_period_seconds(value: float | str) -> timedelta:
    """Validate and transform seconds to a time offset."""
    try:
        return timedelta(seconds=float(value))
    except (ValueError, TypeError) as err:
        raise vol.Invalid(f"Expected seconds, got {value}") from err


time_period = vol.Any(time_period_str, time_period_seconds, timedelta, time_period_dict)


def match_all[_T](value: _T) -> _T:
    """Validate that matches all values."""
    return value


def positive_timedelta(value: timedelta) -> timedelta:
    """Validate timedelta is positive."""
    if value < timedelta(0):
        raise vol.Invalid("Time period should be positive")
    return value


positive_time_period_dict = vol.All(time_period_dict, positive_timedelta)
positive_time_period = vol.All(time_period, positive_timedelta)


def remove_falsy[_T](value: list[_T]) -> list[_T]:
    """Remove falsy values from a list."""
    return [v for v in value if v]


def service(value: Any) -> str:
    """Validate service."""
    # Services use same format as entities so we can use same helper.
    str_value = string(value).lower()
    if valid_entity_id(str_value):
        return str_value

    raise vol.Invalid(f"Service {value} does not match format <domain>.<name>")


def slug(value: Any) -> str:
    """Validate value is a valid slug."""
    if value is None:
        raise vol.Invalid("Slug should not be None")
    str_value = str(value)
    slg = util_slugify(str_value)
    if str_value == slg:
        return str_value
    raise vol.Invalid(f"invalid slug {value} (try {slg})")


def underscore_slug(value: Any) -> str:
    """Validate value is a valid slug, possibly starting with an underscore."""
    if value.startswith("_"):
        return f"_{slug(value[1:])}"
    return slug(value)


def schema_with_slug_keys(
    value_schema: dict | Callable, *, slug_validator: Callable[[Any], str] = slug
) -> Callable:
    """Ensure dicts have slugs as keys.

    Replacement of vol.Schema({cv.slug: value_schema}) to prevent misleading
    "Extra keys" errors from voluptuous.
    """
    schema = vol.Schema({str: value_schema})

    def verify(value: dict) -> dict:
        """Validate all keys are slugs and then the value_schema."""
        if not isinstance(value, dict):
            raise vol.Invalid("expected dictionary")

        for key in value:
            slug_validator(key)

        return cast(dict, schema(value))

    return verify


def slugify(value: Any) -> str:
    """Coerce a value to a slug."""
    if value is None:
        raise vol.Invalid("Slug should not be None")
    slg = util_slugify(str(value))
    if slg:
        return slg
    raise vol.Invalid(f"Unable to slugify {value}")


def string(value: Any) -> str:
    """Coerce value to string, except for None."""
    if value is None:
        raise vol.Invalid("string value is None")

    # This is expected to be the most common case, so check it first.
    if type(value) is str or type(value) is NodeStrClass or isinstance(value, str):
        return value

    if isinstance(value, template_helper.ResultWrapper):
        value = value.render_result

    elif isinstance(value, (list, dict)):
        raise vol.Invalid("value should be a string")

    return str(value)


def string_with_no_html(value: Any) -> str:
    """Validate that the value is a string without HTML."""
    value = string(value)
    regex = re.compile(r"<[a-z].*?>", re.IGNORECASE)
    if regex.search(value):
        raise vol.Invalid("the string should not contain HTML")
    return str(value)


def temperature_unit(value: Any) -> UnitOfTemperature:
    """Validate and transform temperature unit."""
    value = str(value).upper()
    if value == "C":
        return UnitOfTemperature.CELSIUS
    if value == "F":
        return UnitOfTemperature.FAHRENHEIT
    raise vol.Invalid("invalid temperature unit (expected C or F)")


def template(value: Any) -> template_helper.Template:
    """Validate a jinja2 template."""
    if value is None:
        raise vol.Invalid("template value is None")
    if isinstance(value, (list, dict, template_helper.Template)):
        raise vol.Invalid("template value should be a string")
    if not (hass := _async_get_hass_or_none()):
        raise vol.Invalid("Validates schema outside the event loop")

    template_value = template_helper.Template(str(value), hass)

    try:
        template_value.ensure_valid()
    except TemplateError as ex:
        raise vol.Invalid(f"invalid template ({ex})") from ex
    return template_value


def dynamic_template(value: Any) -> template_helper.Template:
    """Validate a dynamic (non static) jinja2 template."""
    if value is None:
        raise vol.Invalid("template value is None")
    if isinstance(value, (list, dict, template_helper.Template)):
        raise vol.Invalid("template value should be a string")
    if not template_helper.is_template_string(str(value)):
        raise vol.Invalid("template value does not contain a dynamic template")
    if not (hass := _async_get_hass_or_none()):
        from .frame import ReportBehavior, report_usage  # noqa: PLC0415

        report_usage(
            (
                "validates schema outside the event loop, "
                "which will stop working in HA Core 2025.10"
            ),
            core_behavior=ReportBehavior.LOG,
        )

    template_value = template_helper.Template(str(value), hass)

    try:
        template_value.ensure_valid()
    except TemplateError as ex:
        raise vol.Invalid(f"invalid template ({ex})") from ex
    return template_value


def template_complex(value: Any) -> Any:
    """Validate a complex jinja2 template."""
    if isinstance(value, list):
        return_list = value.copy()
        for idx, element in enumerate(return_list):
            return_list[idx] = template_complex(element)
        return return_list
    if isinstance(value, dict):
        return {
            template_complex(key): template_complex(element)
            for key, element in value.items()
        }
    if isinstance(value, str) and template_helper.is_template_string(value):
        return template(value)

    return value


def _positive_time_period_template_complex(value: Any) -> Any:
    """Do basic validation of a positive time period expressed as a templated dict."""
    if not isinstance(value, dict) or not value:
        raise vol.Invalid("template should be a dict")
    for key, element in value.items():
        if not isinstance(key, str):
            raise vol.Invalid("key should be a string")
        if not template_helper.is_template_string(key):
            vol.In(_TIME_PERIOD_DICT_KEYS)(key)
        if not isinstance(element, str) or (
            isinstance(element, str) and not template_helper.is_template_string(element)
        ):
            vol.All(vol.Coerce(float), vol.Range(min=0))(element)
    return template_complex(value)


positive_time_period_template = vol.Any(
    positive_time_period, dynamic_template, _positive_time_period_template_complex
)


def datetime(value: Any) -> datetime_sys:
    """Validate datetime."""
    if isinstance(value, datetime_sys):
        return value

    try:
        date_val = dt_util.parse_datetime(value)
    except TypeError:
        date_val = None

    if date_val is None:
        raise vol.Invalid(f"Invalid datetime specified: {value}")

    return date_val


def time_zone(value: str) -> str:
    """Validate timezone."""
    if dt_util.get_time_zone(value) is not None:
        return value
    raise vol.Invalid(
        "Invalid time zone passed in. Valid options can be found here: "
        "http://en.wikipedia.org/wiki/List_of_tz_database_time_zones"
    )


weekdays = vol.All(ensure_list, [vol.In(WEEKDAYS)])


def socket_timeout(value: Any | None) -> object:
    """Validate timeout float > 0.0.

    None coerced to socket._GLOBAL_DEFAULT_TIMEOUT bare object.
    """
    if value is None:
        return _GLOBAL_DEFAULT_TIMEOUT
    try:
        float_value = float(value)
        if float_value > 0.0:
            return float_value
    except Exception as err:
        raise vol.Invalid(f"Invalid socket timeout: {err}") from err
    raise vol.Invalid("Invalid socket timeout value. float > 0.0 required.")


def url(
    value: Any,
    _schema_list: frozenset[UrlProtocolSchema] = EXTERNAL_URL_PROTOCOL_SCHEMA_LIST,
) -> str:
    """Validate an URL."""
    url_in = str(value)

    if urlparse(url_in).scheme in _schema_list:
        return cast(str, vol.Schema(vol.Url())(url_in))

    raise vol.Invalid("invalid url")


def configuration_url(value: Any) -> str:
    """Validate an URL that allows the homeassistant schema."""
    return url(value, CONFIGURATION_URL_PROTOCOL_SCHEMA_LIST)


def url_no_path(value: Any) -> str:
    """Validate a url without a path."""
    url_in = url(value)

    if urlparse(url_in).path not in ("", "/"):
        raise vol.Invalid("url is not allowed to have a path component")

    return url_in


def x10_address(value: str) -> str:
    """Validate an x10 address."""
    regex = re.compile(r"([A-Pa-p]{1})(?:[2-9]|1[0-6]?)$")
    if not regex.match(value):
        raise vol.Invalid("Invalid X10 Address")
    return str(value).lower()


def uuid4_hex(value: Any) -> str:
    """Validate a v4 UUID in hex format."""
    try:
        result = UUID(value, version=4)
    except (ValueError, AttributeError, TypeError) as error:
        raise vol.Invalid("Invalid Version4 UUID", error_message=str(error)) from error

    if result.hex != value.lower():
        # UUID() will create a uuid4 if input is invalid
        raise vol.Invalid("Invalid Version4 UUID")

    return result.hex


_FAKE_UUID_4_HEX = re.compile(r"^[0-9a-f]{32}$")


def fake_uuid4_hex(value: Any) -> str:
    """Validate a fake v4 UUID generated by random_uuid_hex."""
    try:
        if not _FAKE_UUID_4_HEX.match(value):
            raise vol.Invalid("Invalid UUID")
    except TypeError as exc:
        raise vol.Invalid("Invalid UUID") from exc
    return cast(str, value)  # Pattern.match throws if input is not a string


def ensure_list_csv(value: Any) -> list:
    """Ensure that input is a list or make one from comma-separated string."""
    if isinstance(value, str):
        return [member.strip() for member in value.split(",")]
    return ensure_list(value)


class multi_select:
    """Multi select validator returning list of selected values."""

    def __init__(self, options: dict | list) -> None:
        """Initialize multi select."""
        self.options = options

    def __call__(self, selected: list) -> list:
        """Validate input."""
        if not isinstance(selected, list):
            raise vol.Invalid("Not a list")

        for value in selected:
            if value not in self.options:
                raise vol.Invalid(f"{value} is not a valid option")

        return selected


def _deprecated_or_removed(
    key: str,
    replacement_key: str | None,
    default: Any | None,
    raise_if_present: bool,
    option_removed: bool,
) -> Callable[[dict], dict]:
    """Log key as deprecated and provide a replacement (if exists) or fail.

    Expected behavior:
        - Outputs or throws the appropriate deprecation warning if key is detected
        - Outputs or throws the appropriate error if key is detected
          and removed from support
        - Processes schema moving the value from key to replacement_key
        - Processes schema changing nothing if only replacement_key provided
        - No warning if only replacement_key provided
        - No warning if neither key nor replacement_key are provided
            - Adds replacement_key with default value in this case
    """

    def validator(config: dict) -> dict:
        """Check if key is in config and log warning or error."""
        if key in config:
            if option_removed:
                level = logging.ERROR
                option_status = "has been removed"
            else:
                level = logging.WARNING
                option_status = "is deprecated"

            try:
                near = (
                    f"near {config.__config_file__}"  # type: ignore[attr-defined]
                    f":{config.__line__} "  # type: ignore[attr-defined]
                )
            except AttributeError:
                near = ""
            arguments: tuple[str, ...]
            if replacement_key:
                warning = "The '%s' option %s%s, please replace it with '%s'"
                arguments = (key, near, option_status, replacement_key)
            else:
                warning = (
                    "The '%s' option %s%s, please remove it from your configuration"
                )
                arguments = (key, near, option_status)

            if raise_if_present:
                raise vol.Invalid(warning % arguments)

            get_integration_logger(__name__).log(level, warning, *arguments)
            value = config[key]
            if replacement_key or option_removed:
                config.pop(key)
        else:
            value = default

        keys = [key]
        if replacement_key:
            keys.append(replacement_key)
            if value is not None and (
                replacement_key not in config or default == config.get(replacement_key)
            ):
                config[replacement_key] = value

        return has_at_most_one_key(*keys)(config)

    return validator


def deprecated(
    key: str,
    replacement_key: str | None = None,
    default: Any | None = None,
    raise_if_present: bool | None = False,
) -> Callable[[dict], dict]:
    """Log key as deprecated and provide a replacement (if exists).

    Expected behavior:
        - Outputs the appropriate deprecation warning if key is detected
          or raises an exception
        - Processes schema moving the value from key to replacement_key
        - Processes schema changing nothing if only replacement_key provided
        - No warning if only replacement_key provided
        - No warning if neither key nor replacement_key are provided
            - Adds replacement_key with default value in this case
    """
    return _deprecated_or_removed(
        key,
        replacement_key=replacement_key,
        default=default,
        raise_if_present=raise_if_present or False,
        option_removed=False,
    )


def removed(
    key: str,
    default: Any | None = None,
    raise_if_present: bool | None = True,
) -> Callable[[dict], dict]:
    """Log key as deprecated and fail the config validation.

    Expected behavior:
        - Outputs the appropriate error if key is detected and removed from
          support or raises an exception.
    """
    return _deprecated_or_removed(
        key,
        replacement_key=None,
        default=default,
        raise_if_present=raise_if_present or False,
        option_removed=True,
    )


def renamed(
    old_key: str,
    new_key: str,
) -> Callable[[Any], Any]:
    """Replace key with a new key.

    Fails if both the new and old key are present.
    """

    def validator(value: Any) -> Any:
        if not isinstance(value, dict):
            return value

        if old_key in value:
            if new_key in value:
                raise vol.Invalid(
                    f"Cannot specify both '{old_key}' and '{new_key}'. Please use '{new_key}' only."
                )
            value[new_key] = value.pop(old_key)

        return value

    return validator


type ValueSchemas = dict[Hashable, VolSchemaType | Callable[[Any], dict[str, Any]]]


def key_value_schemas(
    key: str,
    value_schemas: ValueSchemas,
    default_schema: VolSchemaType | Callable[[Any], dict[str, Any]] | None = None,
    default_description: str | None = None,
    list_alternatives: bool = True,
) -> Callable[[Any], dict[Hashable, Any]]:
    """Create a validator that validates based on a value for specific key.

    This gives better error messages.

    default_schema: An optional schema to use if the key value is not in value_schemas.
    default_description: A description of what is expected by the default schema, this
    will be added to the error message.
    list_alternatives: If True, list the keys in `value_schemas` in the error message.
    """
    if not list_alternatives and not default_description:
        raise ValueError(
            "default_description must be provided if list_alternatives is False"
        )

    def key_value_validator(value: Any) -> dict[Hashable, Any]:
        if not isinstance(value, dict):
            raise vol.Invalid("Expected a dictionary")

        key_value = value.get(key)

        if isinstance(key_value, Hashable) and key_value in value_schemas:
            return cast(dict[Hashable, Any], value_schemas[key_value](value))

        if default_schema:
            with contextlib.suppress(vol.Invalid):
                return cast(dict[Hashable, Any], default_schema(value))

        if list_alternatives:
            alternatives = ", ".join(str(alternative) for alternative in value_schemas)
            if default_description:
                alternatives = f"{alternatives}, {default_description}"
        else:
            # mypy does not understand that default_description is not None here
            alternatives = default_description  # type: ignore[assignment]
        raise vol.Invalid(
            f"Unexpected value for {key}: '{key_value}'. Expected {alternatives}"
        )

    return key_value_validator


# Validator helpers


def key_dependency[_KT: Hashable, _VT](
    key: Hashable, dependency: Hashable
) -> Callable[[dict[_KT, _VT]], dict[_KT, _VT]]:
    """Validate that all dependencies exist for key."""

    def validator(value: dict[_KT, _VT]) -> dict[_KT, _VT]:
        """Test dependencies."""
        if not isinstance(value, dict):
            raise vol.Invalid("key dependencies require a dict")
        if key in value and dependency not in value:
            raise vol.Invalid(
                f'dependency violation - key "{key}" requires '
                f'key "{dependency}" to exist'
            )

        return value

    return validator


def custom_serializer(schema: Any) -> Any:
    """Serialize additional types for voluptuous_serialize."""
    return _custom_serializer(schema, allow_section=True)


def _custom_serializer(schema: Any, *, allow_section: bool) -> Any:
    """Serialize additional types for voluptuous_serialize."""
    from homeassistant import data_entry_flow  # noqa: PLC0415

    from . import selector  # noqa: PLC0415

    if schema is positive_time_period_dict:
        return {"type": "positive_time_period_dict"}

    if schema is string:
        return {"type": "string"}

    if schema is boolean:
        return {"type": "boolean"}

    if isinstance(schema, data_entry_flow.section):
        if not allow_section:
            raise ValueError("Nesting expandable sections is not supported")
        return {
            "type": "expandable",
            "schema": voluptuous_serialize.convert(
                schema.schema,
                custom_serializer=functools.partial(
                    _custom_serializer, allow_section=False
                ),
            ),
            "expanded": not schema.options["collapsed"],
        }

    if isinstance(schema, multi_select):
        return {"type": "multi_select", "options": schema.options}

    if isinstance(schema, selector.Selector):
        return schema.serialize()

    return voluptuous_serialize.UNSUPPORTED


# Schemas
def empty_config_schema(domain: str) -> Callable[[dict], dict]:
    """Return a config schema which logs if there are configuration parameters."""

    def validator(config: dict) -> dict:
        if config_domain := config.get(domain):
            get_integration_logger(__name__).error(
                (
                    "The %s integration does not support any configuration parameters, "
                    "got %s. Please remove the configuration parameters from your "
                    "configuration."
                ),
                domain,
                config_domain,
            )
        return config

    return validator


def _no_yaml_config_schema(
    domain: str,
    issue_base: str,
    translation_key: str,
    translation_placeholders: dict[str, str],
) -> Callable[[dict], dict]:
    """Return a config schema which logs if attempted to setup from YAML."""

    def raise_issue() -> None:
        from .issue_registry import IssueSeverity, async_create_issue  # noqa: PLC0415

        # HomeAssistantError is raised if called from the wrong thread
        with contextlib.suppress(HomeAssistantError):
            hass = async_get_hass()
            async_create_issue(
                hass,
                HOMEASSISTANT_DOMAIN,
                f"{issue_base}_{domain}",
                is_fixable=False,
                issue_domain=domain,
                severity=IssueSeverity.ERROR,
                translation_key=translation_key,
                translation_placeholders={"domain": domain} | translation_placeholders,
            )

    def validator(config: dict) -> dict:
        if domain in config:
            get_integration_logger(__name__).error(
                (
                    "The %s integration does not support YAML setup, please remove it "
                    "from your configuration file"
                ),
                domain,
            )
            raise_issue()
        return config

    return validator


def config_entry_only_config_schema(domain: str) -> Callable[[dict], dict]:
    """Return a config schema which logs if attempted to setup from YAML.

    Use this when an integration's __init__.py defines setup or async_setup
    but setup from yaml is not supported.
    """

    return _no_yaml_config_schema(
        domain,
        "config_entry_only",
        "config_entry_only",
        {"add_integration": f"/config/integrations/dashboard/add?domain={domain}"},
    )


def platform_only_config_schema(domain: str) -> Callable[[dict], dict]:
    """Return a config schema which logs if attempted to setup from YAML.

    Use this when an integration's __init__.py defines setup or async_setup
    but setup from the integration key is not supported.
    """

    return _no_yaml_config_schema(
        domain,
        "platform_only",
        "platform_only",
        {},
    )


PLATFORM_SCHEMA = vol.Schema(
    {
        vol.Required(CONF_PLATFORM): string,
        vol.Optional(CONF_ENTITY_NAMESPACE): string,
        vol.Optional(CONF_SCAN_INTERVAL): time_period,
    }
)

PLATFORM_SCHEMA_BASE = PLATFORM_SCHEMA.extend({}, extra=vol.ALLOW_EXTRA)


TARGET_FIELDS: VolDictType = {
    vol.Optional(ATTR_ENTITY_ID): vol.All(ensure_list, [strict_entity_id]),
    vol.Optional(ATTR_DEVICE_ID): vol.All(ensure_list, [str]),
    vol.Optional(ATTR_AREA_ID): vol.All(ensure_list, [str]),
    vol.Optional(ATTR_FLOOR_ID): vol.All(ensure_list, [str]),
    vol.Optional(ATTR_LABEL_ID): vol.All(ensure_list, [str]),
}

ENTITY_SERVICE_FIELDS: VolDictType = {
    vol.Optional(ATTR_ENTITY_ID): comp_entity_ids,
    vol.Optional(ATTR_DEVICE_ID): vol.Any(
        ENTITY_MATCH_NONE,
        vol.All(ensure_list, [str]),
    ),
    vol.Optional(ATTR_AREA_ID): vol.Any(
        ENTITY_MATCH_NONE,
        vol.All(ensure_list, [str]),
    ),
    vol.Optional(ATTR_FLOOR_ID): vol.Any(
        ENTITY_MATCH_NONE,
        vol.All(ensure_list, [str]),
    ),
    vol.Optional(ATTR_LABEL_ID): vol.Any(
        ENTITY_MATCH_NONE,
        vol.All(ensure_list, [str]),
    ),
}

TARGET_SERVICE_FIELDS: VolDictType = {
    # Same as ENTITY_SERVICE_FIELDS but supports specifying entity
    # by entity registry ID.
    **ENTITY_SERVICE_FIELDS,
    vol.Optional(ATTR_ENTITY_ID): comp_entity_ids_or_uuids,
}

_TARGET_SERVICE_FIELDS_TEMPLATED: VolDictType = {
    # Either accept static entity IDs, a single dynamic template or a mixed list
    # of static and dynamic templates. While this could be solved with a single
    # complex template, handling it like this, keeps config validation useful.
    # Entity ID can be specified as either a user visible one or by entity registry ID.
    #
    # The schema supports templates as it is meant to be used in the initial validation
    # before templates are automatically rendered by the core logic.
    vol.Optional(ATTR_ENTITY_ID): vol.Any(
        comp_entity_ids_or_uuids,
        dynamic_template,
        vol.All(list, template_complex),
    ),
    vol.Optional(ATTR_DEVICE_ID): vol.Any(
        ENTITY_MATCH_NONE,
        dynamic_template,
        vol.All(ensure_list, [vol.Any(dynamic_template, str)]),
    ),
    vol.Optional(ATTR_AREA_ID): vol.Any(
        ENTITY_MATCH_NONE,
        dynamic_template,
        vol.All(ensure_list, [vol.Any(dynamic_template, str)]),
    ),
    vol.Optional(ATTR_FLOOR_ID): vol.Any(
        ENTITY_MATCH_NONE,
        dynamic_template,
        vol.All(ensure_list, [vol.Any(dynamic_template, str)]),
    ),
    vol.Optional(ATTR_LABEL_ID): vol.Any(
        ENTITY_MATCH_NONE,
        dynamic_template,
        vol.All(ensure_list, [vol.Any(dynamic_template, str)]),
    ),
}

_HAS_ENTITY_SERVICE_FIELD = has_at_least_one_key(*ENTITY_SERVICE_FIELDS)


def is_entity_service_schema(validator: VolSchemaType) -> bool:
    """Check if the passed validator is an entity schema validator.

    The validator must be either of:
    - A validator returned by cv._make_entity_service_schema
    - A validator returned by cv._make_entity_service_schema, wrapped in a vol.Schema
    - A validator returned by cv._make_entity_service_schema, wrapped in a vol.All
    Nesting is allowed.
    """
    if hasattr(validator, "_entity_service_schema"):
        return True
    if isinstance(validator, (vol.All)):
        return any(is_entity_service_schema(val) for val in validator.validators)
    if isinstance(validator, (vol.Schema)):
        return is_entity_service_schema(validator.schema)

    return False


def _make_entity_service_schema(schema: dict, extra: int) -> VolSchemaType:
    """Create an entity service schema."""
    validator = vol.All(
        vol.Schema(
            {
                # The frontend stores data here. Don't use in core.
                vol.Remove("metadata"): dict,
                **schema,
                **ENTITY_SERVICE_FIELDS,
            },
            extra=extra,
        ),
        _HAS_ENTITY_SERVICE_FIELD,
    )
    setattr(validator, "_entity_service_schema", True)
    return validator


BASE_ENTITY_SCHEMA = _make_entity_service_schema({}, vol.PREVENT_EXTRA)


def make_entity_service_schema(
    schema: dict | None, *, extra: int = vol.PREVENT_EXTRA
) -> VolSchemaType:
    """Create an entity service schema."""
    if not schema and extra == vol.PREVENT_EXTRA:
        # If the schema is empty and we don't allow extra keys, we can return
        # the base schema and avoid compiling a new schema which is the case
        # for ~50% of services.
        return BASE_ENTITY_SCHEMA
    return _make_entity_service_schema(schema or {}, extra)


SCRIPT_CONVERSATION_RESPONSE_SCHEMA = vol.Any(template, None)


SCRIPT_VARIABLES_SCHEMA = vol.All(
    vol.Schema({str: template_complex}),
    # pylint: disable-next=unnecessary-lambda
    lambda val: script_variables_helper.ScriptVariables(val),
)


def script_action(value: Any) -> dict:
    """Validate a script action."""
    if not isinstance(value, dict):
        raise vol.Invalid("expected dictionary")

    try:
        action = determine_script_action(value)
    except ValueError as err:
        raise vol.Invalid(str(err)) from err

    return ACTION_TYPE_SCHEMAS[action](value)


SCRIPT_SCHEMA = vol.All(ensure_list, [script_action])

SCRIPT_ACTION_BASE_SCHEMA: VolDictType = {
    vol.Optional(CONF_ALIAS): string,
    vol.Optional(CONF_CONTINUE_ON_ERROR): boolean,
    vol.Optional(CONF_ENABLED): vol.Any(boolean, template),
}

EVENT_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_EVENT): string,
        vol.Optional(CONF_EVENT_DATA): vol.All(dict, template_complex),
        vol.Optional(CONF_EVENT_DATA_TEMPLATE): vol.All(dict, template_complex),
    }
)


def _backward_compat_service_schema(value: Any | None) -> Any:
    """Backward compatibility for service schemas."""

    if not isinstance(value, dict):
        return value

    # `service` has been renamed to `action`
    if CONF_SERVICE in value:
        if CONF_ACTION in value:
            raise vol.Invalid(
                "Cannot specify both 'service' and 'action'. Please use 'action' only."
            )
        value[CONF_ACTION] = value.pop(CONF_SERVICE)

    return value


SERVICE_SCHEMA = vol.All(
    _backward_compat_service_schema,
    vol.Schema(
        {
            **SCRIPT_ACTION_BASE_SCHEMA,
            vol.Exclusive(CONF_ACTION, "service name"): vol.Any(
                service, dynamic_template
            ),
            vol.Exclusive(CONF_SERVICE_TEMPLATE, "service name"): vol.Any(
                service, dynamic_template
            ),
            vol.Optional(CONF_SERVICE_DATA): vol.Any(
                template, vol.All(dict, template_complex)
            ),
            vol.Optional(CONF_SERVICE_DATA_TEMPLATE): vol.Any(
                template, vol.All(dict, template_complex)
            ),
            vol.Optional(CONF_ENTITY_ID): comp_entity_ids,
            vol.Optional(CONF_TARGET): vol.Any(
                _TARGET_SERVICE_FIELDS_TEMPLATED, dynamic_template
            ),
            vol.Optional(CONF_RESPONSE_VARIABLE): str,
            # The frontend stores data here. Don't use in core.
            vol.Remove("metadata"): dict,
        }
    ),
    has_at_least_one_key(CONF_ACTION, CONF_SERVICE_TEMPLATE),
)

NUMERIC_STATE_THRESHOLD_SCHEMA = vol.Any(
    vol.Coerce(float),
    vol.All(str, entity_domain(["input_number", "number", "sensor", "zone"])),
)

CONDITION_BASE_SCHEMA: VolDictType = {
    vol.Optional(CONF_ALIAS): string,
    vol.Optional(CONF_ENABLED): vol.Any(boolean, template),
}

NUMERIC_STATE_CONDITION_SCHEMA = vol.All(
    vol.Schema(
        {
            **CONDITION_BASE_SCHEMA,
            vol.Required(CONF_CONDITION): "numeric_state",
            vol.Required(CONF_ENTITY_ID): entity_ids_or_uuids,
            vol.Optional(CONF_ATTRIBUTE): str,
            CONF_BELOW: NUMERIC_STATE_THRESHOLD_SCHEMA,
            CONF_ABOVE: NUMERIC_STATE_THRESHOLD_SCHEMA,
            vol.Optional(CONF_VALUE_TEMPLATE): template,
        }
    ),
    has_at_least_one_key(CONF_BELOW, CONF_ABOVE),
)

STATE_CONDITION_BASE_SCHEMA = {
    **CONDITION_BASE_SCHEMA,
    vol.Required(CONF_CONDITION): "state",
    vol.Required(CONF_ENTITY_ID): entity_ids_or_uuids,
    vol.Optional(CONF_MATCH, default=ENTITY_MATCH_ALL): vol.All(
        vol.Lower, vol.Any(ENTITY_MATCH_ALL, ENTITY_MATCH_ANY)
    ),
    vol.Optional(CONF_ATTRIBUTE): str,
    vol.Optional(CONF_FOR): positive_time_period_template,
}

STATE_CONDITION_STATE_SCHEMA = vol.Schema(
    {
        **STATE_CONDITION_BASE_SCHEMA,
        vol.Required(CONF_STATE): vol.Any(str, [str]),
    }
)

STATE_CONDITION_ATTRIBUTE_SCHEMA = vol.Schema(
    {
        **STATE_CONDITION_BASE_SCHEMA,
        vol.Required(CONF_STATE): match_all,
    }
)


def STATE_CONDITION_SCHEMA(value: Any) -> dict[str, Any]:
    """Validate a state condition."""
    if not isinstance(value, dict):
        raise vol.Invalid("Expected a dictionary")

    if CONF_ATTRIBUTE in value:
        validated: dict[str, Any] = STATE_CONDITION_ATTRIBUTE_SCHEMA(value)
    else:
        validated = STATE_CONDITION_STATE_SCHEMA(value)

    return key_dependency("for", "state")(validated)


TEMPLATE_CONDITION_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): "template",
        vol.Required(CONF_VALUE_TEMPLATE): template,
    }
)

TIME_CONDITION_SCHEMA = vol.All(
    vol.Schema(
        {
            **CONDITION_BASE_SCHEMA,
            vol.Required(CONF_CONDITION): "time",
            vol.Optional("before"): vol.Any(
                time, vol.All(str, entity_domain(["input_datetime", "time", "sensor"]))
            ),
            vol.Optional("after"): vol.Any(
                time, vol.All(str, entity_domain(["input_datetime", "time", "sensor"]))
            ),
            vol.Optional("weekday"): weekdays,
        }
    ),
    has_at_least_one_key("before", "after", "weekday"),
)

TRIGGER_CONDITION_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): "trigger",
        vol.Required(CONF_ID): vol.All(ensure_list, [string]),
    }
)

AND_CONDITION_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): "and",
        vol.Required(CONF_CONDITIONS): vol.All(
            ensure_list,
            # pylint: disable-next=unnecessary-lambda
            [lambda value: CONDITION_SCHEMA(value)],
        ),
    }
)

AND_CONDITION_SHORTHAND_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required("and"): vol.All(
            ensure_list,
            # pylint: disable-next=unnecessary-lambda
            [lambda value: CONDITION_SCHEMA(value)],
        ),
    }
)

OR_CONDITION_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): "or",
        vol.Required(CONF_CONDITIONS): vol.All(
            ensure_list,
            # pylint: disable-next=unnecessary-lambda
            [lambda value: CONDITION_SCHEMA(value)],
        ),
    }
)

OR_CONDITION_SHORTHAND_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required("or"): vol.All(
            ensure_list,
            # pylint: disable-next=unnecessary-lambda
            [lambda value: CONDITION_SCHEMA(value)],
        ),
    }
)

NOT_CONDITION_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): "not",
        vol.Required(CONF_CONDITIONS): vol.All(
            ensure_list,
            # pylint: disable-next=unnecessary-lambda
            [lambda value: CONDITION_SCHEMA(value)],
        ),
    }
)

NOT_CONDITION_SHORTHAND_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required("not"): vol.All(
            ensure_list,
            # pylint: disable-next=unnecessary-lambda
            [lambda value: CONDITION_SCHEMA(value)],
        ),
    }
)

DEVICE_CONDITION_BASE_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): "device",
        vol.Required(CONF_DEVICE_ID): str,
        vol.Required(CONF_DOMAIN): str,
        vol.Remove("metadata"): dict,
    }
)

DEVICE_CONDITION_SCHEMA = DEVICE_CONDITION_BASE_SCHEMA.extend({}, extra=vol.ALLOW_EXTRA)


def expand_condition_shorthand(value: Any | None) -> Any:
    """Expand boolean condition shorthand notations."""

    if not isinstance(value, dict) or CONF_CONDITIONS in value:
        return value

    for key, schema in (
        ("and", AND_CONDITION_SHORTHAND_SCHEMA),
        ("or", OR_CONDITION_SHORTHAND_SCHEMA),
        ("not", NOT_CONDITION_SHORTHAND_SCHEMA),
    ):
        try:
            schema(value)
            return {
                CONF_CONDITION: key,
                CONF_CONDITIONS: value[key],
                **{k: value[k] for k in value if k != key},
            }
        except vol.MultipleInvalid:
            pass

    if isinstance(value.get(CONF_CONDITION), list):
        try:
            CONDITION_SHORTHAND_SCHEMA(value)
            return {
                CONF_CONDITION: "and",
                CONF_CONDITIONS: value[CONF_CONDITION],
                **{k: value[k] for k in value if k != CONF_CONDITION},
            }
        except vol.MultipleInvalid:
            pass

    return value


dynamic_template_condition = vol.All(
    # Wrap a shorthand template condition in a template condition
    dynamic_template,
    lambda config: {
        CONF_VALUE_TEMPLATE: config,
        CONF_CONDITION: "template",
    },
)

CONDITION_SHORTHAND_SCHEMA = vol.Schema(
    {
        **CONDITION_BASE_SCHEMA,
        vol.Required(CONF_CONDITION): vol.All(
            ensure_list,
            # pylint: disable-next=unnecessary-lambda
            [lambda value: CONDITION_SCHEMA(value)],
        ),
    }
)

BUILT_IN_CONDITIONS: ValueSchemas = {
    "and": AND_CONDITION_SCHEMA,
    "device": DEVICE_CONDITION_SCHEMA,
    "not": NOT_CONDITION_SCHEMA,
    "numeric_state": NUMERIC_STATE_CONDITION_SCHEMA,
    "or": OR_CONDITION_SCHEMA,
    "state": STATE_CONDITION_SCHEMA,
    "template": TEMPLATE_CONDITION_SCHEMA,
    "time": TIME_CONDITION_SCHEMA,
    "trigger": TRIGGER_CONDITION_SCHEMA,
}


# This is first round of validation, we don't want to mutate the config here already,
# just ensure basics as condition type and alias are there.
def _base_condition_validator(value: Any) -> Any:
    vol.Schema(
        {
            **CONDITION_BASE_SCHEMA,
            CONF_CONDITION: vol.All(str, vol.NotIn(BUILT_IN_CONDITIONS)),
        },
        extra=vol.ALLOW_EXTRA,
    )(value)
    return value


CONDITION_SCHEMA: vol.Schema = vol.Schema(
    vol.Any(
        vol.All(
            expand_condition_shorthand,
            key_value_schemas(
                CONF_CONDITION,
                BUILT_IN_CONDITIONS,
                _base_condition_validator,
                "a condition, a list of conditions or a valid template",
                list_alternatives=False,
            ),
        ),
        dynamic_template_condition,
    )
)

CONDITIONS_SCHEMA = vol.All(ensure_list, [CONDITION_SCHEMA])

dynamic_template_condition_action = vol.All(
    # Wrap a shorthand template condition action in a template condition
    vol.Schema(
        {**CONDITION_BASE_SCHEMA, vol.Required(CONF_CONDITION): dynamic_template}
    ),
    lambda config: {
        **config,
        CONF_VALUE_TEMPLATE: config[CONF_CONDITION],
        CONF_CONDITION: "template",
    },
)


CONDITION_ACTION_SCHEMA: vol.Schema = vol.Schema(
    vol.All(
        expand_condition_shorthand,
        key_value_schemas(
            CONF_CONDITION,
            BUILT_IN_CONDITIONS,
            vol.Any(
                dynamic_template_condition_action,
                _base_condition_validator,
            ),
            "a condition, a list of conditions or a valid template",
            list_alternatives=False,
        ),
    )
)


def _trigger_pre_validator(value: Any | None) -> Any:
    """Rewrite trigger `trigger` to `platform`.

    `platform` has been renamed to `trigger` in user documentation and in the automation
    editor. The Python trigger implementation still uses `platform`, so we need to
    rename `trigger` to `platform.
    """

    if not isinstance(value, Mapping):
        # If the value is not a mapping, we let that be handled by the TRIGGER_SCHEMA
        return value

    if CONF_TRIGGER in value:
        if CONF_PLATFORM in value:
            raise vol.Invalid(
                "Cannot specify both 'platform' and 'trigger'. Please use 'trigger' only."
            )
        value = dict(value)
        value[CONF_PLATFORM] = value.pop(CONF_TRIGGER)
    elif CONF_PLATFORM not in value:
        raise vol.Invalid("required key not provided", [CONF_TRIGGER])

    return value


TRIGGER_BASE_SCHEMA = vol.Schema(
    {
        vol.Optional(CONF_ALIAS): str,
        vol.Required(CONF_PLATFORM): str,
        vol.Optional(CONF_ID): str,
        vol.Optional(CONF_VARIABLES): SCRIPT_VARIABLES_SCHEMA,
        vol.Optional(CONF_ENABLED): vol.Any(boolean, template),
    }
)


_base_trigger_validator_schema = TRIGGER_BASE_SCHEMA.extend({}, extra=vol.ALLOW_EXTRA)


def _base_trigger_list_flatten(triggers: list[Any]) -> list[Any]:
    """Flatten trigger arrays containing 'triggers:' sublists into a single list of triggers."""
    flatlist = []
    for t in triggers:
        if CONF_TRIGGERS in t and len(t) == 1:
            triggerlist = ensure_list(t[CONF_TRIGGERS])
            flatlist.extend(triggerlist)
        else:
            flatlist.append(t)

    return flatlist


# This is first round of validation, we don't want to mutate the config here already,
# just ensure basics as platform and ID are there.
def _base_trigger_validator(value: Any) -> Any:
    _base_trigger_validator_schema(value)
    return value


TRIGGER_SCHEMA = vol.All(
    ensure_list,
    _base_trigger_list_flatten,
    [vol.All(_trigger_pre_validator, _base_trigger_validator)],
)

_SCRIPT_DELAY_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_DELAY): positive_time_period_template,
    }
)

_SCRIPT_WAIT_TEMPLATE_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_WAIT_TEMPLATE): template,
        vol.Optional(CONF_TIMEOUT): positive_time_period_template,
        vol.Optional(CONF_CONTINUE_ON_TIMEOUT): boolean,
    }
)

DEVICE_ACTION_BASE_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_DEVICE_ID): string,
        vol.Required(CONF_DOMAIN): str,
        vol.Remove("metadata"): dict,
    }
)

DEVICE_ACTION_SCHEMA = DEVICE_ACTION_BASE_SCHEMA.extend({}, extra=vol.ALLOW_EXTRA)

_SCRIPT_SCENE_SCHEMA = vol.Schema(
    {**SCRIPT_ACTION_BASE_SCHEMA, vol.Required(CONF_SCENE): entity_domain("scene")}
)

_SCRIPT_REPEAT_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_REPEAT): vol.All(
            {
                vol.Exclusive(CONF_COUNT, "repeat"): vol.Any(vol.Coerce(int), template),
                vol.Exclusive(CONF_FOR_EACH, "repeat"): vol.Any(
                    dynamic_template, vol.All(list, template_complex)
                ),
                vol.Exclusive(CONF_WHILE, "repeat"): CONDITIONS_SCHEMA,
                vol.Exclusive(CONF_UNTIL, "repeat"): CONDITIONS_SCHEMA,
                vol.Required(CONF_SEQUENCE): SCRIPT_SCHEMA,
            },
            has_at_least_one_key(CONF_COUNT, CONF_FOR_EACH, CONF_WHILE, CONF_UNTIL),
        ),
    }
)

_SCRIPT_CHOOSE_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_CHOOSE): vol.All(
            ensure_list,
            [
                {
                    vol.Optional(CONF_ALIAS): string,
                    vol.Required(CONF_CONDITIONS): CONDITIONS_SCHEMA,
                    vol.Required(CONF_SEQUENCE): SCRIPT_SCHEMA,
                }
            ],
        ),
        vol.Optional(CONF_DEFAULT): SCRIPT_SCHEMA,
    }
)

_SCRIPT_WAIT_FOR_TRIGGER_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_WAIT_FOR_TRIGGER): TRIGGER_SCHEMA,
        vol.Optional(CONF_TIMEOUT): positive_time_period_template,
        vol.Optional(CONF_CONTINUE_ON_TIMEOUT): boolean,
    }
)

_SCRIPT_IF_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_IF): CONDITIONS_SCHEMA,
        vol.Required(CONF_THEN): SCRIPT_SCHEMA,
        vol.Optional(CONF_ELSE): SCRIPT_SCHEMA,
    }
)

_SCRIPT_SET_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_VARIABLES): SCRIPT_VARIABLES_SCHEMA,
    }
)

_SCRIPT_SET_CONVERSATION_RESPONSE_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(
            CONF_SET_CONVERSATION_RESPONSE
        ): SCRIPT_CONVERSATION_RESPONSE_SCHEMA,
    }
)

_SCRIPT_STOP_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_STOP): vol.Any(None, string),
        vol.Exclusive(CONF_ERROR, "error_or_response"): boolean,
        vol.Exclusive(
            CONF_RESPONSE_VARIABLE,
            "error_or_response",
            msg="not allowed to add a response to an error stop action",
        ): str,
    }
)

_SCRIPT_SEQUENCE_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        # The frontend stores data here. Don't use in core.
        vol.Remove("metadata"): dict,
        vol.Required(CONF_SEQUENCE): SCRIPT_SCHEMA,
    }
)

_parallel_sequence_action = vol.All(
    # Wrap a shorthand sequences in a parallel action
    SCRIPT_SCHEMA,
    lambda config: {
        CONF_SEQUENCE: config,
    },
)

_SCRIPT_PARALLEL_SCHEMA = vol.Schema(
    {
        **SCRIPT_ACTION_BASE_SCHEMA,
        vol.Required(CONF_PARALLEL): vol.All(
            ensure_list, [vol.Any(_SCRIPT_SEQUENCE_SCHEMA, _parallel_sequence_action)]
        ),
    }
)


SCRIPT_ACTION_ACTIVATE_SCENE = "scene"
SCRIPT_ACTION_CALL_SERVICE = "call_service"
SCRIPT_ACTION_CHECK_CONDITION = "condition"
SCRIPT_ACTION_CHOOSE = "choose"
SCRIPT_ACTION_DELAY = "delay"
SCRIPT_ACTION_DEVICE_AUTOMATION = "device"
SCRIPT_ACTION_FIRE_EVENT = "event"
SCRIPT_ACTION_IF = "if"
SCRIPT_ACTION_PARALLEL = "parallel"
SCRIPT_ACTION_REPEAT = "repeat"
SCRIPT_ACTION_SEQUENCE = "sequence"
SCRIPT_ACTION_SET_CONVERSATION_RESPONSE = "set_conversation_response"
SCRIPT_ACTION_STOP = "stop"
SCRIPT_ACTION_VARIABLES = "variables"
SCRIPT_ACTION_WAIT_FOR_TRIGGER = "wait_for_trigger"
SCRIPT_ACTION_WAIT_TEMPLATE = "wait_template"


ACTIONS_MAP = {
    CONF_DELAY: SCRIPT_ACTION_DELAY,
    CONF_WAIT_TEMPLATE: SCRIPT_ACTION_WAIT_TEMPLATE,
    CONF_CONDITION: SCRIPT_ACTION_CHECK_CONDITION,
    "and": SCRIPT_ACTION_CHECK_CONDITION,
    "or": SCRIPT_ACTION_CHECK_CONDITION,
    "not": SCRIPT_ACTION_CHECK_CONDITION,
    CONF_EVENT: SCRIPT_ACTION_FIRE_EVENT,
    CONF_DEVICE_ID: SCRIPT_ACTION_DEVICE_AUTOMATION,
    CONF_SCENE: SCRIPT_ACTION_ACTIVATE_SCENE,
    CONF_REPEAT: SCRIPT_ACTION_REPEAT,
    CONF_CHOOSE: SCRIPT_ACTION_CHOOSE,
    CONF_WAIT_FOR_TRIGGER: SCRIPT_ACTION_WAIT_FOR_TRIGGER,
    CONF_VARIABLES: SCRIPT_ACTION_VARIABLES,
    CONF_IF: SCRIPT_ACTION_IF,
    CONF_ACTION: SCRIPT_ACTION_CALL_SERVICE,
    CONF_SERVICE: SCRIPT_ACTION_CALL_SERVICE,
    CONF_SERVICE_TEMPLATE: SCRIPT_ACTION_CALL_SERVICE,
    CONF_STOP: SCRIPT_ACTION_STOP,
    CONF_PARALLEL: SCRIPT_ACTION_PARALLEL,
    CONF_SEQUENCE: SCRIPT_ACTION_SEQUENCE,
    CONF_SET_CONVERSATION_RESPONSE: SCRIPT_ACTION_SET_CONVERSATION_RESPONSE,
}

ACTIONS_SET = set(ACTIONS_MAP)


def determine_script_action(action: dict[str, Any]) -> str:
    """Determine action type."""
    if not (actions := ACTIONS_SET.intersection(action)):
        raise ValueError("Unable to determine action")
    if len(actions) > 1:
        # Ambiguous action, select the first one in the
        # order of the ACTIONS_MAP
        for action_key, _script_action in ACTIONS_MAP.items():
            if action_key in actions:
                return _script_action
    return ACTIONS_MAP[actions.pop()]


ACTION_TYPE_SCHEMAS: dict[str, Callable[[Any], dict]] = {
    SCRIPT_ACTION_ACTIVATE_SCENE: _SCRIPT_SCENE_SCHEMA,
    SCRIPT_ACTION_CALL_SERVICE: SERVICE_SCHEMA,
    SCRIPT_ACTION_CHECK_CONDITION: CONDITION_ACTION_SCHEMA,
    SCRIPT_ACTION_CHOOSE: _SCRIPT_CHOOSE_SCHEMA,
    SCRIPT_ACTION_DELAY: _SCRIPT_DELAY_SCHEMA,
    SCRIPT_ACTION_DEVICE_AUTOMATION: DEVICE_ACTION_SCHEMA,
    SCRIPT_ACTION_FIRE_EVENT: EVENT_SCHEMA,
    SCRIPT_ACTION_IF: _SCRIPT_IF_SCHEMA,
    SCRIPT_ACTION_PARALLEL: _SCRIPT_PARALLEL_SCHEMA,
    SCRIPT_ACTION_REPEAT: _SCRIPT_REPEAT_SCHEMA,
    SCRIPT_ACTION_SEQUENCE: _SCRIPT_SEQUENCE_SCHEMA,
    SCRIPT_ACTION_SET_CONVERSATION_RESPONSE: _SCRIPT_SET_CONVERSATION_RESPONSE_SCHEMA,
    SCRIPT_ACTION_STOP: _SCRIPT_STOP_SCHEMA,
    SCRIPT_ACTION_VARIABLES: _SCRIPT_SET_SCHEMA,
    SCRIPT_ACTION_WAIT_FOR_TRIGGER: _SCRIPT_WAIT_FOR_TRIGGER_SCHEMA,
    SCRIPT_ACTION_WAIT_TEMPLATE: _SCRIPT_WAIT_TEMPLATE_SCHEMA,
}


currency = vol.In(
    currencies.ACTIVE_CURRENCIES, msg="invalid ISO 4217 formatted currency"
)

historic_currency = vol.In(
    currencies.HISTORIC_CURRENCIES, msg="invalid ISO 4217 formatted historic currency"
)

country = vol.In(COUNTRIES, msg="invalid ISO 3166 formatted country")

language = vol.In(LANGUAGES, msg="invalid RFC 5646 formatted language")


async def async_validate(
    hass: HomeAssistant, validator: Callable[[Any], Any], value: Any
) -> Any:
    """Async friendly schema validation.

    If a validator decorated with @not_async_friendly is called, validation will be
    deferred to an executor. If not, validation will happen in the event loop.
    """
    _validating_async.set(True)
    try:
        return validator(value)
    except MustValidateInExecutor:
        return await hass.async_add_executor_job(
            _validate_in_executor, hass, validator, value
        )
    finally:
        _validating_async.set(False)


def _validate_in_executor(
    hass: HomeAssistant, validator: Callable[[Any], Any], value: Any
) -> Any:
    _hass.hass = hass
    try:
        return validator(value)
    finally:
        _hass.hass = None
</file>

<file path="data_entry_flow.py">
"""Helpers for the data entry flow."""

from __future__ import annotations

from http import HTTPStatus
from typing import Any, Generic, TypeVar

from aiohttp import web
import voluptuous as vol
import voluptuous_serialize

from homeassistant import data_entry_flow
from homeassistant.components.http import HomeAssistantView
from homeassistant.components.http.data_validator import RequestDataValidator

from . import config_validation as cv

_FlowManagerT = TypeVar(
    "_FlowManagerT",
    bound=data_entry_flow.FlowManager[Any, Any, Any],
    default=data_entry_flow.FlowManager,
)


class _BaseFlowManagerView(HomeAssistantView, Generic[_FlowManagerT]):
    """Foundation for flow manager views."""

    def __init__(self, flow_mgr: _FlowManagerT) -> None:
        """Initialize the flow manager index view."""
        self._flow_mgr = flow_mgr

    def _prepare_result_json(
        self, result: data_entry_flow.FlowResult
    ) -> dict[str, Any]:
        """Convert result to JSON serializable dict."""
        if result["type"] == data_entry_flow.FlowResultType.CREATE_ENTRY:
            assert "result" not in result
            return {
                key: val
                for key, val in result.items()
                if key not in ("data", "context")
            }

        data = dict(result)

        if "data_schema" not in result:
            return data

        if (schema := result["data_schema"]) is None:
            data["data_schema"] = []
        else:
            data["data_schema"] = voluptuous_serialize.convert(
                schema, custom_serializer=cv.custom_serializer
            )
        return data


class FlowManagerIndexView(_BaseFlowManagerView[_FlowManagerT]):
    """View to create config flows."""

    @RequestDataValidator(
        vol.Schema(
            {
                vol.Required("handler"): str,
                vol.Optional("show_advanced_options", default=False): cv.boolean,
            },
            extra=vol.ALLOW_EXTRA,
        )
    )
    async def post(self, request: web.Request, data: dict[str, Any]) -> web.Response:
        """Initialize a POST request.

        Override `post` and call `_post_impl` in subclasses which need
        to implement their own `RequestDataValidator`
        """
        return await self._post_impl(request, data)

    async def _post_impl(
        self, request: web.Request, data: dict[str, Any]
    ) -> web.Response:
        """Handle a POST request."""
        try:
            result = await self._flow_mgr.async_init(
                data["handler"],
                context=self.get_context(data),
            )
        except data_entry_flow.UnknownHandler:
            return self.json_message("Invalid handler specified", HTTPStatus.NOT_FOUND)
        except data_entry_flow.UnknownStep as err:
            return self.json_message(str(err), HTTPStatus.BAD_REQUEST)

        result = self._prepare_result_json(result)

        return self.json(result)

    def get_context(self, data: dict[str, Any]) -> dict[str, Any]:
        """Return context."""
        return {"show_advanced_options": data["show_advanced_options"]}


class FlowManagerResourceView(_BaseFlowManagerView[_FlowManagerT]):
    """View to interact with the flow manager."""

    async def get(self, request: web.Request, /, flow_id: str) -> web.Response:
        """Get the current state of a data_entry_flow."""
        try:
            result = await self._flow_mgr.async_configure(flow_id)
        except data_entry_flow.UnknownFlow:
            return self.json_message("Invalid flow specified", HTTPStatus.NOT_FOUND)

        result = self._prepare_result_json(result)

        return self.json(result)

    @RequestDataValidator(vol.Schema(dict), allow_empty=True)
    async def post(
        self, request: web.Request, data: dict[str, Any], flow_id: str
    ) -> web.Response:
        """Handle a POST request."""
        try:
            result = await self._flow_mgr.async_configure(flow_id, data)
        except data_entry_flow.UnknownFlow:
            return self.json_message("Invalid flow specified", HTTPStatus.NOT_FOUND)
        except data_entry_flow.InvalidData as ex:
            return self.json({"errors": ex.schema_errors}, HTTPStatus.BAD_REQUEST)

        result = self._prepare_result_json(result)

        return self.json(result)

    async def delete(self, request: web.Request, flow_id: str) -> web.Response:
        """Cancel a flow in progress."""
        try:
            self._flow_mgr.async_abort(flow_id)
        except data_entry_flow.UnknownFlow:
            return self.json_message("Invalid flow specified", HTTPStatus.NOT_FOUND)

        return self.json_message("Flow aborted")
</file>

<file path="debounce.py">
"""Debounce helper."""

from __future__ import annotations

import asyncio
from collections.abc import AsyncGenerator, Callable
from contextlib import asynccontextmanager
from logging import Logger
from typing import Any

from homeassistant.core import HassJob, HomeAssistant, callback


class Debouncer[_R_co]:
    """Class to rate limit calls to a specific command."""

    def __init__(
        self,
        hass: HomeAssistant,
        logger: Logger,
        *,
        cooldown: float,
        immediate: bool,
        function: Callable[[], _R_co] | None = None,
        background: bool = False,
    ) -> None:
        """Initialize debounce.

        immediate: indicate if the function needs to be called right away and
                   wait <cooldown> until executing next invocation.
        function: optional and can be instantiated later.
        """
        self.hass = hass
        self.logger = logger
        self._function = function
        self.cooldown = cooldown
        self.immediate = immediate
        self._timer_task: asyncio.TimerHandle | None = None
        self._execute_at_end_of_timer: bool = False
        self._execute_lock = asyncio.Lock()
        self._execute_lock_owner: asyncio.Task[Any] | None = None
        self._background = background
        self._job: HassJob[[], _R_co] | None = (
            None
            if function is None
            else HassJob(
                function, f"debouncer cooldown={cooldown}, immediate={immediate}"
            )
        )
        self._shutdown_requested = False

    @asynccontextmanager
    async def async_lock(self) -> AsyncGenerator[None]:
        """Return an async context manager to lock the debouncer."""
        if self._execute_lock_owner is asyncio.current_task():
            raise RuntimeError("Debouncer lock is not re-entrant")

        if self._execute_lock.locked():
            self.logger.debug("Debouncer lock is already acquired, waiting")

        async with self._execute_lock:
            self._execute_lock_owner = asyncio.current_task()
            try:
                yield
            finally:
                self._execute_lock_owner = None

    @property
    def function(self) -> Callable[[], _R_co] | None:
        """Return the function being wrapped by the Debouncer."""
        return self._function

    @function.setter
    def function(self, function: Callable[[], _R_co]) -> None:
        """Update the function being wrapped by the Debouncer."""
        self._function = function
        if self._job is None or function != self._job.target:
            self._job = HassJob(
                function,
                f"debouncer cooldown={self.cooldown}, immediate={self.immediate}",
            )

    @callback
    def async_schedule_call(self) -> None:
        """Schedule a call to the function."""
        if self._async_schedule_or_call_now():
            self._execute_at_end_of_timer = True
            self._on_debounce()

    def _async_schedule_or_call_now(self) -> bool:
        """Check if a call should be scheduled.

        Returns True if the function should be called immediately.

        Returns False if there is nothing to do.
        """
        if self._shutdown_requested:
            self.logger.debug("Debouncer call ignored as shutdown has been requested.")
            return False

        if self._timer_task:
            if not self._execute_at_end_of_timer:
                self._execute_at_end_of_timer = True

            return False

        # If not immediate or in progress, we schedule a call for later.
        if not self.immediate or self._execute_lock.locked():
            self._execute_at_end_of_timer = True
            self._schedule_timer()
            return False

        return True

    async def async_call(self) -> None:
        """Call the function."""
        if not self._async_schedule_or_call_now():
            return

        async with self.async_lock():
            # Abort if timer got set while we're waiting for the lock.
            if self._timer_task:
                return

            assert self._job is not None
            try:
                if task := self.hass.async_run_hass_job(
                    self._job, background=self._background
                ):
                    await task
            finally:
                self._schedule_timer()

    async def _handle_timer_finish(self) -> None:
        """Handle a finished timer."""
        assert self._job is not None

        self._execute_at_end_of_timer = False

        # Locked means a call is in progress. Any call is good, so abort.
        if self._execute_lock.locked():
            return

        async with self.async_lock():
            # Abort if timer got set while we're waiting for the lock.
            if self._timer_task:
                return

            try:
                if task := self.hass.async_run_hass_job(
                    self._job, background=self._background
                ):
                    await task
            except Exception:
                self.logger.exception("Unexpected exception from %s", self.function)
            finally:
                # Schedule a new timer to prevent new runs during cooldown
                self._schedule_timer()

    @callback
    def async_shutdown(self) -> None:
        """Cancel any scheduled call, and prevent new runs."""
        self._shutdown_requested = True
        self.async_cancel()
        # Release hard references to parent function
        # https://github.com/home-assistant/core/issues/137237
        self._function = None
        self._job = None

    @callback
    def async_cancel(self) -> None:
        """Cancel any scheduled call."""
        if self._timer_task:
            self._timer_task.cancel()
            self._timer_task = None

        self._execute_at_end_of_timer = False

    @callback
    def _on_debounce(self) -> None:
        """Create job task, but only if pending."""
        self._timer_task = None
        if not self._execute_at_end_of_timer:
            return
        self._execute_at_end_of_timer = False
        name = f"debouncer {self._job} finish cooldown={self.cooldown}, immediate={self.immediate}"
        if not self._background:
            self.hass.async_create_task(
                self._handle_timer_finish(), name, eager_start=True
            )
            return
        self.hass.async_create_background_task(
            self._handle_timer_finish(), name, eager_start=True
        )

    @callback
    def _schedule_timer(self) -> None:
        """Schedule a timer."""
        if not self._shutdown_requested:
            self._timer_task = self.hass.loop.call_later(
                self.cooldown, self._on_debounce
            )
</file>

<file path="deprecation.py">
"""Deprecation helpers for Home Assistant."""

from __future__ import annotations

from collections.abc import Callable
from contextlib import suppress
from enum import EnumType, IntEnum, IntFlag, StrEnum, _EnumDict
import functools
import inspect
import logging
from typing import Any, NamedTuple


def deprecated_substitute[_ObjectT: object](
    substitute_name: str,
) -> Callable[[Callable[[_ObjectT], Any]], Callable[[_ObjectT], Any]]:
    """Help migrate properties to new names.

    When a property is added to replace an older property, this decorator can
    be added to the new property, listing the old property as the substitute.
    If the old property is defined, its value will be used instead, and a log
    warning will be issued alerting the user of the impending change.
    """

    def decorator(func: Callable[[_ObjectT], Any]) -> Callable[[_ObjectT], Any]:
        """Decorate function as deprecated."""

        def func_wrapper(self: _ObjectT) -> Any:
            """Wrap for the original function."""
            if hasattr(self, substitute_name):
                # If this platform is still using the old property, issue
                # a logger warning once with instructions on how to fix it.
                warnings = getattr(func, "_deprecated_substitute_warnings", {})
                module_name = self.__module__
                if not warnings.get(module_name):
                    logger = logging.getLogger(module_name)
                    logger.warning(
                        (
                            "'%s' is deprecated. Please rename '%s' to "
                            "'%s' in '%s' to ensure future support."
                        ),
                        substitute_name,
                        substitute_name,
                        func.__name__,
                        inspect.getfile(self.__class__),
                    )
                    warnings[module_name] = True
                    setattr(func, "_deprecated_substitute_warnings", warnings)

                # Return the old property
                return getattr(self, substitute_name)
            return func(self)

        return func_wrapper

    return decorator


def get_deprecated(
    config: dict[str, Any], new_name: str, old_name: str, default: Any | None = None
) -> Any | None:
    """Allow an old config name to be deprecated with a replacement.

    If the new config isn't found, but the old one is, the old value is used
    and a warning is issued to the user.
    """
    if old_name in config:
        module = inspect.getmodule(inspect.stack(context=0)[1].frame)
        if module is not None:
            module_name = module.__name__
        else:
            # If Python is unable to access the sources files, the call stack frame
            # will be missing information, so let's guard.
            # https://github.com/home-assistant/core/issues/24982
            module_name = __name__

        logger = logging.getLogger(module_name)
        logger.warning(
            (
                "'%s' is deprecated. Please rename '%s' to '%s' in your "
                "configuration file."
            ),
            old_name,
            old_name,
            new_name,
        )
        return config.get(old_name)
    return config.get(new_name, default)


def deprecated_class[**_P, _R](
    replacement: str, *, breaks_in_ha_version: str | None = None
) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:
    """Mark class as deprecated and provide a replacement class to be used instead.

    If the deprecated function was called from a custom integration, ask the user to
    report an issue.
    """

    def deprecated_decorator(cls: Callable[_P, _R]) -> Callable[_P, _R]:
        """Decorate class as deprecated."""

        @functools.wraps(cls)
        def deprecated_cls(*args: _P.args, **kwargs: _P.kwargs) -> _R:
            """Wrap for the original class."""
            _print_deprecation_warning(
                cls, replacement, "class", "instantiated", breaks_in_ha_version
            )
            return cls(*args, **kwargs)

        return deprecated_cls

    return deprecated_decorator


def deprecated_function[**_P, _R](
    replacement: str, *, breaks_in_ha_version: str | None = None
) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]:
    """Mark function as deprecated and provide a replacement to be used instead.

    If the deprecated function was called from a custom integration, ask the user to
    report an issue.
    """

    def deprecated_decorator(func: Callable[_P, _R]) -> Callable[_P, _R]:
        """Decorate function as deprecated."""

        @functools.wraps(func)
        def deprecated_func(*args: _P.args, **kwargs: _P.kwargs) -> _R:
            """Wrap for the original function."""
            _print_deprecation_warning(
                func, replacement, "function", "called", breaks_in_ha_version
            )
            return func(*args, **kwargs)

        return deprecated_func

    return deprecated_decorator


def deprecated_hass_argument[**_P, _T](
    breaks_in_ha_version: str | None = None,
) -> Callable[[Callable[_P, _T]], Callable[_P, _T]]:
    """Decorate function to indicate that first argument hass will be ignored."""

    def _decorator(func: Callable[_P, _T]) -> Callable[_P, _T]:
        @functools.wraps(func)
        def _inner(*args: _P.args, **kwargs: _P.kwargs) -> _T:
            from homeassistant.core import HomeAssistant  # noqa: PLC0415

            in_arg = len(args) > 0 and isinstance(args[0], HomeAssistant)
            in_kwarg = "hass" in kwargs and isinstance(kwargs["hass"], HomeAssistant)

            if in_arg or in_kwarg:
                _print_deprecation_warning_internal(
                    "hass",
                    func.__module__,
                    f"{func.__name__} without hass argument",
                    "argument",
                    f"passed to {func.__name__}",
                    breaks_in_ha_version,
                    log_when_no_integration_is_found=True,
                )
                if in_arg:
                    args = args[1:]  # type: ignore[assignment]
                if in_kwarg:
                    kwargs.pop("hass")

            return func(*args, **kwargs)

        return _inner

    return _decorator


def _print_deprecation_warning(
    obj: Any,
    replacement: str,
    description: str,
    verb: str,
    breaks_in_ha_version: str | None,
) -> None:
    _print_deprecation_warning_internal(
        obj.__name__,
        obj.__module__,
        replacement,
        description,
        verb,
        breaks_in_ha_version,
        log_when_no_integration_is_found=True,
    )


def _print_deprecation_warning_internal(
    obj_name: str,
    module_name: str,
    replacement: str,
    description: str,
    verb: str,
    breaks_in_ha_version: str | None,
    *,
    log_when_no_integration_is_found: bool,
) -> None:
    # Suppress ImportError due to use of deprecated enum in core.py
    # Can be removed in HA Core 2025.1
    with suppress(ImportError):
        _print_deprecation_warning_internal_impl(
            obj_name,
            module_name,
            replacement,
            description,
            verb,
            breaks_in_ha_version,
            log_when_no_integration_is_found=log_when_no_integration_is_found,
        )


def _print_deprecation_warning_internal_impl(
    obj_name: str,
    module_name: str,
    replacement: str,
    description: str,
    verb: str,
    breaks_in_ha_version: str | None,
    *,
    log_when_no_integration_is_found: bool,
) -> None:
    from homeassistant.core import async_get_hass_or_none  # noqa: PLC0415
    from homeassistant.loader import async_suggest_report_issue  # noqa: PLC0415

    from .frame import MissingIntegrationFrame, get_integration_frame  # noqa: PLC0415

    logger = logging.getLogger(module_name)
    if breaks_in_ha_version:
        breaks_in = f" It will be removed in HA Core {breaks_in_ha_version}."
    else:
        breaks_in = ""
    try:
        integration_frame = get_integration_frame()
    except MissingIntegrationFrame:
        if log_when_no_integration_is_found:
            logger.warning(
                "The deprecated %s %s was %s.%s Use %s instead",
                description,
                obj_name,
                verb,
                breaks_in,
                replacement,
            )
    else:
        if integration_frame.custom_integration:
            report_issue = async_suggest_report_issue(
                async_get_hass_or_none(),
                integration_domain=integration_frame.integration,
                module=integration_frame.module,
            )
            logger.warning(
                ("The deprecated %s %s was %s from %s.%s Use %s instead, please %s"),
                description,
                obj_name,
                verb,
                integration_frame.integration,
                breaks_in,
                replacement,
                report_issue,
            )
        else:
            logger.warning(
                "The deprecated %s %s was %s from %s.%s Use %s instead",
                description,
                obj_name,
                verb,
                integration_frame.integration,
                breaks_in,
                replacement,
            )


class DeprecatedConstant[T](NamedTuple):
    """Deprecated constant."""

    value: T
    replacement: str
    breaks_in_ha_version: str | None


class DeprecatedConstantEnum[T: (StrEnum | IntEnum | IntFlag)](NamedTuple):
    """Deprecated constant."""

    enum: T
    breaks_in_ha_version: str | None


class DeprecatedAlias[T](NamedTuple):
    """Deprecated alias."""

    value: T
    replacement: str
    breaks_in_ha_version: str | None


class DeferredDeprecatedAlias[T]:
    """Deprecated alias with deferred evaluation of the value."""

    def __init__(
        self,
        value_fn: Callable[[], T],
        replacement: str,
        breaks_in_ha_version: str | None,
    ) -> None:
        """Initialize."""
        self.breaks_in_ha_version = breaks_in_ha_version
        self.replacement = replacement
        self._value_fn = value_fn

    @functools.cached_property
    def value(self) -> T:
        """Return the value."""
        return self._value_fn()


_PREFIX_DEPRECATED = "_DEPRECATED_"


def check_if_deprecated_constant(name: str, module_globals: dict[str, Any]) -> Any:
    """Check if the not found name is a deprecated constant.

    If it is, print a deprecation warning and return the value of the constant.
    Otherwise raise AttributeError.
    """
    module_name = module_globals.get("__name__")
    value = replacement = None
    description = "constant"
    if (deprecated_const := module_globals.get(_PREFIX_DEPRECATED + name)) is None:
        raise AttributeError(f"Module {module_name!r} has no attribute {name!r}")
    if isinstance(deprecated_const, DeprecatedConstant):
        value = deprecated_const.value
        replacement = deprecated_const.replacement
        breaks_in_ha_version = deprecated_const.breaks_in_ha_version
    elif isinstance(deprecated_const, DeprecatedConstantEnum):
        value = deprecated_const.enum
        replacement = (
            f"{deprecated_const.enum.__class__.__name__}.{deprecated_const.enum.name}"
        )
        breaks_in_ha_version = deprecated_const.breaks_in_ha_version
    elif isinstance(deprecated_const, (DeprecatedAlias, DeferredDeprecatedAlias)):
        description = "alias"
        value = deprecated_const.value
        replacement = deprecated_const.replacement
        breaks_in_ha_version = deprecated_const.breaks_in_ha_version

    if value is None or replacement is None:
        msg = (
            f"Value of {_PREFIX_DEPRECATED}{name} is an instance of "
            f"{type(deprecated_const)} but an instance of DeprecatedAlias, "
            "DeferredDeprecatedAlias, DeprecatedConstant or DeprecatedConstantEnum "
            "is required"
        )

        logging.getLogger(module_name).debug(msg)
        # PEP 562 -- Module __getattr__ and __dir__
        # specifies that __getattr__ should raise AttributeError if the attribute is not
        # found.
        # https://peps.python.org/pep-0562/#specification
        raise AttributeError(msg)

    _print_deprecation_warning_internal(
        name,
        module_name or __name__,
        replacement,
        description,
        "used",
        breaks_in_ha_version,
        log_when_no_integration_is_found=False,
    )
    return value


def dir_with_deprecated_constants(module_globals_keys: list[str]) -> list[str]:
    """Return dir() with deprecated constants."""
    return module_globals_keys + [
        name.removeprefix(_PREFIX_DEPRECATED)
        for name in module_globals_keys
        if name.startswith(_PREFIX_DEPRECATED)
    ]


def all_with_deprecated_constants(module_globals: dict[str, Any]) -> list[str]:
    """Generate a list for __all___ with deprecated constants."""
    # Iterate over a copy in case the globals dict is mutated by another thread
    # while we loop over it.
    module_globals_keys = list(module_globals)
    return [itm for itm in module_globals_keys if not itm.startswith("_")] + [
        name.removeprefix(_PREFIX_DEPRECATED)
        for name in module_globals_keys
        if name.startswith(_PREFIX_DEPRECATED)
    ]


class EnumWithDeprecatedMembers(EnumType):
    """Enum with deprecated members."""

    def __new__(
        mcs,
        cls: str,
        bases: tuple[type, ...],
        classdict: _EnumDict,
        *,
        deprecated: dict[str, tuple[str, str]],
        **kwds: Any,
    ) -> Any:
        """Create a new class."""
        classdict["__deprecated__"] = deprecated
        return super().__new__(mcs, cls, bases, classdict, **kwds)

    def __getattribute__(cls, name: str) -> Any:
        """Warn if accessing a deprecated member."""
        deprecated = super().__getattribute__("__deprecated__")
        if name in deprecated:
            _print_deprecation_warning_internal(
                f"{cls.__name__}.{name}",
                cls.__module__,
                f"{deprecated[name][0]}",
                "enum member",
                "used",
                deprecated[name][1],
                log_when_no_integration_is_found=False,
            )
        return super().__getattribute__(name)
</file>

<file path="device_registry.py">
"""Provide a way to connect entities belonging to one device."""

from __future__ import annotations

from collections import defaultdict
from collections.abc import Iterable, Mapping
from datetime import datetime
from enum import StrEnum
from functools import lru_cache
import logging
import time
from typing import TYPE_CHECKING, Any, Literal, TypedDict

import attr
from yarl import URL

from homeassistant.const import EVENT_HOMEASSISTANT_STARTED, EVENT_HOMEASSISTANT_STOP
from homeassistant.core import (
    Event,
    HomeAssistant,
    ReleaseChannel,
    callback,
    get_release_channel,
)
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import async_suggest_report_issue
from homeassistant.util import uuid as uuid_util
from homeassistant.util.dt import utc_from_timestamp, utcnow
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.json import format_unserializable_data

from . import storage, translation
from .debounce import Debouncer
from .deprecation import deprecated_function
from .frame import ReportBehavior, report_usage
from .json import JSON_DUMP, find_paths_unserializable_data, json_bytes, json_fragment
from .registry import BaseRegistry, BaseRegistryItems, RegistryIndexType
from .singleton import singleton
from .typing import UNDEFINED, UndefinedType

if TYPE_CHECKING:
    # mypy cannot workout _cache Protocol with attrs
    from propcache.api import cached_property as under_cached_property

    from homeassistant.config_entries import ConfigEntry

    from . import entity_registry
else:
    from propcache.api import under_cached_property

_LOGGER = logging.getLogger(__name__)

DATA_REGISTRY: HassKey[DeviceRegistry] = HassKey("device_registry")
EVENT_DEVICE_REGISTRY_UPDATED: EventType[EventDeviceRegistryUpdatedData] = EventType(
    "device_registry_updated"
)
STORAGE_KEY = "core.device_registry"
STORAGE_VERSION_MAJOR = 1
STORAGE_VERSION_MINOR = 12

CLEANUP_DELAY = 10

CONNECTION_BLUETOOTH = "bluetooth"
CONNECTION_NETWORK_MAC = "mac"
CONNECTION_UPNP = "upnp"
CONNECTION_ZIGBEE = "zigbee"

ORPHANED_DEVICE_KEEP_SECONDS = 86400 * 30

# Can be removed when suggested_area is removed from DeviceEntry
RUNTIME_ONLY_ATTRS = {"suggested_area"}

CONFIGURATION_URL_SCHEMES = {"http", "https", "homeassistant"}


class DeviceEntryDisabler(StrEnum):
    """What disabled a device entry."""

    CONFIG_ENTRY = "config_entry"
    INTEGRATION = "integration"
    USER = "user"


class DeviceInfo(TypedDict, total=False):
    """Entity device information for device registry."""

    configuration_url: str | URL | None
    connections: set[tuple[str, str]]
    created_at: str
    default_manufacturer: str
    default_model: str
    default_name: str
    entry_type: DeviceEntryType | None
    identifiers: set[tuple[str, str]]
    manufacturer: str | None
    model: str | None
    model_id: str | None
    modified_at: str
    name: str | None
    serial_number: str | None
    suggested_area: str | None
    sw_version: str | None
    hw_version: str | None
    translation_key: str | None
    translation_placeholders: Mapping[str, str] | None
    via_device: tuple[str, str]


DEVICE_INFO_TYPES = {
    # Device info is categorized by finding the first device info type which has all
    # the keys of the device info. The link device info type must be kept first
    # to make it preferred over primary.
    "link": {
        "connections",
        "identifiers",
    },
    "primary": {
        "configuration_url",
        "connections",
        "entry_type",
        "hw_version",
        "identifiers",
        "manufacturer",
        "model",
        "model_id",
        "name",
        "serial_number",
        "suggested_area",
        "sw_version",
        "via_device",
    },
    "secondary": {
        "connections",
        "default_manufacturer",
        "default_model",
        "default_name",
        # Used by Fritz
        "via_device",
    },
}

DEVICE_INFO_KEYS = set.union(*(itm for itm in DEVICE_INFO_TYPES.values()))

# Integrations which may share a device with a native integration
LOW_PRIO_CONFIG_ENTRY_DOMAINS = {"homekit_controller", "matter", "mqtt", "upnp"}


class _EventDeviceRegistryUpdatedData_Create(TypedDict):
    """EventDeviceRegistryUpdated data for action type 'create'."""

    action: Literal["create"]
    device_id: str


class _EventDeviceRegistryUpdatedData_Remove(TypedDict):
    """EventDeviceRegistryUpdated data for action type 'remove'."""

    action: Literal["remove"]
    device_id: str
    device: dict[str, Any]


class _EventDeviceRegistryUpdatedData_Update(TypedDict):
    """EventDeviceRegistryUpdated data for action type 'update'."""

    action: Literal["update"]
    device_id: str
    changes: dict[str, Any]


type EventDeviceRegistryUpdatedData = (
    _EventDeviceRegistryUpdatedData_Create
    | _EventDeviceRegistryUpdatedData_Remove
    | _EventDeviceRegistryUpdatedData_Update
)


class DeviceEntryType(StrEnum):
    """Device entry type."""

    SERVICE = "service"


class DeviceInfoError(HomeAssistantError):
    """Raised when device info is invalid."""

    def __init__(self, domain: str, device_info: DeviceInfo, message: str) -> None:
        """Initialize error."""
        super().__init__(
            f"Invalid device info {device_info} for '{domain}' config entry: {message}",
        )
        self.device_info = device_info
        self.domain = domain


class DeviceCollisionError(HomeAssistantError):
    """Raised when a device collision is detected."""


class DeviceIdentifierCollisionError(DeviceCollisionError):
    """Raised when a device identifier collision is detected."""

    def __init__(
        self, identifiers: set[tuple[str, str]], existing_device: DeviceEntry
    ) -> None:
        """Initialize error."""
        super().__init__(
            f"Identifiers {identifiers} already registered with {existing_device}"
        )


class DeviceConnectionCollisionError(DeviceCollisionError):
    """Raised when a device connection collision is detected."""

    def __init__(
        self, normalized_connections: set[tuple[str, str]], existing_device: DeviceEntry
    ) -> None:
        """Initialize error."""
        super().__init__(
            f"Connections {normalized_connections} "
            f"already registered with {existing_device}"
        )


def _validate_device_info(
    config_entry: ConfigEntry,
    device_info: DeviceInfo,
) -> str:
    """Process a device info."""
    keys = set(device_info)

    # If no keys or not enough info to match up, abort
    if not device_info.get("connections") and not device_info.get("identifiers"):
        raise DeviceInfoError(
            config_entry.domain,
            device_info,
            "device info must include at least one of identifiers or connections",
        )

    device_info_type: str | None = None

    # Find the first device info type which has all keys in the device info
    for possible_type, allowed_keys in DEVICE_INFO_TYPES.items():
        if keys <= allowed_keys:
            device_info_type = possible_type
            break

    if device_info_type is None:
        raise DeviceInfoError(
            config_entry.domain,
            device_info,
            (
                "device info needs to either describe a device, "
                "link to existing device or provide extra information."
            ),
        )

    return device_info_type


_cached_parse_url = lru_cache(maxsize=512)(URL)
"""Parse a URL and cache the result."""


def _validate_configuration_url(value: Any) -> str | None:
    """Validate and convert configuration_url."""
    if value is None:
        return None

    url_as_str = str(value)
    url = value if type(value) is URL else _cached_parse_url(url_as_str)

    if url.scheme not in CONFIGURATION_URL_SCHEMES or not url.host:
        raise ValueError(f"invalid configuration_url '{value}'")

    return url_as_str


@lru_cache(maxsize=512)
def format_mac(mac: str) -> str:
    """Format the mac address string for entry into dev reg."""
    to_test = mac

    if len(to_test) == 17 and to_test.count(":") == 5:
        return to_test.lower()

    if len(to_test) == 17 and to_test.count("-") == 5:
        to_test = to_test.replace("-", "")
    elif len(to_test) == 14 and to_test.count(".") == 2:
        to_test = to_test.replace(".", "")

    if len(to_test) == 12:
        # no : included
        return ":".join(to_test.lower()[i : i + 2] for i in range(0, 12, 2))

    # Not sure how formatted, return original
    return mac


def _normalize_connections(
    connections: Iterable[tuple[str, str]],
) -> set[tuple[str, str]]:
    """Normalize connections to ensure we can match mac addresses."""
    return {
        (key, format_mac(value)) if key == CONNECTION_NETWORK_MAC else (key, value)
        for key, value in connections
    }


def _normalize_connections_validator(
    instance: Any,
    attribute: Any,
    connections: Iterable[tuple[str, str]],
) -> None:
    """Check connections normalization used as attrs validator."""
    for key, value in connections:
        if key == CONNECTION_NETWORK_MAC and format_mac(value) != value:
            raise ValueError(f"Invalid mac address format: {value}")


@attr.s(frozen=True, slots=True)
class DeviceEntry:
    """Device Registry Entry."""

    area_id: str | None = attr.ib(default=None)
    config_entries: set[str] = attr.ib(converter=set, factory=set)
    config_entries_subentries: dict[str, set[str | None]] = attr.ib(factory=dict)
    configuration_url: str | None = attr.ib(default=None)
    connections: set[tuple[str, str]] = attr.ib(
        converter=set, factory=set, validator=_normalize_connections_validator
    )
    created_at: datetime = attr.ib(factory=utcnow)
    disabled_by: DeviceEntryDisabler | None = attr.ib(default=None)
    entry_type: DeviceEntryType | None = attr.ib(default=None)
    hw_version: str | None = attr.ib(default=None)
    id: str = attr.ib(factory=uuid_util.random_uuid_hex)
    identifiers: set[tuple[str, str]] = attr.ib(converter=set, factory=set)
    labels: set[str] = attr.ib(converter=set, factory=set)
    manufacturer: str | None = attr.ib(default=None)
    model: str | None = attr.ib(default=None)
    model_id: str | None = attr.ib(default=None)
    modified_at: datetime = attr.ib(factory=utcnow)
    name_by_user: str | None = attr.ib(default=None)
    name: str | None = attr.ib(default=None)
    primary_config_entry: str | None = attr.ib(default=None)
    serial_number: str | None = attr.ib(default=None)
    # Suggested area is deprecated and will be removed from DeviceEntry in 2026.9.
    _suggested_area: str | None = attr.ib(default=None)
    sw_version: str | None = attr.ib(default=None)
    via_device_id: str | None = attr.ib(default=None)
    _cache: dict[str, Any] = attr.ib(factory=dict, eq=False, init=False)

    @property
    def disabled(self) -> bool:
        """Return if entry is disabled."""
        return self.disabled_by is not None

    @property
    def dict_repr(self) -> dict[str, Any]:
        """Return a dict representation of the entry."""
        # Convert sets and tuples to lists
        # so the JSON serializer does not have to do
        # it every time
        return {
            "area_id": self.area_id,
            "configuration_url": self.configuration_url,
            "config_entries": list(self.config_entries),
            "config_entries_subentries": {
                config_entry_id: list(subentries)
                for config_entry_id, subentries in self.config_entries_subentries.items()
            },
            "connections": list(self.connections),
            "created_at": self.created_at.timestamp(),
            "disabled_by": self.disabled_by,
            "entry_type": self.entry_type,
            "hw_version": self.hw_version,
            "id": self.id,
            "identifiers": list(self.identifiers),
            "labels": list(self.labels),
            "manufacturer": self.manufacturer,
            "model": self.model,
            "model_id": self.model_id,
            "modified_at": self.modified_at.timestamp(),
            "name_by_user": self.name_by_user,
            "name": self.name,
            "primary_config_entry": self.primary_config_entry,
            "serial_number": self.serial_number,
            "sw_version": self.sw_version,
            "via_device_id": self.via_device_id,
        }

    @under_cached_property
    def json_repr(self) -> bytes | None:
        """Return a cached JSON representation of the entry."""
        try:
            dict_repr = self.dict_repr
            return json_bytes(dict_repr)
        except (ValueError, TypeError):
            _LOGGER.error(
                "Unable to serialize entry %s to JSON. Bad data found at %s",
                self.id,
                format_unserializable_data(
                    find_paths_unserializable_data(dict_repr, dump=JSON_DUMP)
                ),
            )
        return None

    @under_cached_property
    def as_storage_fragment(self) -> json_fragment:
        """Return a json fragment for storage."""
        return json_fragment(
            json_bytes(
                {
                    "area_id": self.area_id,
                    # The config_entries list can be removed from the storage
                    # representation in HA Core 2026.2
                    "config_entries": list(self.config_entries),
                    "config_entries_subentries": {
                        config_entry_id: list(subentries)
                        for config_entry_id, subentries in self.config_entries_subentries.items()
                    },
                    "configuration_url": self.configuration_url,
                    "connections": list(self.connections),
                    "created_at": self.created_at,
                    "disabled_by": self.disabled_by,
                    "entry_type": self.entry_type,
                    "hw_version": self.hw_version,
                    "id": self.id,
                    "identifiers": list(self.identifiers),
                    "labels": list(self.labels),
                    "manufacturer": self.manufacturer,
                    "model": self.model,
                    "model_id": self.model_id,
                    "modified_at": self.modified_at,
                    "name_by_user": self.name_by_user,
                    "name": self.name,
                    "primary_config_entry": self.primary_config_entry,
                    "serial_number": self.serial_number,
                    "sw_version": self.sw_version,
                    "via_device_id": self.via_device_id,
                }
            )
        )

    @property
    @deprecated_function(
        "code which ignores suggested_area", breaks_in_ha_version="2026.9"
    )
    def suggested_area(self) -> str | None:
        """Return the suggested area for this device entry."""
        return self._suggested_area


@attr.s(frozen=True, slots=True)
class DeletedDeviceEntry:
    """Deleted Device Registry Entry."""

    area_id: str | None = attr.ib()
    config_entries: set[str] = attr.ib()
    config_entries_subentries: dict[str, set[str | None]] = attr.ib()
    connections: set[tuple[str, str]] = attr.ib(
        validator=_normalize_connections_validator
    )
    created_at: datetime = attr.ib()
    disabled_by: DeviceEntryDisabler | UndefinedType | None = attr.ib()
    id: str = attr.ib()
    identifiers: set[tuple[str, str]] = attr.ib()
    labels: set[str] = attr.ib()
    modified_at: datetime = attr.ib()
    name_by_user: str | None = attr.ib()
    orphaned_timestamp: float | None = attr.ib()
    _cache: dict[str, Any] = attr.ib(factory=dict, eq=False, init=False)

    def to_device_entry(
        self,
        config_entry: ConfigEntry,
        config_subentry_id: str | None,
        connections: set[tuple[str, str]],
        identifiers: set[tuple[str, str]],
        disabled_by: DeviceEntryDisabler | UndefinedType | None,
    ) -> DeviceEntry:
        """Create DeviceEntry from DeletedDeviceEntry."""
        # Adjust disabled_by based on config entry state
        if self.disabled_by is not UNDEFINED:
            disabled_by = self.disabled_by
            if config_entry.disabled_by:
                if disabled_by is None:
                    disabled_by = DeviceEntryDisabler.CONFIG_ENTRY
            elif disabled_by == DeviceEntryDisabler.CONFIG_ENTRY:
                disabled_by = None
        else:
            disabled_by = disabled_by if disabled_by is not UNDEFINED else None
        return DeviceEntry(
            area_id=self.area_id,
            # type ignores: likely https://github.com/python/mypy/issues/8625
            config_entries={config_entry.entry_id},  # type: ignore[arg-type]
            config_entries_subentries={config_entry.entry_id: {config_subentry_id}},
            connections=self.connections & connections,  # type: ignore[arg-type]
            created_at=self.created_at,
            disabled_by=disabled_by,
            identifiers=self.identifiers & identifiers,  # type: ignore[arg-type]
            id=self.id,
            labels=self.labels,  # type: ignore[arg-type]
            name_by_user=self.name_by_user,
        )

    @under_cached_property
    def as_storage_fragment(self) -> json_fragment:
        """Return a json fragment for storage."""
        return json_fragment(
            json_bytes(
                {
                    "area_id": self.area_id,
                    # The config_entries list can be removed from the storage
                    # representation in HA Core 2026.2
                    "config_entries": list(self.config_entries),
                    "config_entries_subentries": {
                        config_entry_id: list(subentries)
                        for config_entry_id, subentries in self.config_entries_subentries.items()
                    },
                    "connections": list(self.connections),
                    "created_at": self.created_at,
                    "disabled_by": self.disabled_by
                    if self.disabled_by is not UNDEFINED
                    else None,
                    "disabled_by_undefined": self.disabled_by is UNDEFINED,
                    "identifiers": list(self.identifiers),
                    "id": self.id,
                    "labels": list(self.labels),
                    "modified_at": self.modified_at,
                    "name_by_user": self.name_by_user,
                    "orphaned_timestamp": self.orphaned_timestamp,
                }
            )
        )


class DeviceRegistryStore(storage.Store[dict[str, list[dict[str, Any]]]]):
    """Store entity registry data."""

    async def _async_migrate_func(  # noqa: C901
        self,
        old_major_version: int,
        old_minor_version: int,
        old_data: dict[str, list[dict[str, Any]]],
    ) -> dict[str, Any]:
        """Migrate to the new version."""
        # Support for a future major version bump to 2 added in HA Core 2025.2.
        # Major versions 1 and 2 will be the same, except that version 2 will no
        # longer store a list of config_entries.
        if old_major_version < 3:
            if old_minor_version < 2:
                # Version 1.2 implements migration and freezes the available keys,
                # populate keys which were introduced before version 1.2
                for device in old_data["devices"]:
                    device.setdefault("area_id", None)
                    device.setdefault("configuration_url", None)
                    device.setdefault("disabled_by", None)
                    try:
                        device["entry_type"] = DeviceEntryType(
                            device.get("entry_type"),  # type: ignore[arg-type]
                        )
                    except ValueError:
                        device["entry_type"] = None
                    device.setdefault("name_by_user", None)
                    # via_device_id was originally introduced as hub_device_id
                    device.setdefault("via_device_id", device.get("hub_device_id"))
                old_data.setdefault("deleted_devices", [])
                for device in old_data["deleted_devices"]:
                    device.setdefault("orphaned_timestamp", None)
            if old_minor_version < 3:
                # Version 1.3 adds hw_version
                for device in old_data["devices"]:
                    device["hw_version"] = None
            if old_minor_version < 4:
                # Introduced in 2023.11
                for device in old_data["devices"]:
                    device["serial_number"] = None
            if old_minor_version < 5:
                # Introduced in 2024.3
                for device in old_data["devices"]:
                    device["labels"] = []
            if old_minor_version < 6:
                # Introduced in 2024.7
                for device in old_data["devices"]:
                    device["primary_config_entry"] = None
            if old_minor_version < 7:
                # Introduced in 2024.8
                for device in old_data["devices"]:
                    device["model_id"] = None
            if old_minor_version < 8:
                # Introduced in 2024.8
                created_at = utc_from_timestamp(0).isoformat()
                for device in old_data["devices"]:
                    device["created_at"] = device["modified_at"] = created_at
                for device in old_data["deleted_devices"]:
                    device["created_at"] = device["modified_at"] = created_at
            if old_minor_version < 9:
                # Introduced in 2025.2
                for device in old_data["devices"]:
                    device["config_entries_subentries"] = {
                        config_entry_id: {None}
                        for config_entry_id in device["config_entries"]
                    }
                for device in old_data["deleted_devices"]:
                    device["config_entries_subentries"] = {
                        config_entry_id: {None}
                        for config_entry_id in device["config_entries"]
                    }
            if old_minor_version < 10:
                # Introduced in 2025.6
                for device in old_data["deleted_devices"]:
                    device["area_id"] = None
                    device["disabled_by"] = None
                    device["labels"] = []
                    device["name_by_user"] = None
            if old_minor_version < 11:
                # Normalization of stored CONNECTION_NETWORK_MAC, introduced in 2025.8
                for device in old_data["devices"]:
                    device["connections"] = _normalize_connections(
                        device["connections"]
                    )
                for device in old_data["deleted_devices"]:
                    device["connections"] = _normalize_connections(
                        device["connections"]
                    )
            if old_minor_version < 12:
                # Version 1.12 adds undefined flags to deleted devices, this is a bugfix
                # of version 1.10
                for device in old_data["deleted_devices"]:
                    device["disabled_by_undefined"] = old_minor_version < 10

        if old_major_version > 2:
            raise NotImplementedError
        return old_data


class DeviceRegistryItems[_EntryTypeT: (DeviceEntry, DeletedDeviceEntry)](
    BaseRegistryItems[_EntryTypeT]
):
    """Container for device registry items, maps device id -> entry.

    Maintains two additional indexes:
    - (connection_type, connection identifier) -> entry
    - (DOMAIN, identifier) -> entry
    """

    def __init__(self) -> None:
        """Initialize the container."""
        super().__init__()
        self._connections: dict[tuple[str, str], _EntryTypeT] = {}
        self._identifiers: dict[tuple[str, str], _EntryTypeT] = {}

    def _index_entry(self, key: str, entry: _EntryTypeT) -> None:
        """Index an entry."""
        for connection in entry.connections:
            self._connections[connection] = entry
        for identifier in entry.identifiers:
            self._identifiers[identifier] = entry

    def _unindex_entry(
        self, key: str, replacement_entry: _EntryTypeT | None = None
    ) -> None:
        """Unindex an entry."""
        old_entry = self.data[key]
        for connection in old_entry.connections:
            if connection in self._connections:
                del self._connections[connection]
        for identifier in old_entry.identifiers:
            if identifier in self._identifiers:
                del self._identifiers[identifier]

    def get_entry(
        self,
        identifiers: set[tuple[str, str]] | None = None,
        connections: set[tuple[str, str]] | None = None,
    ) -> _EntryTypeT | None:
        """Get entry from identifiers or connections."""
        if identifiers:
            for identifier in identifiers:
                if identifier in self._identifiers:
                    return self._identifiers[identifier]
        if not connections:
            return None
        for connection in _normalize_connections(connections):
            if connection in self._connections:
                return self._connections[connection]
        return None

    def get_entries(
        self,
        identifiers: set[tuple[str, str]] | None,
        connections: set[tuple[str, str]] | None,
    ) -> Iterable[_EntryTypeT]:
        """Get entries from identifiers or connections."""
        if identifiers:
            for identifier in identifiers:
                if identifier in self._identifiers:
                    yield self._identifiers[identifier]
        if connections:
            for connection in _normalize_connections(connections):
                if connection in self._connections:
                    yield self._connections[connection]


class ActiveDeviceRegistryItems(DeviceRegistryItems[DeviceEntry]):
    """Container for active (non-deleted) device registry entries."""

    def __init__(self) -> None:
        """Initialize the container.

        Maintains three additional indexes:

        - area_id -> dict[key, True]
        - config_entry_id -> dict[key, True]
        - label -> dict[key, True]
        """
        super().__init__()
        self._area_id_index: RegistryIndexType = defaultdict(dict)
        self._config_entry_id_index: RegistryIndexType = defaultdict(dict)
        self._labels_index: RegistryIndexType = defaultdict(dict)

    def _index_entry(self, key: str, entry: DeviceEntry) -> None:
        """Index an entry."""
        super()._index_entry(key, entry)
        if (area_id := entry.area_id) is not None:
            self._area_id_index[area_id][key] = True
        for label in entry.labels:
            self._labels_index[label][key] = True
        for config_entry_id in entry.config_entries:
            self._config_entry_id_index[config_entry_id][key] = True

    def _unindex_entry(
        self, key: str, replacement_entry: DeviceEntry | None = None
    ) -> None:
        """Unindex an entry."""
        entry = self.data[key]
        if area_id := entry.area_id:
            self._unindex_entry_value(key, area_id, self._area_id_index)
        if labels := entry.labels:
            for label in labels:
                self._unindex_entry_value(key, label, self._labels_index)
        for config_entry_id in entry.config_entries:
            self._unindex_entry_value(key, config_entry_id, self._config_entry_id_index)
        super()._unindex_entry(key, replacement_entry)

    def get_devices_for_area_id(self, area_id: str) -> list[DeviceEntry]:
        """Get devices for area."""
        data = self.data
        return [data[key] for key in self._area_id_index.get(area_id, ())]

    def get_devices_for_label(self, label: str) -> list[DeviceEntry]:
        """Get devices for label."""
        data = self.data
        return [data[key] for key in self._labels_index.get(label, ())]

    def get_devices_for_config_entry_id(
        self, config_entry_id: str
    ) -> list[DeviceEntry]:
        """Get devices for config entry."""
        data = self.data
        return [
            data[key] for key in self._config_entry_id_index.get(config_entry_id, ())
        ]


class DeviceRegistry(BaseRegistry[dict[str, list[dict[str, Any]]]]):
    """Class to hold a registry of devices."""

    devices: ActiveDeviceRegistryItems
    deleted_devices: DeviceRegistryItems[DeletedDeviceEntry]
    _device_data: dict[str, DeviceEntry]

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the device registry."""
        self.hass = hass
        self._store = DeviceRegistryStore(
            hass,
            STORAGE_VERSION_MAJOR,
            STORAGE_KEY,
            atomic_writes=True,
            minor_version=STORAGE_VERSION_MINOR,
            serialize_in_event_loop=False,
        )

    @callback
    def async_get(self, device_id: str) -> DeviceEntry | None:
        """Get device.

        We retrieve the DeviceEntry from the underlying dict to avoid
        the overhead of the UserDict __getitem__.
        """
        return self._device_data.get(device_id)

    @callback
    def async_get_device(
        self,
        identifiers: set[tuple[str, str]] | None = None,
        connections: set[tuple[str, str]] | None = None,
    ) -> DeviceEntry | None:
        """Check if device is registered."""
        return self.devices.get_entry(identifiers, connections)

    def _substitute_name_placeholders(
        self,
        domain: str,
        name: str,
        translation_placeholders: Mapping[str, str],
    ) -> str:
        """Substitute placeholders in entity name."""
        try:
            return name.format(**translation_placeholders)
        except KeyError as err:
            if get_release_channel() is not ReleaseChannel.STABLE:
                raise HomeAssistantError(f"Missing placeholder {err}") from err
            report_issue = async_suggest_report_issue(
                self.hass, integration_domain=domain
            )
            _LOGGER.warning(
                (
                    "Device from integration %s has translation placeholders '%s' "
                    "which do not match the name '%s', please %s"
                ),
                domain,
                translation_placeholders,
                name,
                report_issue,
            )
            return name

    @callback
    def async_get_or_create(
        self,
        *,
        config_entry_id: str,
        config_subentry_id: str | None | UndefinedType = UNDEFINED,
        configuration_url: str | URL | None | UndefinedType = UNDEFINED,
        connections: set[tuple[str, str]] | None | UndefinedType = UNDEFINED,
        created_at: str | datetime | UndefinedType = UNDEFINED,  # will be ignored
        default_manufacturer: str | None | UndefinedType = UNDEFINED,
        default_model: str | None | UndefinedType = UNDEFINED,
        default_name: str | None | UndefinedType = UNDEFINED,
        # To disable a device if it gets created, does not affect existing devices
        disabled_by: DeviceEntryDisabler | None | UndefinedType = UNDEFINED,
        entry_type: DeviceEntryType | None | UndefinedType = UNDEFINED,
        hw_version: str | None | UndefinedType = UNDEFINED,
        identifiers: set[tuple[str, str]] | None | UndefinedType = UNDEFINED,
        manufacturer: str | None | UndefinedType = UNDEFINED,
        model: str | None | UndefinedType = UNDEFINED,
        model_id: str | None | UndefinedType = UNDEFINED,
        modified_at: str | datetime | UndefinedType = UNDEFINED,  # will be ignored
        name: str | None | UndefinedType = UNDEFINED,
        serial_number: str | None | UndefinedType = UNDEFINED,
        suggested_area: str | None | UndefinedType = UNDEFINED,
        sw_version: str | None | UndefinedType = UNDEFINED,
        translation_key: str | None = None,
        translation_placeholders: Mapping[str, str] | None = None,
        via_device: tuple[str, str] | None | UndefinedType = UNDEFINED,
    ) -> DeviceEntry:
        """Get device. Create if it doesn't exist."""
        if configuration_url is not UNDEFINED:
            configuration_url = _validate_configuration_url(configuration_url)

        config_entry = self.hass.config_entries.async_get_entry(config_entry_id)
        if config_entry is None:
            raise HomeAssistantError(
                f"Can't link device to unknown config entry {config_entry_id}"
            )

        if translation_key:
            full_translation_key = (
                f"component.{config_entry.domain}.device.{translation_key}.name"
            )
            translations = translation.async_get_cached_translations(
                self.hass, self.hass.config.language, "device", config_entry.domain
            )
            translated_name = translations.get(full_translation_key, translation_key)
            name = self._substitute_name_placeholders(
                config_entry.domain, translated_name, translation_placeholders or {}
            )

        # Reconstruct a DeviceInfo dict from the arguments.
        # When we upgrade to Python 3.12, we can change this method to instead
        # accept kwargs typed as a DeviceInfo dict (PEP 692)
        device_info: DeviceInfo = {  # type: ignore[assignment]
            key: val
            for key, val in (
                ("configuration_url", configuration_url),
                ("connections", connections),
                ("default_manufacturer", default_manufacturer),
                ("default_model", default_model),
                ("default_name", default_name),
                ("entry_type", entry_type),
                ("hw_version", hw_version),
                ("identifiers", identifiers),
                ("manufacturer", manufacturer),
                ("model", model),
                ("model_id", model_id),
                ("name", name),
                ("serial_number", serial_number),
                ("suggested_area", suggested_area),
                ("sw_version", sw_version),
                ("via_device", via_device),
            )
            if val is not UNDEFINED
        }

        device_info_type = _validate_device_info(config_entry, device_info)

        if identifiers is None or identifiers is UNDEFINED:
            identifiers = set()

        if connections is None or connections is UNDEFINED:
            connections = set()
        else:
            connections = _normalize_connections(connections)

        device = self.devices.get_entry(
            identifiers=identifiers, connections=connections
        )

        is_new = False

        if device is None:
            is_new = True

            deleted_device = self.deleted_devices.get_entry(identifiers, connections)
            if deleted_device is None:
                area_id: str | None = None
                if (
                    suggested_area is not None
                    and suggested_area is not UNDEFINED
                    and suggested_area != ""
                ):
                    # Circular dep
                    from . import area_registry as ar  # noqa: PLC0415

                    area = ar.async_get(self.hass).async_get_or_create(suggested_area)
                    area_id = area.id
                device = DeviceEntry(area_id=area_id)

            else:
                self.deleted_devices.pop(deleted_device.id)
                device = deleted_device.to_device_entry(
                    config_entry,
                    # Interpret not specifying a subentry as None
                    config_subentry_id if config_subentry_id is not UNDEFINED else None,
                    connections,
                    identifiers,
                    disabled_by,
                )
                disabled_by = UNDEFINED

            self.devices[device.id] = device
            # If creating a new device, default to the config entry name
            if device_info_type == "primary" and (not name or name is UNDEFINED):
                name = config_entry.title

        if default_manufacturer is not UNDEFINED and device.manufacturer is None:
            manufacturer = default_manufacturer

        if default_model is not UNDEFINED and device.model is None:
            model = default_model

        if default_name is not UNDEFINED and device.name is None:
            name = default_name

        if via_device is not None and via_device is not UNDEFINED:
            if (via := self.devices.get_entry(identifiers={via_device})) is None:
                report_usage(
                    "calls `device_registry.async_get_or_create` referencing a "
                    f"non existing `via_device` {via_device}, "
                    f"with device info: {device_info}",
                    core_behavior=ReportBehavior.LOG,
                    breaks_in_ha_version="2025.12.0",
                )

            via_device_id: str | UndefinedType = via.id if via else UNDEFINED
        else:
            via_device_id = UNDEFINED

        device = self._async_update_device(
            device.id,
            allow_collisions=True,
            add_config_entry_id=config_entry_id,
            add_config_subentry_id=config_subentry_id,
            configuration_url=configuration_url,
            device_info_type=device_info_type,
            disabled_by=disabled_by,
            entry_type=entry_type,
            hw_version=hw_version,
            is_new=is_new,
            manufacturer=manufacturer,
            merge_connections=connections or UNDEFINED,
            merge_identifiers=identifiers or UNDEFINED,
            model=model,
            model_id=model_id,
            name=name,
            serial_number=serial_number,
            suggested_area=suggested_area,
            sw_version=sw_version,
            via_device_id=via_device_id,
        )

        # This is safe because _async_update_device will always return a device
        # in this use case.
        assert device
        return device

    @callback
    def _async_update_device(  # noqa: C901
        self,
        device_id: str,
        *,
        add_config_entry_id: str | UndefinedType = UNDEFINED,
        add_config_subentry_id: str | None | UndefinedType = UNDEFINED,
        # Temporary flag so we don't blow up when collisions are implicitly introduced
        # by calls to async_get_or_create.
        allow_collisions: bool = False,
        area_id: str | None | UndefinedType = UNDEFINED,
        configuration_url: str | URL | None | UndefinedType = UNDEFINED,
        device_info_type: str | UndefinedType = UNDEFINED,
        disabled_by: DeviceEntryDisabler | None | UndefinedType = UNDEFINED,
        entry_type: DeviceEntryType | None | UndefinedType = UNDEFINED,
        hw_version: str | None | UndefinedType = UNDEFINED,
        is_new: bool = False,
        labels: set[str] | UndefinedType = UNDEFINED,
        manufacturer: str | None | UndefinedType = UNDEFINED,
        merge_connections: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        merge_identifiers: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        model: str | None | UndefinedType = UNDEFINED,
        model_id: str | None | UndefinedType = UNDEFINED,
        name_by_user: str | None | UndefinedType = UNDEFINED,
        name: str | None | UndefinedType = UNDEFINED,
        new_connections: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        new_identifiers: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        remove_config_entry_id: str | UndefinedType = UNDEFINED,
        remove_config_subentry_id: str | None | UndefinedType = UNDEFINED,
        serial_number: str | None | UndefinedType = UNDEFINED,
        # Can be removed when suggested_area is removed from DeviceEntry
        suggested_area: str | None | UndefinedType = UNDEFINED,
        sw_version: str | None | UndefinedType = UNDEFINED,
        via_device_id: str | None | UndefinedType = UNDEFINED,
    ) -> DeviceEntry | None:
        """Private update device attributes.

        :param add_config_subentry_id: Add the device to a specific subentry of add_config_entry_id
        :param remove_config_subentry_id: Remove the device from a specific subentry of remove_config_entry_id
        """
        old = self.devices[device_id]

        new_values: dict[str, Any] = {}  # Dict with new key/value pairs
        old_values: dict[str, Any] = {}  # Dict with old key/value pairs

        config_entries = old.config_entries
        config_entries_subentries = old.config_entries_subentries

        if add_config_entry_id is not UNDEFINED:
            if (
                add_config_entry := self.hass.config_entries.async_get_entry(
                    add_config_entry_id
                )
            ) is None:
                raise HomeAssistantError(
                    f"Can't link device to unknown config entry {add_config_entry_id}"
                )

        if add_config_subentry_id is not UNDEFINED:
            if add_config_entry_id is UNDEFINED:
                raise HomeAssistantError(
                    "Can't add config subentry without specifying config entry"
                )
            if (
                add_config_subentry_id
                # mypy says add_config_entry can be None. That's impossible, because we
                # raise above if that happens
                and add_config_subentry_id not in add_config_entry.subentries  # type: ignore[union-attr]
            ):
                raise HomeAssistantError(
                    f"Config entry {add_config_entry_id} has no subentry {add_config_subentry_id}"
                )

        if (
            remove_config_subentry_id is not UNDEFINED
            and remove_config_entry_id is UNDEFINED
        ):
            raise HomeAssistantError(
                "Can't remove config subentry without specifying config entry"
            )

        if not new_connections and not new_identifiers:
            raise HomeAssistantError(
                "A device must have at least one of identifiers or connections"
            )

        if merge_connections is not UNDEFINED and new_connections is not UNDEFINED:
            raise HomeAssistantError(
                "Cannot define both merge_connections and new_connections"
            )

        if merge_identifiers is not UNDEFINED and new_identifiers is not UNDEFINED:
            raise HomeAssistantError(
                "Cannot define both merge_identifiers and new_identifiers"
            )

        if add_config_entry_id is not UNDEFINED:
            if add_config_subentry_id is UNDEFINED:
                # Interpret not specifying a subentry as None (the main entry)
                add_config_subentry_id = None

            primary_entry_id = old.primary_config_entry
            if (
                device_info_type == "primary"
                and add_config_entry_id != primary_entry_id
            ):
                if (
                    primary_entry_id is None
                    or not (
                        primary_entry := self.hass.config_entries.async_get_entry(
                            primary_entry_id
                        )
                    )
                    or primary_entry.domain in LOW_PRIO_CONFIG_ENTRY_DOMAINS
                ):
                    new_values["primary_config_entry"] = add_config_entry_id
                    old_values["primary_config_entry"] = primary_entry_id

            if add_config_entry_id not in old.config_entries:
                config_entries = old.config_entries | {add_config_entry_id}
                config_entries_subentries = old.config_entries_subentries | {
                    add_config_entry_id: {add_config_subentry_id}
                }
                # Enable the device if it was disabled by config entry and we're adding
                # a non disabled config entry
                if (
                    # mypy says add_config_entry can be None. That's impossible, because we
                    # raise above if that happens
                    not add_config_entry.disabled_by  # type: ignore[union-attr]
                    and old.disabled_by is DeviceEntryDisabler.CONFIG_ENTRY
                ):
                    new_values["disabled_by"] = None
                    old_values["disabled_by"] = old.disabled_by
            elif (
                add_config_subentry_id
                not in old.config_entries_subentries[add_config_entry_id]
            ):
                config_entries_subentries = old.config_entries_subentries | {
                    add_config_entry_id: old.config_entries_subentries[
                        add_config_entry_id
                    ]
                    | {add_config_subentry_id}
                }

        if (
            remove_config_entry_id is not UNDEFINED
            and remove_config_entry_id in config_entries
        ):
            if remove_config_subentry_id is UNDEFINED:
                config_entries_subentries = dict(old.config_entries_subentries)
                del config_entries_subentries[remove_config_entry_id]
            elif (
                remove_config_subentry_id
                in old.config_entries_subentries[remove_config_entry_id]
            ):
                config_entries_subentries = old.config_entries_subentries | {
                    remove_config_entry_id: old.config_entries_subentries[
                        remove_config_entry_id
                    ]
                    - {remove_config_subentry_id}
                }
                if not config_entries_subentries[remove_config_entry_id]:
                    del config_entries_subentries[remove_config_entry_id]

            if remove_config_entry_id not in config_entries_subentries:
                if config_entries == {remove_config_entry_id}:
                    self.async_remove_device(device_id)
                    return None

                if remove_config_entry_id == old.primary_config_entry:
                    new_values["primary_config_entry"] = None
                    old_values["primary_config_entry"] = old.primary_config_entry

                config_entries = config_entries - {remove_config_entry_id}

                # Disable the device if it is enabled and all remaining config entries
                # are disabled
                has_enabled_config_entries = any(
                    config_entry.disabled_by is None
                    for config_entry_id in config_entries
                    if (
                        config_entry := self.hass.config_entries.async_get_entry(
                            config_entry_id
                        )
                    )
                    is not None
                )
                if not has_enabled_config_entries and old.disabled_by is None:
                    new_values["disabled_by"] = DeviceEntryDisabler.CONFIG_ENTRY
                    old_values["disabled_by"] = old.disabled_by

        if config_entries != old.config_entries:
            new_values["config_entries"] = config_entries
            old_values["config_entries"] = old.config_entries

        if config_entries_subentries != old.config_entries_subentries:
            new_values["config_entries_subentries"] = config_entries_subentries
            old_values["config_entries_subentries"] = old.config_entries_subentries

        added_connections: set[tuple[str, str]] | None = None
        added_identifiers: set[tuple[str, str]] | None = None

        if merge_connections is not UNDEFINED:
            normalized_connections = self._validate_connections(
                device_id,
                merge_connections,
                allow_collisions,
            )
            old_connections = old.connections
            if not normalized_connections.issubset(old_connections):
                added_connections = normalized_connections
                new_values["connections"] = old_connections | normalized_connections
                old_values["connections"] = old_connections

        if merge_identifiers is not UNDEFINED:
            merge_identifiers = self._validate_identifiers(
                device_id, merge_identifiers, allow_collisions
            )
            old_identifiers = old.identifiers
            if not merge_identifiers.issubset(old_identifiers):
                added_identifiers = merge_identifiers
                new_values["identifiers"] = old_identifiers | merge_identifiers
                old_values["identifiers"] = old_identifiers

        if new_connections is not UNDEFINED:
            added_connections = new_values["connections"] = self._validate_connections(
                device_id, new_connections, False
            )
            old_values["connections"] = old.connections

        if new_identifiers is not UNDEFINED:
            added_identifiers = new_values["identifiers"] = self._validate_identifiers(
                device_id, new_identifiers, False
            )
            old_values["identifiers"] = old.identifiers

        if configuration_url is not UNDEFINED:
            configuration_url = _validate_configuration_url(configuration_url)

        for attr_name, value in (
            ("area_id", area_id),
            ("configuration_url", configuration_url),
            ("disabled_by", disabled_by),
            ("entry_type", entry_type),
            ("hw_version", hw_version),
            ("labels", labels),
            ("manufacturer", manufacturer),
            ("model", model),
            ("model_id", model_id),
            ("name", name),
            ("name_by_user", name_by_user),
            ("serial_number", serial_number),
            ("sw_version", sw_version),
            ("via_device_id", via_device_id),
        ):
            if value is not UNDEFINED and value != getattr(old, attr_name):
                new_values[attr_name] = value
                old_values[attr_name] = getattr(old, attr_name)

        # Can be removed when suggested_area is removed from DeviceEntry
        if suggested_area is not UNDEFINED and suggested_area != old._suggested_area:  # noqa: SLF001
            new_values["suggested_area"] = suggested_area
            old_values["suggested_area"] = old._suggested_area  # noqa: SLF001

        if not new_values and not is_new:
            return old

        # This condition can be removed when suggested_area is removed from DeviceEntry
        if not RUNTIME_ONLY_ATTRS.issuperset(new_values):
            # Change modified_at if we are changing something that we store
            new_values["modified_at"] = utcnow()

        self.hass.verify_event_loop_thread("device_registry._async_update_device")
        new = attr.evolve(old, **new_values)
        self.devices[device_id] = new

        # NOTE: Once we solve the broader issue of duplicated devices, we might
        # want to revisit it. Instead of simply removing the duplicated deleted device,
        # we might want to merge the information from it into the non-deleted device.
        for deleted_device in self.deleted_devices.get_entries(
            added_identifiers, added_connections
        ):
            del self.deleted_devices[deleted_device.id]

        # If its only run time attributes (suggested_area)
        # that do not get saved we do not want to write
        # to disk or fire an event as we would end up
        # firing events for data we have nothing to compare
        # against since its never saved on disk
        if RUNTIME_ONLY_ATTRS.issuperset(new_values):
            # This can be removed when suggested_area is removed from DeviceEntry
            return new

        self.async_schedule_save()

        data: EventDeviceRegistryUpdatedData
        if is_new:
            data = {"action": "create", "device_id": new.id}
        else:
            data = {"action": "update", "device_id": new.id, "changes": old_values}

        self.hass.bus.async_fire_internal(EVENT_DEVICE_REGISTRY_UPDATED, data)

        return new

    @callback
    def async_update_device(
        self,
        device_id: str,
        *,
        add_config_entry_id: str | UndefinedType = UNDEFINED,
        add_config_subentry_id: str | None | UndefinedType = UNDEFINED,
        area_id: str | None | UndefinedType = UNDEFINED,
        configuration_url: str | URL | None | UndefinedType = UNDEFINED,
        device_info_type: str | UndefinedType = UNDEFINED,
        disabled_by: DeviceEntryDisabler | None | UndefinedType = UNDEFINED,
        entry_type: DeviceEntryType | None | UndefinedType = UNDEFINED,
        hw_version: str | None | UndefinedType = UNDEFINED,
        labels: set[str] | UndefinedType = UNDEFINED,
        manufacturer: str | None | UndefinedType = UNDEFINED,
        merge_connections: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        merge_identifiers: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        model: str | None | UndefinedType = UNDEFINED,
        model_id: str | None | UndefinedType = UNDEFINED,
        name_by_user: str | None | UndefinedType = UNDEFINED,
        name: str | None | UndefinedType = UNDEFINED,
        new_connections: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        new_identifiers: set[tuple[str, str]] | UndefinedType = UNDEFINED,
        remove_config_entry_id: str | UndefinedType = UNDEFINED,
        remove_config_subentry_id: str | None | UndefinedType = UNDEFINED,
        serial_number: str | None | UndefinedType = UNDEFINED,
        # suggested_area is deprecated and will be removed in 2026.9
        suggested_area: str | None | UndefinedType = UNDEFINED,
        sw_version: str | None | UndefinedType = UNDEFINED,
        via_device_id: str | None | UndefinedType = UNDEFINED,
    ) -> DeviceEntry | None:
        """Update device attributes.

        :param add_config_subentry_id: Add the device to a specific subentry of add_config_entry_id
        :param remove_config_subentry_id: Remove the device from a specific subentry of remove_config_entry_id
        """
        if suggested_area is not UNDEFINED:
            report_usage(
                "passes a suggested_area to device_registry.async_update device",
                core_behavior=ReportBehavior.LOG,
                breaks_in_ha_version="2026.9.0",
            )

        return self._async_update_device(
            device_id,
            add_config_entry_id=add_config_entry_id,
            add_config_subentry_id=add_config_subentry_id,
            area_id=area_id,
            configuration_url=configuration_url,
            device_info_type=device_info_type,
            disabled_by=disabled_by,
            entry_type=entry_type,
            hw_version=hw_version,
            labels=labels,
            manufacturer=manufacturer,
            merge_connections=merge_connections,
            merge_identifiers=merge_identifiers,
            model=model,
            model_id=model_id,
            name_by_user=name_by_user,
            name=name,
            new_connections=new_connections,
            new_identifiers=new_identifiers,
            remove_config_entry_id=remove_config_entry_id,
            remove_config_subentry_id=remove_config_subentry_id,
            serial_number=serial_number,
            suggested_area=suggested_area,
            sw_version=sw_version,
            via_device_id=via_device_id,
        )

    @callback
    def _validate_connections(
        self,
        device_id: str,
        connections: set[tuple[str, str]],
        allow_collisions: bool,
    ) -> set[tuple[str, str]]:
        """Normalize and validate connections, raise on collision with other devices."""
        normalized_connections = _normalize_connections(connections)
        if allow_collisions:
            return normalized_connections

        for connection in normalized_connections:
            # We need to iterate over each connection because if there is a
            # conflict, the index will only see the last one and we will not
            # be able to tell which one caused the conflict
            if (
                existing_device := self.devices.get_entry(connections={connection})
            ) and existing_device.id != device_id:
                raise DeviceConnectionCollisionError(
                    normalized_connections, existing_device
                )

        return normalized_connections

    @callback
    def _validate_identifiers(
        self,
        device_id: str,
        identifiers: set[tuple[str, str]],
        allow_collisions: bool,
    ) -> set[tuple[str, str]]:
        """Validate identifiers, raise on collision with other devices."""
        if allow_collisions:
            return identifiers

        for identifier in identifiers:
            # We need to iterate over each identifier because if there is a
            # conflict, the index will only see the last one and we will not
            # be able to tell which one caused the conflict
            if (
                existing_device := self.devices.get_entry(identifiers={identifier})
            ) and existing_device.id != device_id:
                raise DeviceIdentifierCollisionError(identifiers, existing_device)

        return identifiers

    @callback
    def async_remove_device(self, device_id: str) -> None:
        """Remove a device from the device registry."""
        self.hass.verify_event_loop_thread("device_registry.async_remove_device")
        device = self.devices.pop(device_id)
        self.deleted_devices[device_id] = DeletedDeviceEntry(
            area_id=device.area_id,
            config_entries=device.config_entries,
            config_entries_subentries=device.config_entries_subentries,
            connections=device.connections,
            created_at=device.created_at,
            disabled_by=device.disabled_by,
            identifiers=device.identifiers,
            id=device.id,
            labels=device.labels,
            modified_at=utcnow(),
            name_by_user=device.name_by_user,
            orphaned_timestamp=None,
        )
        for other_device in list(self.devices.values()):
            if other_device.via_device_id == device_id:
                self._async_update_device(other_device.id, via_device_id=None)
        self.hass.bus.async_fire_internal(
            EVENT_DEVICE_REGISTRY_UPDATED,
            _EventDeviceRegistryUpdatedData_Remove(
                action="remove", device_id=device_id, device=device.dict_repr
            ),
        )
        self.async_schedule_save()

    async def async_load(self) -> None:
        """Load the device registry."""
        async_setup_cleanup(self.hass, self)

        data = await self._store.async_load()

        devices = ActiveDeviceRegistryItems()
        deleted_devices: DeviceRegistryItems[DeletedDeviceEntry] = DeviceRegistryItems()

        if data is not None:
            for device in data["devices"]:
                devices[device["id"]] = DeviceEntry(
                    area_id=device["area_id"],
                    config_entries=set(device["config_entries_subentries"]),
                    config_entries_subentries={
                        config_entry_id: set(subentries)
                        for config_entry_id, subentries in device[
                            "config_entries_subentries"
                        ].items()
                    },
                    configuration_url=device["configuration_url"],
                    # type ignores (if tuple arg was cast): likely https://github.com/python/mypy/issues/8625
                    connections={
                        tuple(conn)  # type: ignore[misc]
                        for conn in device["connections"]
                    },
                    created_at=datetime.fromisoformat(device["created_at"]),
                    disabled_by=(
                        DeviceEntryDisabler(device["disabled_by"])
                        if device["disabled_by"]
                        else None
                    ),
                    entry_type=(
                        DeviceEntryType(device["entry_type"])
                        if device["entry_type"]
                        else None
                    ),
                    hw_version=device["hw_version"],
                    id=device["id"],
                    identifiers={
                        tuple(iden)  # type: ignore[misc]
                        for iden in device["identifiers"]
                    },
                    labels=set(device["labels"]),
                    manufacturer=device["manufacturer"],
                    model=device["model"],
                    model_id=device["model_id"],
                    modified_at=datetime.fromisoformat(device["modified_at"]),
                    name_by_user=device["name_by_user"],
                    name=device["name"],
                    primary_config_entry=device["primary_config_entry"],
                    serial_number=device["serial_number"],
                    sw_version=device["sw_version"],
                    via_device_id=device["via_device_id"],
                )

            # Introduced in 0.111
            def get_optional_enum[_EnumT: StrEnum](
                cls: type[_EnumT], value: str | None, undefined: bool
            ) -> _EnumT | UndefinedType | None:
                """Convert string to the passed enum, UNDEFINED or None."""
                if undefined:
                    return UNDEFINED
                if value is None:
                    return None
                try:
                    return cls(value)
                except ValueError:
                    return None

            for device in data["deleted_devices"]:
                deleted_devices[device["id"]] = DeletedDeviceEntry(
                    area_id=device["area_id"],
                    config_entries=set(device["config_entries"]),
                    config_entries_subentries={
                        config_entry_id: set(subentries)
                        for config_entry_id, subentries in device[
                            "config_entries_subentries"
                        ].items()
                    },
                    connections={tuple(conn) for conn in device["connections"]},
                    created_at=datetime.fromisoformat(device["created_at"]),
                    disabled_by=get_optional_enum(
                        DeviceEntryDisabler,
                        device["disabled_by"],
                        device["disabled_by_undefined"],
                    ),
                    identifiers={tuple(iden) for iden in device["identifiers"]},
                    id=device["id"],
                    labels=set(device["labels"]),
                    modified_at=datetime.fromisoformat(device["modified_at"]),
                    name_by_user=device["name_by_user"],
                    orphaned_timestamp=device["orphaned_timestamp"],
                )

        self.devices = devices
        self.deleted_devices = deleted_devices
        self._device_data = devices.data

    @callback
    def _data_to_save(self) -> dict[str, Any]:
        """Return data of device registry to store in a file."""
        # Create intermediate lists to allow this method to be called from a thread
        # other than the event loop.
        return {
            "devices": [
                entry.as_storage_fragment for entry in list(self.devices.values())
            ],
            "deleted_devices": [
                entry.as_storage_fragment
                for entry in list(self.deleted_devices.values())
            ],
        }

    @callback
    def async_clear_config_entry(self, config_entry_id: str) -> None:
        """Clear config entry from registry entries."""
        now_time = time.time()
        for device in self.devices.get_devices_for_config_entry_id(config_entry_id):
            self._async_update_device(device.id, remove_config_entry_id=config_entry_id)
        for deleted_device in list(self.deleted_devices.values()):
            config_entries = deleted_device.config_entries
            if config_entry_id not in config_entries:
                continue
            if config_entries == {config_entry_id}:
                # Add a time stamp when the deleted device became orphaned
                self.deleted_devices[deleted_device.id] = attr.evolve(
                    deleted_device,
                    orphaned_timestamp=now_time,
                    config_entries=set(),
                    config_entries_subentries={},
                )
            else:
                config_entries = config_entries - {config_entry_id}
                config_entries_subentries = dict(
                    deleted_device.config_entries_subentries
                )
                del config_entries_subentries[config_entry_id]
                # No need to reindex here since we currently
                # do not have a lookup by config entry
                self.deleted_devices[deleted_device.id] = attr.evolve(
                    deleted_device,
                    config_entries=config_entries,
                    config_entries_subentries=config_entries_subentries,
                )
            self.async_schedule_save()

    @callback
    def async_clear_config_subentry(
        self, config_entry_id: str, config_subentry_id: str
    ) -> None:
        """Clear config entry from registry entries."""
        now_time = time.time()
        for device in self.devices.get_devices_for_config_entry_id(config_entry_id):
            self._async_update_device(
                device.id,
                remove_config_entry_id=config_entry_id,
                remove_config_subentry_id=config_subentry_id,
            )
        for deleted_device in list(self.deleted_devices.values()):
            config_entries = deleted_device.config_entries
            config_entries_subentries = deleted_device.config_entries_subentries
            if (
                config_entry_id not in config_entries_subentries
                or config_subentry_id not in config_entries_subentries[config_entry_id]
            ):
                continue
            if config_entries_subentries == {config_entry_id: {config_subentry_id}}:
                # We're removing the last config subentry from the last config
                # entry, add a time stamp when the deleted device became orphaned
                self.deleted_devices[deleted_device.id] = attr.evolve(
                    deleted_device,
                    orphaned_timestamp=now_time,
                    config_entries=set(),
                    config_entries_subentries={},
                )
            else:
                config_entries_subentries = config_entries_subentries | {
                    config_entry_id: config_entries_subentries[config_entry_id]
                    - {config_subentry_id}
                }
                if not config_entries_subentries[config_entry_id]:
                    del config_entries_subentries[config_entry_id]
                    config_entries = config_entries - {config_entry_id}
                # No need to reindex here since we currently
                # do not have a lookup by config entry
                self.deleted_devices[deleted_device.id] = attr.evolve(
                    deleted_device,
                    config_entries=config_entries,
                    config_entries_subentries=config_entries_subentries,
                )
            self.async_schedule_save()

    @callback
    def async_purge_expired_orphaned_devices(self) -> None:
        """Purge expired orphaned devices from the registry.

        We need to purge these periodically to avoid the database
        growing without bound.
        """
        now_time = time.time()
        for deleted_device in list(self.deleted_devices.values()):
            if deleted_device.orphaned_timestamp is None:
                continue

            if (
                deleted_device.orphaned_timestamp + ORPHANED_DEVICE_KEEP_SECONDS
                < now_time
            ):
                del self.deleted_devices[deleted_device.id]

    @callback
    def async_clear_area_id(self, area_id: str) -> None:
        """Clear area id from registry entries."""
        for device in self.devices.get_devices_for_area_id(area_id):
            self._async_update_device(device.id, area_id=None)
        for deleted_device in list(self.deleted_devices.values()):
            if deleted_device.area_id != area_id:
                continue
            self.deleted_devices[deleted_device.id] = attr.evolve(
                deleted_device, area_id=None
            )
            self.async_schedule_save()

    @callback
    def async_clear_label_id(self, label_id: str) -> None:
        """Clear label from registry entries."""
        for device in self.devices.get_devices_for_label(label_id):
            self._async_update_device(device.id, labels=device.labels - {label_id})
        for deleted_device in list(self.deleted_devices.values()):
            if label_id not in deleted_device.labels:
                continue
            self.deleted_devices[deleted_device.id] = attr.evolve(
                deleted_device, labels=deleted_device.labels - {label_id}
            )
            self.async_schedule_save()


@callback
@singleton(DATA_REGISTRY)
def async_get(hass: HomeAssistant) -> DeviceRegistry:
    """Get device registry."""
    return DeviceRegistry(hass)


async def async_load(hass: HomeAssistant) -> None:
    """Load device registry."""
    assert DATA_REGISTRY not in hass.data
    await async_get(hass).async_load()


@callback
def async_entries_for_area(registry: DeviceRegistry, area_id: str) -> list[DeviceEntry]:
    """Return entries that match an area."""
    return registry.devices.get_devices_for_area_id(area_id)


@callback
def async_entries_for_label(
    registry: DeviceRegistry, label_id: str
) -> list[DeviceEntry]:
    """Return entries that match a label."""
    return registry.devices.get_devices_for_label(label_id)


@callback
def async_entries_for_config_entry(
    registry: DeviceRegistry, config_entry_id: str
) -> list[DeviceEntry]:
    """Return entries that match a config entry."""
    return registry.devices.get_devices_for_config_entry_id(config_entry_id)


@callback
def async_config_entry_disabled_by_changed(
    registry: DeviceRegistry, config_entry: ConfigEntry
) -> None:
    """Handle a config entry being disabled or enabled.

    Disable devices in the registry that are associated with a config entry when
    the config entry is disabled, enable devices in the registry that are associated
    with a config entry when the config entry is enabled and the devices are marked
    DeviceEntryDisabler.CONFIG_ENTRY.
    Only disable a device if all associated config entries are disabled.
    """

    devices = async_entries_for_config_entry(registry, config_entry.entry_id)

    if not config_entry.disabled_by:
        for device in devices:
            if device.disabled_by is not DeviceEntryDisabler.CONFIG_ENTRY:
                continue
            registry._async_update_device(device.id, disabled_by=None)  # noqa: SLF001
        return

    enabled_config_entries = {
        entry.entry_id
        for entry in registry.hass.config_entries.async_entries()
        if not entry.disabled_by
    }

    for device in devices:
        if device.disabled:
            # Device already disabled, do not overwrite
            continue
        if len(device.config_entries) > 1 and device.config_entries.intersection(
            enabled_config_entries
        ):
            continue
        registry._async_update_device(  # noqa: SLF001
            device.id, disabled_by=DeviceEntryDisabler.CONFIG_ENTRY
        )


@callback
def async_cleanup(
    hass: HomeAssistant,
    dev_reg: DeviceRegistry,
    ent_reg: entity_registry.EntityRegistry,
) -> None:
    """Clean up device registry."""
    # Find all devices that are referenced by a config_entry.
    config_entry_ids = set(hass.config_entries.async_entry_ids())
    references_config_entries = {
        device.id
        for device in dev_reg.devices.values()
        for config_entry_id in device.config_entries
        if config_entry_id in config_entry_ids
    }

    # Find all devices that are referenced in the entity registry.
    device_ids_referenced_by_entities = set(ent_reg.entities.get_device_ids())

    orphan = (
        set(dev_reg.devices)
        - device_ids_referenced_by_entities
        - references_config_entries
    )

    for dev_id in orphan:
        dev_reg.async_remove_device(dev_id)

    # Find all referenced config entries that no longer exist
    # This shouldn't happen but have not been able to track down the bug :(
    for device in list(dev_reg.devices.values()):
        for config_entry_id in device.config_entries:
            if config_entry_id not in config_entry_ids:
                dev_reg._async_update_device(  # noqa: SLF001
                    device.id, remove_config_entry_id=config_entry_id
                )

    # Periodic purge of orphaned devices to avoid the registry
    # growing without bounds when there are lots of deleted devices
    dev_reg.async_purge_expired_orphaned_devices()


@callback
def async_setup_cleanup(hass: HomeAssistant, dev_reg: DeviceRegistry) -> None:
    """Clean up device registry when entities removed."""
    from . import entity_registry, label_registry as lr  # noqa: PLC0415

    @callback
    def _label_removed_from_registry_filter(
        event_data: lr.EventLabelRegistryUpdatedData,
    ) -> bool:
        """Filter all except for the remove action from label registry events."""
        return event_data["action"] == "remove"

    @callback
    def _handle_label_registry_update(event: lr.EventLabelRegistryUpdated) -> None:
        """Update devices that have a label that has been removed."""
        dev_reg.async_clear_label_id(event.data["label_id"])

    hass.bus.async_listen(
        event_type=lr.EVENT_LABEL_REGISTRY_UPDATED,
        event_filter=_label_removed_from_registry_filter,
        listener=_handle_label_registry_update,
    )

    @callback
    def _async_cleanup() -> None:
        """Cleanup."""
        ent_reg = entity_registry.async_get(hass)
        async_cleanup(hass, dev_reg, ent_reg)

    debounced_cleanup: Debouncer[None] = Debouncer(
        hass, _LOGGER, cooldown=CLEANUP_DELAY, immediate=False, function=_async_cleanup
    )

    @callback
    def _async_entity_registry_changed(
        event: Event[entity_registry.EventEntityRegistryUpdatedData],
    ) -> None:
        """Handle entity updated or removed dispatch."""
        debounced_cleanup.async_schedule_call()

    @callback
    def entity_registry_changed_filter(
        event_data: entity_registry.EventEntityRegistryUpdatedData,
    ) -> bool:
        """Handle entity updated or removed filter."""
        if (
            event_data["action"] == "update"
            and "device_id" not in event_data["changes"]
        ) or event_data["action"] == "create":
            return False

        return True

    def _async_listen_for_cleanup() -> None:
        """Listen for entity registry changes."""
        hass.bus.async_listen(
            entity_registry.EVENT_ENTITY_REGISTRY_UPDATED,
            _async_entity_registry_changed,
            event_filter=entity_registry_changed_filter,
        )

    if hass.is_running:
        _async_listen_for_cleanup()
        return

    async def startup_clean(event: Event) -> None:
        """Clean up on startup."""
        _async_listen_for_cleanup()
        await debounced_cleanup.async_call()

    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STARTED, startup_clean)

    @callback
    def _on_homeassistant_stop(event: Event) -> None:
        """Cancel debounced cleanup."""
        debounced_cleanup.async_cancel()

    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, _on_homeassistant_stop)
</file>

<file path="device.py">
"""Provides useful helpers for handling devices."""

from homeassistant.core import HomeAssistant, callback

from . import device_registry as dr, entity_registry as er


@callback
def async_entity_id_to_device_id(
    hass: HomeAssistant,
    entity_id_or_uuid: str,
) -> str | None:
    """Resolve the device id to the entity id or entity uuid."""

    ent_reg = er.async_get(hass)

    entity_id = er.async_validate_entity_id(ent_reg, entity_id_or_uuid)
    if (entity := ent_reg.async_get(entity_id)) is None:
        return None

    return entity.device_id


@callback
def async_entity_id_to_device(
    hass: HomeAssistant,
    entity_id_or_uuid: str,
) -> dr.DeviceEntry | None:
    """Resolve the device entry for the entity id or entity uuid."""

    if (device_id := async_entity_id_to_device_id(hass, entity_id_or_uuid)) is None:
        return None

    return dr.async_get(hass).async_get(device_id)


@callback
def async_device_info_to_link_from_entity(
    hass: HomeAssistant,
    entity_id_or_uuid: str,
) -> dr.DeviceInfo | None:
    """DeviceInfo with information to link a device from an entity.

    DeviceInfo will only return information to categorize as a link.
    """

    return async_device_info_to_link_from_device_id(
        hass,
        async_entity_id_to_device_id(hass, entity_id_or_uuid),
    )


@callback
def async_device_info_to_link_from_device_id(
    hass: HomeAssistant,
    device_id: str | None,
) -> dr.DeviceInfo | None:
    """DeviceInfo with information to link a device from a device id.

    DeviceInfo will only return information to categorize as a link.
    """

    dev_reg = dr.async_get(hass)

    if device_id is None or (device := dev_reg.async_get(device_id=device_id)) is None:
        return None

    return dr.DeviceInfo(
        identifiers=device.identifiers,
        connections=device.connections,
    )


@callback
def async_remove_stale_devices_links_keep_entity_device(
    hass: HomeAssistant,
    entry_id: str,
    source_entity_id_or_uuid: str | None,
) -> None:
    """Remove entry_id from all devices except that of source_entity_id_or_uuid.

    Also moves all entities linked to the entry_id to the device of
    source_entity_id_or_uuid.
    """

    async_remove_stale_devices_links_keep_current_device(
        hass=hass,
        entry_id=entry_id,
        current_device_id=async_entity_id_to_device_id(hass, source_entity_id_or_uuid)
        if source_entity_id_or_uuid
        else None,
    )


@callback
def async_remove_stale_devices_links_keep_current_device(
    hass: HomeAssistant,
    entry_id: str,
    current_device_id: str | None,
) -> None:
    """Remove entry_id from all devices except current_device_id."""

    dev_reg = dr.async_get(hass)
    ent_reg = er.async_get(hass)

    # Make sure all entities are linked to the correct device
    for entity in ent_reg.entities.get_entries_for_config_entry_id(entry_id):
        if entity.device_id == current_device_id:
            continue
        ent_reg.async_update_entity(entity.entity_id, device_id=current_device_id)

    # Removes all devices from the config entry that are not the same as the current device
    for device in dev_reg.devices.get_devices_for_config_entry_id(entry_id):
        if device.id == current_device_id:
            continue
        dev_reg.async_update_device(device.id, remove_config_entry_id=entry_id)
</file>

<file path="discovery_flow.py">
"""The discovery flow helper."""

from __future__ import annotations

from collections.abc import Coroutine
import dataclasses
from typing import TYPE_CHECKING, Any, NamedTuple, Self

from homeassistant.const import EVENT_HOMEASSISTANT_STARTED
from homeassistant.core import CoreState, Event, HomeAssistant, callback
from homeassistant.loader import bind_hass
from homeassistant.util.async_ import gather_with_limited_concurrency
from homeassistant.util.hass_dict import HassKey

if TYPE_CHECKING:
    from homeassistant.config_entries import ConfigFlowContext, ConfigFlowResult

FLOW_INIT_LIMIT = 20
DISCOVERY_FLOW_DISPATCHER: HassKey[FlowDispatcher] = HassKey(
    "discovery_flow_dispatcher"
)


@dataclasses.dataclass(kw_only=True, slots=True)
class DiscoveryKey:
    """Serializable discovery key."""

    domain: str
    key: str | tuple[str, ...]
    version: int

    @classmethod
    def from_json_dict(cls, json_dict: dict[str, Any]) -> Self:
        """Construct from JSON dict."""
        if type(key := json_dict["key"]) is list:
            key = tuple(key)
        return cls(domain=json_dict["domain"], key=key, version=json_dict["version"])


@bind_hass
@callback
def async_create_flow(
    hass: HomeAssistant,
    domain: str,
    context: ConfigFlowContext,
    data: Any,
    *,
    discovery_key: DiscoveryKey | None = None,
) -> None:
    """Create a discovery flow."""
    dispatcher: FlowDispatcher | None = None
    if DISCOVERY_FLOW_DISPATCHER in hass.data:
        dispatcher = hass.data[DISCOVERY_FLOW_DISPATCHER]
    elif hass.state is not CoreState.running:
        dispatcher = hass.data[DISCOVERY_FLOW_DISPATCHER] = FlowDispatcher(hass)
        dispatcher.async_setup()

    if discovery_key:
        context = context | {"discovery_key": discovery_key}

    if not dispatcher or dispatcher.started:
        if init_coro := _async_init_flow(hass, domain, context, data):
            hass.async_create_background_task(
                init_coro, f"discovery flow {domain} {context}", eager_start=True
            )
        return

    dispatcher.async_create(domain, context, data)


@callback
def _async_init_flow(
    hass: HomeAssistant, domain: str, context: ConfigFlowContext, data: Any
) -> Coroutine[None, None, ConfigFlowResult] | None:
    """Create a discovery flow."""
    # Avoid spawning flows that have the same initial discovery data
    # as ones in progress as it may cause additional device probing
    # which can overload devices since zeroconf/ssdp updates can happen
    # multiple times in the same minute
    if (
        hass.config_entries.flow.async_has_matching_discovery_flow(
            domain, context, data
        )
        or hass.is_stopping
    ):
        return None

    return hass.config_entries.flow.async_init(domain, context=context, data=data)


class PendingFlowKey(NamedTuple):
    """Key for pending flows."""

    domain: str
    source: str


class PendingFlowValue(NamedTuple):
    """Value for pending flows."""

    context: ConfigFlowContext
    data: Any


class FlowDispatcher:
    """Dispatch discovery flows."""

    def __init__(self, hass: HomeAssistant) -> None:
        """Init the discovery dispatcher."""
        self.hass = hass
        self.started = False
        self.pending_flows: dict[PendingFlowKey, list[PendingFlowValue]] = {}

    @callback
    def async_setup(self) -> None:
        """Set up the flow disptcher."""
        self.hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STARTED, self._async_start)

    async def _async_start(self, event: Event) -> None:
        """Start processing pending flows."""
        pending_flows = self.pending_flows
        self.pending_flows = {}
        self.started = True
        init_coros = (
            init_coro
            for flow_key, flows in pending_flows.items()
            for flow_values in flows
            if (
                init_coro := _async_init_flow(
                    self.hass,
                    flow_key.domain,
                    flow_values.context,
                    flow_values.data,
                )
            )
        )
        await gather_with_limited_concurrency(FLOW_INIT_LIMIT, *init_coros)

    @callback
    def async_create(self, domain: str, context: ConfigFlowContext, data: Any) -> None:
        """Create and add or queue a flow."""
        key = PendingFlowKey(domain, context["source"])
        values = PendingFlowValue(context, data)
        existing = self.pending_flows.setdefault(key, [])
        if not any(existing_values.data == data for existing_values in existing):
            existing.append(values)
</file>

<file path="discovery.py">
"""Helper methods to help with platform discovery.

There are two different types of discoveries that can be fired/listened for.
 - listen/discover is for services. These are targeted at a component.
 - listen_platform/discover_platform is for platforms. These are used by
   components to allow discovery of their platforms.
"""

from __future__ import annotations

from collections.abc import Callable, Coroutine
from typing import Any, TypedDict

from homeassistant import core, setup
from homeassistant.const import Platform
from homeassistant.loader import bind_hass
from homeassistant.util.signal_type import SignalTypeFormat

from .dispatcher import async_dispatcher_connect, async_dispatcher_send_internal
from .typing import ConfigType, DiscoveryInfoType

SIGNAL_PLATFORM_DISCOVERED: SignalTypeFormat[DiscoveryDict] = SignalTypeFormat(
    "discovery.platform_discovered_{}"
)
EVENT_LOAD_PLATFORM = "load_platform.{}"
ATTR_PLATFORM = "platform"
ATTR_DISCOVERED = "discovered"


class DiscoveryDict(TypedDict):
    """Discovery data."""

    service: str
    platform: str | None
    discovered: DiscoveryInfoType | None


@core.callback
@bind_hass
def async_listen(
    hass: core.HomeAssistant,
    service: str,
    callback: Callable[
        [str, DiscoveryInfoType | None], Coroutine[Any, Any, None] | None
    ],
) -> None:
    """Set up listener for discovery of specific service.

    Service can be a string or a list/tuple.
    """
    job = core.HassJob(callback, f"discovery listener {service}")

    @core.callback
    def _async_discovery_event_listener(discovered: DiscoveryDict) -> None:
        """Listen for discovery events."""
        hass.async_run_hass_job(job, discovered["service"], discovered["discovered"])

    async_dispatcher_connect(
        hass,
        SIGNAL_PLATFORM_DISCOVERED.format(service),
        _async_discovery_event_listener,
    )


@bind_hass
def discover(
    hass: core.HomeAssistant,
    service: str,
    discovered: DiscoveryInfoType,
    component: str,
    hass_config: ConfigType,
) -> None:
    """Fire discovery event. Can ensure a component is loaded."""
    hass.create_task(
        async_discover(hass, service, discovered, component, hass_config),
        f"discover {service} {component} {discovered}",
    )


@bind_hass
async def async_discover(
    hass: core.HomeAssistant,
    service: str,
    discovered: DiscoveryInfoType | None,
    component: str | None,
    hass_config: ConfigType,
) -> None:
    """Fire discovery event. Can ensure a component is loaded."""
    if component is not None and component not in hass.config.components:
        await setup.async_setup_component(hass, component, hass_config)

    data: DiscoveryDict = {
        "service": service,
        "platform": None,
        "discovered": discovered,
    }

    async_dispatcher_send_internal(
        hass, SIGNAL_PLATFORM_DISCOVERED.format(service), data
    )


@bind_hass
def async_listen_platform(
    hass: core.HomeAssistant,
    component: str,
    callback: Callable[[str, dict[str, Any] | None], Any],
) -> Callable[[], None]:
    """Register a platform loader listener.

    This method must be run in the event loop.
    """
    service = EVENT_LOAD_PLATFORM.format(component)
    job = core.HassJob(callback, f"platform loaded {component}")

    @core.callback
    def _async_discovery_platform_listener(discovered: DiscoveryDict) -> None:
        """Listen for platform discovery events."""
        if not (platform := discovered["platform"]):
            return
        hass.async_run_hass_job(job, platform, discovered.get("discovered"))

    return async_dispatcher_connect(
        hass,
        SIGNAL_PLATFORM_DISCOVERED.format(service),
        _async_discovery_platform_listener,
    )


@bind_hass
def load_platform(
    hass: core.HomeAssistant,
    component: Platform | str,
    platform: str,
    discovered: DiscoveryInfoType | None,
    hass_config: ConfigType,
) -> None:
    """Load a component and platform dynamically."""
    hass.create_task(
        async_load_platform(hass, component, platform, discovered, hass_config),
        f"discovery load_platform {component} {platform}",
    )


@bind_hass
async def async_load_platform(
    hass: core.HomeAssistant,
    component: Platform | str,
    platform: str,
    discovered: DiscoveryInfoType | None,
    hass_config: ConfigType,
) -> None:
    """Load a component and platform dynamically.

    Use `async_listen_platform` to register a callback for these events.

    Warning: This method can load a base component if its not loaded which
    can take a long time since base components currently have to import
    every platform integration listed under it to do config validation.
    To avoid waiting for this, use
    `hass.async_create_task(async_load_platform(..))` instead.
    """
    assert hass_config is not None, "You need to pass in the real hass config"

    setup_success = True

    if component not in hass.config.components:
        setup_success = await setup.async_setup_component(hass, component, hass_config)

    # No need to send signal if we could not set up component
    if not setup_success:
        return

    service = EVENT_LOAD_PLATFORM.format(component)

    data: DiscoveryDict = {
        "service": service,
        "platform": platform,
        "discovered": discovered,
    }

    async_dispatcher_send_internal(
        hass, SIGNAL_PLATFORM_DISCOVERED.format(service), data
    )
</file>

<file path="dispatcher.py">
"""Helpers for Home Assistant dispatcher & internal component/platform."""

from __future__ import annotations

from collections import defaultdict
from collections.abc import Callable, Coroutine
from functools import partial
import logging
from typing import Any, overload

from homeassistant.core import (
    HassJob,
    HassJobType,
    HomeAssistant,
    callback,
    get_hassjob_callable_job_type,
)
from homeassistant.loader import bind_hass
from homeassistant.util.async_ import run_callback_threadsafe
from homeassistant.util.logging import catch_log_exception, log_exception

# Explicit reexport of 'SignalType' for backwards compatibility
from homeassistant.util.signal_type import SignalType as SignalType  # noqa: PLC0414

_LOGGER = logging.getLogger(__name__)
DATA_DISPATCHER = "dispatcher"


type _DispatcherDataType[*_Ts] = dict[
    SignalType[*_Ts] | str,
    dict[
        Callable[[*_Ts], Any] | Callable[..., Any],
        HassJob[..., None | Coroutine[Any, Any, None]] | None,
    ],
]


@overload
@bind_hass
def dispatcher_connect[*_Ts](
    hass: HomeAssistant, signal: SignalType[*_Ts], target: Callable[[*_Ts], None]
) -> Callable[[], None]: ...


@overload
@bind_hass
def dispatcher_connect(
    hass: HomeAssistant, signal: str, target: Callable[..., None]
) -> Callable[[], None]: ...


@bind_hass  # type: ignore[misc]  # workaround; exclude typing of 2 overload in func def
def dispatcher_connect[*_Ts](
    hass: HomeAssistant,
    signal: SignalType[*_Ts],
    target: Callable[[*_Ts], None],
) -> Callable[[], None]:
    """Connect a callable function to a signal."""
    async_unsub = run_callback_threadsafe(
        hass.loop, async_dispatcher_connect, hass, signal, target
    ).result()

    def remove_dispatcher() -> None:
        """Remove signal listener."""
        run_callback_threadsafe(hass.loop, async_unsub).result()

    return remove_dispatcher


@callback
def _async_remove_dispatcher[*_Ts](
    dispatchers: _DispatcherDataType[*_Ts],
    signal: SignalType[*_Ts] | str,
    target: Callable[[*_Ts], Any] | Callable[..., Any],
) -> None:
    """Remove signal listener."""
    try:
        signal_dispatchers = dispatchers[signal]
        del signal_dispatchers[target]
        # Cleanup the signal dict if it is now empty
        # to prevent memory leaks
        if not signal_dispatchers:
            del dispatchers[signal]
    except (KeyError, ValueError):
        # KeyError is key target listener did not exist
        # ValueError if listener did not exist within signal
        _LOGGER.warning("Unable to remove unknown dispatcher %s", target)


@overload
@callback
@bind_hass
def async_dispatcher_connect[*_Ts](
    hass: HomeAssistant, signal: SignalType[*_Ts], target: Callable[[*_Ts], Any]
) -> Callable[[], None]: ...


@overload
@callback
@bind_hass
def async_dispatcher_connect(
    hass: HomeAssistant, signal: str, target: Callable[..., Any]
) -> Callable[[], None]: ...


@callback
@bind_hass
def async_dispatcher_connect[*_Ts](
    hass: HomeAssistant,
    signal: SignalType[*_Ts] | str,
    target: Callable[[*_Ts], Any] | Callable[..., Any],
) -> Callable[[], None]:
    """Connect a callable function to a signal.

    This method must be run in the event loop.
    """
    if DATA_DISPATCHER not in hass.data:
        hass.data[DATA_DISPATCHER] = defaultdict(dict)
    dispatchers: _DispatcherDataType[*_Ts] = hass.data[DATA_DISPATCHER]
    dispatchers[signal][target] = None
    # Use a partial for the remove since it uses
    # less memory than a full closure since a partial copies
    # the body of the function and we don't have to store
    # many different copies of the same function
    return partial(_async_remove_dispatcher, dispatchers, signal, target)


@overload
@bind_hass
def dispatcher_send[*_Ts](
    hass: HomeAssistant, signal: SignalType[*_Ts], *args: *_Ts
) -> None: ...


@overload
@bind_hass
def dispatcher_send(hass: HomeAssistant, signal: str, *args: Any) -> None: ...


@bind_hass  # type: ignore[misc]  # workaround; exclude typing of 2 overload in func def
def dispatcher_send[*_Ts](
    hass: HomeAssistant, signal: SignalType[*_Ts], *args: *_Ts
) -> None:
    """Send signal and data."""
    hass.loop.call_soon_threadsafe(async_dispatcher_send_internal, hass, signal, *args)


def _format_err[*_Ts](
    signal: SignalType[*_Ts] | str,
    target: Callable[[*_Ts], Any] | Callable[..., Any],
    *args: Any,
) -> str:
    """Format error message."""

    return (
        # Functions wrapped in partial do not have a __name__
        f"Exception in {getattr(target, '__name__', None) or target} "
        f"when dispatching '{signal}': {args}"
    )


def _generate_job[*_Ts](
    signal: SignalType[*_Ts] | str, target: Callable[[*_Ts], Any] | Callable[..., Any]
) -> HassJob[..., Coroutine[Any, Any, None] | None]:
    """Generate a HassJob for a signal and target."""
    job_type = get_hassjob_callable_job_type(target)
    name = f"dispatcher {signal}"
    if job_type is HassJobType.Callback:
        # We will catch exceptions in the callback to avoid
        # wrapping the callback since calling wraps() is more
        # expensive than the whole dispatcher_send process
        return HassJob(target, name, job_type=job_type)
    return HassJob(
        catch_log_exception(
            target, partial(_format_err, signal, target), job_type=job_type
        ),
        name,
        job_type=job_type,
    )


@overload
@callback
@bind_hass
def async_dispatcher_send[*_Ts](
    hass: HomeAssistant, signal: SignalType[*_Ts], *args: *_Ts
) -> None: ...


@overload
@callback
@bind_hass
def async_dispatcher_send(hass: HomeAssistant, signal: str, *args: Any) -> None: ...


@callback
@bind_hass
def async_dispatcher_send[*_Ts](
    hass: HomeAssistant, signal: SignalType[*_Ts] | str, *args: *_Ts
) -> None:
    """Send signal and data.

    This method must be run in the event loop.
    """
    # We turned on asyncio debug in April 2024 in the dev containers
    # in the hope of catching some of the issues that have been
    # reported. It will take a while to get all the issues fixed in
    # custom components.
    #
    # In 2025.5 we should guard the `verify_event_loop_thread`
    # check with a check for the `hass.config.debug` flag being set as
    # long term we don't want to be checking this in production
    # environments since it is a performance hit.
    hass.verify_event_loop_thread("async_dispatcher_send")
    async_dispatcher_send_internal(hass, signal, *args)


@callback
@bind_hass
def async_dispatcher_send_internal[*_Ts](
    hass: HomeAssistant, signal: SignalType[*_Ts] | str, *args: *_Ts
) -> None:
    """Send signal and data.

    This method is intended to only be used by core internally
    and should not be considered a stable API. We will make
    breaking changes to this function in the future and it
    should not be used in integrations.

    This method must be run in the event loop.
    """
    if (maybe_dispatchers := hass.data.get(DATA_DISPATCHER)) is None:
        return
    dispatchers: _DispatcherDataType[*_Ts] = maybe_dispatchers
    if (target_list := dispatchers.get(signal)) is None:
        return

    for target, job in list(target_list.items()):
        if job is None:
            job = _generate_job(signal, target)
            target_list[target] = job
        # We do not wrap Callback jobs in catch_log_exception since
        # single use dispatchers spend more time wrapping the callback
        # than the actual callback takes to run in many cases.
        if job.job_type is HassJobType.Callback:
            try:
                job.target(*args)
            except Exception:  # noqa: BLE001
                log_exception(partial(_format_err, signal, target), *args)  # type: ignore[arg-type]
        else:
            hass.async_run_hass_job(job, *args)
</file>

<file path="entity_component.py">
"""Helpers for components that manage entities."""

from __future__ import annotations

import asyncio
from collections.abc import Callable, Iterable, Mapping
from datetime import timedelta
import logging
from types import ModuleType
from typing import Any

from homeassistant import config as conf_util
from homeassistant.config_entries import ConfigEntry
from homeassistant.const import (
    CONF_ENTITY_NAMESPACE,
    CONF_SCAN_INTERVAL,
    EVENT_HOMEASSISTANT_STOP,
)
from homeassistant.core import (
    Event,
    HassJobType,
    HomeAssistant,
    ServiceCall,
    SupportsResponse,
    callback,
)
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import async_get_integration, bind_hass
from homeassistant.setup import async_prepare_setup_platform
from homeassistant.util.hass_dict import HassKey

from . import discovery, entity, service
from .entity_platform import EntityPlatform
from .typing import ConfigType, DiscoveryInfoType, VolDictType, VolSchemaType

DEFAULT_SCAN_INTERVAL = timedelta(seconds=15)
DATA_INSTANCES: HassKey[dict[str, EntityComponent]] = HassKey("entity_components")


@bind_hass
async def async_update_entity(hass: HomeAssistant, entity_id: str) -> None:
    """Trigger an update for an entity."""
    domain = entity_id.partition(".")[0]
    entity_comp = hass.data.get(DATA_INSTANCES, {}).get(domain)

    if entity_comp is None:
        logging.getLogger(__name__).warning(
            "Forced update failed. Component for %s not loaded.", entity_id
        )
        return

    if (entity_obj := entity_comp.get_entity(entity_id)) is None:
        logging.getLogger(__name__).warning(
            "Forced update failed. Entity %s not found.", entity_id
        )
        return

    await entity_obj.async_update_ha_state(True)


class EntityComponent[_EntityT: entity.Entity = entity.Entity]:
    """The EntityComponent manages platforms that manage entities.

    An example of an entity component is 'light', which manages platforms such
    as 'hue.light'.

    This class has the following responsibilities:
     - Process the configuration and set up a platform based component, for example light.
     - Manage the platforms and their entities.
     - Help extract the entities from a service call.
     - Listen for discovery events for platforms related to the domain.
    """

    def __init__(
        self,
        logger: logging.Logger,
        domain: str,
        hass: HomeAssistant,
        scan_interval: timedelta = DEFAULT_SCAN_INTERVAL,
    ) -> None:
        """Initialize an entity component."""
        self.logger = logger
        self.hass = hass
        self.domain = domain
        self.scan_interval = scan_interval

        self.config: ConfigType | None = None

        domain_platform = self._async_init_entity_platform(domain, None)
        self._platforms: dict[
            str | tuple[str, timedelta | None, str | None], EntityPlatform
        ] = {domain: domain_platform}
        self.async_add_entities = domain_platform.async_add_entities
        self.add_entities = domain_platform.add_entities
        self._entities: dict[str, entity.Entity] = domain_platform.domain_entities
        hass.data.setdefault(DATA_INSTANCES, {})[domain] = self  # type: ignore[assignment]

    @property
    def entities(self) -> Iterable[_EntityT]:
        """Return an iterable that returns all entities.

        As the underlying dicts may change when async context is lost,
        callers that iterate over this asynchronously should make a copy
        using list() before iterating.
        """
        return self._entities.values()  # type: ignore[return-value]

    def get_entity(self, entity_id: str) -> _EntityT | None:
        """Get an entity."""
        return self._entities.get(entity_id)  # type: ignore[return-value]

    def register_shutdown(self) -> None:
        """Register shutdown on Home Assistant STOP event.

        Note: this is only required if the integration never calls
        `setup` or `async_setup`.
        """
        self.hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, self._async_shutdown)

    def setup(self, config: ConfigType) -> None:
        """Set up a full entity component.

        This doesn't block the executor to protect from deadlocks.
        """
        self.hass.create_task(
            self.async_setup(config), f"EntityComponent setup {self.domain}"
        )

    async def async_setup(self, config: ConfigType) -> None:
        """Set up a full entity component.

        Loads the platforms from the config and will listen for supported
        discovered platforms.

        This method must be run in the event loop.
        """
        self.register_shutdown()

        self.config = config

        # Look in config for Domain, Domain 2, Domain 3 etc and load them
        for p_type, p_config in conf_util.config_per_platform(config, self.domain):
            if p_type is not None:
                self.hass.async_create_task_internal(
                    self.async_setup_platform(p_type, p_config),
                    f"EntityComponent setup platform {p_type} {self.domain}",
                    eager_start=True,
                )

        # Generic discovery listener for loading platform dynamically
        # Refer to: homeassistant.helpers.discovery.async_load_platform()
        discovery.async_listen_platform(
            self.hass, self.domain, self._async_component_platform_discovered
        )

    async def _async_component_platform_discovered(
        self, platform: str, info: dict[str, Any] | None
    ) -> None:
        """Handle the loading of a platform."""
        await self.async_setup_platform(platform, {}, info)

    async def async_setup_entry(self, config_entry: ConfigEntry) -> bool:
        """Set up a config entry."""
        platform_type = config_entry.domain
        platform = await async_prepare_setup_platform(
            self.hass,
            # In future PR we should make hass_config part of the constructor
            # params.
            self.config or {},
            self.domain,
            platform_type,
        )

        if platform is None:
            return False

        key = config_entry.entry_id

        if key in self._platforms:
            raise ValueError(
                f"Config entry {config_entry.title} ({key}) for "
                f"{platform_type}.{self.domain} has already been setup!"
            )

        self._platforms[key] = self._async_init_entity_platform(
            platform_type,
            platform,
            scan_interval=getattr(platform, "SCAN_INTERVAL", None),
        )

        return await self._platforms[key].async_setup_entry(config_entry)

    async def async_unload_entry(self, config_entry: ConfigEntry) -> bool:
        """Unload a config entry."""
        key = config_entry.entry_id

        if (platform := self._platforms.pop(key, None)) is None:
            raise ValueError("Config entry was never loaded!")

        await platform.async_reset()
        return True

    async def async_extract_from_service(
        self, service_call: ServiceCall, expand_group: bool = True
    ) -> list[_EntityT]:
        """Extract all known and available entities from a service call.

        Will return an empty list if entities specified but unknown.

        This method must be run in the event loop.
        """
        return await service.async_extract_entities(
            self.entities, service_call, expand_group
        )

    @callback
    def async_register_entity_service(
        self,
        name: str,
        schema: VolDictType | VolSchemaType | None,
        func: str | Callable[..., Any],
        required_features: list[int] | None = None,
        supports_response: SupportsResponse = SupportsResponse.NONE,
        *,
        description_placeholders: Mapping[str, str] | None = None,
    ) -> None:
        """Register an entity service."""
        service.async_register_entity_service(
            self.hass,
            self.domain,
            name,
            entities=self._entities,
            func=func,
            job_type=HassJobType.Coroutinefunction,
            required_features=required_features,
            schema=schema,
            supports_response=supports_response,
            description_placeholders=description_placeholders,
        )

    async def async_setup_platform(
        self,
        platform_type: str,
        platform_config: ConfigType,
        discovery_info: DiscoveryInfoType | None = None,
    ) -> None:
        """Set up a platform for this component."""
        if self.config is None:
            raise RuntimeError("async_setup needs to be called first")

        platform = await async_prepare_setup_platform(
            self.hass, self.config, self.domain, platform_type
        )

        if platform is None:
            return

        # Use config scan interval, fallback to platform if none set
        scan_interval = platform_config.get(
            CONF_SCAN_INTERVAL, getattr(platform, "SCAN_INTERVAL", None)
        )
        entity_namespace = platform_config.get(CONF_ENTITY_NAMESPACE)

        key = (platform_type, scan_interval, entity_namespace)

        if key not in self._platforms:
            self._platforms[key] = self._async_init_entity_platform(
                platform_type, platform, scan_interval, entity_namespace
            )

        await self._platforms[key].async_setup(platform_config, discovery_info)

    async def _async_reset(self) -> None:
        """Remove entities and reset the entity component to initial values.

        This method must be run in the event loop.
        """
        tasks = []

        for key, platform in self._platforms.items():
            if key == self.domain:
                tasks.append(platform.async_reset())
            else:
                tasks.append(platform.async_destroy())

        if tasks:
            await asyncio.gather(*tasks)

        self._platforms = {self.domain: self._platforms[self.domain]}
        self.config = None

    async def async_remove_entity(self, entity_id: str) -> None:
        """Remove an entity managed by one of the platforms."""
        found = None

        for platform in self._platforms.values():
            if entity_id in platform.entities:
                found = platform
                break

        if found:
            await found.async_remove_entity(entity_id)

    async def async_prepare_reload(
        self, *, skip_reset: bool = False
    ) -> ConfigType | None:
        """Prepare reloading this entity component.

        This method must be run in the event loop.
        """
        try:
            conf = await conf_util.async_hass_config_yaml(self.hass)
        except HomeAssistantError as err:
            self.logger.error(err)
            return None

        integration = await async_get_integration(self.hass, self.domain)

        processed_conf = await conf_util.async_process_component_and_handle_errors(
            self.hass, conf, integration
        )

        if processed_conf is None:
            return None

        if not skip_reset:
            await self._async_reset()

        return processed_conf

    @callback
    def _async_init_entity_platform(
        self,
        platform_type: str,
        platform: ModuleType | None,
        scan_interval: timedelta | None = None,
        entity_namespace: str | None = None,
    ) -> EntityPlatform:
        """Initialize an entity platform."""
        if scan_interval is None:
            scan_interval = self.scan_interval

        entity_platform = EntityPlatform(
            hass=self.hass,
            logger=self.logger,
            domain=self.domain,
            platform_name=platform_type,
            platform=platform,
            scan_interval=scan_interval,
            entity_namespace=entity_namespace,
        )
        entity_platform.async_prepare()
        return entity_platform

    @callback
    def _async_shutdown(self, event: Event) -> None:
        """Call when Home Assistant is stopping."""
        for platform in self._platforms.values():
            platform.async_shutdown()
</file>

<file path="entity_platform.py">
"""Class to manage the entities for a single platform."""

from __future__ import annotations

import asyncio
from collections.abc import Awaitable, Callable, Coroutine, Iterable, Mapping
from contextvars import ContextVar
from datetime import timedelta
from logging import Logger, getLogger
from typing import TYPE_CHECKING, Any, Protocol, overload

from homeassistant import config_entries
from homeassistant.const import (
    ATTR_RESTORED,
    DEVICE_DEFAULT_NAME,
    EVENT_HOMEASSISTANT_STARTED,
)
from homeassistant.core import (
    CALLBACK_TYPE,
    DOMAIN as HOMEASSISTANT_DOMAIN,
    CoreState,
    HomeAssistant,
    ServiceCall,
    SupportsResponse,
    callback,
    split_entity_id,
    valid_entity_id,
)
from homeassistant.exceptions import (
    ConfigEntryAuthFailed,
    ConfigEntryError,
    ConfigEntryNotReady,
    HomeAssistantError,
    PlatformNotReady,
)
from homeassistant.generated import languages
from homeassistant.setup import SetupPhases, async_start_setup
from homeassistant.util.async_ import create_eager_task
from homeassistant.util.hass_dict import HassKey

from . import device_registry as dr, entity_registry as er, service, translation
from .deprecation import deprecated_function
from .entity_registry import EntityRegistry, RegistryEntryDisabler, RegistryEntryHider
from .event import async_call_later
from .issue_registry import IssueSeverity, async_create_issue
from .typing import UNDEFINED, ConfigType, DiscoveryInfoType, VolDictType, VolSchemaType

if TYPE_CHECKING:
    from .entity import Entity


SLOW_SETUP_WARNING = 10
SLOW_SETUP_MAX_WAIT = 60
SLOW_ADD_ENTITY_MAX_WAIT = 15  # Per Entity
SLOW_ADD_MIN_TIMEOUT = 500

PLATFORM_NOT_READY_RETRIES = 10
DATA_ENTITY_PLATFORM: HassKey[dict[str, list[EntityPlatform]]] = HassKey(
    "entity_platform"
)
DATA_DOMAIN_ENTITIES: HassKey[dict[str, dict[str, Entity]]] = HassKey("domain_entities")
DATA_DOMAIN_PLATFORM_ENTITIES: HassKey[dict[tuple[str, str], dict[str, Entity]]] = (
    HassKey("domain_platform_entities")
)
PLATFORM_NOT_READY_BASE_WAIT_TIME = 30  # seconds

_LOGGER = getLogger(__name__)


class AddEntitiesCallback(Protocol):
    """Protocol type for EntityPlatform.add_entities callback."""

    def __call__(
        self, new_entities: Iterable[Entity], update_before_add: bool = False
    ) -> None:
        """Define add_entities type."""


class AddConfigEntryEntitiesCallback(Protocol):
    """Protocol type for EntityPlatform.add_entities callback."""

    def __call__(
        self,
        new_entities: Iterable[Entity],
        update_before_add: bool = False,
        *,
        config_subentry_id: str | None = None,
    ) -> None:
        """Define add_entities type.

        :param config_subentry_id: subentry which the entities should be added to
        """


class EntityPlatformModule(Protocol):
    """Protocol type for entity platform modules."""

    async def async_setup_platform(
        self,
        hass: HomeAssistant,
        config: ConfigType,
        async_add_entities: AddEntitiesCallback,
        discovery_info: DiscoveryInfoType | None = None,
    ) -> None:
        """Set up an integration platform async."""

    def setup_platform(
        self,
        hass: HomeAssistant,
        config: ConfigType,
        add_entities: AddEntitiesCallback,
        discovery_info: DiscoveryInfoType | None = None,
    ) -> None:
        """Set up an integration platform."""

    async def async_setup_entry(
        self,
        hass: HomeAssistant,
        entry: config_entries.ConfigEntry,
        async_add_entities: AddConfigEntryEntitiesCallback,
    ) -> None:
        """Set up an integration platform from a config entry."""


class PlatformData:
    """Information about a platform, used by entities."""

    def __init__(
        self,
        hass: HomeAssistant,
        *,
        domain: str,
        platform_name: str,
    ) -> None:
        """Initialize the base entity platform."""
        self.hass = hass
        self.domain = domain
        self.platform_name = platform_name
        self.component_translations: dict[str, str] = {}
        self.platform_translations: dict[str, str] = {}
        self.object_id_component_translations: dict[str, str] = {}
        self.object_id_platform_translations: dict[str, str] = {}
        self.default_language_platform_translations: dict[str, str] = {}

    async def _async_get_translations(
        self, language: str, category: str, integration: str
    ) -> dict[str, str]:
        """Get translations for a language, category, and integration."""
        try:
            return await translation.async_get_translations(
                self.hass, language, category, {integration}
            )
        except Exception as err:  # noqa: BLE001
            _LOGGER.debug(
                "Could not load translations for %s",
                integration,
                exc_info=err,
            )
        return {}

    async def async_load_translations(self) -> None:
        """Load translations."""
        hass = self.hass
        object_id_language = (
            hass.config.language
            if hass.config.language in languages.NATIVE_ENTITY_IDS
            else languages.DEFAULT_LANGUAGE
        )
        config_language = hass.config.language
        self.component_translations = await self._async_get_translations(
            config_language, "entity_component", self.domain
        )
        self.platform_translations = await self._async_get_translations(
            config_language, "entity", self.platform_name
        )
        if object_id_language == config_language:
            self.object_id_component_translations = self.component_translations
            self.object_id_platform_translations = self.platform_translations
        else:
            self.object_id_component_translations = await self._async_get_translations(
                object_id_language, "entity_component", self.domain
            )
            self.object_id_platform_translations = await self._async_get_translations(
                object_id_language, "entity", self.platform_name
            )
        if config_language == languages.DEFAULT_LANGUAGE:
            self.default_language_platform_translations = self.platform_translations
        else:
            self.default_language_platform_translations = (
                await self._async_get_translations(
                    languages.DEFAULT_LANGUAGE, "entity", self.platform_name
                )
            )


class EntityPlatform:
    """Manage the entities for a single platform.

    An example of an entity platform is 'hue.light', which is managed by
    the entity component 'light'.
    """

    def __init__(
        self,
        *,
        hass: HomeAssistant,
        logger: Logger,
        domain: str,
        platform_name: str,
        platform: EntityPlatformModule | None,
        scan_interval: timedelta,
        entity_namespace: str | None,
    ) -> None:
        """Initialize the entity platform."""
        self.hass = hass
        self.logger = logger
        self.platform = platform
        self.scan_interval = scan_interval
        self.scan_interval_seconds = scan_interval.total_seconds()
        self.entity_namespace = entity_namespace
        self.config_entry: config_entries.ConfigEntry | None = None
        # Storage for entities for this specific platform only
        # which are indexed by entity_id
        self.entities: dict[str, Entity] = {}
        self._tasks: list[asyncio.Task[None]] = []
        # Stop tracking tasks after setup is completed
        self._setup_complete = False
        # Method to cancel the state change listener
        self._async_polling_timer: asyncio.TimerHandle | None = None
        # Method to cancel the retry of setup
        self._async_cancel_retry_setup: CALLBACK_TYPE | None = None
        self._process_updates: asyncio.Lock | None = None

        self.parallel_updates: asyncio.Semaphore | None = None
        self._update_in_sequence: bool = False

        # Platform is None for the EntityComponent "catch-all" EntityPlatform
        # which powers entity_component.add_entities
        self.parallel_updates_created = platform is None

        # Storage for entities indexed by domain
        # with the child dict indexed by entity_id
        #
        # This is usually media_player, light, switch, etc.
        self.domain_entities = hass.data.setdefault(
            DATA_DOMAIN_ENTITIES, {}
        ).setdefault(domain, {})

        # Storage for entities indexed by domain and platform
        # with the child dict indexed by entity_id
        #
        # This is usually media_player.yamaha, light.hue, switch.tplink, etc.
        key = (domain, platform_name)
        self.domain_platform_entities = hass.data.setdefault(
            DATA_DOMAIN_PLATFORM_ENTITIES, {}
        ).setdefault(key, {})

        self.platform_data = PlatformData(
            hass, domain=domain, platform_name=platform_name
        )

    def __repr__(self) -> str:
        """Represent an EntityPlatform."""
        return (
            "<EntityPlatform "
            f"domain={self.domain} "
            f"platform_name={self.platform_name} "
            f"config_entry={self.config_entry}>"
        )

    @callback
    def _get_parallel_updates_semaphore(
        self, entity_has_sync_update: bool
    ) -> asyncio.Semaphore | None:
        """Get or create a semaphore for parallel updates.

        Semaphore will be created on demand because we base it off if update
        method is async or not.

        - If parallel updates is set to 0, we skip the semaphore.
        - If parallel updates is set to a number, we initialize the semaphore
          to that number.

        The default value for parallel requests is decided based on the first
        entity of the platform which is added to Home Assistant. It's 1 if the
        entity implements the update method, else it's 0.
        """
        if self.parallel_updates_created:
            return self.parallel_updates

        self.parallel_updates_created = True

        parallel_updates = getattr(self.platform, "PARALLEL_UPDATES", None)

        if parallel_updates is None and entity_has_sync_update:
            parallel_updates = 1

        if parallel_updates == 0:
            parallel_updates = None

        if parallel_updates is not None:
            self.parallel_updates = asyncio.Semaphore(parallel_updates)
            self._update_in_sequence = parallel_updates == 1

        return self.parallel_updates

    async def async_setup(
        self,
        platform_config: ConfigType,
        discovery_info: DiscoveryInfoType | None = None,
    ) -> None:
        """Set up the platform from a config file."""
        platform = self.platform
        hass = self.hass

        if not hasattr(platform, "async_setup_platform") and not hasattr(
            platform, "setup_platform"
        ):
            self.logger.error(
                (
                    "The %s platform for the %s integration does not support platform"
                    " setup. Please remove it from your config."
                ),
                self.platform_name,
                self.domain,
            )
            learn_more_url = None
            if self.platform:
                if "custom_components" in self.platform.__file__:  # type: ignore[attr-defined]
                    self.logger.warning(
                        (
                            "The %s platform module for the %s custom integration does not implement"
                            " async_setup_platform or setup_platform."
                        ),
                        self.platform_name,
                        self.domain,
                    )
                else:
                    learn_more_url = f"https://www.home-assistant.io/integrations/{self.platform_name}/"
            platform_key = f"platform: {self.platform_name}"
            yaml_example = f"```yaml\n{self.domain}:\n  - {platform_key}\n```"
            async_create_issue(
                self.hass,
                HOMEASSISTANT_DOMAIN,
                f"platform_integration_no_support_{self.domain}_{self.platform_name}",
                is_fixable=False,
                issue_domain=self.platform_name,
                learn_more_url=learn_more_url,
                severity=IssueSeverity.ERROR,
                translation_key="no_platform_setup",
                translation_placeholders={
                    "domain": self.domain,
                    "platform": self.platform_name,
                    "platform_key": platform_key,
                    "yaml_example": yaml_example,
                },
            )

            return

        @callback
        def async_create_setup_awaitable() -> (
            Coroutine[Any, Any, None] | asyncio.Future[None]
        ):
            """Get task to set up platform."""
            if getattr(platform, "async_setup_platform", None):
                return platform.async_setup_platform(  # type: ignore[union-attr]
                    hass,
                    platform_config,
                    self._async_schedule_add_entities,
                    discovery_info,
                )

            # This should not be replaced with hass.async_add_job because
            # we don't want to track this task in case it blocks startup.
            return hass.loop.run_in_executor(
                None,
                platform.setup_platform,  # type: ignore[union-attr]
                hass,
                platform_config,
                self._schedule_add_entities,
                discovery_info,
            )

        with async_start_setup(
            hass,
            integration=self.platform_name,
            group=str(id(platform_config)),
            phase=SetupPhases.PLATFORM_SETUP,
        ):
            await self._async_setup_platform(async_create_setup_awaitable)

    @callback
    def async_shutdown(self) -> None:
        """Call when Home Assistant is stopping."""
        self.async_cancel_retry_setup()
        self.async_unsub_polling()

    @callback
    def async_cancel_retry_setup(self) -> None:
        """Cancel retry setup."""
        if self._async_cancel_retry_setup is not None:
            self._async_cancel_retry_setup()
            self._async_cancel_retry_setup = None

    async def async_setup_entry(self, config_entry: config_entries.ConfigEntry) -> bool:
        """Set up the platform from a config entry."""
        # Store it so that we can save config entry ID in entity registry
        self.config_entry = config_entry
        platform = self.platform

        @callback
        def async_create_setup_awaitable() -> Coroutine[Any, Any, None]:
            """Get task to set up platform."""
            config_entries.current_entry.set(config_entry)

            return platform.async_setup_entry(  # type: ignore[union-attr]
                self.hass, config_entry, self._async_schedule_add_entities_for_entry
            )

        return await self._async_setup_platform(async_create_setup_awaitable)

    async def _async_setup_platform(
        self,
        async_create_setup_awaitable: Callable[[], Awaitable[None]],
        tries: int = 0,
    ) -> bool:
        """Set up a platform via config file or config entry.

        async_create_setup_awaitable creates an awaitable that sets up platform.
        """
        current_platform.set(self)
        logger = self.logger
        hass = self.hass
        full_name = f"{self.platform_name}.{self.domain}"

        await self.platform_data.async_load_translations()

        logger.info("Setting up %s", full_name)
        warn_task = hass.loop.call_at(
            hass.loop.time() + SLOW_SETUP_WARNING,
            logger.warning,
            "Setup of %s platform %s is taking over %s seconds.",
            self.domain,
            self.platform_name,
            SLOW_SETUP_WARNING,
        )
        try:
            awaitable = async_create_setup_awaitable()
            if asyncio.iscoroutine(awaitable):
                awaitable = create_eager_task(awaitable, loop=hass.loop)

            async with hass.timeout.async_timeout(SLOW_SETUP_MAX_WAIT, self.domain):
                await asyncio.shield(awaitable)

            # Block till all entities are done
            while self._tasks:
                # Await all tasks even if they are done
                # to ensure exceptions are propagated
                pending = self._tasks.copy()
                self._tasks.clear()
                await asyncio.gather(*pending)
        except PlatformNotReady as ex:
            tries += 1
            wait_time = min(tries, 6) * PLATFORM_NOT_READY_BASE_WAIT_TIME
            message = str(ex)
            ready_message = f"ready yet: {message}" if message else "ready yet"
            if tries == 1:
                logger.warning(
                    "Platform %s not %s; Retrying in background in %d seconds",
                    self.platform_name,
                    ready_message,
                    wait_time,
                )
            else:
                logger.debug(
                    "Platform %s not %s; Retrying in %d seconds",
                    self.platform_name,
                    ready_message,
                    wait_time,
                )

            async def setup_again(*_args: Any) -> None:
                """Run setup again."""
                self._async_cancel_retry_setup = None
                await self._async_setup_platform(async_create_setup_awaitable, tries)

            if hass.state is CoreState.running:
                self._async_cancel_retry_setup = async_call_later(
                    hass, wait_time, setup_again
                )
            else:
                self._async_cancel_retry_setup = hass.bus.async_listen_once(
                    EVENT_HOMEASSISTANT_STARTED, setup_again
                )
            return False
        except TimeoutError:
            logger.error(
                (
                    "Setup of platform %s is taking longer than %s seconds."
                    " Startup will proceed without waiting any longer."
                ),
                self.platform_name,
                SLOW_SETUP_MAX_WAIT,
            )
            return False
        except (ConfigEntryNotReady, ConfigEntryAuthFailed, ConfigEntryError) as exc:
            _LOGGER.error(
                "%s raises exception %s in forwarded platform "
                "%s; Instead raise %s before calling async_forward_entry_setups",
                self.platform_name,
                type(exc).__name__,
                self.domain,
                type(exc).__name__,
            )
            return False
        except Exception as exc:
            logger.exception(
                "Error while setting up %s platform for %s: %s",
                self.platform_name,
                self.domain,
                exc,  # noqa: TRY401
            )
            return False
        else:
            hass.config.components.add(full_name)
            self._setup_complete = True
            return True
        finally:
            warn_task.cancel()

    def _schedule_add_entities(
        self, new_entities: Iterable[Entity], update_before_add: bool = False
    ) -> None:
        """Schedule adding entities for a single platform, synchronously."""
        self.hass.loop.call_soon_threadsafe(
            self._async_schedule_add_entities,
            list(new_entities),
            update_before_add,
        )

    @callback
    def _async_schedule_add_entities(
        self, new_entities: Iterable[Entity], update_before_add: bool = False
    ) -> None:
        """Schedule adding entities for a single platform async."""
        entities: list[Entity] = (
            new_entities if type(new_entities) is list else list(new_entities)
        )
        # handle empty list from component/platform
        if not entities:
            return
        task = self.hass.async_create_task_internal(
            self.async_add_entities(entities, update_before_add=update_before_add),
            f"EntityPlatform async_add_entities {self.domain}.{self.platform_name}",
            eager_start=True,
        )

        if not self._setup_complete:
            self._tasks.append(task)

    @callback
    def _async_schedule_add_entities_for_entry(
        self,
        new_entities: Iterable[Entity],
        update_before_add: bool = False,
        *,
        config_subentry_id: str | None = None,
    ) -> None:
        """Schedule adding entities for a single platform async and track the task."""
        assert self.config_entry
        entities: list[Entity] = (
            new_entities if type(new_entities) is list else list(new_entities)
        )
        # handle empty list from component/platform
        if not entities:
            return
        task = self.config_entry.async_create_task(
            self.hass,
            self.async_add_entities(
                entities,
                update_before_add=update_before_add,
                config_subentry_id=config_subentry_id,
            ),
            f"EntityPlatform async_add_entities_for_entry {self.domain}.{self.platform_name}",
            eager_start=True,
        )

        if not self._setup_complete:
            self._tasks.append(task)

    def add_entities(
        self, new_entities: Iterable[Entity], update_before_add: bool = False
    ) -> None:
        """Add entities for a single platform."""
        # That avoid deadlocks
        if update_before_add:
            self.logger.warning(
                "Call 'add_entities' with update_before_add=True "
                "only inside tests or you can run into a deadlock!"
            )

        asyncio.run_coroutine_threadsafe(
            self.async_add_entities(list(new_entities), update_before_add),
            self.hass.loop,
        ).result()

    async def _async_add_and_update_entities(
        self,
        entities: list[Entity],
        timeout: float,
        config_subentry_id: str | None,
    ) -> None:
        """Add entities for a single platform and update them.

        Since we are updating the entities before adding them, we need to
        schedule the coroutines as tasks so we can await them in the event
        loop. This is because the update is likely to yield control to the
        event loop and will finish faster if we run them concurrently.
        """
        results: list[BaseException | None] | None = None
        entity_registry = er.async_get(self.hass)
        try:
            async with self.hass.timeout.async_timeout(timeout, self.domain):
                results = await asyncio.gather(
                    *(
                        create_eager_task(
                            self._async_add_entity(
                                entity, True, entity_registry, config_subentry_id
                            ),
                            loop=self.hass.loop,
                        )
                        for entity in entities
                    ),
                    return_exceptions=True,
                )
        except TimeoutError:
            self.logger.warning(
                "Timed out adding entities for domain %s with platform %s after %ds",
                self.domain,
                self.platform_name,
                timeout,
            )

        if not results:
            return

        for idx, result in enumerate(results):
            if isinstance(result, Exception):
                entity = entities[idx]
                self.logger.exception(
                    "Error adding entity %s for domain %s with platform %s",
                    entity.entity_id,
                    self.domain,
                    self.platform_name,
                    exc_info=result,
                )
            elif isinstance(result, BaseException):
                raise result

    async def _async_add_entities(
        self,
        entities: list[Entity],
        timeout: float,
        config_subentry_id: str | None,
    ) -> None:
        """Add entities for a single platform without updating.

        In this case we are not updating the entities before adding them
        which means it is likely that we will not have to yield control
        to the event loop so we can await the coros directly without
        scheduling them as tasks.
        """
        entity_registry = er.async_get(self.hass)
        try:
            async with self.hass.timeout.async_timeout(timeout, self.domain):
                for entity in entities:
                    try:
                        await self._async_add_entity(
                            entity, False, entity_registry, config_subentry_id
                        )
                    except Exception as ex:
                        self.logger.exception(
                            "Error adding entity %s for domain %s with platform %s",
                            entity.entity_id,
                            self.domain,
                            self.platform_name,
                            exc_info=ex,
                        )
        except TimeoutError:
            self.logger.warning(
                "Timed out adding entities for domain %s with platform %s after %ds",
                self.domain,
                self.platform_name,
                timeout,
            )

    async def async_add_entities(
        self,
        new_entities: Iterable[Entity],
        update_before_add: bool = False,
        *,
        config_subentry_id: str | None = None,
    ) -> None:
        """Add entities for a single platform async.

        This method must be run in the event loop.

        :param config_subentry_id: subentry which the entities should be added to
        """
        if config_subentry_id and (
            not self.config_entry
            or config_subentry_id not in self.config_entry.subentries
        ):
            raise HomeAssistantError(
                f"Can't add entities to unknown subentry {config_subentry_id} of config "
                f"entry {self.config_entry.entry_id if self.config_entry else None}"
            )

        entities: list[Entity] = (
            new_entities if type(new_entities) is list else list(new_entities)
        )
        timeout = max(SLOW_ADD_ENTITY_MAX_WAIT * len(entities), SLOW_ADD_MIN_TIMEOUT)
        if update_before_add:
            await self._async_add_and_update_entities(
                entities, timeout, config_subentry_id
            )
        else:
            await self._async_add_entities(entities, timeout, config_subentry_id)

        if (
            (self.config_entry and self.config_entry.pref_disable_polling)
            or self._async_polling_timer is not None
            or not any(
                # Entity may have failed to add or called `add_to_platform_abort`
                # so we check if the entity is in self.entities before
                # checking `entity.should_poll` since `should_poll` may need to
                # check `self.hass` which will be `None` if the entity did not add
                entity.entity_id
                and entity.entity_id in self.entities
                and entity.should_poll
                for entity in entities
            )
        ):
            return

        self._async_polling_timer = self.hass.loop.call_later(
            self.scan_interval_seconds,
            self._async_handle_interval_callback,
        )

    @callback
    def _async_handle_interval_callback(self) -> None:
        """Update all the entity states in a single platform."""
        self._async_polling_timer = self.hass.loop.call_later(
            self.scan_interval_seconds,
            self._async_handle_interval_callback,
        )
        if self.config_entry:
            self.config_entry.async_create_background_task(
                self.hass,
                self._async_update_entity_states(),
                name=f"EntityPlatform poll {self.domain}.{self.platform_name}",
                eager_start=True,
            )
        else:
            self.hass.async_create_background_task(
                self._async_update_entity_states(),
                name=f"EntityPlatform poll {self.domain}.{self.platform_name}",
                eager_start=True,
            )

    def _entity_id_already_exists(self, entity_id: str) -> tuple[bool, bool]:
        """Check if an entity_id already exists.

        Returns a tuple [already_exists, restored]
        """
        already_exists = entity_id in self.entities
        restored = False

        if not already_exists and not self.hass.states.async_available(entity_id):
            existing = self.hass.states.get(entity_id)
            if existing is not None and ATTR_RESTORED in existing.attributes:
                restored = True
            else:
                already_exists = True
        return (already_exists, restored)

    async def _async_add_entity(
        self,
        entity: Entity,
        update_before_add: bool,
        entity_registry: EntityRegistry,
        config_subentry_id: str | None,
    ) -> None:
        """Add an entity to the platform."""
        if entity is None:
            raise ValueError("Entity cannot be None")

        entity.add_to_platform_start(
            self.hass,
            self,
            self._get_parallel_updates_semaphore(hasattr(entity, "update")),
        )

        # Update properties before we generate the entity_id. This will happen
        # also for disabled entities.
        if update_before_add:
            try:
                await entity.async_device_update(warning=False)
            except Exception:
                self.logger.exception("%s: Error on device update!", self.platform_name)
                entity.add_to_platform_abort()
                return

        entity_name = entity.name
        if entity_name is UNDEFINED:
            entity_name = None

        suggested_object_id: str | None = None

        # An entity may suggest the entity_id by setting entity_id itself
        if not hasattr(entity, "internal_integration_suggested_object_id"):
            if entity.entity_id is not None and not valid_entity_id(entity.entity_id):
                entity.add_to_platform_abort()
                raise HomeAssistantError(f"Invalid entity ID: {entity.entity_id}")
            entity.internal_integration_suggested_object_id = (
                split_entity_id(entity.entity_id)[1]
                if entity.entity_id is not None
                else None
            )

        # Get entity_id from unique ID registration
        if entity.unique_id is not None:
            registered_entity_id = entity_registry.async_get_entity_id(
                self.domain, self.platform_name, entity.unique_id
            )
            if registered_entity_id:
                already_exists, _ = self._entity_id_already_exists(registered_entity_id)

                if already_exists:
                    # If there's a collision, the entry belongs to another entity
                    entity.registry_entry = None
                    msg = (
                        f"Platform {self.platform_name} does not generate unique IDs. "
                    )
                    if entity.entity_id:
                        msg += (
                            f"ID {entity.unique_id} is already used by"
                            f" {registered_entity_id} - ignoring {entity.entity_id}"
                        )
                    else:
                        msg += (
                            f"ID {entity.unique_id} already exists - ignoring"
                            f" {registered_entity_id}"
                        )
                    self.logger.error(msg)
                    entity.add_to_platform_abort()
                    return

            device: dr.DeviceEntry | None
            if self.config_entry:
                if device_info := entity.device_info:
                    try:
                        device = dr.async_get(self.hass).async_get_or_create(
                            config_entry_id=self.config_entry.entry_id,
                            config_subentry_id=config_subentry_id,
                            **device_info,
                        )
                    except dr.DeviceInfoError as exc:
                        self.logger.error(
                            "%s: Not adding entity with invalid device info: %s",
                            self.platform_name,
                            str(exc),
                        )
                        entity.add_to_platform_abort()
                        return

                    entity.device_entry = device
                else:
                    device = entity.device_entry
            else:
                device = None

            suggested_object_id, object_id_base = _async_derive_object_ids(entity, self)

            disabled_by: RegistryEntryDisabler | None = None
            if not entity.entity_registry_enabled_default:
                disabled_by = RegistryEntryDisabler.INTEGRATION

            hidden_by: RegistryEntryHider | None = None
            if not entity.entity_registry_visible_default:
                hidden_by = RegistryEntryHider.INTEGRATION

            entry = entity_registry.async_get_or_create(
                self.domain,
                self.platform_name,
                entity.unique_id,
                capabilities=entity.capability_attributes,
                config_entry=self.config_entry,
                config_subentry_id=config_subentry_id,
                device_id=device.id if device else None,
                disabled_by=disabled_by,
                entity_category=entity.entity_category,
                get_initial_options=entity.get_initial_entity_options,
                has_entity_name=entity.has_entity_name,
                hidden_by=hidden_by,
                object_id_base=object_id_base,
                original_device_class=entity.device_class,
                original_icon=entity.icon,
                original_name=entity_name,
                suggested_object_id=suggested_object_id,
                supported_features=entity.supported_features,
                translation_key=entity.translation_key,
                unit_of_measurement=entity.unit_of_measurement,
            )

            if device and device.disabled and not entry.disabled:
                entry = entity_registry.async_update_entity(
                    entry.entity_id, disabled_by=RegistryEntryDisabler.DEVICE
                )

            entity.registry_entry = entry
            entity.entity_id = entry.entity_id

        else:  # entity.unique_id is None  # noqa: PLR5501
            # We won't generate an entity ID if the platform has already set one
            # We will however make sure that platform cannot pick a registered ID
            if entity.entity_id is None or entity_registry.async_is_registered(
                entity.entity_id
            ):
                object_ids = _async_derive_object_ids(
                    entity, self, fallback_object_id=DEVICE_DEFAULT_NAME
                )
                suggested_object_id = (
                    object_ids[0] if object_ids[0] is not None else object_ids[1]
                )
                entity.entity_id = entity_registry.async_get_available_entity_id(
                    self.domain, suggested_object_id
                )

        already_exists, restored = self._entity_id_already_exists(entity.entity_id)

        if already_exists:
            self.logger.error(
                "Entity id already exists - ignoring: %s", entity.entity_id
            )
            entity.add_to_platform_abort()
            return

        if entity.registry_entry and entity.registry_entry.disabled:
            self.logger.debug(
                "Not adding entity %s because it's disabled",
                entry.name
                or entity_name
                or f'"{self.platform_name} {entity.unique_id}"',
            )
            entity.add_to_platform_abort()
            return

        entity_id = entity.entity_id
        self.entities[entity_id] = entity
        self.domain_entities[entity_id] = entity
        self.domain_platform_entities[entity_id] = entity

        if not restored:
            # Reserve the state in the state machine
            # because as soon as we return control to the event
            # loop below, another entity could be added
            # with the same id before `entity.add_to_platform_finish()`
            # has a chance to finish.
            self.hass.states.async_reserve(entity.entity_id)

        def remove_entity_cb() -> None:
            """Remove entity from entities dict."""
            del self.entities[entity_id]
            del self.domain_entities[entity_id]
            del self.domain_platform_entities[entity_id]

        entity.async_on_remove(remove_entity_cb)

        await entity.add_to_platform_finish()

    async def async_reset(self) -> None:
        """Remove all entities and reset data.

        This method must be run in the event loop.
        """
        self.async_cancel_retry_setup()

        if not self.entities:
            return

        # Removals are awaited in series since in most
        # cases calling async_remove will not yield control
        # to the event loop and we want to avoid scheduling
        # one task per entity.
        for entity in list(self.entities.values()):
            try:
                await entity.async_remove()
            except Exception:
                self.logger.exception(
                    "Error while removing entity %s", entity.entity_id
                )

        self.async_unsub_polling()
        self._setup_complete = False

    @callback
    def async_unsub_polling(self) -> None:
        """Stop polling."""
        if self._async_polling_timer is not None:
            self._async_polling_timer.cancel()
            self._async_polling_timer = None

    @callback
    def async_prepare(self) -> None:
        """Register the entity platform in DATA_ENTITY_PLATFORM."""
        self.hass.data.setdefault(DATA_ENTITY_PLATFORM, {}).setdefault(
            self.platform_name, []
        ).append(self)

    async def async_destroy(self) -> None:
        """Destroy an entity platform.

        Call before discarding the object.
        """
        await self.async_reset()
        self.hass.data[DATA_ENTITY_PLATFORM][self.platform_name].remove(self)

    async def async_remove_entity(self, entity_id: str) -> None:
        """Remove entity id from platform."""
        await self.entities[entity_id].async_remove()

        # Clean up polling job if no longer needed
        if self._async_polling_timer is not None and not any(
            entity.should_poll for entity in self.entities.values()
        ):
            self.async_unsub_polling()

    async def async_extract_from_service(
        self, service_call: ServiceCall, expand_group: bool = True
    ) -> list[Entity]:
        """Extract all known and available entities from a service call.

        Will return an empty list if entities specified but unknown.

        This method must be run in the event loop.
        """
        return await service.async_extract_entities(
            self.entities.values(), service_call, expand_group
        )

    @callback
    def async_register_entity_service(
        self,
        name: str,
        schema: VolDictType | VolSchemaType | None,
        func: str | Callable[..., Any],
        required_features: Iterable[int] | None = None,
        supports_response: SupportsResponse = SupportsResponse.NONE,
        *,
        entity_device_classes: Iterable[str | None] | None = None,
        description_placeholders: Mapping[str, str] | None = None,
    ) -> None:
        """Register an entity service.

        Services will automatically be shared by all platforms of the same domain.
        """
        if self.hass.services.has_service(self.platform_name, name):
            return

        service.async_register_entity_service(
            self.hass,
            self.platform_name,
            name,
            entity_device_classes=entity_device_classes,
            entities=self.domain_platform_entities,
            func=func,
            job_type=None,
            required_features=required_features,
            schema=schema,
            supports_response=supports_response,
            description_placeholders=description_placeholders,
        )

    async def _async_update_entity_states(self) -> None:
        """Update the states of all the polling entities.

        To protect from flooding the executor, we will update async entities
        in parallel and other entities sequential.

        This method must be run in the event loop.
        """
        if self._process_updates is None:
            self._process_updates = asyncio.Lock()
        if self._process_updates.locked():
            self.logger.warning(
                "Updating %s %s took longer than the scheduled update interval %s",
                self.platform_name,
                self.domain,
                self.scan_interval,
            )
            return

        async with self._process_updates:
            if self._update_in_sequence or len(self.entities) <= 1:
                # If we know we will update sequentially, we want to avoid scheduling
                # the coroutines as tasks that will wait on the semaphore lock.
                for entity in list(self.entities.values()):
                    # If the entity is removed from hass during the previous
                    # entity being updated, we need to skip updating the
                    # entity.
                    if entity.should_poll and entity.hass:
                        await entity.async_update_ha_state(True)
                return

            if tasks := [
                create_eager_task(
                    entity.async_update_ha_state(True), loop=self.hass.loop
                )
                for entity in self.entities.values()
                if entity.should_poll
            ]:
                await asyncio.gather(*tasks)

    @property
    def domain(self) -> str:
        """Return the domain (e.g. light)."""
        return self.platform_data.domain

    @property
    def platform_name(self) -> str:
        """Return the platform name (e.g hue)."""
        return self.platform_data.platform_name

    @property
    @deprecated_function(
        "platform_data.component_translations",
        breaks_in_ha_version="2026.8",
    )
    def component_translations(self) -> dict[str, str]:
        """Return the component translations.

        Will be removed in Home Assistant Core 2026.8.
        """
        return self.platform_data.component_translations

    @property
    @deprecated_function(
        "platform_data.platform_translations",
        breaks_in_ha_version="2026.8",
    )
    def platform_translations(self) -> dict[str, str]:
        """Return the platform translations.

        Will be removed in Home Assistant Core 2026.8.
        """
        return self.platform_data.platform_translations

    @property
    @deprecated_function(
        "platform_data.object_id_component_translations",
        breaks_in_ha_version="2026.8",
    )
    def object_id_component_translations(self) -> dict[str, str]:
        """Return the object ID component translations.

        Will be removed in Home Assistant Core 2026.8.
        """
        return self.platform_data.object_id_component_translations

    @property
    @deprecated_function(
        "platform_data.object_id_platform_translations",
        breaks_in_ha_version="2026.8",
    )
    def object_id_platform_translations(self) -> dict[str, str]:
        """Return the object ID platform translations.

        Will be removed in Home Assistant Core 2026.8.
        """
        return self.platform_data.object_id_platform_translations

    @property
    @deprecated_function(
        "platform_data.default_language_platform_translations",
        breaks_in_ha_version="2026.8",
    )
    def default_language_platform_translations(self) -> dict[str, str]:
        """Return the default language platform translations.

        Will be removed in Home Assistant Core 2026.8.
        """
        return self.platform_data.default_language_platform_translations

    @deprecated_function(
        "platform_data.async_load_translations",
        breaks_in_ha_version="2026.8",
    )
    async def async_load_translations(self) -> None:
        """Load translations.

        Will be removed in Home Assistant Core 2026.8.
        """
        return await self.platform_data.async_load_translations()


@overload
def _async_derive_object_ids(
    entity: Entity, platform: EntityPlatform, *, fallback_object_id: None = None
) -> tuple[str | None, str | None]: ...


@overload
def _async_derive_object_ids(
    entity: Entity, platform: EntityPlatform, *, fallback_object_id: str
) -> tuple[str, None] | tuple[None, str]: ...


@callback
def _async_derive_object_ids(
    entity: Entity, platform: EntityPlatform, *, fallback_object_id: str | None = None
) -> tuple[str | None, str | None]:
    """Derive the object IDs for an entity.

    Derives both suggested and base object IDs.
    """
    is_base = True
    object_id: str | None

    if entity.internal_integration_suggested_object_id is not None:
        is_base = False
        object_id = entity.internal_integration_suggested_object_id
    else:
        object_id = entity.suggested_object_id

    if not object_id and fallback_object_id is not None:
        object_id = fallback_object_id

    if platform.entity_namespace is not None:
        is_base = False
        if entity.unique_id is not None and not object_id:
            object_id = f"{platform.platform_name}_{entity.unique_id}"
        object_id = f"{platform.entity_namespace} {object_id}"

    suggested_object_id: str | None = None
    object_id_base: str | None = None
    if is_base:
        object_id_base = object_id
    else:
        suggested_object_id = object_id

    return suggested_object_id, object_id_base


current_platform: ContextVar[EntityPlatform | None] = ContextVar(
    "current_platform", default=None
)


@callback
def async_get_current_platform() -> EntityPlatform:
    """Get the current platform from context."""
    if (platform := current_platform.get()) is None:
        raise RuntimeError("Cannot get non-set current platform")
    return platform


@callback
def async_get_platforms(
    hass: HomeAssistant, integration_name: str
) -> list[EntityPlatform]:
    """Find existing platforms."""
    if (
        DATA_ENTITY_PLATFORM not in hass.data
        or integration_name not in hass.data[DATA_ENTITY_PLATFORM]
    ):
        return []

    return hass.data[DATA_ENTITY_PLATFORM][integration_name]
</file>

<file path="entity_registry.py">
"""Provide a registry to track entity IDs.

The Entity Registry keeps a registry of entities. Entities are uniquely
identified by their domain, platform and a unique id provided by that platform.

The Entity Registry will persist itself 10 seconds after a new entity is
registered. Registering a new entity while a timer is in progress resets the
timer.
"""

from __future__ import annotations

from collections import defaultdict
from collections.abc import Callable, Hashable, KeysView, Mapping
from datetime import datetime, timedelta
from enum import StrEnum
import logging
import time
from typing import TYPE_CHECKING, Any, Literal, NotRequired, TypedDict

import attr
import voluptuous as vol

from homeassistant.const import (
    ATTR_DEVICE_CLASS,
    ATTR_FRIENDLY_NAME,
    ATTR_ICON,
    ATTR_RESTORED,
    ATTR_SUPPORTED_FEATURES,
    ATTR_UNIT_OF_MEASUREMENT,
    EVENT_HOMEASSISTANT_START,
    EVENT_HOMEASSISTANT_STOP,
    MAX_LENGTH_STATE_DOMAIN,
    MAX_LENGTH_STATE_ENTITY_ID,
    STATE_UNAVAILABLE,
    STATE_UNKNOWN,
    EntityCategory,
    Platform,
)
from homeassistant.core import (
    Event,
    HomeAssistant,
    callback,
    split_entity_id,
    valid_entity_id,
)
from homeassistant.exceptions import MaxLengthExceeded
from homeassistant.loader import async_suggest_report_issue
from homeassistant.util import slugify, uuid as uuid_util
from homeassistant.util.dt import utc_from_timestamp, utcnow
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.json import format_unserializable_data
from homeassistant.util.read_only_dict import ReadOnlyDict

from . import device_registry as dr, storage
from .device_registry import (
    EVENT_DEVICE_REGISTRY_UPDATED,
    EventDeviceRegistryUpdatedData,
)
from .frame import ReportBehavior, report_usage
from .json import JSON_DUMP, find_paths_unserializable_data, json_bytes, json_fragment
from .registry import BaseRegistry, BaseRegistryItems, RegistryIndexType
from .singleton import singleton
from .typing import UNDEFINED, UndefinedType

if TYPE_CHECKING:
    # mypy cannot workout _cache Protocol with attrs
    from propcache.api import cached_property as under_cached_property

    from homeassistant.config_entries import ConfigEntry
else:
    from propcache.api import under_cached_property

DATA_REGISTRY: HassKey[EntityRegistry] = HassKey("entity_registry")
EVENT_ENTITY_REGISTRY_UPDATED: EventType[EventEntityRegistryUpdatedData] = EventType(
    "entity_registry_updated"
)

_LOGGER = logging.getLogger(__name__)

STORAGE_VERSION_MAJOR = 1
STORAGE_VERSION_MINOR = 20
STORAGE_KEY = "core.entity_registry"

CLEANUP_INTERVAL = 3600 * 24
ORPHANED_ENTITY_KEEP_SECONDS = 3600 * 24 * 30

ENTITY_CATEGORY_VALUE_TO_INDEX: dict[EntityCategory | None, int] = {
    val: idx for idx, val in enumerate(EntityCategory)
}
ENTITY_CATEGORY_INDEX_TO_VALUE = dict(enumerate(EntityCategory))

# Attributes relevant to describing entity
# to external services.
ENTITY_DESCRIBING_ATTRIBUTES = {
    "capabilities",
    "device_class",
    "entity_id",
    "name",
    "original_name",
    "supported_features",
    "unit_of_measurement",
}


class RegistryEntryDisabler(StrEnum):
    """What disabled a registry entry."""

    CONFIG_ENTRY = "config_entry"
    DEVICE = "device"
    HASS = "hass"
    INTEGRATION = "integration"
    USER = "user"


class RegistryEntryHider(StrEnum):
    """What hid a registry entry."""

    INTEGRATION = "integration"
    USER = "user"


class _EventEntityRegistryUpdatedData_CreateRemove(TypedDict):
    """EventEntityRegistryUpdated data for action type 'create' and 'remove'."""

    action: Literal["create", "remove"]
    entity_id: str


class _EventEntityRegistryUpdatedData_Update(TypedDict):
    """EventEntityRegistryUpdated data for action type 'update'."""

    action: Literal["update"]
    entity_id: str
    changes: dict[str, Any]  # Required with action == "update"
    old_entity_id: NotRequired[str]


type EventEntityRegistryUpdatedData = (
    _EventEntityRegistryUpdatedData_CreateRemove
    | _EventEntityRegistryUpdatedData_Update
)


type EntityOptionsType = Mapping[str, Mapping[str, Any]]
type ReadOnlyEntityOptionsType = ReadOnlyDict[str, ReadOnlyDict[str, Any]]

DISPLAY_DICT_OPTIONAL = (
    # key, attr_name, convert_to_list
    ("ai", "area_id", False),
    ("lb", "labels", True),
    ("di", "device_id", False),
    ("ic", "icon", False),
    ("tk", "translation_key", False),
)


def _protect_entity_options(
    data: EntityOptionsType | None,
) -> ReadOnlyEntityOptionsType:
    """Protect entity options from being modified."""
    if data is None:
        return ReadOnlyDict({})
    return ReadOnlyDict({key: ReadOnlyDict(val) for key, val in data.items()})


def _protect_optional_entity_options(
    data: EntityOptionsType | UndefinedType | None,
) -> ReadOnlyEntityOptionsType | UndefinedType:
    """Protect entity options from being modified."""
    if data is UNDEFINED:
        return UNDEFINED
    if data is None:
        return ReadOnlyDict({})
    return ReadOnlyDict({key: ReadOnlyDict(val) for key, val in data.items()})


@attr.s(frozen=True, kw_only=True, slots=True)
class RegistryEntry:
    """Entity Registry Entry."""

    entity_id: str = attr.ib()
    unique_id: str = attr.ib()
    platform: str = attr.ib()
    previous_unique_id: str | None = attr.ib(default=None)
    aliases: set[str] = attr.ib(factory=set)
    area_id: str | None = attr.ib(default=None)
    categories: dict[str, str] = attr.ib(factory=dict)
    capabilities: Mapping[str, Any] | None = attr.ib()
    config_entry_id: str | None = attr.ib()
    config_subentry_id: str | None = attr.ib()
    created_at: datetime = attr.ib()
    device_class: str | None = attr.ib(default=None)
    device_id: str | None = attr.ib()
    domain: str = attr.ib(init=False, repr=False)
    disabled_by: RegistryEntryDisabler | None = attr.ib()
    entity_category: EntityCategory | None = attr.ib()
    has_entity_name: bool = attr.ib()
    hidden_by: RegistryEntryHider | None = attr.ib()
    icon: str | None = attr.ib(default=None)
    id: str = attr.ib(
        converter=attr.converters.default_if_none(factory=uuid_util.random_uuid_hex)  # type: ignore[misc]
    )
    labels: set[str] = attr.ib(factory=set)
    modified_at: datetime = attr.ib(factory=utcnow)
    name: str | None = attr.ib(default=None)
    object_id_base: str | None = attr.ib()
    options: ReadOnlyEntityOptionsType = attr.ib(converter=_protect_entity_options)
    # As set by integration
    original_device_class: str | None = attr.ib()
    original_icon: str | None = attr.ib()
    original_name: str | None = attr.ib()
    suggested_object_id: str | None = attr.ib()
    supported_features: int = attr.ib()
    translation_key: str | None = attr.ib()
    unit_of_measurement: str | None = attr.ib()
    _cache: dict[str, Any] = attr.ib(factory=dict, eq=False, init=False)

    @domain.default
    def _domain_default(self) -> str:
        """Compute domain value."""
        return split_entity_id(self.entity_id)[0]

    @property
    def disabled(self) -> bool:
        """Return if entry is disabled."""
        return self.disabled_by is not None

    @property
    def hidden(self) -> bool:
        """Return if entry is hidden."""
        return self.hidden_by is not None

    @property
    def _as_display_dict(self) -> dict[str, Any] | None:
        """Return a partial dict representation of the entry.

        This version only includes what's needed for display.
        Returns None if there's no data needed for display.
        """
        display_dict: dict[str, Any] = {"ei": self.entity_id, "pl": self.platform}
        for key, attr_name, convert_list in DISPLAY_DICT_OPTIONAL:
            if (attr_val := getattr(self, attr_name)) is not None:
                # Convert sets and tuples to lists
                # so the JSON serializer does not have to do
                # it every time
                display_dict[key] = list(attr_val) if convert_list else attr_val
        if (category := self.entity_category) is not None:
            display_dict["ec"] = ENTITY_CATEGORY_VALUE_TO_INDEX[category]
        if self.hidden_by is not None:
            display_dict["hb"] = True
        if self.has_entity_name:
            display_dict["hn"] = True
        name = self.name or self.original_name
        if name is not None:
            display_dict["en"] = name
        if self.domain == "sensor" and (sensor_options := self.options.get("sensor")):
            if (precision := sensor_options.get("display_precision")) is not None or (
                precision := sensor_options.get("suggested_display_precision")
            ) is not None:
                display_dict["dp"] = precision
        return display_dict

    @under_cached_property
    def display_json_repr(self) -> bytes | None:
        """Return a cached partial JSON representation of the entry.

        This version only includes what's needed for display.
        """
        try:
            dict_repr = self._as_display_dict
            json_repr: bytes | None = json_bytes(dict_repr) if dict_repr else None
        except (ValueError, TypeError):
            _LOGGER.error(
                "Unable to serialize entry %s to JSON. Bad data found at %s",
                self.entity_id,
                format_unserializable_data(
                    find_paths_unserializable_data(dict_repr, dump=JSON_DUMP)
                ),
            )
            return None
        return json_repr

    @under_cached_property
    def as_partial_dict(self) -> dict[str, Any]:
        """Return a partial dict representation of the entry."""
        # Convert sets and tuples to lists
        # so the JSON serializer does not have to do
        # it every time
        return {
            "area_id": self.area_id,
            "categories": self.categories,
            "config_entry_id": self.config_entry_id,
            "config_subentry_id": self.config_subentry_id,
            "created_at": self.created_at.timestamp(),
            "device_id": self.device_id,
            "disabled_by": self.disabled_by,
            "entity_category": self.entity_category,
            "entity_id": self.entity_id,
            "has_entity_name": self.has_entity_name,
            "hidden_by": self.hidden_by,
            "icon": self.icon,
            "id": self.id,
            "labels": list(self.labels),
            "modified_at": self.modified_at.timestamp(),
            "name": self.name,
            "options": self.options,
            "original_name": self.original_name,
            "platform": self.platform,
            "translation_key": self.translation_key,
            "unique_id": self.unique_id,
        }

    @under_cached_property
    def extended_dict(self) -> dict[str, Any]:
        """Return a extended dict representation of the entry."""
        # Convert sets and tuples to lists
        # so the JSON serializer does not have to do
        # it every time
        return {
            **self.as_partial_dict,
            "aliases": list(self.aliases),
            "capabilities": self.capabilities,
            "device_class": self.device_class,
            "original_device_class": self.original_device_class,
            "original_icon": self.original_icon,
        }

    @under_cached_property
    def partial_json_repr(self) -> bytes | None:
        """Return a cached partial JSON representation of the entry."""
        try:
            dict_repr = self.as_partial_dict
            return json_bytes(dict_repr)
        except (ValueError, TypeError):
            _LOGGER.error(
                "Unable to serialize entry %s to JSON. Bad data found at %s",
                self.entity_id,
                format_unserializable_data(
                    find_paths_unserializable_data(dict_repr, dump=JSON_DUMP)
                ),
            )
        return None

    @under_cached_property
    def as_storage_fragment(self) -> json_fragment:
        """Return a json fragment for storage."""
        return json_fragment(
            json_bytes(
                {
                    "aliases": list(self.aliases),
                    "area_id": self.area_id,
                    "categories": self.categories,
                    "capabilities": self.capabilities,
                    "config_entry_id": self.config_entry_id,
                    "config_subentry_id": self.config_subentry_id,
                    "created_at": self.created_at,
                    "device_class": self.device_class,
                    "device_id": self.device_id,
                    "disabled_by": self.disabled_by,
                    "entity_category": self.entity_category,
                    "entity_id": self.entity_id,
                    "hidden_by": self.hidden_by,
                    "icon": self.icon,
                    "id": self.id,
                    "has_entity_name": self.has_entity_name,
                    "labels": list(self.labels),
                    "modified_at": self.modified_at,
                    "name": self.name,
                    "object_id_base": self.object_id_base,
                    "options": self.options,
                    "original_device_class": self.original_device_class,
                    "original_icon": self.original_icon,
                    "original_name": self.original_name,
                    "platform": self.platform,
                    "suggested_object_id": self.suggested_object_id,
                    "supported_features": self.supported_features,
                    "translation_key": self.translation_key,
                    "unique_id": self.unique_id,
                    "previous_unique_id": self.previous_unique_id,
                    "unit_of_measurement": self.unit_of_measurement,
                }
            )
        )

    @callback
    def write_unavailable_state(self, hass: HomeAssistant) -> None:
        """Write the unavailable state to the state machine."""
        attrs: dict[str, Any] = {ATTR_RESTORED: True}

        if self.capabilities is not None:
            attrs.update(self.capabilities)

        device_class = self.device_class or self.original_device_class
        if device_class is not None:
            attrs[ATTR_DEVICE_CLASS] = device_class

        icon = self.icon or self.original_icon
        if icon is not None:
            attrs[ATTR_ICON] = icon

        name = self.name or self.original_name
        if name is not None:
            attrs[ATTR_FRIENDLY_NAME] = name

        if self.supported_features is not None:
            attrs[ATTR_SUPPORTED_FEATURES] = self.supported_features

        if self.unit_of_measurement is not None:
            attrs[ATTR_UNIT_OF_MEASUREMENT] = self.unit_of_measurement

        hass.states.async_set(self.entity_id, STATE_UNAVAILABLE, attrs)


@callback
def _async_get_full_entity_name(
    name: str | None,
    *,
    device: dr.DeviceEntry | None = None,
    platform: str,
    unique_id: str,
) -> str:
    """Get full name for an entity.

    This includes the device name if appropriate.
    """
    if device is not None:
        device_name = device.name_by_user or device.name
        if not name:
            name = device_name
        else:
            name = f"{device_name} {name}"

    if not name:
        name = f"{platform}_{unique_id}"

    return name


@attr.s(frozen=True, slots=True)
class DeletedRegistryEntry:
    """Deleted Entity Registry Entry."""

    entity_id: str = attr.ib()
    unique_id: str = attr.ib()
    platform: str = attr.ib()

    aliases: set[str] = attr.ib()
    area_id: str | None = attr.ib()
    categories: dict[str, str] = attr.ib()
    config_entry_id: str | None = attr.ib()
    config_subentry_id: str | None = attr.ib()
    created_at: datetime = attr.ib()
    device_class: str | None = attr.ib()
    disabled_by: RegistryEntryDisabler | UndefinedType | None = attr.ib()
    domain: str = attr.ib(init=False, repr=False)
    hidden_by: RegistryEntryHider | UndefinedType | None = attr.ib()
    icon: str | None = attr.ib()
    id: str = attr.ib()
    labels: set[str] = attr.ib()
    modified_at: datetime = attr.ib()
    name: str | None = attr.ib()
    options: ReadOnlyEntityOptionsType | UndefinedType = attr.ib(
        converter=_protect_optional_entity_options
    )
    orphaned_timestamp: float | None = attr.ib()

    _cache: dict[str, Any] = attr.ib(factory=dict, eq=False, init=False)

    @domain.default
    def _domain_default(self) -> str:
        """Compute domain value."""
        return split_entity_id(self.entity_id)[0]

    @under_cached_property
    def as_storage_fragment(self) -> json_fragment:
        """Return a json fragment for storage."""
        return json_fragment(
            json_bytes(
                {
                    "aliases": list(self.aliases),
                    "area_id": self.area_id,
                    "categories": self.categories,
                    "config_entry_id": self.config_entry_id,
                    "config_subentry_id": self.config_subentry_id,
                    "created_at": self.created_at,
                    "device_class": self.device_class,
                    "disabled_by": self.disabled_by
                    if self.disabled_by is not UNDEFINED
                    else None,
                    "disabled_by_undefined": self.disabled_by is UNDEFINED,
                    "entity_id": self.entity_id,
                    "hidden_by": self.hidden_by
                    if self.hidden_by is not UNDEFINED
                    else None,
                    "hidden_by_undefined": self.hidden_by is UNDEFINED,
                    "icon": self.icon,
                    "id": self.id,
                    "labels": list(self.labels),
                    "modified_at": self.modified_at,
                    "name": self.name,
                    "options": self.options if self.options is not UNDEFINED else {},
                    "options_undefined": self.options is UNDEFINED,
                    "orphaned_timestamp": self.orphaned_timestamp,
                    "platform": self.platform,
                    "unique_id": self.unique_id,
                }
            )
        )


class EntityRegistryStore(storage.Store[dict[str, list[dict[str, Any]]]]):
    """Store entity registry data."""

    async def _async_migrate_func(  # noqa: C901
        self,
        old_major_version: int,
        old_minor_version: int,
        old_data: dict[str, list[dict[str, Any]]],
    ) -> dict:
        """Migrate to the new version."""
        data = old_data
        if old_major_version == 1:
            if old_minor_version < 2:
                # Version 1.2 implements migration and freezes the available keys
                for entity in data["entities"]:
                    # Populate keys which were introduced before version 1.2
                    entity.setdefault("area_id", None)
                    entity.setdefault("capabilities", {})
                    entity.setdefault("config_entry_id", None)
                    entity.setdefault("device_class", None)
                    entity.setdefault("device_id", None)
                    entity.setdefault("disabled_by", None)
                    entity.setdefault("entity_category", None)
                    entity.setdefault("icon", None)
                    entity.setdefault("name", None)
                    entity.setdefault("original_icon", None)
                    entity.setdefault("original_name", None)
                    entity.setdefault("supported_features", 0)
                    entity.setdefault("unit_of_measurement", None)

            if old_minor_version < 3:
                # Version 1.3 adds original_device_class
                for entity in data["entities"]:
                    # Move device_class to original_device_class
                    entity["original_device_class"] = entity["device_class"]
                    entity["device_class"] = None

            if old_minor_version < 4:
                # Version 1.4 adds id
                for entity in data["entities"]:
                    entity["id"] = uuid_util.random_uuid_hex()

            if old_minor_version < 5:
                # Version 1.5 adds entity options
                for entity in data["entities"]:
                    entity["options"] = {}

            if old_minor_version < 6:
                # Version 1.6 adds hidden_by
                for entity in data["entities"]:
                    entity["hidden_by"] = None

            if old_minor_version < 7:
                # Version 1.7 adds has_entity_name
                for entity in data["entities"]:
                    entity["has_entity_name"] = False

            if old_minor_version < 8:
                # Cleanup after frontend bug which incorrectly updated device_class
                # Fixed by frontend PR #13551
                for entity in data["entities"]:
                    domain = split_entity_id(entity["entity_id"])[0]
                    if domain in [Platform.BINARY_SENSOR, Platform.COVER]:
                        continue
                    entity["device_class"] = None

            if old_minor_version < 9:
                # Version 1.9 adds translation_key
                for entity in data["entities"]:
                    entity["translation_key"] = None

            if old_minor_version < 10:
                # Version 1.10 adds aliases
                for entity in data["entities"]:
                    entity["aliases"] = []

            if old_minor_version < 11:
                # Version 1.11 adds deleted_entities
                data["deleted_entities"] = data.get("deleted_entities", [])

            if old_minor_version < 12:
                # Version 1.12 adds previous_unique_id
                for entity in data["entities"]:
                    entity["previous_unique_id"] = None

            if old_minor_version < 13:
                # Version 1.13 adds labels
                for entity in data["entities"]:
                    entity["labels"] = []

            if old_minor_version < 14:
                # Version 1.14 adds categories
                for entity in data["entities"]:
                    entity["categories"] = {}

            if old_minor_version < 15:
                # Version 1.15 adds created_at and modified_at
                created_at = utc_from_timestamp(0).isoformat()
                for entity in data["entities"]:
                    entity["created_at"] = entity["modified_at"] = created_at
                for entity in data["deleted_entities"]:
                    entity["created_at"] = entity["modified_at"] = created_at

            if old_minor_version < 16:
                # Version 1.16 adds config_subentry_id
                for entity in data["entities"]:
                    entity["config_subentry_id"] = None
                for entity in data["deleted_entities"]:
                    entity["config_subentry_id"] = None

            if old_minor_version < 17:
                # Version 1.17 adds suggested_object_id
                for entity in data["entities"]:
                    entity["suggested_object_id"] = None

            if old_minor_version < 18:
                # Version 1.18 adds user customizations to deleted entities
                for entity in data["deleted_entities"]:
                    entity["aliases"] = []
                    entity["area_id"] = None
                    entity["categories"] = {}
                    entity["device_class"] = None
                    entity["disabled_by"] = None
                    entity["hidden_by"] = None
                    entity["icon"] = None
                    entity["labels"] = []
                    entity["name"] = None
                    entity["options"] = {}
            if old_minor_version < 19:
                # Version 1.19 adds undefined flags to deleted entities, this is a bugfix
                # of version 1.18
                set_to_undefined = old_minor_version < 18
                for entity in data["deleted_entities"]:
                    entity["disabled_by_undefined"] = set_to_undefined
                    entity["hidden_by_undefined"] = set_to_undefined
                    entity["options_undefined"] = set_to_undefined

            if old_minor_version < 20:
                # Version 1.20 adds object_id_base to entities
                for entity in data["entities"]:
                    entity["object_id_base"] = entity["original_name"]

        if old_major_version > 1:
            raise NotImplementedError
        return data


class EntityRegistryItems(BaseRegistryItems[RegistryEntry]):
    """Container for entity registry items, maps entity_id -> entry.

    Maintains six additional indexes:
    - id -> entry
    - (domain, platform, unique_id) -> entity_id
    - config_entry_id -> dict[key, True]
    - device_id -> dict[key, True]
    - area_id -> dict[key, True]
    - label -> dict[key, True]
    """

    def __init__(self) -> None:
        """Initialize the container."""
        super().__init__()
        self._entry_ids: dict[str, RegistryEntry] = {}
        self._index: dict[tuple[str, str, str], str] = {}
        self._config_entry_id_index: RegistryIndexType = defaultdict(dict)
        self._device_id_index: RegistryIndexType = defaultdict(dict)
        self._area_id_index: RegistryIndexType = defaultdict(dict)
        self._labels_index: RegistryIndexType = defaultdict(dict)

    def _index_entry(self, key: str, entry: RegistryEntry) -> None:
        """Index an entry."""
        self._entry_ids[entry.id] = entry
        self._index[(entry.domain, entry.platform, entry.unique_id)] = entry.entity_id
        # python has no ordered set, so we use a dict with True values
        # https://discuss.python.org/t/add-orderedset-to-stdlib/12730
        if (config_entry_id := entry.config_entry_id) is not None:
            self._config_entry_id_index[config_entry_id][key] = True
        if (device_id := entry.device_id) is not None:
            self._device_id_index[device_id][key] = True
        if (area_id := entry.area_id) is not None:
            self._area_id_index[area_id][key] = True
        for label in entry.labels:
            self._labels_index[label][key] = True

    def _unindex_entry(
        self, key: str, replacement_entry: RegistryEntry | None = None
    ) -> None:
        """Unindex an entry."""
        entry = self.data[key]
        del self._entry_ids[entry.id]
        del self._index[(entry.domain, entry.platform, entry.unique_id)]
        if config_entry_id := entry.config_entry_id:
            self._unindex_entry_value(key, config_entry_id, self._config_entry_id_index)
        if device_id := entry.device_id:
            self._unindex_entry_value(key, device_id, self._device_id_index)
        if area_id := entry.area_id:
            self._unindex_entry_value(key, area_id, self._area_id_index)
        if labels := entry.labels:
            for label in labels:
                self._unindex_entry_value(key, label, self._labels_index)

    def get_device_ids(self) -> KeysView[str]:
        """Return device ids."""
        return self._device_id_index.keys()

    def get_entity_id(self, key: tuple[str, str, str]) -> str | None:
        """Get entity_id from (domain, platform, unique_id)."""
        return self._index.get(key)

    def get_entry(self, key: str) -> RegistryEntry | None:
        """Get entry from id."""
        return self._entry_ids.get(key)

    def get_entries_for_device_id(
        self, device_id: str, include_disabled_entities: bool = False
    ) -> list[RegistryEntry]:
        """Get entries for device."""
        data = self.data
        return [
            entry
            for key in self._device_id_index.get(device_id, ())
            if not (entry := data[key]).disabled_by or include_disabled_entities
        ]

    def get_entries_for_config_entry_id(
        self, config_entry_id: str
    ) -> list[RegistryEntry]:
        """Get entries for config entry."""
        data = self.data
        return [
            data[key] for key in self._config_entry_id_index.get(config_entry_id, ())
        ]

    def get_entries_for_area_id(self, area_id: str) -> list[RegistryEntry]:
        """Get entries for area."""
        data = self.data
        return [data[key] for key in self._area_id_index.get(area_id, ())]

    def get_entries_for_label(self, label: str) -> list[RegistryEntry]:
        """Get entries for label."""
        data = self.data
        return [data[key] for key in self._labels_index.get(label, ())]


def _validate_item(
    hass: HomeAssistant,
    domain: str,
    platform: str,
    *,
    config_entry_id: str | None | UndefinedType = None,
    config_subentry_id: str | None | UndefinedType = None,
    device_id: str | None | UndefinedType = None,
    disabled_by: RegistryEntryDisabler | None | UndefinedType = None,
    entity_category: EntityCategory | None | UndefinedType = None,
    hidden_by: RegistryEntryHider | None | UndefinedType = None,
    old_config_subentry_id: str | None = None,
    report_non_string_unique_id: bool = True,
    unique_id: str | Hashable | UndefinedType | Any,
) -> None:
    """Validate entity registry item."""
    if unique_id is not UNDEFINED and not isinstance(unique_id, Hashable):
        raise TypeError(f"unique_id must be a string, got {unique_id}")
    if (
        report_non_string_unique_id
        and unique_id is not UNDEFINED
        and not isinstance(unique_id, str)
    ):
        # In HA Core 2025.10, we should fail if unique_id is not a string
        report_issue = async_suggest_report_issue(hass, integration_domain=platform)
        _LOGGER.error(
            "'%s' from integration %s has a non string unique_id '%s', please %s",
            domain,
            platform,
            unique_id,
            report_issue,
        )
    if config_entry_id and config_entry_id is not UNDEFINED:
        if not hass.config_entries.async_get_entry(config_entry_id):
            raise ValueError(
                f"Can't link entity to unknown config entry {config_entry_id}"
            )
    if (
        config_entry_id
        and config_entry_id is not UNDEFINED
        and old_config_subentry_id
        and config_subentry_id is UNDEFINED
    ):
        raise ValueError("Can't change config entry without changing subentry")
    if (
        config_entry_id
        and config_entry_id is not UNDEFINED
        and config_subentry_id
        and config_subentry_id is not UNDEFINED
    ):
        if (
            not (config_entry := hass.config_entries.async_get_entry(config_entry_id))
            or config_subentry_id not in config_entry.subentries
        ):
            raise ValueError(
                f"Config entry {config_entry_id} has no subentry {config_subentry_id}"
            )
    if device_id and device_id is not UNDEFINED:
        device_registry = dr.async_get(hass)
        if not device_registry.async_get(device_id):
            raise ValueError(f"Device {device_id} does not exist")
    if (
        disabled_by
        and disabled_by is not UNDEFINED
        and not isinstance(disabled_by, RegistryEntryDisabler)
    ):
        raise ValueError(
            f"disabled_by must be a RegistryEntryDisabler value, got {disabled_by}"
        )
    if (
        entity_category
        and entity_category is not UNDEFINED
        and not isinstance(entity_category, EntityCategory)
    ):
        raise ValueError(
            f"entity_category must be a valid EntityCategory instance, got {entity_category}"
        )
    if (
        hidden_by
        and hidden_by is not UNDEFINED
        and not isinstance(hidden_by, RegistryEntryHider)
    ):
        raise ValueError(
            f"hidden_by must be a RegistryEntryHider value, got {hidden_by}"
        )


class EntityRegistry(BaseRegistry):
    """Class to hold a registry of entities."""

    deleted_entities: dict[tuple[str, str, str], DeletedRegistryEntry]
    entities: EntityRegistryItems
    _entities_data: dict[str, RegistryEntry]

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the registry."""
        self.hass = hass
        self._store = EntityRegistryStore(
            hass,
            STORAGE_VERSION_MAJOR,
            STORAGE_KEY,
            atomic_writes=True,
            minor_version=STORAGE_VERSION_MINOR,
            serialize_in_event_loop=False,
        )
        self.hass.bus.async_listen(
            EVENT_DEVICE_REGISTRY_UPDATED,
            self.async_device_modified,
        )

    @callback
    def async_is_registered(self, entity_id: str) -> bool:
        """Check if an entity_id is currently registered."""
        return entity_id in self.entities

    @callback
    def async_get(self, entity_id_or_uuid: str) -> RegistryEntry | None:
        """Get EntityEntry for an entity_id or entity entry id.

        We retrieve the RegistryEntry from the underlying dict to avoid
        the overhead of the UserDict __getitem__.
        """
        return self._entities_data.get(entity_id_or_uuid) or self.entities.get_entry(
            entity_id_or_uuid
        )

    @callback
    def async_get_entity_id(
        self, domain: str, platform: str, unique_id: str
    ) -> str | None:
        """Check if an entity_id is currently registered."""
        return self.entities.get_entity_id((domain, platform, unique_id))

    @callback
    def async_device_ids(self) -> list[str]:
        """Return known device ids."""
        return list(self.entities.get_device_ids())

    def _entity_id_available(self, entity_id: str) -> bool:
        """Return True if the entity_id is available.

        An entity_id is available if:
        - It's not registered
        - It's available (not in the state machine and not reserved)

        Note that an entity_id which belongs to a deleted entity is considered
        available.
        """
        return entity_id not in self.entities and self.hass.states.async_available(
            entity_id
        )

    @callback
    def async_generate_entity_id(
        self,
        domain: str,
        suggested_object_id: str,
        *,
        current_entity_id: str | None = None,
        reserved_entity_ids: set[str] | None = None,
    ) -> str:
        """Get available entity ID.

        This function is deprecated. Use `async_get_available_entity_id` instead.

        Entity ID conflicts are checked against registered and currently existing entities,
        as well as provided `reserved_entity_ids`.
        """
        report_usage(
            "calls `entity_registry.async_generate_entity_id`, "
            "which is deprecated and will be removed in Home Assistant 2027.2; "
            "use `entity_registry.async_get_available_entity_id` instead",
            core_behavior=ReportBehavior.LOG,
            breaks_in_ha_version="2027.2.0",
        )

        return self.async_get_available_entity_id(
            domain,
            suggested_object_id,
            current_entity_id=current_entity_id,
            reserved_entity_ids=reserved_entity_ids,
        )

    @callback
    def async_get_available_entity_id(
        self,
        domain: str,
        suggested_object_id: str,
        *,
        current_entity_id: str | None = None,
        reserved_entity_ids: set[str] | None = None,
    ) -> str:
        """Get next available entity ID.

        Entity ID conflicts are checked against registered and currently existing entities,
        as well as provided `reserved_entity_ids`.
        """
        preferred_string = f"{domain}.{slugify(suggested_object_id)}"

        if len(domain) > MAX_LENGTH_STATE_DOMAIN:
            raise MaxLengthExceeded(domain, "domain", MAX_LENGTH_STATE_DOMAIN)

        test_string = preferred_string[:MAX_LENGTH_STATE_ENTITY_ID]

        tries = 1
        while (
            not self._entity_id_available(test_string)
            and test_string != current_entity_id
        ) or (reserved_entity_ids and test_string in reserved_entity_ids):
            tries += 1
            len_suffix = len(str(tries)) + 1
            test_string = (
                f"{preferred_string[: MAX_LENGTH_STATE_ENTITY_ID - len_suffix]}_{tries}"
            )

        return test_string

    def _async_generate_entity_id(
        self,
        *,
        current_entity_id: str | None,
        device_id: str | None,
        domain: str,
        has_entity_name: bool,
        name: str | None,
        object_id_base: str | None,
        platform: str,
        reserved_entity_ids: set[str] | None = None,
        suggested_object_id: str | None,
        unique_id: str,
    ) -> str:
        """Generate an entity ID, based on all the provided parameters.

        `name` is the name set by the user, not the original name from the integration.
        `name` has priority over `suggested_object_id`, which has priority
        over `object_id_base`.
        `name` and `suggested_object_id` will never be prefixed with the device name,
        `object_id_base` will be if `has_entity_name` is True.

        Entity ID conflicts are checked against registered and currently
        existing entities, as well as provided `reserved_entity_ids`.
        """
        object_id: str | None
        use_device = False
        if name is not None:
            object_id = name
        elif suggested_object_id is not None:
            object_id = suggested_object_id
        else:
            object_id = object_id_base
            if has_entity_name:
                use_device = True

        device = (
            dr.async_get(self.hass).async_get(device_id)
            if use_device and device_id is not None
            else None
        )

        object_id = _async_get_full_entity_name(
            object_id,
            device=device,
            platform=platform,
            unique_id=unique_id,
        )
        return self.async_get_available_entity_id(
            domain,
            object_id,
            current_entity_id=current_entity_id,
            reserved_entity_ids=reserved_entity_ids,
        )

    @callback
    def async_regenerate_entity_id(
        self,
        entry: RegistryEntry,
        *,
        reserved_entity_ids: set[str] | None = None,
    ) -> str:
        """Regenerate an entity ID for an entry.

        Entity ID conflicts are checked against registered and currently existing entities,
        as well as provided `reserved_entity_ids`.
        """
        return self._async_generate_entity_id(
            current_entity_id=entry.entity_id,
            device_id=entry.device_id,
            domain=entry.domain,
            has_entity_name=entry.has_entity_name,
            name=entry.name,
            object_id_base=entry.object_id_base,
            platform=entry.platform,
            reserved_entity_ids=reserved_entity_ids,
            suggested_object_id=entry.suggested_object_id,
            unique_id=entry.unique_id,
        )

    @callback
    def async_get_or_create(
        self,
        domain: str,
        platform: str,
        unique_id: str,
        *,
        # Used for entity ID generation, if entity gets created.
        # `suggested_object_id` has priority over `object_id_base`.
        object_id_base: str | None | UndefinedType = UNDEFINED,
        suggested_object_id: str | None | UndefinedType = UNDEFINED,
        # To disable or hide an entity if it gets created, does not affect
        # existing entities
        disabled_by: RegistryEntryDisabler | None = None,
        hidden_by: RegistryEntryHider | None = None,
        # Function to generate initial entity options if it gets created
        get_initial_options: Callable[[], EntityOptionsType | None] | None = None,
        # Data that we want entry to have
        capabilities: Mapping[str, Any] | None | UndefinedType = UNDEFINED,
        config_entry: ConfigEntry | None | UndefinedType = UNDEFINED,
        config_subentry_id: str | None | UndefinedType = UNDEFINED,
        device_id: str | None | UndefinedType = UNDEFINED,
        entity_category: EntityCategory | UndefinedType | None = UNDEFINED,
        has_entity_name: bool | UndefinedType = UNDEFINED,
        original_device_class: str | None | UndefinedType = UNDEFINED,
        original_icon: str | None | UndefinedType = UNDEFINED,
        original_name: str | None | UndefinedType = UNDEFINED,
        supported_features: int | None | UndefinedType = UNDEFINED,
        translation_key: str | None | UndefinedType = UNDEFINED,
        unit_of_measurement: str | None | UndefinedType = UNDEFINED,
    ) -> RegistryEntry:
        """Get entity. Create if it doesn't exist."""
        config_entry_id: str | None | UndefinedType = UNDEFINED
        if not config_entry:
            config_entry_id = None
        elif config_entry is not UNDEFINED:
            config_entry_id = config_entry.entry_id

        supported_features = supported_features or 0

        entity_id = self.async_get_entity_id(domain, platform, unique_id)

        if entity_id:
            return self._async_update_entity(
                entity_id,
                capabilities=capabilities,
                config_entry_id=config_entry_id,
                config_subentry_id=config_subentry_id,
                device_id=device_id,
                entity_category=entity_category,
                has_entity_name=has_entity_name,
                object_id_base=object_id_base,
                original_device_class=original_device_class,
                original_icon=original_icon,
                original_name=original_name,
                suggested_object_id=suggested_object_id,
                supported_features=supported_features,
                translation_key=translation_key,
                unit_of_measurement=unit_of_measurement,
            )

        self.hass.verify_event_loop_thread("entity_registry.async_get_or_create")
        _validate_item(
            self.hass,
            domain,
            platform,
            config_entry_id=config_entry_id,
            config_subentry_id=config_subentry_id,
            device_id=device_id,
            disabled_by=disabled_by,
            entity_category=entity_category,
            hidden_by=hidden_by,
            unique_id=unique_id,
        )

        entity_registry_id: str | None = None
        created_at = utcnow()
        deleted_entity = self.deleted_entities.pop((domain, platform, unique_id), None)
        options: Mapping[str, Mapping[str, Any]] | None
        if deleted_entity is not None:
            aliases = deleted_entity.aliases
            area_id = deleted_entity.area_id
            categories = deleted_entity.categories
            created_at = deleted_entity.created_at
            device_class = deleted_entity.device_class
            if deleted_entity.disabled_by is not UNDEFINED:
                disabled_by = deleted_entity.disabled_by
                # Adjust disabled_by based on config entry state
                if config_entry and config_entry is not UNDEFINED:
                    if config_entry.disabled_by:
                        if disabled_by is None:
                            disabled_by = RegistryEntryDisabler.CONFIG_ENTRY
                    elif disabled_by == RegistryEntryDisabler.CONFIG_ENTRY:
                        disabled_by = None
                elif disabled_by == RegistryEntryDisabler.CONFIG_ENTRY:
                    disabled_by = None
            # Restore entity_id if it's available
            if self._entity_id_available(deleted_entity.entity_id):
                entity_id = deleted_entity.entity_id
            entity_registry_id = deleted_entity.id
            if deleted_entity.hidden_by is not UNDEFINED:
                hidden_by = deleted_entity.hidden_by
            icon = deleted_entity.icon
            labels = deleted_entity.labels
            name = deleted_entity.name
            if deleted_entity.options is not UNDEFINED:
                options = deleted_entity.options
            else:
                options = get_initial_options() if get_initial_options else None
        else:
            aliases = set()
            area_id = None
            categories = {}
            device_class = None
            icon = None
            labels = set()
            name = None
            options = get_initial_options() if get_initial_options else None

        def none_if_undefined[_T](value: _T | UndefinedType) -> _T | None:
            """Return None if value is UNDEFINED, otherwise return value."""
            return None if value is UNDEFINED else value

        device_id = none_if_undefined(device_id)
        has_entity_name_bool = none_if_undefined(has_entity_name) or False
        object_id_base = none_if_undefined(object_id_base)
        suggested_object_id = none_if_undefined(suggested_object_id)

        if entity_id is None:
            entity_id = self._async_generate_entity_id(
                current_entity_id=None,
                device_id=device_id,
                domain=domain,
                has_entity_name=has_entity_name_bool,
                name=name,
                object_id_base=object_id_base,
                platform=platform,
                suggested_object_id=suggested_object_id,
                unique_id=unique_id,
            )

        if (
            disabled_by is None
            and config_entry
            and config_entry is not UNDEFINED
            and config_entry.pref_disable_new_entities
        ):
            disabled_by = RegistryEntryDisabler.INTEGRATION

        entry = RegistryEntry(
            aliases=aliases,
            area_id=area_id,
            categories=categories,
            capabilities=none_if_undefined(capabilities),
            config_entry_id=none_if_undefined(config_entry_id),
            config_subentry_id=none_if_undefined(config_subentry_id),
            created_at=created_at,
            device_class=device_class,
            device_id=device_id,
            disabled_by=disabled_by,
            entity_category=none_if_undefined(entity_category),
            entity_id=entity_id,
            hidden_by=hidden_by,
            has_entity_name=has_entity_name_bool,
            icon=icon,
            id=entity_registry_id,
            labels=labels,
            name=name,
            object_id_base=object_id_base,
            options=options,
            original_device_class=none_if_undefined(original_device_class),
            original_icon=none_if_undefined(original_icon),
            original_name=none_if_undefined(original_name),
            platform=platform,
            suggested_object_id=suggested_object_id,
            supported_features=none_if_undefined(supported_features) or 0,
            translation_key=none_if_undefined(translation_key),
            unique_id=unique_id,
            unit_of_measurement=none_if_undefined(unit_of_measurement),
        )
        self.entities[entity_id] = entry
        _LOGGER.info("Registered new %s.%s entity: %s", domain, platform, entity_id)
        self.async_schedule_save()

        self.hass.bus.async_fire_internal(
            EVENT_ENTITY_REGISTRY_UPDATED,
            _EventEntityRegistryUpdatedData_CreateRemove(
                action="create", entity_id=entity_id
            ),
        )

        return entry

    @callback
    def async_remove(self, entity_id: str) -> None:
        """Remove an entity from registry."""
        self.hass.verify_event_loop_thread("entity_registry.async_remove")
        if entity_id not in self.entities:
            # Allow attempts to remove an entity which does not exist. If this is
            # not allowed, there will be races during cleanup where we iterate over
            # lists of entities to remove, but there are listeners for entity
            # registry events which delete entities at the same time.
            # For example, if we clean up entities A and B, there might be a listener
            # which deletes entity B when entity A is being removed.
            return
        entity = self.entities.pop(entity_id)
        config_entry_id = entity.config_entry_id
        key = (entity.domain, entity.platform, entity.unique_id)
        # If the entity does not belong to a config entry, mark it as orphaned
        orphaned_timestamp = None if config_entry_id else time.time()
        self.deleted_entities[key] = DeletedRegistryEntry(
            aliases=entity.aliases,
            area_id=entity.area_id,
            categories=entity.categories,
            config_entry_id=config_entry_id,
            config_subentry_id=entity.config_subentry_id,
            created_at=entity.created_at,
            device_class=entity.device_class,
            disabled_by=entity.disabled_by,
            entity_id=entity_id,
            hidden_by=entity.hidden_by,
            icon=entity.icon,
            id=entity.id,
            labels=entity.labels,
            modified_at=utcnow(),
            name=entity.name,
            options=entity.options,
            orphaned_timestamp=orphaned_timestamp,
            platform=entity.platform,
            unique_id=entity.unique_id,
        )
        self.hass.bus.async_fire_internal(
            EVENT_ENTITY_REGISTRY_UPDATED,
            _EventEntityRegistryUpdatedData_CreateRemove(
                action="remove", entity_id=entity_id
            ),
        )
        self.async_schedule_save()

    @callback
    def async_device_modified(
        self, event: Event[EventDeviceRegistryUpdatedData]
    ) -> None:
        """Handle the removal or update of a device.

        Remove entities from the registry that are associated to a device when
        the device is removed.

        Disable entities in the registry that are associated to a device when
        the device is disabled.
        """
        if event.data["action"] == "remove":
            entities = async_entries_for_device(
                self, event.data["device_id"], include_disabled_entities=True
            )
            removed_device_dict = event.data["device"]
            for entity in entities:
                config_entry_id = entity.config_entry_id
                if (
                    config_entry_id in removed_device_dict["config_entries"]
                    and entity.config_subentry_id
                    in removed_device_dict["config_entries_subentries"][config_entry_id]
                ):
                    self.async_remove(entity.entity_id)
                else:
                    if entity.entity_id not in self.entities:
                        # Entity has been removed already, skip it
                        continue
                    self.async_update_entity(entity.entity_id, device_id=None)
            return

        if event.data["action"] != "update":
            # Ignore "create" action
            return

        device_registry = dr.async_get(self.hass)
        device = device_registry.async_get(event.data["device_id"])

        # The device may be deleted already if the event handling is late, do nothing
        # in that case. Entities will be removed when we get the "remove" event.
        if not device:
            return

        # Remove entities which belong to config entries no longer associated with the
        # device
        if old_config_entries := event.data["changes"].get("config_entries"):
            entities = async_entries_for_device(
                self, event.data["device_id"], include_disabled_entities=True
            )
            for entity in entities:
                config_entry_id = entity.config_entry_id
                if (
                    entity.config_entry_id in old_config_entries
                    and entity.config_entry_id not in device.config_entries
                ):
                    self.async_remove(entity.entity_id)

        # Remove entities which belong to config subentries no longer associated with the
        # device
        if old_config_entries_subentries := event.data["changes"].get(
            "config_entries_subentries"
        ):
            entities = async_entries_for_device(
                self, event.data["device_id"], include_disabled_entities=True
            )
            for entity in entities:
                config_entry_id = entity.config_entry_id
                config_subentry_id = entity.config_subentry_id
                if (
                    config_entry_id in device.config_entries
                    and config_entry_id in old_config_entries_subentries
                    and config_subentry_id
                    in old_config_entries_subentries[config_entry_id]
                    and config_subentry_id
                    not in device.config_entries_subentries[config_entry_id]
                ):
                    self.async_remove(entity.entity_id)

        # Re-enable disabled entities if the device is no longer disabled
        if not device.disabled:
            entities = async_entries_for_device(
                self, event.data["device_id"], include_disabled_entities=True
            )
            for entity in entities:
                if entity.disabled_by is not RegistryEntryDisabler.DEVICE:
                    continue
                self.async_update_entity(entity.entity_id, disabled_by=None)
            return

        # Ignore device disabled by config entry, this is handled by
        # async_config_entry_disabled_by_changed
        if device.disabled_by is dr.DeviceEntryDisabler.CONFIG_ENTRY:
            return

        # Fetch entities which are not already disabled and disable them
        entities = async_entries_for_device(self, event.data["device_id"])
        for entity in entities:
            self.async_update_entity(
                entity.entity_id, disabled_by=RegistryEntryDisabler.DEVICE
            )

    @callback
    def _async_update_entity(
        self,
        entity_id: str,
        *,
        aliases: set[str] | UndefinedType = UNDEFINED,
        area_id: str | None | UndefinedType = UNDEFINED,
        categories: dict[str, str] | UndefinedType = UNDEFINED,
        capabilities: Mapping[str, Any] | None | UndefinedType = UNDEFINED,
        config_entry_id: str | None | UndefinedType = UNDEFINED,
        config_subentry_id: str | None | UndefinedType = UNDEFINED,
        device_class: str | None | UndefinedType = UNDEFINED,
        device_id: str | None | UndefinedType = UNDEFINED,
        disabled_by: RegistryEntryDisabler | None | UndefinedType = UNDEFINED,
        entity_category: EntityCategory | None | UndefinedType = UNDEFINED,
        hidden_by: RegistryEntryHider | None | UndefinedType = UNDEFINED,
        icon: str | None | UndefinedType = UNDEFINED,
        has_entity_name: bool | UndefinedType = UNDEFINED,
        labels: set[str] | UndefinedType = UNDEFINED,
        name: str | None | UndefinedType = UNDEFINED,
        new_entity_id: str | UndefinedType = UNDEFINED,
        new_unique_id: str | UndefinedType = UNDEFINED,
        object_id_base: str | None | UndefinedType = UNDEFINED,
        options: EntityOptionsType | UndefinedType = UNDEFINED,
        original_device_class: str | None | UndefinedType = UNDEFINED,
        original_icon: str | None | UndefinedType = UNDEFINED,
        original_name: str | None | UndefinedType = UNDEFINED,
        platform: str | None | UndefinedType = UNDEFINED,
        suggested_object_id: str | None | UndefinedType = UNDEFINED,
        supported_features: int | UndefinedType = UNDEFINED,
        translation_key: str | None | UndefinedType = UNDEFINED,
        unit_of_measurement: str | None | UndefinedType = UNDEFINED,
    ) -> RegistryEntry:
        """Private facing update properties method."""
        old = self.entities[entity_id]

        new_values: dict[str, Any] = {}  # Dict with new key/value pairs
        old_values: dict[str, Any] = {}  # Dict with old key/value pairs

        for attr_name, value in (
            ("aliases", aliases),
            ("area_id", area_id),
            ("categories", categories),
            ("capabilities", capabilities),
            ("config_entry_id", config_entry_id),
            ("config_subentry_id", config_subentry_id),
            ("device_class", device_class),
            ("device_id", device_id),
            ("disabled_by", disabled_by),
            ("entity_category", entity_category),
            ("hidden_by", hidden_by),
            ("icon", icon),
            ("has_entity_name", has_entity_name),
            ("labels", labels),
            ("name", name),
            ("object_id_base", object_id_base),
            ("options", options),
            ("original_device_class", original_device_class),
            ("original_icon", original_icon),
            ("original_name", original_name),
            ("platform", platform),
            ("suggested_object_id", suggested_object_id),
            ("supported_features", supported_features),
            ("translation_key", translation_key),
            ("unit_of_measurement", unit_of_measurement),
        ):
            if value is not UNDEFINED and value != getattr(old, attr_name):
                new_values[attr_name] = value
                old_values[attr_name] = getattr(old, attr_name)

        # Only validate if data has changed
        if new_values or new_unique_id is not UNDEFINED:
            _validate_item(
                self.hass,
                old.domain,
                old.platform,
                config_entry_id=config_entry_id,
                config_subentry_id=config_subentry_id,
                device_id=device_id,
                disabled_by=disabled_by,
                entity_category=entity_category,
                hidden_by=hidden_by,
                old_config_subentry_id=old.config_subentry_id,
                unique_id=new_unique_id,
            )

        if disabled_by is UNDEFINED and config_entry_id is not UNDEFINED:
            if config_entry_id:
                config_entry = self.hass.config_entries.async_get_entry(config_entry_id)
                if TYPE_CHECKING:
                    # We've checked the config_entry exists in _validate_item
                    assert config_entry is not None
                if config_entry.disabled_by:
                    if old.disabled_by is None:
                        new_values["disabled_by"] = RegistryEntryDisabler.CONFIG_ENTRY
                elif old.disabled_by == RegistryEntryDisabler.CONFIG_ENTRY:
                    new_values["disabled_by"] = None
            elif old.disabled_by == RegistryEntryDisabler.CONFIG_ENTRY:
                new_values["disabled_by"] = None

        if new_entity_id is not UNDEFINED and new_entity_id != old.entity_id:
            if not self._entity_id_available(new_entity_id):
                raise ValueError("Entity with this ID is already registered")

            if not valid_entity_id(new_entity_id):
                raise ValueError("Invalid entity ID")

            if split_entity_id(new_entity_id)[0] != split_entity_id(entity_id)[0]:
                raise ValueError("New entity ID should be same domain")

            self.entities.pop(entity_id)
            entity_id = new_values["entity_id"] = new_entity_id
            old_values["entity_id"] = old.entity_id

        if new_unique_id is not UNDEFINED:
            conflict_entity_id = self.async_get_entity_id(
                old.domain, old.platform, new_unique_id
            )
            if conflict_entity_id:
                raise ValueError(
                    f"Unique id '{new_unique_id}' is already in use by "
                    f"'{conflict_entity_id}'"
                )
            new_values["unique_id"] = new_unique_id
            old_values["unique_id"] = old.unique_id
            new_values["previous_unique_id"] = old.unique_id

        if not new_values:
            return old

        new_values["modified_at"] = utcnow()

        self.hass.verify_event_loop_thread("entity_registry.async_update_entity")

        new = self.entities[entity_id] = attr.evolve(old, **new_values)

        self.async_schedule_save()

        data: _EventEntityRegistryUpdatedData_Update = {
            "action": "update",
            "entity_id": entity_id,
            "changes": old_values,
        }

        if old.entity_id != entity_id:
            data["old_entity_id"] = old.entity_id

        self.hass.bus.async_fire_internal(EVENT_ENTITY_REGISTRY_UPDATED, data)

        return new

    @callback
    def async_update_entity(
        self,
        entity_id: str,
        *,
        aliases: set[str] | UndefinedType = UNDEFINED,
        area_id: str | None | UndefinedType = UNDEFINED,
        categories: dict[str, str] | UndefinedType = UNDEFINED,
        capabilities: Mapping[str, Any] | None | UndefinedType = UNDEFINED,
        config_entry_id: str | None | UndefinedType = UNDEFINED,
        config_subentry_id: str | None | UndefinedType = UNDEFINED,
        device_class: str | None | UndefinedType = UNDEFINED,
        device_id: str | None | UndefinedType = UNDEFINED,
        disabled_by: RegistryEntryDisabler | None | UndefinedType = UNDEFINED,
        entity_category: EntityCategory | None | UndefinedType = UNDEFINED,
        hidden_by: RegistryEntryHider | None | UndefinedType = UNDEFINED,
        icon: str | None | UndefinedType = UNDEFINED,
        has_entity_name: bool | UndefinedType = UNDEFINED,
        labels: set[str] | UndefinedType = UNDEFINED,
        name: str | None | UndefinedType = UNDEFINED,
        new_entity_id: str | UndefinedType = UNDEFINED,
        new_unique_id: str | UndefinedType = UNDEFINED,
        original_device_class: str | None | UndefinedType = UNDEFINED,
        original_icon: str | None | UndefinedType = UNDEFINED,
        original_name: str | None | UndefinedType = UNDEFINED,
        supported_features: int | UndefinedType = UNDEFINED,
        translation_key: str | None | UndefinedType = UNDEFINED,
        unit_of_measurement: str | None | UndefinedType = UNDEFINED,
    ) -> RegistryEntry:
        """Update properties of an entity."""
        return self._async_update_entity(
            entity_id,
            aliases=aliases,
            area_id=area_id,
            categories=categories,
            capabilities=capabilities,
            config_entry_id=config_entry_id,
            config_subentry_id=config_subentry_id,
            device_class=device_class,
            device_id=device_id,
            disabled_by=disabled_by,
            entity_category=entity_category,
            hidden_by=hidden_by,
            icon=icon,
            has_entity_name=has_entity_name,
            labels=labels,
            name=name,
            new_entity_id=new_entity_id,
            new_unique_id=new_unique_id,
            original_device_class=original_device_class,
            original_icon=original_icon,
            original_name=original_name,
            supported_features=supported_features,
            translation_key=translation_key,
            unit_of_measurement=unit_of_measurement,
        )

    @callback
    def async_update_entity_platform(
        self,
        entity_id: str,
        new_platform: str,
        *,
        new_config_entry_id: str | UndefinedType = UNDEFINED,
        new_config_subentry_id: str | UndefinedType = UNDEFINED,
        new_unique_id: str | UndefinedType = UNDEFINED,
        new_device_id: str | None | UndefinedType = UNDEFINED,
    ) -> RegistryEntry:
        """Update entity platform.

        This should only be used when an entity needs to be migrated between
        integrations.
        """
        if (
            state := self.hass.states.get(entity_id)
        ) is not None and state.state != STATE_UNKNOWN:
            raise ValueError("Only entities that haven't been loaded can be migrated")

        old = self.entities[entity_id]
        if new_config_entry_id == UNDEFINED and old.config_entry_id is not None:
            raise ValueError(
                f"new_config_entry_id required because {entity_id} is already linked "
                "to a config entry"
            )

        return self._async_update_entity(
            entity_id,
            new_unique_id=new_unique_id,
            config_entry_id=new_config_entry_id,
            config_subentry_id=new_config_subentry_id,
            device_id=new_device_id,
            platform=new_platform,
        )

    @callback
    def async_update_entity_options(
        self, entity_id: str, domain: str, options: Mapping[str, Any] | None
    ) -> RegistryEntry:
        """Update entity options for a domain.

        If the domain options are set to None, they will be removed.
        """
        old = self.entities[entity_id]
        new_options: dict[str, Mapping] = {
            key: value for key, value in old.options.items() if key != domain
        }
        if options is not None:
            new_options[domain] = options
        return self._async_update_entity(entity_id, options=new_options)

    async def async_load(self) -> None:
        """Load the entity registry."""
        _async_setup_cleanup(self.hass, self)
        _async_setup_entity_restore(self.hass, self)

        data = await self._store.async_load()
        entities = EntityRegistryItems()
        deleted_entities: dict[tuple[str, str, str], DeletedRegistryEntry] = {}

        if data is not None:
            for entity in data["entities"]:
                try:
                    domain = split_entity_id(entity["entity_id"])[0]
                    _validate_item(
                        self.hass,
                        domain,
                        entity["platform"],
                        report_non_string_unique_id=False,
                        unique_id=entity["unique_id"],
                    )
                except (TypeError, ValueError) as err:
                    report_issue = async_suggest_report_issue(
                        self.hass, integration_domain=entity["platform"]
                    )
                    _LOGGER.error(
                        (
                            "Entity registry entry '%s' from integration %s could not "
                            "be loaded: '%s', please %s"
                        ),
                        entity["entity_id"],
                        entity["platform"],
                        str(err),
                        report_issue,
                    )
                    continue

                entities[entity["entity_id"]] = RegistryEntry(
                    aliases=set(entity["aliases"]),
                    area_id=entity["area_id"],
                    categories=entity["categories"],
                    capabilities=entity["capabilities"],
                    config_entry_id=entity["config_entry_id"],
                    config_subentry_id=entity["config_subentry_id"],
                    created_at=datetime.fromisoformat(entity["created_at"]),
                    device_class=entity["device_class"],
                    device_id=entity["device_id"],
                    disabled_by=RegistryEntryDisabler(entity["disabled_by"])
                    if entity["disabled_by"]
                    else None,
                    entity_category=EntityCategory(entity["entity_category"])
                    if entity["entity_category"]
                    else None,
                    entity_id=entity["entity_id"],
                    hidden_by=RegistryEntryHider(entity["hidden_by"])
                    if entity["hidden_by"]
                    else None,
                    icon=entity["icon"],
                    id=entity["id"],
                    has_entity_name=entity["has_entity_name"],
                    labels=set(entity["labels"]),
                    modified_at=datetime.fromisoformat(entity["modified_at"]),
                    name=entity["name"],
                    object_id_base=entity.get("object_id_base"),
                    options=entity["options"],
                    original_device_class=entity["original_device_class"],
                    original_icon=entity["original_icon"],
                    original_name=entity["original_name"],
                    platform=entity["platform"],
                    suggested_object_id=entity["suggested_object_id"],
                    supported_features=entity["supported_features"],
                    translation_key=entity["translation_key"],
                    unique_id=entity["unique_id"],
                    previous_unique_id=entity["previous_unique_id"],
                    unit_of_measurement=entity["unit_of_measurement"],
                )

            def get_optional_enum[_EnumT: StrEnum](
                cls: type[_EnumT], value: str | None, undefined: bool
            ) -> _EnumT | UndefinedType | None:
                """Convert string to the passed enum, UNDEFINED or None."""
                if undefined:
                    return UNDEFINED
                if value is None:
                    return None
                try:
                    return cls(value)
                except ValueError:
                    return None

            for entity in data["deleted_entities"]:
                try:
                    domain = split_entity_id(entity["entity_id"])[0]
                    _validate_item(
                        self.hass,
                        domain,
                        entity["platform"],
                        report_non_string_unique_id=False,
                        unique_id=entity["unique_id"],
                    )
                except (TypeError, ValueError):
                    continue
                key = (
                    split_entity_id(entity["entity_id"])[0],
                    entity["platform"],
                    entity["unique_id"],
                )
                deleted_entities[key] = DeletedRegistryEntry(
                    aliases=set(entity["aliases"]),
                    area_id=entity["area_id"],
                    categories=entity["categories"],
                    config_entry_id=entity["config_entry_id"],
                    config_subentry_id=entity["config_subentry_id"],
                    created_at=datetime.fromisoformat(entity["created_at"]),
                    device_class=entity["device_class"],
                    disabled_by=get_optional_enum(
                        RegistryEntryDisabler,
                        entity["disabled_by"],
                        entity["disabled_by_undefined"],
                    ),
                    entity_id=entity["entity_id"],
                    hidden_by=get_optional_enum(
                        RegistryEntryHider,
                        entity["hidden_by"],
                        entity["hidden_by_undefined"],
                    ),
                    icon=entity["icon"],
                    id=entity["id"],
                    labels=set(entity["labels"]),
                    modified_at=datetime.fromisoformat(entity["modified_at"]),
                    name=entity["name"],
                    options=entity["options"]
                    if not entity["options_undefined"]
                    else UNDEFINED,
                    orphaned_timestamp=entity["orphaned_timestamp"],
                    platform=entity["platform"],
                    unique_id=entity["unique_id"],
                )

        self.deleted_entities = deleted_entities
        self.entities = entities
        self._entities_data = entities.data

    def _data_to_save(self) -> dict[str, Any]:
        """Return data of entity registry to store in a file."""
        # Create intermediate lists to allow this method to be called from a thread
        # other than the event loop.
        return {
            "entities": [
                entry.as_storage_fragment for entry in list(self.entities.values())
            ],
            "deleted_entities": [
                entry.as_storage_fragment
                for entry in list(self.deleted_entities.values())
            ],
        }

    @callback
    def async_clear_category_id(self, scope: str, category_id: str) -> None:
        """Clear category id from registry entries."""
        for entity_id, entry in self.entities.items():
            if (
                existing_category_id := entry.categories.get(scope)
            ) and category_id == existing_category_id:
                categories = entry.categories.copy()
                del categories[scope]
                self.async_update_entity(entity_id, categories=categories)
        for key, deleted_entity in list(self.deleted_entities.items()):
            if (
                existing_category_id := deleted_entity.categories.get(scope)
            ) and category_id == existing_category_id:
                categories = deleted_entity.categories.copy()
                del categories[scope]
                self.deleted_entities[key] = attr.evolve(
                    deleted_entity, categories=categories
                )
                self.async_schedule_save()

    @callback
    def async_clear_label_id(self, label_id: str) -> None:
        """Clear label from registry entries."""
        for entry in self.entities.get_entries_for_label(label_id):
            self.async_update_entity(entry.entity_id, labels=entry.labels - {label_id})
        for key, deleted_entity in list(self.deleted_entities.items()):
            if label_id not in deleted_entity.labels:
                continue
            self.deleted_entities[key] = attr.evolve(
                deleted_entity, labels=deleted_entity.labels - {label_id}
            )
            self.async_schedule_save()

    @callback
    def async_clear_config_entry(self, config_entry_id: str) -> None:
        """Clear config entry from registry entries."""
        now_time = time.time()
        for entity_id in [
            entry.entity_id
            for entry in self.entities.get_entries_for_config_entry_id(config_entry_id)
        ]:
            self.async_remove(entity_id)
        for key, deleted_entity in list(self.deleted_entities.items()):
            if config_entry_id != deleted_entity.config_entry_id:
                continue
            # Add a time stamp when the deleted entity became orphaned
            self.deleted_entities[key] = attr.evolve(
                deleted_entity, orphaned_timestamp=now_time, config_entry_id=None
            )
            self.async_schedule_save()

    @callback
    def async_clear_config_subentry(
        self, config_entry_id: str, config_subentry_id: str
    ) -> None:
        """Clear config subentry from registry entries."""
        now_time = time.time()
        for entity_id in [
            entry.entity_id
            for entry in self.entities.get_entries_for_config_entry_id(config_entry_id)
            if entry.config_subentry_id == config_subentry_id
        ]:
            self.async_remove(entity_id)
        for key, deleted_entity in list(self.deleted_entities.items()):
            if config_subentry_id != deleted_entity.config_subentry_id:
                continue
            # Add a time stamp when the deleted entity became orphaned
            self.deleted_entities[key] = attr.evolve(
                deleted_entity,
                orphaned_timestamp=now_time,
                config_entry_id=None,
                config_subentry_id=None,
            )
            self.async_schedule_save()

    @callback
    def async_purge_expired_orphaned_entities(self) -> None:
        """Purge expired orphaned entities from the registry.

        We need to purge these periodically to avoid the database
        growing without bound.
        """
        now_time = time.time()
        for key, deleted_entity in list(self.deleted_entities.items()):
            if (orphaned_timestamp := deleted_entity.orphaned_timestamp) is None:
                continue

            if orphaned_timestamp + ORPHANED_ENTITY_KEEP_SECONDS < now_time:
                self.deleted_entities.pop(key)
                self.async_schedule_save()

    @callback
    def async_clear_area_id(self, area_id: str) -> None:
        """Clear area id from registry entries."""
        for entry in self.entities.get_entries_for_area_id(area_id):
            self.async_update_entity(entry.entity_id, area_id=None)
        for key, deleted_entity in list(self.deleted_entities.items()):
            if deleted_entity.area_id != area_id:
                continue
            self.deleted_entities[key] = attr.evolve(deleted_entity, area_id=None)
            self.async_schedule_save()


@callback
@singleton(DATA_REGISTRY)
def async_get(hass: HomeAssistant) -> EntityRegistry:
    """Get entity registry."""
    return EntityRegistry(hass)


async def async_load(hass: HomeAssistant) -> None:
    """Load entity registry."""
    assert DATA_REGISTRY not in hass.data
    await async_get(hass).async_load()


@callback
def async_entries_for_device(
    registry: EntityRegistry, device_id: str, include_disabled_entities: bool = False
) -> list[RegistryEntry]:
    """Return entries that match a device."""
    return registry.entities.get_entries_for_device_id(
        device_id, include_disabled_entities
    )


@callback
def async_entries_for_area(
    registry: EntityRegistry, area_id: str
) -> list[RegistryEntry]:
    """Return entries that match an area."""
    return registry.entities.get_entries_for_area_id(area_id)


@callback
def async_entries_for_label(
    registry: EntityRegistry, label_id: str
) -> list[RegistryEntry]:
    """Return entries that match a label."""
    return registry.entities.get_entries_for_label(label_id)


@callback
def async_entries_for_category(
    registry: EntityRegistry, scope: str, category_id: str
) -> list[RegistryEntry]:
    """Return entries that match a category in a scope."""
    return [
        entry
        for entry in registry.entities.values()
        if (
            (existing_category_id := entry.categories.get(scope))
            and category_id == existing_category_id
        )
    ]


@callback
def async_entries_for_config_entry(
    registry: EntityRegistry, config_entry_id: str
) -> list[RegistryEntry]:
    """Return entries that match a config entry."""
    return registry.entities.get_entries_for_config_entry_id(config_entry_id)


@callback
def async_config_entry_disabled_by_changed(
    registry: EntityRegistry, config_entry: ConfigEntry
) -> None:
    """Handle a config entry being disabled or enabled.

    Disable entities in the registry that are associated with a config entry when
    the config entry is disabled, enable entities in the registry that are associated
    with a config entry when the config entry is enabled and the entities are marked
    DISABLED_CONFIG_ENTRY.
    """

    entities = async_entries_for_config_entry(registry, config_entry.entry_id)

    if not config_entry.disabled_by:
        for entity in entities:
            if entity.disabled_by is not RegistryEntryDisabler.CONFIG_ENTRY:
                continue
            registry.async_update_entity(entity.entity_id, disabled_by=None)
        return

    for entity in entities:
        if entity.disabled:
            # Entity already disabled, do not overwrite
            continue
        registry.async_update_entity(
            entity.entity_id, disabled_by=RegistryEntryDisabler.CONFIG_ENTRY
        )


@callback
def _async_setup_cleanup(hass: HomeAssistant, registry: EntityRegistry) -> None:
    """Clean up device registry when entities removed."""
    from . import category_registry as cr, event, label_registry as lr  # noqa: PLC0415

    @callback
    def _removed_from_registry_filter(
        event_data: lr.EventLabelRegistryUpdatedData
        | cr.EventCategoryRegistryUpdatedData,
    ) -> bool:
        """Filter all except for the remove action from registry events."""
        return event_data["action"] == "remove"

    @callback
    def _handle_label_registry_update(event: lr.EventLabelRegistryUpdated) -> None:
        """Update entity that have a label that has been removed."""
        registry.async_clear_label_id(event.data["label_id"])

    hass.bus.async_listen(
        event_type=lr.EVENT_LABEL_REGISTRY_UPDATED,
        event_filter=_removed_from_registry_filter,
        listener=_handle_label_registry_update,
    )

    @callback
    def _handle_category_registry_update(
        event: cr.EventCategoryRegistryUpdated,
    ) -> None:
        """Update entity that have a category that has been removed."""
        registry.async_clear_category_id(event.data["scope"], event.data["category_id"])

    hass.bus.async_listen(
        event_type=cr.EVENT_CATEGORY_REGISTRY_UPDATED,
        event_filter=_removed_from_registry_filter,
        listener=_handle_category_registry_update,
    )

    @callback
    def cleanup(_: datetime) -> None:
        """Clean up entity registry."""
        # Periodic purge of orphaned entities to avoid the registry
        # growing without bounds when there are lots of deleted entities
        registry.async_purge_expired_orphaned_entities()

    cancel = event.async_track_time_interval(
        hass, cleanup, timedelta(seconds=CLEANUP_INTERVAL)
    )

    @callback
    def _on_homeassistant_stop(event: Event) -> None:
        """Cancel cleanup."""
        cancel()

    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_STOP, _on_homeassistant_stop)


@callback
def _async_setup_entity_restore(hass: HomeAssistant, registry: EntityRegistry) -> None:
    """Set up the entity restore mechanism."""

    @callback
    def cleanup_restored_states_filter(event_data: Mapping[str, Any]) -> bool:
        """Clean up restored states filter."""
        return (event_data["action"] == "remove") or (
            event_data["action"] == "update"
            and "old_entity_id" in event_data
            and event_data["entity_id"] != event_data["old_entity_id"]
        )

    @callback
    def cleanup_restored_states(event: Event[EventEntityRegistryUpdatedData]) -> None:
        """Clean up restored states."""
        if event.data["action"] == "update":
            old_entity_id = event.data["old_entity_id"]
            old_state = hass.states.get(old_entity_id)
            if old_state is None or not old_state.attributes.get(ATTR_RESTORED):
                return
            hass.states.async_remove(old_entity_id, context=event.context)
            if entry := registry.async_get(event.data["entity_id"]):
                entry.write_unavailable_state(hass)
            return

        state = hass.states.get(event.data["entity_id"])

        if state is None or not state.attributes.get(ATTR_RESTORED):
            return

        hass.states.async_remove(event.data["entity_id"], context=event.context)

    hass.bus.async_listen(
        EVENT_ENTITY_REGISTRY_UPDATED,
        cleanup_restored_states,
        event_filter=cleanup_restored_states_filter,
    )

    if hass.is_running:
        return

    @callback
    def _write_unavailable_states(_: Event) -> None:
        """Make sure state machine contains entry for each registered entity."""
        existing = set(hass.states.async_entity_ids())

        for entry in registry.entities.values():
            if entry.entity_id in existing or entry.disabled:
                continue

            entry.write_unavailable_state(hass)

    hass.bus.async_listen(EVENT_HOMEASSISTANT_START, _write_unavailable_states)


async def async_migrate_entries(
    hass: HomeAssistant,
    config_entry_id: str,
    entry_callback: Callable[[RegistryEntry], dict[str, Any] | None],
) -> None:
    """Migrate entity registry entries which belong to a config entry.

    Can be used as a migrator of unique_ids or to update other entity registry data.
    Can also be used to remove duplicated entity registry entries.
    """
    ent_reg = async_get(hass)
    entities = ent_reg.entities
    for entry in entities.get_entries_for_config_entry_id(config_entry_id):
        if (
            entities.get_entry(entry.id)
            and (updates := entry_callback(entry)) is not None
        ):
            ent_reg.async_update_entity(entry.entity_id, **updates)


@callback
def async_validate_entity_id(registry: EntityRegistry, entity_id_or_uuid: str) -> str:
    """Validate and resolve an entity id or UUID to an entity id.

    Raises vol.Invalid if the entity or UUID is invalid, or if the UUID is not
    associated with an entity registry item.
    """
    if valid_entity_id(entity_id_or_uuid):
        return entity_id_or_uuid
    if (entry := registry.entities.get_entry(entity_id_or_uuid)) is None:
        raise vol.Invalid(f"Unknown entity registry entry {entity_id_or_uuid}")
    return entry.entity_id


@callback
def async_resolve_entity_id(
    registry: EntityRegistry, entity_id_or_uuid: str
) -> str | None:
    """Validate and resolve an entity id or UUID to an entity id.

    Returns None if the entity or UUID is invalid, or if the UUID is not
    associated with an entity registry item.
    """
    if valid_entity_id(entity_id_or_uuid):
        return entity_id_or_uuid
    if (entry := registry.entities.get_entry(entity_id_or_uuid)) is None:
        return None
    return entry.entity_id


@callback
def async_validate_entity_ids(
    registry: EntityRegistry, entity_ids_or_uuids: list[str]
) -> list[str]:
    """Validate and resolve a list of entity ids or UUIDs to a list of entity ids.

    Returns a list with UUID resolved to entity_ids.
    Raises vol.Invalid if any item is invalid, or if any a UUID is not associated with
    an entity registry item.
    """

    return [async_validate_entity_id(registry, item) for item in entity_ids_or_uuids]
</file>

<file path="entity_values.py">
"""A class to hold entity values."""

from __future__ import annotations

import fnmatch
from functools import lru_cache
import re
from typing import Any

from homeassistant.const import MAX_EXPECTED_ENTITY_IDS
from homeassistant.core import split_entity_id


class EntityValues:
    """Class to store entity id based values.

    This class is expected to only be used infrequently
    as it caches all entity ids up to MAX_EXPECTED_ENTITY_IDS.

    The cache includes `self` so it is important to
    only use this in places where usage of `EntityValues` is immortal.
    """

    def __init__(
        self,
        exact: dict[str, dict[str, str]] | None = None,
        domain: dict[str, dict[str, str]] | None = None,
        glob: dict[str, dict[str, str]] | None = None,
    ) -> None:
        """Initialize an EntityConfigDict."""
        self._exact = exact
        self._domain = domain

        if glob is None:
            compiled: dict[re.Pattern[str], Any] | None = None
        else:
            compiled = {
                re.compile(fnmatch.translate(key)): value for key, value in glob.items()
            }

        self._glob = compiled

    @lru_cache(maxsize=MAX_EXPECTED_ENTITY_IDS)
    def get(self, entity_id: str) -> dict[str, str]:
        """Get config for an entity id."""
        domain, _ = split_entity_id(entity_id)
        result: dict[str, str] = {}

        if self._domain is not None and domain in self._domain:
            result.update(self._domain[domain])

        if self._glob is not None:
            for pattern, values in self._glob.items():
                if pattern.match(entity_id):
                    result.update(values)

        if self._exact is not None and entity_id in self._exact:
            result.update(self._exact[entity_id])

        return result
</file>

<file path="entity.py">
"""An abstract class for entities."""

from __future__ import annotations

from abc import ABCMeta
import asyncio
from collections import deque
from collections.abc import Callable, Coroutine, Iterable, Mapping
import dataclasses
from enum import Enum, auto
import functools as ft
import logging
import math
from operator import attrgetter
import sys
import threading
import time
from types import FunctionType
from typing import TYPE_CHECKING, Any, Final, Literal, NotRequired, TypedDict, final

from propcache.api import cached_property
import voluptuous as vol

from homeassistant.const import (
    ATTR_ASSUMED_STATE,
    ATTR_ATTRIBUTION,
    ATTR_DEVICE_CLASS,
    ATTR_ENTITY_PICTURE,
    ATTR_FRIENDLY_NAME,
    ATTR_ICON,
    ATTR_SUPPORTED_FEATURES,
    ATTR_UNIT_OF_MEASUREMENT,
    DEVICE_DEFAULT_NAME,
    STATE_OFF,
    STATE_ON,
    STATE_UNAVAILABLE,
    STATE_UNKNOWN,
    EntityCategory,
)
from homeassistant.core import (
    CALLBACK_TYPE,
    Context,
    Event,
    HassJobType,
    HomeAssistant,
    ReleaseChannel,
    callback,
    get_hassjob_callable_job_type,
    get_release_channel,
)
from homeassistant.core_config import DATA_CUSTOMIZE
from homeassistant.exceptions import HomeAssistantError, NoEntitySpecifiedError
from homeassistant.loader import async_suggest_report_issue, bind_hass
from homeassistant.util import ensure_unique_string, slugify
from homeassistant.util.frozen_dataclass_compat import FrozenOrThawed

from . import device_registry as dr, entity_registry as er, singleton
from .device_registry import DeviceInfo, EventDeviceRegistryUpdatedData
from .event import (
    async_track_device_registry_updated_event,
    async_track_entity_registry_updated_event,
)
from .frame import report_non_thread_safe_operation
from .typing import UNDEFINED, StateType, UndefinedType

timer = time.time

if TYPE_CHECKING:
    from .entity_platform import EntityPlatform, PlatformData

_LOGGER = logging.getLogger(__name__)
SLOW_UPDATE_WARNING = 10
DATA_ENTITY_SOURCE = "entity_info"

# Used when converting float states to string: limit precision according to machine
# epsilon to make the string representation readable
FLOAT_PRECISION = abs(int(math.floor(math.log10(abs(sys.float_info.epsilon))))) - 1

# How many times per hour we allow capabilities to be updated before logging a warning
CAPABILITIES_UPDATE_LIMIT = 100

CONTEXT_RECENT_TIME_SECONDS = 5  # Time that a context is considered recent


@callback
def async_setup(hass: HomeAssistant) -> None:
    """Set up entity sources."""
    entity_sources(hass)


@callback
@bind_hass
@singleton.singleton(DATA_ENTITY_SOURCE)
def entity_sources(hass: HomeAssistant) -> dict[str, EntityInfo]:
    """Get the entity sources.

    Items are added to this dict by Entity.async_internal_added_to_hass and
    removed by Entity.async_internal_will_remove_from_hass.
    """
    return {}


def generate_entity_id(
    entity_id_format: str,
    name: str | None,
    current_ids: list[str] | None = None,
    hass: HomeAssistant | None = None,
) -> str:
    """Generate a unique entity ID based on given entity IDs or used IDs."""
    return async_generate_entity_id(entity_id_format, name, current_ids, hass)


@callback
def async_generate_entity_id(
    entity_id_format: str,
    name: str | None,
    current_ids: Iterable[str] | None = None,
    hass: HomeAssistant | None = None,
) -> str:
    """Generate a unique entity ID based on given entity IDs or used IDs."""
    name = (name or DEVICE_DEFAULT_NAME).lower()
    preferred_string = entity_id_format.format(slugify(name))

    if current_ids is not None:
        return ensure_unique_string(preferred_string, current_ids)

    if hass is None:
        raise ValueError("Missing required parameter current_ids or hass")

    test_string = preferred_string
    tries = 1
    while not hass.states.async_available(test_string):
        tries += 1
        test_string = f"{preferred_string}_{tries}"

    return test_string


def get_capability(hass: HomeAssistant, entity_id: str, capability: str) -> Any | None:
    """Get a capability attribute of an entity.

    First try the statemachine, then entity registry.
    """
    if state := hass.states.get(entity_id):
        return state.attributes.get(capability)

    entity_registry = er.async_get(hass)
    if not (entry := entity_registry.async_get(entity_id)):
        raise HomeAssistantError(f"Unknown entity {entity_id}")

    return entry.capabilities.get(capability) if entry.capabilities else None


def get_device_class(hass: HomeAssistant, entity_id: str) -> str | None:
    """Get device class of an entity.

    First try the statemachine, then entity registry.
    """
    if state := hass.states.get(entity_id):
        return state.attributes.get(ATTR_DEVICE_CLASS)

    entity_registry = er.async_get(hass)
    if not (entry := entity_registry.async_get(entity_id)):
        raise HomeAssistantError(f"Unknown entity {entity_id}")

    return entry.device_class or entry.original_device_class


def get_supported_features(hass: HomeAssistant, entity_id: str) -> int:
    """Get supported features for an entity.

    First try the statemachine, then entity registry.
    """
    if state := hass.states.get(entity_id):
        return state.attributes.get(ATTR_SUPPORTED_FEATURES, 0)  # type: ignore[no-any-return]

    entity_registry = er.async_get(hass)
    if not (entry := entity_registry.async_get(entity_id)):
        raise HomeAssistantError(f"Unknown entity {entity_id}")

    return entry.supported_features or 0


def get_unit_of_measurement(hass: HomeAssistant, entity_id: str) -> str | None:
    """Get unit of measurement of an entity.

    First try the statemachine, then entity registry.
    """
    if state := hass.states.get(entity_id):
        return state.attributes.get(ATTR_UNIT_OF_MEASUREMENT)

    entity_registry = er.async_get(hass)
    if not (entry := entity_registry.async_get(entity_id)):
        raise HomeAssistantError(f"Unknown entity {entity_id}")

    return entry.unit_of_measurement


ENTITY_CATEGORIES_SCHEMA: Final = vol.Coerce(EntityCategory)


class EntityInfo(TypedDict):
    """Entity info."""

    domain: str
    config_entry: NotRequired[str]


class StateInfo(TypedDict):
    """State info."""

    unrecorded_attributes: frozenset[str]


class EntityPlatformState(Enum):
    """The platform state of an entity."""

    # Not Added: Not yet added to a platform, states are not written to the
    # state machine.
    NOT_ADDED = auto()

    # Adding: Preparing for adding to a platform, states are not written to the
    # state machine.
    ADDING = auto()

    # Added: Added to a platform, states are written to the state machine.
    ADDED = auto()

    # Removed: Removed from a platform, states are not written to the
    # state machine.
    REMOVED = auto()


_SENTINEL = object()


class EntityDescription(metaclass=FrozenOrThawed, frozen_or_thawed=True):
    """A class that describes Home Assistant entities."""

    # This is the key identifier for this entity
    key: str

    device_class: str | None = None
    entity_category: EntityCategory | None = None
    entity_registry_enabled_default: bool = True
    entity_registry_visible_default: bool = True
    force_update: bool = False
    icon: str | None = None
    has_entity_name: bool = False
    name: str | UndefinedType | None = UNDEFINED
    translation_key: str | None = None
    translation_placeholders: Mapping[str, str] | None = None
    unit_of_measurement: str | None = None


@dataclasses.dataclass(frozen=True, slots=True)
class CalculatedState:
    """Container with state and attributes.

    Returned by Entity._async_calculate_state.
    """

    state: str
    # The union of all attributes, after overriding with entity registry settings
    attributes: dict[str, Any]


class CachedProperties(type):
    """Metaclass which invalidates cached entity properties on write to _attr_.

    A class which has CachedProperties can optionally have a list of cached
    properties, passed as cached_properties, which must be a set of strings.
    - Each item in the cached_property set must be the name of a method decorated
      with @cached_property
    - For each item in the cached_property set, a property function with the
      same name, prefixed with _attr_, will be created
    - The property _attr_-property functions allow setting, getting and deleting
      data, which will be stored in an attribute prefixed with __attr_
    - The _attr_-property setter will invalidate the @cached_property by calling
      delattr on it
    """

    def __new__(
        mcs,
        name: str,
        bases: tuple[type, ...],
        namespace: dict[Any, Any],
        cached_properties: set[str] | None = None,
        **kwargs: Any,
    ) -> Any:
        """Start creating a new CachedProperties.

        Pop cached_properties and store it in the namespace.
        """
        namespace["_CachedProperties__cached_properties"] = cached_properties or set()
        return super().__new__(mcs, name, bases, namespace, **kwargs)

    def __init__(
        cls,
        name: str,
        bases: tuple[type, ...],
        namespace: dict[Any, Any],
        **kwargs: Any,
    ) -> None:
        """Finish creating a new CachedProperties.

        Wrap _attr_ for cached properties in property objects.
        """

        def deleter(name: str) -> Callable[[Any], None]:
            """Create a deleter for an _attr_ property."""
            private_attr_name = f"__attr_{name}"

            def _deleter(o: Any) -> None:
                """Delete an _attr_ property.

                Does two things:
                - Delete the __attr_ attribute
                - Invalidate the cache of the cached property

                Raises AttributeError if the __attr_ attribute does not exist
                """
                # Invalidate the cache of the cached property
                o.__dict__.pop(name, None)
                # Delete the __attr_ attribute
                delattr(o, private_attr_name)

            return _deleter

        def setter(name: str) -> Callable[[Any, Any], None]:
            """Create a setter for an _attr_ property."""
            private_attr_name = f"__attr_{name}"

            def _setter(o: Any, val: Any) -> None:
                """Set an _attr_ property to the backing __attr attribute.

                Also invalidates the corresponding cached_property by calling
                delattr on it.
                """
                if (
                    old_val := getattr(o, private_attr_name, _SENTINEL)
                ) == val and type(old_val) is type(val):
                    return
                setattr(o, private_attr_name, val)
                # Invalidate the cache of the cached property
                o.__dict__.pop(name, None)

            return _setter

        def make_property(name: str) -> property:
            """Help create a property object."""
            return property(
                fget=attrgetter(f"__attr_{name}"), fset=setter(name), fdel=deleter(name)
            )

        def wrap_attr(cls: CachedProperties, property_name: str) -> None:
            """Wrap a cached property's corresponding _attr in a property.

            If the class being created has an _attr class attribute, move it, and its
            annotations, to the __attr attribute.
            """
            attr_name = f"_attr_{property_name}"
            private_attr_name = f"__attr_{property_name}"
            # Check if an _attr_ class attribute exits and move it to __attr_. We check
            # __dict__ here because we don't care about _attr_ class attributes in parents.
            if attr_name in cls.__dict__:
                attr = getattr(cls, attr_name)
                if isinstance(attr, (FunctionType, property)):
                    raise TypeError(f"Can't override {attr_name} in subclass")
                setattr(cls, private_attr_name, attr)
                annotations = cls.__annotations__
                if attr_name in annotations:
                    annotations[private_attr_name] = annotations.pop(attr_name)
            # Create the _attr_ property
            setattr(cls, attr_name, make_property(property_name))

        cached_properties: set[str] = namespace["_CachedProperties__cached_properties"]
        seen_props: set[str] = set()  # Keep track of properties which have been handled
        for property_name in cached_properties:
            wrap_attr(cls, property_name)
            seen_props.add(property_name)

        # Look for cached properties of parent classes where this class has
        # corresponding _attr_ class attributes and re-wrap them.
        for parent in cls.__mro__[:0:-1]:
            if "_CachedProperties__cached_properties" not in parent.__dict__:
                continue
            cached_properties = getattr(parent, "_CachedProperties__cached_properties")  # noqa: B009
            for property_name in cached_properties:
                if property_name in seen_props:
                    continue
                attr_name = f"_attr_{property_name}"
                # Check if an _attr_ class attribute exits. We check __dict__ here because
                # we don't care about _attr_ class attributes in parents.
                if (attr_name) not in cls.__dict__:
                    continue
                wrap_attr(cls, property_name)
                seen_props.add(property_name)


class ABCCachedProperties(CachedProperties, ABCMeta):
    """Add ABCMeta to CachedProperties."""


CACHED_PROPERTIES_WITH_ATTR_ = {
    "assumed_state",
    "attribution",
    "available",
    "capability_attributes",
    "device_class",
    "device_info",
    "entity_category",
    "has_entity_name",
    "entity_picture",
    "entity_registry_enabled_default",
    "entity_registry_visible_default",
    "extra_state_attributes",
    "force_update",
    "icon",
    "name",
    "should_poll",
    "state",
    "supported_features",
    "translation_key",
    "translation_placeholders",
    "unique_id",
    "unit_of_measurement",
}


class Entity(
    metaclass=ABCCachedProperties, cached_properties=CACHED_PROPERTIES_WITH_ATTR_
):
    """An abstract class for Home Assistant entities."""

    # SAFE TO OVERWRITE
    # The properties and methods here are safe to overwrite when inheriting
    # this class. These may be used to customize the behavior of the entity.
    entity_id: str = None  # type: ignore[assignment]

    # Owning hass instance. Set by EntityPlatform by calling add_to_platform_start
    # While not purely typed, it makes typehinting more useful for us
    # and removes the need for constant None checks or asserts.
    hass: HomeAssistant = None  # type: ignore[assignment]

    # Owning platform instance. Set by EntityPlatform by calling add_to_platform_start
    # While not purely typed, it makes typehinting more useful for us
    # and removes the need for constant None checks or asserts.
    platform: EntityPlatform = None  # type: ignore[assignment]
    platform_data: PlatformData = None  # type: ignore[assignment]

    # Entity description instance for this Entity
    entity_description: EntityDescription

    # Integration suggested object id, derived from entity_id, if it is set by the
    # integration before the entity is added.
    # Only handled internally, never to be used by integrations.
    internal_integration_suggested_object_id: str | None

    # If we reported if this entity was slow
    _slow_reported = False

    # If we reported deprecated supported features constants
    _deprecated_supported_features_reported = False

    # If we reported this entity is updated while disabled
    _disabled_reported = False

    # If we reported this entity is using async_update_ha_state, while
    # it should be using async_write_ha_state.
    _async_update_ha_state_reported = False

    # If we reported this entity was added without its platform set
    _no_platform_reported = False

    # If we reported the name translation placeholders do not match the name
    _name_translation_placeholders_reported = False

    # Protect for multiple updates
    _update_staged = False

    # _verified_state_writable is set to True if the entity has been verified
    # to be writable. This is used to avoid repeated checks.
    _verified_state_writable = False

    # Process updates in parallel
    parallel_updates: asyncio.Semaphore | None = None

    # Entry in the entity registry
    registry_entry: er.RegistryEntry | None = None

    # If the entity is removed from the entity registry
    _removed_from_registry: bool = False

    # The device entry for this entity
    device_entry: dr.DeviceEntry | None = None

    # Hold list for functions to call on remove.
    _on_remove: list[CALLBACK_TYPE] | None = None

    _unsub_device_updates: CALLBACK_TYPE | None = None

    # Context
    _context: Context | None = None
    _context_set: float | None = None

    # If entity is added to an entity platform
    _platform_state = EntityPlatformState.NOT_ADDED

    # Attributes to exclude from recording, only set by base components, e.g. light
    _entity_component_unrecorded_attributes: frozenset[str] = frozenset()
    # Additional integration specific attributes to exclude from recording, set by
    # platforms, e.g. a derived class in hue.light
    _unrecorded_attributes: frozenset[str] = frozenset()
    # Union of _entity_component_unrecorded_attributes and _unrecorded_attributes,
    # set automatically by __init_subclass__
    __combined_unrecorded_attributes: frozenset[str] = (
        _entity_component_unrecorded_attributes | _unrecorded_attributes
    )
    # Job type cache
    _job_types: dict[str, HassJobType] | None = None

    # StateInfo. Set by EntityPlatform by calling async_internal_added_to_hass
    # While not purely typed, it makes typehinting more useful for us
    # and removes the need for constant None checks or asserts.
    _state_info: StateInfo = None  # type: ignore[assignment]

    __capabilities_updated_at: deque[float]
    __capabilities_updated_at_reported: bool = False
    __remove_future: asyncio.Future[None] | None = None

    # Entity Properties
    _attr_assumed_state: bool = False
    _attr_attribution: str | None = None
    _attr_available: bool = True
    _attr_capability_attributes: dict[str, Any] | None = None
    _attr_device_class: str | None
    _attr_device_info: DeviceInfo | None = None
    _attr_entity_category: EntityCategory | None
    _attr_has_entity_name: bool
    _attr_entity_picture: str | None = None
    _attr_entity_registry_enabled_default: bool
    _attr_entity_registry_visible_default: bool
    _attr_extra_state_attributes: dict[str, Any]
    _attr_force_update: bool
    _attr_icon: str | None
    _attr_name: str | None
    _attr_should_poll: bool = True
    _attr_state: StateType = STATE_UNKNOWN
    _attr_supported_features: int | None = None
    _attr_translation_key: str | None
    _attr_translation_placeholders: Mapping[str, str]
    _attr_unique_id: str | None = None
    _attr_unit_of_measurement: str | None

    def __init_subclass__(cls, **kwargs: Any) -> None:
        """Initialize an Entity subclass."""
        super().__init_subclass__(**kwargs)
        cls.__combined_unrecorded_attributes = (
            cls._entity_component_unrecorded_attributes | cls._unrecorded_attributes
        )

    def get_hassjob_type(self, function_name: str) -> HassJobType:
        """Get the job type function for the given name.

        This is used for entity service calls to avoid
        figuring out the job type each time.
        """
        if not self._job_types:
            self._job_types = {}
        if function_name not in self._job_types:
            self._job_types[function_name] = get_hassjob_callable_job_type(
                getattr(self, function_name)
            )
        return self._job_types[function_name]

    @cached_property
    def should_poll(self) -> bool:
        """Return True if entity has to be polled for state.

        False if entity pushes its state to HA.
        """
        return self._attr_should_poll

    @cached_property
    def unique_id(self) -> str | None:
        """Return a unique ID."""
        return self._attr_unique_id

    @cached_property
    def use_device_name(self) -> bool:
        """Return if this entity does not have its own name.

        Should be True if the entity represents the single main feature of a device.
        """
        if hasattr(self, "_attr_name"):
            return not self._attr_name
        if (
            name_translation_key := self._name_translation_key
        ) and name_translation_key in self.platform_data.platform_translations:
            return False
        if hasattr(self, "entity_description"):
            return not self.entity_description.name
        return not self.name

    @cached_property
    def has_entity_name(self) -> bool:
        """Return if the name of the entity is describing only the entity itself."""
        if hasattr(self, "_attr_has_entity_name"):
            return self._attr_has_entity_name
        if hasattr(self, "entity_description"):
            return self.entity_description.has_entity_name
        return False

    def _device_class_name_helper(
        self,
        component_translations: dict[str, str],
    ) -> str | None:
        """Return a translated name of the entity based on its device class."""
        if not self.has_entity_name:
            return None
        device_class_key = self.device_class or "_"
        platform_domain = self.platform_data.domain
        name_translation_key = (
            f"component.{platform_domain}.entity_component.{device_class_key}.name"
        )
        return component_translations.get(name_translation_key)

    @cached_property
    def _object_id_device_class_name(self) -> str | None:
        """Return a translated name of the entity based on its device class."""
        return self._device_class_name_helper(
            self.platform_data.object_id_component_translations
        )

    @cached_property
    def _device_class_name(self) -> str | None:
        """Return a translated name of the entity based on its device class."""
        return self._device_class_name_helper(self.platform_data.component_translations)

    def _default_to_device_class_name(self) -> bool:
        """Return True if an unnamed entity should be named by its device class."""
        return False

    @cached_property
    def _name_translation_key(self) -> str | None:
        """Return translation key for entity name."""
        if self.translation_key is None:
            return None
        platform_data = self.platform_data
        return (
            f"component.{platform_data.platform_name}.entity.{platform_data.domain}"
            f".{self.translation_key}.name"
        )

    @cached_property
    def _unit_of_measurement_translation_key(self) -> str | None:
        """Return translation key for unit of measurement."""
        if self.translation_key is None:
            return None
        if self.platform_data is None:
            raise ValueError(
                f"Entity {type(self)} cannot have a translation key for "
                "unit of measurement before being added to the entity platform"
            )
        platform_data = self.platform_data
        return (
            f"component.{platform_data.platform_name}.entity.{platform_data.domain}"
            f".{self.translation_key}.unit_of_measurement"
        )

    def _substitute_name_placeholders(self, name: str) -> str:
        """Substitute placeholders in entity name."""
        try:
            return name.format(**self.translation_placeholders)
        except KeyError as err:
            if not self._name_translation_placeholders_reported:
                if get_release_channel() is not ReleaseChannel.STABLE:
                    raise HomeAssistantError(f"Missing placeholder {err}") from err
                report_issue = self._suggest_report_issue()
                _LOGGER.warning(
                    (
                        "Entity %s (%s) has translation placeholders '%s' which do not "
                        "match the name '%s', please %s"
                    ),
                    self.entity_id,
                    type(self),
                    self.translation_placeholders,
                    name,
                    report_issue,
                )
                self._name_translation_placeholders_reported = True
            return name

    def _name_internal(
        self,
        device_class_name: str | None,
        platform_translations: dict[str, str],
    ) -> str | UndefinedType | None:
        """Return the name of the entity."""
        if hasattr(self, "_attr_name"):
            return self._attr_name
        if (
            self.has_entity_name
            and (name_translation_key := self._name_translation_key)
            and (name := platform_translations.get(name_translation_key))
        ):
            return self._substitute_name_placeholders(name)
        if hasattr(self, "entity_description"):
            description_name = self.entity_description.name
            if description_name is UNDEFINED and self._default_to_device_class_name():
                return device_class_name
            return description_name

        # The entity has no name set by _attr_name, translation_key or entity_description
        # Check if the entity should be named by its device class
        if self._default_to_device_class_name():
            return device_class_name
        return UNDEFINED

    @property
    def suggested_object_id(self) -> str | None:
        """Return suggested object id."""
        if (
            # Check our class has overridden the name property from Entity
            # We need to use type.__getattribute__ to retrieve the underlying
            # property or cached_property object instead of the property's
            # value.
            type.__getattribute__(self.__class__, "name")
            is type.__getattribute__(Entity, "name")
            # The check for self.platform_data guards against integrations not using an
            # EntityComponent and can be removed in HA Core 2026.8
            and self.platform_data
        ):
            name = self._name_internal(
                self._object_id_device_class_name,
                self.platform_data.object_id_platform_translations,
            )
        else:
            name = self.name

        return None if name is UNDEFINED else name

    @cached_property
    def name(self) -> str | UndefinedType | None:
        """Return the name of the entity."""
        # The check for self.platform_data guards against integrations not using an
        # EntityComponent and can be removed in HA Core 2026.8
        if not self.platform_data:
            return self._name_internal(None, {})
        return self._name_internal(
            self._device_class_name,
            self.platform_data.platform_translations,
        )

    @cached_property
    def state(self) -> StateType:
        """Return the state of the entity."""
        return self._attr_state

    @cached_property
    def capability_attributes(self) -> dict[str, Any] | None:
        """Return the capability attributes.

        Attributes that explain the capabilities of an entity.

        Implemented by component base class. Convention for attribute names
        is lowercase snake_case.
        """
        return self._attr_capability_attributes

    def get_initial_entity_options(self) -> er.EntityOptionsType | None:
        """Return initial entity options.

        These will be stored in the entity registry the first time the entity is seen,
        and then never updated.

        Implemented by component base class, should not be extended by integrations.

        Note: Not a property to avoid calculating unless needed.
        """
        return None

    @cached_property
    def state_attributes(self) -> dict[str, Any] | None:
        """Return the state attributes.

        Implemented by component base class, should not be extended by integrations.
        Convention for attribute names is lowercase snake_case.
        """
        return None

    @cached_property
    def extra_state_attributes(self) -> Mapping[str, Any] | None:
        """Return entity specific state attributes.

        Implemented by platform classes. Convention for attribute names
        is lowercase snake_case.
        """
        if hasattr(self, "_attr_extra_state_attributes"):
            return self._attr_extra_state_attributes
        return None

    @cached_property
    def device_info(self) -> DeviceInfo | None:
        """Return device specific attributes.

        Implemented by platform classes.
        """
        return self._attr_device_info

    @cached_property
    def device_class(self) -> str | None:
        """Return the class of this device, from component DEVICE_CLASSES."""
        if hasattr(self, "_attr_device_class"):
            return self._attr_device_class
        if hasattr(self, "entity_description"):
            return self.entity_description.device_class
        return None

    @cached_property
    def unit_of_measurement(self) -> str | None:
        """Return the unit of measurement of this entity, if any."""
        if hasattr(self, "_attr_unit_of_measurement"):
            return self._attr_unit_of_measurement
        if hasattr(self, "entity_description"):
            return self.entity_description.unit_of_measurement
        return None

    @cached_property
    def icon(self) -> str | None:
        """Return the icon to use in the frontend, if any."""
        if hasattr(self, "_attr_icon"):
            return self._attr_icon
        if hasattr(self, "entity_description"):
            return self.entity_description.icon
        return None

    @cached_property
    def entity_picture(self) -> str | None:
        """Return the entity picture to use in the frontend, if any."""
        return self._attr_entity_picture

    @cached_property
    def available(self) -> bool:
        """Return True if entity is available."""
        return self._attr_available

    @cached_property
    def assumed_state(self) -> bool:
        """Return True if unable to access real state of the entity."""
        return self._attr_assumed_state

    @cached_property
    def force_update(self) -> bool:
        """Return True if state updates should be forced.

        If True, a state change will be triggered anytime the state property is
        updated, not just when the value changes.
        """
        if hasattr(self, "_attr_force_update"):
            return self._attr_force_update
        if hasattr(self, "entity_description"):
            return self.entity_description.force_update
        return False

    @cached_property
    def supported_features(self) -> int | None:
        """Flag supported features."""
        return self._attr_supported_features

    @cached_property
    def entity_registry_enabled_default(self) -> bool:
        """Return if the entity should be enabled when first added.

        This only applies when fist added to the entity registry.
        """
        if hasattr(self, "_attr_entity_registry_enabled_default"):
            return self._attr_entity_registry_enabled_default
        if hasattr(self, "entity_description"):
            return self.entity_description.entity_registry_enabled_default
        return True

    @cached_property
    def entity_registry_visible_default(self) -> bool:
        """Return if the entity should be visible when first added.

        This only applies when fist added to the entity registry.
        """
        if hasattr(self, "_attr_entity_registry_visible_default"):
            return self._attr_entity_registry_visible_default
        if hasattr(self, "entity_description"):
            return self.entity_description.entity_registry_visible_default
        return True

    @cached_property
    def attribution(self) -> str | None:
        """Return the attribution."""
        return self._attr_attribution

    @cached_property
    def entity_category(self) -> EntityCategory | None:
        """Return the category of the entity, if any."""
        if hasattr(self, "_attr_entity_category"):
            return self._attr_entity_category
        if hasattr(self, "entity_description"):
            return self.entity_description.entity_category
        return None

    @cached_property
    def translation_key(self) -> str | None:
        """Return the translation key to translate the entity's states."""
        if hasattr(self, "_attr_translation_key"):
            return self._attr_translation_key
        if hasattr(self, "entity_description"):
            return self.entity_description.translation_key
        return None

    @final
    @cached_property
    def translation_placeholders(self) -> Mapping[str, str]:
        """Return the translation placeholders for translated entity's name."""
        if hasattr(self, "_attr_translation_placeholders"):
            return self._attr_translation_placeholders
        if hasattr(self, "entity_description"):
            return self.entity_description.translation_placeholders or {}
        return {}

    # DO NOT OVERWRITE
    # These properties and methods are either managed by Home Assistant or they
    # are used to perform a very specific function. Overwriting these may
    # produce undesirable effects in the entity's operation.

    @property
    def enabled(self) -> bool:
        """Return if the entity is enabled in the entity registry.

        If an entity is not part of the registry, it cannot be disabled
        and will therefore always be enabled.
        """
        return self.registry_entry is None or not self.registry_entry.disabled

    @callback
    def async_set_context(self, context: Context) -> None:
        """Set the context the entity currently operates under."""
        self._context = context
        self._context_set = time.time()

    async def async_update_ha_state(self, force_refresh: bool = False) -> None:
        """Update Home Assistant with current state of entity.

        If force_refresh == True will update entity before setting state.

        This method must be run in the event loop.
        """
        if self.hass is None:
            raise RuntimeError(f"Attribute hass is None for {self}")

        if self.entity_id is None:
            raise NoEntitySpecifiedError(
                f"No entity id specified for entity {self.name}"
            )

        # update entity data
        if force_refresh:
            try:
                await self.async_device_update()
            except Exception:
                _LOGGER.exception("Update for %s fails", self.entity_id)
                return
        elif not self._async_update_ha_state_reported:
            report_issue = self._suggest_report_issue()
            _LOGGER.warning(
                (
                    "Entity %s (%s) is using self.async_update_ha_state(), without"
                    " enabling force_refresh. Instead it should use"
                    " self.async_write_ha_state(), please %s"
                ),
                self.entity_id,
                type(self),
                report_issue,
            )
            self._async_update_ha_state_reported = True

        self._async_write_ha_state()

    @callback
    def _async_verify_state_writable(self) -> None:
        """Verify the entity is in a writable state."""
        if self.hass is None:
            raise RuntimeError(f"Attribute hass is None for {self}")

        # The check for self.platform guards against integrations not using an
        # EntityComponent and can be removed in HA Core 2026.8
        if self.platform is None and not self._no_platform_reported:  # type: ignore[unreachable]
            report_issue = self._suggest_report_issue()  # type: ignore[unreachable]
            _LOGGER.warning(
                (
                    "Entity %s (%s) does not have a platform, this may be caused by "
                    "adding it manually instead of with an EntityComponent helper"
                    ", please %s"
                ),
                self.entity_id,
                type(self),
                report_issue,
            )
            self._no_platform_reported = True

        if self.entity_id is None:
            raise NoEntitySpecifiedError(
                f"No entity id specified for entity {self.name}"
            )

        self._verified_state_writable = True

    @callback
    def _async_write_ha_state_from_call_soon_threadsafe(self) -> None:
        """Write the state to the state machine from the event loop thread."""
        if not self.hass or not self._verified_state_writable:
            self._async_verify_state_writable()
        self._async_write_ha_state()

    @callback
    def async_write_ha_state(self) -> None:
        """Write the state to the state machine."""
        if not self.hass or not self._verified_state_writable:
            self._async_verify_state_writable()
        if self.hass.loop_thread_id != threading.get_ident():
            report_non_thread_safe_operation("async_write_ha_state")
        self._async_write_ha_state()

    def _stringify_state(self, available: bool) -> str:
        """Convert state to string."""
        if not available:
            return STATE_UNAVAILABLE
        if (state := self.state) is None:
            return STATE_UNKNOWN
        if type(state) is str:
            # fast path for strings
            return state
        if isinstance(state, float):
            # If the entity's state is a float, limit precision according to machine
            # epsilon to make the string representation readable
            return f"{state:.{FLOAT_PRECISION}}"
        return str(state)

    def _friendly_name_internal(self) -> str | None:
        """Return the friendly name.

        If has_entity_name is False, this returns self.name
        If has_entity_name is True, this returns device.name + self.name
        """
        name = self.name
        if name is UNDEFINED:
            name = None

        if not self.has_entity_name or not (device_entry := self.device_entry):
            return name

        device_name = device_entry.name_by_user or device_entry.name
        if name is None and self.use_device_name:
            return device_name
        return f"{device_name} {name}" if device_name else name

    @callback
    def _async_calculate_state(self) -> CalculatedState:
        """Calculate state string and attribute mapping."""
        state, attr, _, _, _ = self.__async_calculate_state()
        return CalculatedState(state, attr)

    def __async_calculate_state(
        self,
    ) -> tuple[str, dict[str, Any], Mapping[str, Any] | None, str | None, int | None]:
        """Calculate state string and attribute mapping.

        Returns a tuple:
        state - the stringified state
        attr - the attribute dictionary
        capability_attr - a mapping with capability attributes
        original_device_class - the device class which may be overridden
        supported_features - the supported features

        This method is called when writing the state to avoid the overhead of creating
        a dataclass object.
        """
        entry = self.registry_entry

        capability_attr = self.capability_attributes
        attr = capability_attr.copy() if capability_attr else {}

        available = self.available  # only call self.available once per update cycle
        state = self._stringify_state(available)
        if available:
            if state_attributes := self.state_attributes:
                attr |= state_attributes
            if extra_state_attributes := self.extra_state_attributes:
                attr |= extra_state_attributes

        if (unit_of_measurement := self.unit_of_measurement) is not None:
            attr[ATTR_UNIT_OF_MEASUREMENT] = unit_of_measurement

        if assumed_state := self.assumed_state:
            attr[ATTR_ASSUMED_STATE] = assumed_state

        if (attribution := self.attribution) is not None:
            attr[ATTR_ATTRIBUTION] = attribution

        original_device_class = self.device_class
        if (
            device_class := (entry and entry.device_class) or original_device_class
        ) is not None:
            attr[ATTR_DEVICE_CLASS] = str(device_class)

        if (entity_picture := self.entity_picture) is not None:
            attr[ATTR_ENTITY_PICTURE] = entity_picture

        if (icon := (entry and entry.icon) or self.icon) is not None:
            attr[ATTR_ICON] = icon

        if (
            name := (entry and entry.name) or self._friendly_name_internal()
        ) is not None:
            attr[ATTR_FRIENDLY_NAME] = name

        if (supported_features := self.supported_features) is not None:
            attr[ATTR_SUPPORTED_FEATURES] = supported_features

        return (state, attr, capability_attr, original_device_class, supported_features)

    @callback
    def _async_write_ha_state(self) -> None:
        """Write the state to the state machine."""
        # The check for self.platform guards against integrations not using an
        # EntityComponent (which has not been allowed since HA Core 2024.1)
        if not self.platform:
            if self._platform_state is EntityPlatformState.REMOVED:
                # Don't write state if the entity is not added to the platform.
                return
        elif self._platform_state is not EntityPlatformState.ADDED:
            if (entry := self.registry_entry) and entry.disabled_by:
                if not self._disabled_reported:
                    self._disabled_reported = True
                    _LOGGER.warning(
                        (
                            "Entity %s is incorrectly being triggered for updates while it"
                            " is disabled. This is a bug in the %s integration"
                        ),
                        self.entity_id,
                        self.platform.platform_name,
                    )
            return

        state_calculate_start = timer()
        state, attr, capabilities, original_device_class, supported_features = (
            self.__async_calculate_state()
        )
        time_now = timer()

        if entry := self.registry_entry:
            # Make sure capabilities in the entity registry are up to date. Capabilities
            # include capability attributes, device class and supported features
            supported_features = supported_features or 0
            if (
                capabilities != entry.capabilities
                or original_device_class != entry.original_device_class
                or supported_features != entry.supported_features
            ):
                if not self.__capabilities_updated_at_reported:
                    # _Entity__capabilities_updated_at is because of name mangling
                    if not (
                        capabilities_updated_at := getattr(
                            self, "_Entity__capabilities_updated_at", None
                        )
                    ):
                        self.__capabilities_updated_at = deque(
                            maxlen=CAPABILITIES_UPDATE_LIMIT + 1
                        )
                        capabilities_updated_at = self.__capabilities_updated_at
                    capabilities_updated_at.append(time_now)
                    while time_now - capabilities_updated_at[0] > 3600:
                        capabilities_updated_at.popleft()
                    if len(capabilities_updated_at) > CAPABILITIES_UPDATE_LIMIT:
                        self.__capabilities_updated_at_reported = True
                        report_issue = self._suggest_report_issue()
                        _LOGGER.warning(
                            (
                                "Entity %s (%s) is updating its capabilities too often,"
                                " please %s"
                            ),
                            self.entity_id,
                            type(self),
                            report_issue,
                        )
                entity_registry = er.async_get(self.hass)
                self.registry_entry = entity_registry.async_update_entity(
                    self.entity_id,
                    capabilities=capabilities,
                    original_device_class=original_device_class,
                    supported_features=supported_features,
                )

        if time_now - state_calculate_start > 0.4 and not self._slow_reported:
            self._slow_reported = True
            report_issue = self._suggest_report_issue()
            _LOGGER.warning(
                "Updating state for %s (%s) took %.3f seconds. Please %s",
                self.entity_id,
                type(self),
                time_now - state_calculate_start,
                report_issue,
            )

        try:
            # Most of the time this will already be
            # set and since try is near zero cost
            # on py3.11+ its faster to assume it is
            # set and catch the exception if it is not.
            custom = self.hass.data[DATA_CUSTOMIZE].get(self.entity_id)
        except KeyError:
            pass
        else:
            # Overwrite properties that have been set in the config file.
            if custom:
                attr |= custom

        if (
            self._context_set is not None
            and time_now - self._context_set > CONTEXT_RECENT_TIME_SECONDS
        ):
            self._context = None
            self._context_set = None

        # Intentionally called with positional args for performance reasons
        self.hass.states.async_set_internal(
            self.entity_id,
            state,
            attr,
            self.force_update,
            self._context,
            self._state_info,
            time_now,
        )

    def schedule_update_ha_state(self, force_refresh: bool = False) -> None:
        """Schedule an update ha state change task.

        Scheduling the update avoids executor deadlocks.

        Entity state and attributes are read when the update ha state change
        task is executed.
        If state is changed more than once before the ha state change task has
        been executed, the intermediate state transitions will be missed.
        """
        if force_refresh:
            self.hass.create_task(
                self.async_update_ha_state(force_refresh),
                f"Entity {self.entity_id} schedule update ha state",
            )
        else:
            self.hass.loop.call_soon_threadsafe(
                self._async_write_ha_state_from_call_soon_threadsafe
            )

    @callback
    def async_schedule_update_ha_state(self, force_refresh: bool = False) -> None:
        """Schedule an update ha state change task.

        This method must be run in the event loop.
        Scheduling the update avoids executor deadlocks.

        Entity state and attributes are read when the update ha state change
        task is executed.
        If state is changed more than once before the ha state change task has
        been executed, the intermediate state transitions will be missed.
        """
        if force_refresh:
            self.hass.async_create_task(
                self.async_update_ha_state(force_refresh),
                f"Entity schedule update ha state {self.entity_id}",
                eager_start=True,
            )
        else:
            self.async_write_ha_state()

    @callback
    def _async_slow_update_warning(self) -> None:
        """Log a warning if update is taking too long."""
        _LOGGER.warning(
            "Update of %s is taking over %s seconds",
            self.entity_id,
            SLOW_UPDATE_WARNING,
        )

    async def async_device_update(self, warning: bool = True) -> None:
        """Process 'update' or 'async_update' from entity.

        This method is a coroutine.
        """
        if self._update_staged:
            return

        hass = self.hass
        assert hass is not None

        self._update_staged = True

        # Process update sequential
        if self.parallel_updates:
            await self.parallel_updates.acquire()

        if warning:
            update_warn = hass.loop.call_at(
                hass.loop.time() + SLOW_UPDATE_WARNING, self._async_slow_update_warning
            )

        try:
            if hasattr(self, "async_update"):
                await self.async_update()
            elif hasattr(self, "update"):
                await hass.async_add_executor_job(self.update)
            else:
                return
        finally:
            self._update_staged = False
            if warning:
                update_warn.cancel()
            if self.parallel_updates:
                self.parallel_updates.release()

    @callback
    def async_on_remove(self, func: CALLBACK_TYPE) -> None:
        """Add a function to call when entity is removed or not added."""
        if self._on_remove is None:
            self._on_remove = []
        self._on_remove.append(func)

    async def async_removed_from_registry(self) -> None:
        """Run when entity has been removed from entity registry.

        To be extended by integrations.
        """

    @callback
    def add_to_platform_start(
        self,
        hass: HomeAssistant,
        platform: EntityPlatform,
        parallel_updates: asyncio.Semaphore | None,
    ) -> None:
        """Start adding an entity to a platform."""
        if self._platform_state is not EntityPlatformState.NOT_ADDED:
            raise HomeAssistantError(
                f"Entity '{self.entity_id}' cannot be added a second time to an entity"
                " platform"
            )

        self.hass = hass
        self.platform = platform
        self.platform_data = platform.platform_data
        self.parallel_updates = parallel_updates
        self._platform_state = EntityPlatformState.ADDING

    def _call_on_remove_callbacks(self) -> None:
        """Call callbacks registered by async_on_remove."""
        if self._on_remove is None:
            return
        while self._on_remove:
            self._on_remove.pop()()

    @callback
    def add_to_platform_abort(self) -> None:
        """Abort adding an entity to a platform."""

        self._platform_state = EntityPlatformState.REMOVED
        self._call_on_remove_callbacks()

        self.hass = None  # type: ignore[assignment]
        self.platform = None  # type: ignore[assignment]
        self.parallel_updates = None

    async def add_to_platform_finish(self) -> None:
        """Finish adding an entity to a platform."""
        await self.async_internal_added_to_hass()
        await self.async_added_to_hass()
        self._platform_state = EntityPlatformState.ADDED
        self.async_write_ha_state()

    @final
    async def async_remove(self, *, force_remove: bool = False) -> None:
        """Remove entity from Home Assistant.

        If the entity has a non disabled entry in the entity registry,
        the entity's state will be set to unavailable, in the same way
        as when the entity registry is loaded.

        If the entity doesn't have a non disabled entry in the entity registry,
        or if force_remove=True, its state will be removed.
        """
        if self.__remove_future is not None:
            await self.__remove_future
            return

        self.__remove_future = self.hass.loop.create_future()
        try:
            await self.__async_remove_impl(force_remove)
        except BaseException as ex:
            self.__remove_future.set_exception(ex)
            raise
        finally:
            self.__remove_future.set_result(None)

    @final
    async def __async_remove_impl(self, force_remove: bool) -> None:
        """Remove entity from Home Assistant."""

        self._platform_state = EntityPlatformState.REMOVED

        self._call_on_remove_callbacks()

        await self.async_internal_will_remove_from_hass()
        await self.async_will_remove_from_hass()

        # Check if entry still exists in entity registry (e.g. unloading config entry)
        if (
            not force_remove
            and self.registry_entry
            and not self.registry_entry.disabled
            # Check if entity is still in the entity registry
            # by checking self._removed_from_registry
            #
            # Because self.registry_entry is unset in a task,
            # its possible that the entity has been removed but
            # the task has not yet been executed.
            #
            # self._removed_from_registry is set to True in a
            # callback which does not have the same issue.
            #
            and not self._removed_from_registry
        ):
            # Set the entity's state will to unavailable + ATTR_RESTORED: True
            self.registry_entry.write_unavailable_state(self.hass)
        else:
            self.hass.states.async_remove(self.entity_id, context=self._context)

    async def async_added_to_hass(self) -> None:
        """Run when entity about to be added to hass.

        To be extended by integrations.
        """

    async def async_will_remove_from_hass(self) -> None:
        """Run when entity will be removed from hass.

        To be extended by integrations.
        """

    @callback
    def async_registry_entry_updated(self) -> None:
        """Run when the entity registry entry has been updated.

        To be extended by integrations.
        """

    async def async_internal_added_to_hass(self) -> None:
        """Run when entity about to be added to hass.

        Not to be extended by integrations.
        """
        entity_info: EntityInfo = {
            "domain": self.platform.platform_name,
        }
        if self.platform.config_entry:
            entity_info["config_entry"] = self.platform.config_entry.entry_id

        entity_sources(self.hass)[self.entity_id] = entity_info

        self._state_info = {
            "unrecorded_attributes": self.__combined_unrecorded_attributes
        }

        if self.registry_entry is not None:
            # This is an assert as it should never happen, but helps in tests
            assert not self.registry_entry.disabled_by, (
                f"Entity '{self.entity_id}' is being added while it's disabled"
            )

            self.async_on_remove(
                async_track_entity_registry_updated_event(
                    self.hass,
                    self.entity_id,
                    self._async_registry_updated,
                    job_type=HassJobType.Callback,
                )
            )
            self._async_subscribe_device_updates()

    async def async_internal_will_remove_from_hass(self) -> None:
        """Run when entity will be removed from hass.

        Not to be extended by integrations.
        """
        # The check for self.platform guards against integrations not using an
        # EntityComponent and can be removed in HA Core 2026.8
        if self.platform:
            del entity_sources(self.hass)[self.entity_id]

    @callback
    def _async_registry_updated(
        self, event: Event[er.EventEntityRegistryUpdatedData]
    ) -> None:
        """Handle entity registry update."""
        action = event.data["action"]
        is_remove = action == "remove"
        self._removed_from_registry = is_remove
        if action == "update" or is_remove:
            self.hass.async_create_task_internal(
                self._async_process_registry_update_or_remove(event), eager_start=True
            )

    async def _async_process_registry_update_or_remove(
        self, event: Event[er.EventEntityRegistryUpdatedData]
    ) -> None:
        """Handle entity registry update or remove."""
        data = event.data
        if data["action"] == "remove":
            await self.async_removed_from_registry()
            self.registry_entry = None
            await self.async_remove()

        if data["action"] != "update":
            return

        if "device_id" in data["changes"]:
            self._async_subscribe_device_updates()

        ent_reg = er.async_get(self.hass)
        old = self.registry_entry
        registry_entry = ent_reg.async_get(data["entity_id"])
        assert registry_entry is not None
        self.registry_entry = registry_entry

        if device_id := registry_entry.device_id:
            self.device_entry = dr.async_get(self.hass).async_get(device_id)

        if registry_entry.disabled:
            await self.async_remove()
            return

        assert old is not None
        if registry_entry.entity_id == old.entity_id:
            self.async_registry_entry_updated()
            self.async_write_ha_state()
            return

        await self.async_remove(force_remove=True)

        self.entity_id = registry_entry.entity_id

        # Clear the remove future to handle entity added again after entity id change
        self.__remove_future = None
        self._platform_state = EntityPlatformState.NOT_ADDED
        await self.platform.async_add_entities(
            [self], config_subentry_id=registry_entry.config_subentry_id
        )

    @callback
    def _async_unsubscribe_device_updates(self) -> None:
        """Unsubscribe from device registry updates."""
        if not self._unsub_device_updates:
            return
        self._unsub_device_updates()
        self._unsub_device_updates = None

    @callback
    def _async_device_registry_updated(
        self, event: Event[EventDeviceRegistryUpdatedData]
    ) -> None:
        """Handle device registry update."""
        data = event.data

        if data["action"] != "update":
            return

        if "name" not in data["changes"] and "name_by_user" not in data["changes"]:
            return

        self.device_entry = dr.async_get(self.hass).async_get(data["device_id"])
        self.async_write_ha_state()

    @callback
    def _async_subscribe_device_updates(self) -> None:
        """Subscribe to device registry updates."""
        assert self.registry_entry

        self._async_unsubscribe_device_updates()

        if (device_id := self.registry_entry.device_id) is None:
            return

        if not self.has_entity_name:
            return

        self._unsub_device_updates = async_track_device_registry_updated_event(
            self.hass,
            device_id,
            self._async_device_registry_updated,
            job_type=HassJobType.Callback,
        )
        if (
            not self._on_remove
            or self._async_unsubscribe_device_updates not in self._on_remove
        ):
            self.async_on_remove(self._async_unsubscribe_device_updates)

    def __repr__(self) -> str:
        """Return the representation.

        If the entity is not added to a platform it's not safe to call _stringify_state.
        """
        if self._platform_state is not EntityPlatformState.ADDED:
            return f"<entity unknown.unknown={STATE_UNKNOWN}>"
        return f"<entity {self.entity_id}={self._stringify_state(self.available)}>"

    async def async_request_call[_T](self, coro: Coroutine[Any, Any, _T]) -> _T:
        """Process request batched."""
        if self.parallel_updates:
            await self.parallel_updates.acquire()

        try:
            return await coro
        finally:
            if self.parallel_updates:
                self.parallel_updates.release()

    def _suggest_report_issue(self) -> str:
        """Suggest to report an issue."""
        # The check for self.platform_data guards against integrations not using an
        # EntityComponent and can be removed in HA Core 2026.8
        platform_name = self.platform_data.platform_name if self.platform_data else None
        return async_suggest_report_issue(
            self.hass, integration_domain=platform_name, module=type(self).__module__
        )


class ToggleEntityDescription(EntityDescription, frozen_or_thawed=True):
    """A class that describes toggle entities."""


TOGGLE_ENTITY_CACHED_PROPERTIES_WITH_ATTR_ = {"is_on"}


class ToggleEntity(
    Entity, cached_properties=TOGGLE_ENTITY_CACHED_PROPERTIES_WITH_ATTR_
):
    """An abstract class for entities that can be turned on and off."""

    entity_description: ToggleEntityDescription
    _attr_is_on: bool | None = None
    _attr_state: None = None

    @property
    @final
    def state(self) -> Literal["on", "off"] | None:
        """Return the state."""
        if (is_on := self.is_on) is None:
            return None
        return STATE_ON if is_on else STATE_OFF

    @cached_property
    def is_on(self) -> bool | None:
        """Return True if entity is on."""
        return self._attr_is_on

    def turn_on(self, **kwargs: Any) -> None:
        """Turn the entity on."""
        raise NotImplementedError

    async def async_turn_on(self, **kwargs: Any) -> None:
        """Turn the entity on."""
        await self.hass.async_add_executor_job(ft.partial(self.turn_on, **kwargs))

    def turn_off(self, **kwargs: Any) -> None:
        """Turn the entity off."""
        raise NotImplementedError

    async def async_turn_off(self, **kwargs: Any) -> None:
        """Turn the entity off."""
        await self.hass.async_add_executor_job(ft.partial(self.turn_off, **kwargs))

    @final
    def toggle(self, **kwargs: Any) -> None:
        """Toggle the entity.

        This method will never be called by Home Assistant and should not be implemented
        by integrations.
        """

    async def async_toggle(self, **kwargs: Any) -> None:
        """Toggle the entity.

        This method should typically not be implemented by integrations, it's enough to
        implement async_turn_on + async_turn_off or turn_on + turn_off.
        """
        if self.is_on:
            await self.async_turn_off(**kwargs)
        else:
            await self.async_turn_on(**kwargs)
</file>

<file path="entityfilter.py">
"""Helper class to implement include/exclude of entities and domains."""

from __future__ import annotations

from collections.abc import Callable
import fnmatch
from functools import lru_cache, partial
import operator
import re

import voluptuous as vol

from homeassistant.const import (
    CONF_DOMAINS,
    CONF_ENTITIES,
    CONF_EXCLUDE,
    CONF_INCLUDE,
    MAX_EXPECTED_ENTITY_IDS,
)
from homeassistant.core import split_entity_id

from . import config_validation as cv

CONF_INCLUDE_DOMAINS = "include_domains"
CONF_INCLUDE_ENTITY_GLOBS = "include_entity_globs"
CONF_INCLUDE_ENTITIES = "include_entities"
CONF_EXCLUDE_DOMAINS = "exclude_domains"
CONF_EXCLUDE_ENTITY_GLOBS = "exclude_entity_globs"
CONF_EXCLUDE_ENTITIES = "exclude_entities"

CONF_ENTITY_GLOBS = "entity_globs"


class EntityFilter:
    """A entity filter."""

    def __init__(self, config: dict[str, list[str]]) -> None:
        """Init the filter."""
        self.empty_filter: bool = sum(len(val) for val in config.values()) == 0
        self.config = config
        self._include_e = set(config[CONF_INCLUDE_ENTITIES])
        self._exclude_e = set(config[CONF_EXCLUDE_ENTITIES])
        self._include_d = set(config[CONF_INCLUDE_DOMAINS])
        self._exclude_d = set(config[CONF_EXCLUDE_DOMAINS])
        self._include_eg = _convert_globs_to_pattern(config[CONF_INCLUDE_ENTITY_GLOBS])
        self._exclude_eg = _convert_globs_to_pattern(config[CONF_EXCLUDE_ENTITY_GLOBS])
        self._filter = _generate_filter_from_sets_and_pattern_lists(
            self._include_d,
            self._include_e,
            self._exclude_d,
            self._exclude_e,
            self._include_eg,
            self._exclude_eg,
        )

    def explicitly_included(self, entity_id: str) -> bool:
        """Check if an entity is explicitly included."""
        return entity_id in self._include_e or (
            bool(self._include_eg and self._include_eg.match(entity_id))
        )

    def explicitly_excluded(self, entity_id: str) -> bool:
        """Check if an entity is explicitly excluded."""
        return entity_id in self._exclude_e or (
            bool(self._exclude_eg and self._exclude_eg.match(entity_id))
        )

    def get_filter(self) -> Callable[[str], bool]:
        """Return the filter function."""
        return self._filter

    def __call__(self, entity_id: str) -> bool:
        """Run the filter."""
        return self._filter(entity_id)


def convert_filter(config: dict[str, list[str]]) -> EntityFilter:
    """Convert the filter schema into a filter."""
    return EntityFilter(config)


BASE_FILTER_SCHEMA = vol.Schema(
    {
        vol.Optional(CONF_EXCLUDE_DOMAINS, default=[]): vol.All(
            cv.ensure_list, [cv.string]
        ),
        vol.Optional(CONF_EXCLUDE_ENTITY_GLOBS, default=[]): vol.All(
            cv.ensure_list, [cv.string]
        ),
        vol.Optional(CONF_EXCLUDE_ENTITIES, default=[]): cv.entity_ids,
        vol.Optional(CONF_INCLUDE_DOMAINS, default=[]): vol.All(
            cv.ensure_list, [cv.string]
        ),
        vol.Optional(CONF_INCLUDE_ENTITY_GLOBS, default=[]): vol.All(
            cv.ensure_list, [cv.string]
        ),
        vol.Optional(CONF_INCLUDE_ENTITIES, default=[]): cv.entity_ids,
    }
)

FILTER_SCHEMA = vol.All(BASE_FILTER_SCHEMA, convert_filter)


def convert_include_exclude_filter(
    config: dict[str, dict[str, list[str]]],
) -> EntityFilter:
    """Convert the include exclude filter schema into a filter."""
    include = config[CONF_INCLUDE]
    exclude = config[CONF_EXCLUDE]
    return convert_filter(
        {
            CONF_INCLUDE_DOMAINS: include[CONF_DOMAINS],
            CONF_INCLUDE_ENTITY_GLOBS: include[CONF_ENTITY_GLOBS],
            CONF_INCLUDE_ENTITIES: include[CONF_ENTITIES],
            CONF_EXCLUDE_DOMAINS: exclude[CONF_DOMAINS],
            CONF_EXCLUDE_ENTITY_GLOBS: exclude[CONF_ENTITY_GLOBS],
            CONF_EXCLUDE_ENTITIES: exclude[CONF_ENTITIES],
        }
    )


INCLUDE_EXCLUDE_FILTER_SCHEMA_INNER = vol.Schema(
    {
        vol.Optional(CONF_DOMAINS, default=[]): vol.All(cv.ensure_list, [cv.string]),
        vol.Optional(CONF_ENTITY_GLOBS, default=[]): vol.All(
            cv.ensure_list, [cv.string]
        ),
        vol.Optional(CONF_ENTITIES, default=[]): cv.entity_ids,
    }
)

INCLUDE_EXCLUDE_BASE_FILTER_SCHEMA = vol.Schema(
    {
        vol.Optional(
            CONF_INCLUDE, default=INCLUDE_EXCLUDE_FILTER_SCHEMA_INNER({})
        ): INCLUDE_EXCLUDE_FILTER_SCHEMA_INNER,
        vol.Optional(
            CONF_EXCLUDE, default=INCLUDE_EXCLUDE_FILTER_SCHEMA_INNER({})
        ): INCLUDE_EXCLUDE_FILTER_SCHEMA_INNER,
    }
)

INCLUDE_EXCLUDE_FILTER_SCHEMA = vol.All(
    INCLUDE_EXCLUDE_BASE_FILTER_SCHEMA, convert_include_exclude_filter
)


def _convert_globs_to_pattern(globs: list[str] | None) -> re.Pattern[str] | None:
    """Convert a list of globs to a re pattern list."""
    if globs is None:
        return None

    translated_patterns: list[str] = [
        pattern for glob in set(globs) if (pattern := fnmatch.translate(glob))
    ]

    if not translated_patterns:
        return None

    inner = "|".join(translated_patterns)
    combined = f"(?:{inner})"
    return re.compile(combined)


def generate_filter(
    include_domains: list[str],
    include_entities: list[str],
    exclude_domains: list[str],
    exclude_entities: list[str],
    include_entity_globs: list[str] | None = None,
    exclude_entity_globs: list[str] | None = None,
) -> Callable[[str], bool]:
    """Return a function that will filter entities based on the args."""
    return _generate_filter_from_sets_and_pattern_lists(
        set(include_domains),
        set(include_entities),
        set(exclude_domains),
        set(exclude_entities),
        _convert_globs_to_pattern(include_entity_globs),
        _convert_globs_to_pattern(exclude_entity_globs),
    )


def _generate_filter_from_sets_and_pattern_lists(
    include_d: set[str],
    include_e: set[str],
    exclude_d: set[str],
    exclude_e: set[str],
    include_eg: re.Pattern[str] | None,
    exclude_eg: re.Pattern[str] | None,
) -> Callable[[str], bool]:
    """Generate a filter from pre-comuted sets and pattern lists."""
    have_exclude = bool(exclude_e or exclude_d or exclude_eg)
    have_include = bool(include_e or include_d or include_eg)

    # Case 1 - No filter
    # - All entities included
    if not have_include and not have_exclude:
        return bool

    # Case 2 - Only includes
    # - Entity listed in entities include: include
    # - Otherwise, entity matches domain include: include
    # - Otherwise, entity matches glob include: include
    # - Otherwise: exclude
    if have_include and not have_exclude:

        @lru_cache(maxsize=MAX_EXPECTED_ENTITY_IDS)
        def entity_included(entity_id: str) -> bool:
            """Return true if entity matches inclusion filters."""
            return (
                entity_id in include_e
                or split_entity_id(entity_id)[0] in include_d
                or (bool(include_eg and include_eg.match(entity_id)))
            )

        # Return filter function for case 2
        return entity_included

    # Case 3 - Only excludes
    # - Entity listed in exclude: exclude
    # - Otherwise, entity matches domain exclude: exclude
    # - Otherwise, entity matches glob exclude: exclude
    # - Otherwise: include
    if not have_include and have_exclude:

        @lru_cache(maxsize=MAX_EXPECTED_ENTITY_IDS)
        def entity_not_excluded(entity_id: str) -> bool:
            """Return true if entity matches exclusion filters."""
            return not (
                entity_id in exclude_e
                or split_entity_id(entity_id)[0] in exclude_d
                or (exclude_eg and exclude_eg.match(entity_id))
            )

        return entity_not_excluded

    # Case 4 - Domain and/or glob includes (may also have excludes)
    # - Entity listed in entities include: include
    # - Otherwise, entity listed in entities exclude: exclude
    # - Otherwise, entity matches glob include: include
    # - Otherwise, entity matches glob exclude: exclude
    # - Otherwise, entity matches domain include: include
    # - Otherwise: exclude
    if include_d or include_eg:

        @lru_cache(maxsize=MAX_EXPECTED_ENTITY_IDS)
        def entity_filter_4a(entity_id: str) -> bool:
            """Return filter function for case 4a."""
            return entity_id in include_e or (
                entity_id not in exclude_e
                and (
                    bool(include_eg and include_eg.match(entity_id))
                    or (
                        split_entity_id(entity_id)[0] in include_d
                        and not (exclude_eg and exclude_eg.match(entity_id))
                    )
                )
            )

        return entity_filter_4a

    # Case 5 - Domain and/or glob excludes (no domain and/or glob includes)
    # - Entity listed in entities include: include
    # - Otherwise, entity listed in exclude: exclude
    # - Otherwise, entity matches glob exclude: exclude
    # - Otherwise, entity matches domain exclude: exclude
    # - Otherwise: include
    if exclude_d or exclude_eg:

        @lru_cache(maxsize=MAX_EXPECTED_ENTITY_IDS)
        def entity_filter_4b(entity_id: str) -> bool:
            """Return filter function for case 4b."""
            domain = split_entity_id(entity_id)[0]
            if domain in exclude_d or bool(exclude_eg and exclude_eg.match(entity_id)):
                return entity_id in include_e
            return entity_id not in exclude_e

        return entity_filter_4b

    # Case 6 - No Domain and/or glob includes or excludes
    # - Entity listed in entities include: include
    # - Otherwise: exclude
    return partial(operator.contains, include_e)
</file>

<file path="event.py">
"""Helpers for listening to events."""

from __future__ import annotations

import asyncio
from collections import defaultdict
from collections.abc import Callable, Coroutine, Iterable, Mapping, Sequence
import copy
from dataclasses import dataclass
from datetime import datetime, timedelta
from functools import partial, wraps
import logging
from random import randint
import time
from typing import TYPE_CHECKING, Any, Concatenate, Generic, TypeVar

from homeassistant.const import (
    EVENT_CORE_CONFIG_UPDATE,
    EVENT_STATE_CHANGED,
    EVENT_STATE_REPORTED,
    MATCH_ALL,
    SUN_EVENT_SUNRISE,
    SUN_EVENT_SUNSET,
)
from homeassistant.core import (
    CALLBACK_TYPE,
    Event,
    # Explicit reexport of 'EventStateChangedData' for backwards compatibility
    EventStateChangedData as EventStateChangedData,  # noqa: PLC0414
    EventStateEventData,
    EventStateReportedData,
    HassJob,
    HassJobType,
    HomeAssistant,
    State,
    callback,
    split_entity_id,
)
from homeassistant.exceptions import HomeAssistantError, TemplateError
from homeassistant.loader import bind_hass
from homeassistant.util import dt as dt_util
from homeassistant.util.async_ import run_callback_threadsafe
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey

from . import frame
from .device_registry import (
    EVENT_DEVICE_REGISTRY_UPDATED,
    EventDeviceRegistryUpdatedData,
)
from .entity_registry import (
    EVENT_ENTITY_REGISTRY_UPDATED,
    EventEntityRegistryUpdatedData,
)
from .ratelimit import KeyedRateLimit
from .sun import get_astral_event_next
from .template import Template, result_as_boolean
from .template.render_info import RenderInfo
from .typing import TemplateVarsType

_TRACK_STATE_CHANGE_DATA: HassKey[_KeyedEventData[EventStateChangedData]] = HassKey(
    "track_state_change_data"
)
_TRACK_STATE_REPORT_DATA: HassKey[_KeyedEventData[EventStateReportedData]] = HassKey(
    "track_state_report_data"
)
_TRACK_STATE_ADDED_DOMAIN_DATA: HassKey[_KeyedEventData[EventStateChangedData]] = (
    HassKey("track_state_added_domain_data")
)
_TRACK_STATE_REMOVED_DOMAIN_DATA: HassKey[_KeyedEventData[EventStateChangedData]] = (
    HassKey("track_state_removed_domain_data")
)
_TRACK_ENTITY_REGISTRY_UPDATED_DATA: HassKey[
    _KeyedEventData[EventEntityRegistryUpdatedData]
] = HassKey("track_entity_registry_updated_data")
_TRACK_DEVICE_REGISTRY_UPDATED_DATA: HassKey[
    _KeyedEventData[EventDeviceRegistryUpdatedData]
] = HassKey("track_device_registry_updated_data")

_ALL_LISTENER = "all"
_DOMAINS_LISTENER = "domains"
_ENTITIES_LISTENER = "entities"

_LOGGER = logging.getLogger(__name__)

# Used to spread async_track_utc_time_change listeners and DataUpdateCoordinator
# refresh cycles between RANDOM_MICROSECOND_MIN..RANDOM_MICROSECOND_MAX.
# The values have been determined experimentally in production testing, background
# in PR https://github.com/home-assistant/core/pull/82233
RANDOM_MICROSECOND_MIN = 50000
RANDOM_MICROSECOND_MAX = 500000

_TypedDictT = TypeVar("_TypedDictT", bound=Mapping[str, Any])


@dataclass(slots=True, frozen=True)
class _KeyedEventTracker(Generic[_TypedDictT]):
    """Class to track events by key."""

    key: HassKey[_KeyedEventData[_TypedDictT]]
    event_type: EventType[_TypedDictT] | str
    dispatcher_callable: Callable[
        [
            HomeAssistant,
            dict[str, list[HassJob[[Event[_TypedDictT]], Any]]],
            Event[_TypedDictT],
        ],
        None,
    ]
    filter_callable: Callable[
        [
            HomeAssistant,
            dict[str, list[HassJob[[Event[_TypedDictT]], Any]]],
            _TypedDictT,
        ],
        bool,
    ]


@dataclass(slots=True, frozen=True)
class _KeyedEventData(Generic[_TypedDictT]):
    """Class to track data for events by key."""

    listener: CALLBACK_TYPE
    callbacks: defaultdict[str, list[HassJob[[Event[_TypedDictT]], Any]]]


@dataclass(slots=True)
class TrackStates:
    """Class for keeping track of states being tracked.

    all_states: All states on the system are being tracked
    entities: Lowercased entities to track
    domains: Lowercased domains to track
    """

    all_states: bool
    entities: set[str]
    domains: set[str]


@dataclass(slots=True)
class TrackTemplate:
    """Class for keeping track of a template with variables.

    The template is template to calculate.
    The variables are variables to pass to the template.
    The rate_limit is a rate limit on how often the template is re-rendered.
    """

    template: Template
    variables: TemplateVarsType
    rate_limit: float | None = None


@dataclass(slots=True)
class TrackTemplateResult:
    """Class for result of template tracking.

    template
        The template that has changed.
    last_result
        The output from the template on the last successful run, or None
        if no previous successful run.
    result
        Result from the template run. This will be a string or an
        TemplateError if the template resulted in an error.
    """

    template: Template
    last_result: Any
    result: Any


def threaded_listener_factory[**_P](
    async_factory: Callable[Concatenate[HomeAssistant, _P], Any],
) -> Callable[Concatenate[HomeAssistant, _P], CALLBACK_TYPE]:
    """Convert an async event helper to a threaded one."""

    @wraps(async_factory)
    def factory(
        hass: HomeAssistant, *args: _P.args, **kwargs: _P.kwargs
    ) -> CALLBACK_TYPE:
        """Call async event helper safely."""
        if not isinstance(hass, HomeAssistant):
            raise TypeError("First parameter needs to be a hass instance")

        async_remove = run_callback_threadsafe(
            hass.loop, partial(async_factory, hass, *args, **kwargs)
        ).result()

        def remove() -> None:
            """Threadsafe removal."""
            run_callback_threadsafe(hass.loop, async_remove).result()

        return remove

    return factory


@callback
@bind_hass
def async_track_state_change(
    hass: HomeAssistant,
    entity_ids: str | Iterable[str],
    action: Callable[
        [str, State | None, State | None], Coroutine[Any, Any, None] | None
    ],
    from_state: str | Iterable[str] | None = None,
    to_state: str | Iterable[str] | None = None,
) -> CALLBACK_TYPE:
    """Track specific state changes.

    entity_ids, from_state and to_state can be string or list.
    Use list to match multiple.

    Returns a function that can be called to remove the listener.

    If entity_ids are not MATCH_ALL along with from_state and to_state
    being None, async_track_state_change_event should be used instead
    as it is slightly faster.

    This function is deprecated and will be removed in Home Assistant 2025.5.

    Must be run within the event loop.
    """
    frame.report_usage(
        "calls `async_track_state_change` instead of `async_track_state_change_event`"
        " which is deprecated and will be removed in Home Assistant 2025.5",
        core_behavior=frame.ReportBehavior.LOG,
    )

    if from_state is not None:
        match_from_state = process_state_match(from_state)
    if to_state is not None:
        match_to_state = process_state_match(to_state)

    # Ensure it is a lowercase list with entity ids we want to match on
    if entity_ids == MATCH_ALL:
        pass
    elif isinstance(entity_ids, str):
        entity_ids = (entity_ids.lower(),)
    else:
        entity_ids = tuple(entity_id.lower() for entity_id in entity_ids)

    job = HassJob(action, f"track state change {entity_ids} {from_state} {to_state}")

    @callback
    def state_change_filter(event_data: EventStateChangedData) -> bool:
        """Handle specific state changes."""
        if from_state is not None:
            old_state_str: str | None = None
            if (old_state := event_data["old_state"]) is not None:
                old_state_str = old_state.state

            if not match_from_state(old_state_str):
                return False

        if to_state is not None:
            new_state_str: str | None = None
            if (new_state := event_data["new_state"]) is not None:
                new_state_str = new_state.state

            if not match_to_state(new_state_str):
                return False

        return True

    @callback
    def state_change_dispatcher(event: Event[EventStateChangedData]) -> None:
        """Handle specific state changes."""
        hass.async_run_hass_job(
            job,
            event.data["entity_id"],
            event.data["old_state"],
            event.data["new_state"],
        )

    @callback
    def state_change_listener(event: Event[EventStateChangedData]) -> None:
        """Handle specific state changes."""
        if not state_change_filter(event.data):
            return

        state_change_dispatcher(event)

    if entity_ids != MATCH_ALL:
        # If we have a list of entity ids we use
        # async_track_state_change_event to route
        # by entity_id to avoid iterating though state change
        # events and creating a jobs where the most
        # common outcome is to return right away because
        # the entity_id does not match since usually
        # only one or two listeners want that specific
        # entity_id.
        return async_track_state_change_event(hass, entity_ids, state_change_listener)

    return hass.bus.async_listen(
        EVENT_STATE_CHANGED,
        state_change_dispatcher,
        event_filter=state_change_filter,
    )


track_state_change = threaded_listener_factory(async_track_state_change)


@bind_hass
def async_track_state_change_event(
    hass: HomeAssistant,
    entity_ids: str | Iterable[str],
    action: Callable[[Event[EventStateChangedData]], Any],
    job_type: HassJobType | None = None,
) -> CALLBACK_TYPE:
    """Track specific state change events indexed by entity_id.

    Unlike async_track_state_change, async_track_state_change_event
    passes the full event to the callback.

    The action will not be called immediately, but will be scheduled to run
    in the next event loop iteration, even if the action is decorated with
    @callback.

    In order to avoid having to iterate a long list
    of EVENT_STATE_CHANGED and fire and create a job
    for each one, we keep a dict of entity ids that
    care about the state change events so we can
    do a fast dict lookup to route events.
    The passed in entity_ids will be automatically lower cased.

    EVENT_STATE_CHANGED is fired on each occasion the state is updated
    and changed, opposite of EVENT_STATE_REPORTED.
    """
    if not (entity_ids := _async_string_to_lower_list(entity_ids)):
        return _remove_empty_listener
    return _async_track_state_change_event(hass, entity_ids, action, job_type)


@callback
def _async_dispatch_entity_id_event_soon[_StateEventDataT: EventStateEventData](
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[_StateEventDataT]], Any]]],
    event: Event[_StateEventDataT],
) -> None:
    """Dispatch to listeners soon to ensure one event loop runs before dispatch."""
    hass.loop.call_soon(_async_dispatch_entity_id_event, hass, callbacks, event)


@callback
def _async_dispatch_entity_id_event[_StateEventDataT: EventStateEventData](
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[_StateEventDataT]], Any]]],
    event: Event[_StateEventDataT],
) -> None:
    """Dispatch to listeners."""
    if not (callbacks_list := callbacks.get(event.data["entity_id"])):
        return
    for job in callbacks_list.copy():
        try:
            hass.async_run_hass_job(job, event)
        except Exception:
            _LOGGER.exception(
                "Error while dispatching event for %s to %s",
                event.data["entity_id"],
                job,
            )


@callback
def _async_state_filter[_StateEventDataT: EventStateEventData](
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[_StateEventDataT]], Any]]],
    event_data: _StateEventDataT,
) -> bool:
    """Filter state changes by entity_id."""
    return event_data["entity_id"] in callbacks


_KEYED_TRACK_STATE_CHANGE = _KeyedEventTracker(
    key=_TRACK_STATE_CHANGE_DATA,
    event_type=EVENT_STATE_CHANGED,
    dispatcher_callable=_async_dispatch_entity_id_event_soon,
    filter_callable=_async_state_filter,
)


@bind_hass
def _async_track_state_change_event(
    hass: HomeAssistant,
    entity_ids: str | Iterable[str],
    action: Callable[[Event[EventStateChangedData]], Any],
    job_type: HassJobType | None,
) -> CALLBACK_TYPE:
    """Faster version of async_track_state_change_event.

    The passed in entity_ids will not be automatically lower cased.
    """
    return _async_track_event(
        _KEYED_TRACK_STATE_CHANGE, hass, entity_ids, action, job_type
    )


_KEYED_TRACK_STATE_REPORT = _KeyedEventTracker(
    key=_TRACK_STATE_REPORT_DATA,
    event_type=EVENT_STATE_REPORTED,
    dispatcher_callable=_async_dispatch_entity_id_event_soon,
    filter_callable=_async_state_filter,
)


def async_track_state_report_event(
    hass: HomeAssistant,
    entity_ids: str | Iterable[str],
    action: Callable[[Event[EventStateReportedData]], Any],
    job_type: HassJobType | None = None,
) -> CALLBACK_TYPE:
    """Track EVENT_STATE_REPORTED by entity_ids.

    EVENT_STATE_REPORTED is fired on each occasion the state is updated
    but not changed, opposite of EVENT_STATE_CHANGED.
    """
    return _async_track_event(
        _KEYED_TRACK_STATE_REPORT, hass, entity_ids, action, job_type
    )


@callback
def _remove_empty_listener() -> None:
    """Remove a listener that does nothing."""


@callback
def _remove_listener(
    hass: HomeAssistant,
    tracker: _KeyedEventTracker[_TypedDictT],
    keys: Iterable[str],
    job: HassJob[[Event[_TypedDictT]], Any],
    callbacks: dict[str, list[HassJob[[Event[_TypedDictT]], Any]]],
) -> None:
    """Remove listener."""
    for key in keys:
        callbacks[key].remove(job)
        if not callbacks[key]:
            del callbacks[key]

    if not callbacks:
        hass.data.pop(tracker.key).listener()


# tracker, not hass is intentionally the first argument here since its
# constant and may be used in a partial in the future
def _async_track_event(
    tracker: _KeyedEventTracker[_TypedDictT],
    hass: HomeAssistant,
    keys: str | Iterable[str],
    action: Callable[[Event[_TypedDictT]], None],
    job_type: HassJobType | None,
) -> CALLBACK_TYPE:
    """Track an event by a specific key.

    This function is intended for internal use only.
    """
    if not keys:
        return _remove_empty_listener

    hass_data = hass.data
    tracker_key = tracker.key
    if tracker_key in hass_data:
        event_data = hass_data[tracker_key]
        callbacks = event_data.callbacks
    else:
        callbacks = defaultdict(list)
        listener = hass.bus.async_listen(
            tracker.event_type,
            partial(tracker.dispatcher_callable, hass, callbacks),
            event_filter=partial(tracker.filter_callable, hass, callbacks),
        )
        event_data = _KeyedEventData(listener, callbacks)
        hass_data[tracker_key] = event_data

    job = HassJob(action, f"track {tracker.event_type} event {keys}", job_type=job_type)

    if isinstance(keys, str):
        # Almost all calls to this function use a single key
        # so we optimize for that case. We don't use setdefault
        # here because this function gets called ~20000 times
        # during startup, and we want to avoid the overhead of
        # creating empty lists and throwing them away.
        callbacks[keys].append(job)
        keys = (keys,)
    else:
        for key in keys:
            callbacks[key].append(job)

    return partial(_remove_listener, hass, tracker, keys, job, callbacks)


@callback
def _async_dispatch_old_entity_id_or_entity_id_event(
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[EventEntityRegistryUpdatedData]], Any]]],
    event: Event[EventEntityRegistryUpdatedData],
) -> None:
    """Dispatch to listeners."""
    if not (
        callbacks_list := callbacks.get(  # type: ignore[call-overload]  # mypy bug?
            event.data.get("old_entity_id", event.data["entity_id"])
        )
    ):
        return
    for job in callbacks_list.copy():
        try:
            hass.async_run_hass_job(job, event)
        except Exception:
            _LOGGER.exception(
                "Error while dispatching event for %s to %s",
                event.data.get("old_entity_id", event.data["entity_id"]),
                job,
            )


@callback
def _async_entity_registry_updated_filter(
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[EventEntityRegistryUpdatedData]], Any]]],
    event_data: EventEntityRegistryUpdatedData,
) -> bool:
    """Filter entity registry updates by entity_id."""
    return event_data.get("old_entity_id", event_data["entity_id"]) in callbacks


_KEYED_TRACK_ENTITY_REGISTRY_UPDATED = _KeyedEventTracker(
    key=_TRACK_ENTITY_REGISTRY_UPDATED_DATA,
    event_type=EVENT_ENTITY_REGISTRY_UPDATED,
    dispatcher_callable=_async_dispatch_old_entity_id_or_entity_id_event,
    filter_callable=_async_entity_registry_updated_filter,
)


@bind_hass
@callback
def async_track_entity_registry_updated_event(
    hass: HomeAssistant,
    entity_ids: str | Iterable[str],
    action: Callable[[Event[EventEntityRegistryUpdatedData]], Any],
    job_type: HassJobType | None = None,
) -> CALLBACK_TYPE:
    """Track specific entity registry updated events indexed by entity_id.

    Entities must be lower case.

    Similar to async_track_state_change_event.
    """
    return _async_track_event(
        _KEYED_TRACK_ENTITY_REGISTRY_UPDATED, hass, entity_ids, action, job_type
    )


@callback
def async_has_entity_registry_updated_listeners(hass: HomeAssistant) -> bool:
    """Check if async_track_entity_registry_updated_event has been called yet."""
    return _KEYED_TRACK_ENTITY_REGISTRY_UPDATED.key in hass.data


@callback
def _async_device_registry_updated_filter(
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[EventDeviceRegistryUpdatedData]], Any]]],
    event_data: EventDeviceRegistryUpdatedData,
) -> bool:
    """Filter device registry updates by device_id."""
    return event_data["device_id"] in callbacks


@callback
def _async_dispatch_device_id_event(
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[EventDeviceRegistryUpdatedData]], Any]]],
    event: Event[EventDeviceRegistryUpdatedData],
) -> None:
    """Dispatch to listeners."""
    if not (callbacks_list := callbacks.get(event.data["device_id"])):
        return
    for job in callbacks_list.copy():
        try:
            hass.async_run_hass_job(job, event)
        except Exception:
            _LOGGER.exception(
                "Error while dispatching event for %s to %s",
                event.data["device_id"],
                job,
            )


_KEYED_TRACK_DEVICE_REGISTRY_UPDATED = _KeyedEventTracker(
    key=_TRACK_DEVICE_REGISTRY_UPDATED_DATA,
    event_type=EVENT_DEVICE_REGISTRY_UPDATED,
    dispatcher_callable=_async_dispatch_device_id_event,
    filter_callable=_async_device_registry_updated_filter,
)


@callback
def async_track_device_registry_updated_event(
    hass: HomeAssistant,
    device_ids: str | Iterable[str],
    action: Callable[[Event[EventDeviceRegistryUpdatedData]], Any],
    job_type: HassJobType | None = None,
) -> CALLBACK_TYPE:
    """Track specific device registry updated events indexed by device_id.

    Similar to async_track_entity_registry_updated_event.
    """
    return _async_track_event(
        _KEYED_TRACK_DEVICE_REGISTRY_UPDATED, hass, device_ids, action, job_type
    )


@callback
def _async_dispatch_domain_event(
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[EventStateChangedData]], Any]]],
    event: Event[EventStateChangedData],
) -> None:
    """Dispatch domain event listeners."""
    domain = split_entity_id(event.data["entity_id"])[0]
    for job in callbacks.get(domain, []) + callbacks.get(MATCH_ALL, []):
        try:
            hass.async_run_hass_job(job, event)
        except Exception:
            _LOGGER.exception(
                "Error while processing event %s for domain %s", event, domain
            )


@callback
def _async_domain_added_filter(
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[EventStateChangedData]], Any]]],
    event_data: EventStateChangedData,
) -> bool:
    """Filter state changes by entity_id."""
    return event_data["old_state"] is None and (
        MATCH_ALL in callbacks
        or
        # If old_state is None, new_state must be set but
        # mypy doesn't know that
        event_data["new_state"].domain in callbacks  # type: ignore[union-attr]
    )


@bind_hass
def async_track_state_added_domain(
    hass: HomeAssistant,
    domains: str | Iterable[str],
    action: Callable[[Event[EventStateChangedData]], Any],
    job_type: HassJobType | None = None,
) -> CALLBACK_TYPE:
    """Track state change events when an entity is added to domains."""
    if not (domains := _async_string_to_lower_list(domains)):
        return _remove_empty_listener
    return _async_track_state_added_domain(hass, domains, action, job_type)


_KEYED_TRACK_STATE_ADDED_DOMAIN = _KeyedEventTracker(
    key=_TRACK_STATE_ADDED_DOMAIN_DATA,
    event_type=EVENT_STATE_CHANGED,
    dispatcher_callable=_async_dispatch_domain_event,
    filter_callable=_async_domain_added_filter,
)


@bind_hass
def _async_track_state_added_domain(
    hass: HomeAssistant,
    domains: str | Iterable[str],
    action: Callable[[Event[EventStateChangedData]], Any],
    job_type: HassJobType | None,
) -> CALLBACK_TYPE:
    """Track state change events when an entity is added to domains."""
    return _async_track_event(
        _KEYED_TRACK_STATE_ADDED_DOMAIN, hass, domains, action, job_type
    )


@callback
def _async_domain_removed_filter(
    hass: HomeAssistant,
    callbacks: dict[str, list[HassJob[[Event[EventStateChangedData]], Any]]],
    event_data: EventStateChangedData,
) -> bool:
    """Filter state changes by entity_id."""
    return event_data["new_state"] is None and (
        MATCH_ALL in callbacks
        or
        # If new_state is None, old_state must be set but
        # mypy doesn't know that
        event_data["old_state"].domain in callbacks  # type: ignore[union-attr]
    )


_KEYED_TRACK_STATE_REMOVED_DOMAIN = _KeyedEventTracker(
    key=_TRACK_STATE_REMOVED_DOMAIN_DATA,
    event_type=EVENT_STATE_CHANGED,
    dispatcher_callable=_async_dispatch_domain_event,
    filter_callable=_async_domain_removed_filter,
)


@bind_hass
def async_track_state_removed_domain(
    hass: HomeAssistant,
    domains: str | Iterable[str],
    action: Callable[[Event[EventStateChangedData]], Any],
    job_type: HassJobType | None = None,
) -> CALLBACK_TYPE:
    """Track state change events when an entity is removed from domains."""
    return _async_track_event(
        _KEYED_TRACK_STATE_REMOVED_DOMAIN, hass, domains, action, job_type
    )


@callback
def _async_string_to_lower_list(instr: str | Iterable[str]) -> list[str]:
    if isinstance(instr, str):
        return [instr.lower()]

    return [mstr.lower() for mstr in instr]


class _TrackStateChangeFiltered:
    """Handle removal / refresh of tracker."""

    def __init__(
        self,
        hass: HomeAssistant,
        track_states: TrackStates,
        action: Callable[[Event[EventStateChangedData]], Any],
    ) -> None:
        """Handle removal / refresh of tracker init."""
        self.hass = hass
        self._action = action
        self._action_as_hassjob = HassJob(
            action, f"track state change filtered {track_states}"
        )
        self._listeners: dict[str, Callable[[], None]] = {}
        self._last_track_states: TrackStates = track_states

    @callback
    def async_setup(self) -> None:
        """Create listeners to track states."""
        track_states = self._last_track_states

        if (
            not track_states.all_states
            and not track_states.domains
            and not track_states.entities
        ):
            return

        if track_states.all_states:
            self._setup_all_listener()
            return

        self._setup_domains_listener(track_states.domains)
        self._setup_entities_listener(track_states.domains, track_states.entities)

    @property
    def listeners(self) -> dict[str, bool | set[str]]:
        """State changes that will cause a re-render."""
        track_states = self._last_track_states
        return {
            _ALL_LISTENER: track_states.all_states,
            _ENTITIES_LISTENER: track_states.entities,
            _DOMAINS_LISTENER: track_states.domains,
        }

    @callback
    def async_update_listeners(self, new_track_states: TrackStates) -> None:
        """Update the listeners based on the new TrackStates."""
        last_track_states = self._last_track_states
        self._last_track_states = new_track_states

        had_all_listener = last_track_states.all_states

        if new_track_states.all_states:
            if had_all_listener:
                return
            self._cancel_listener(_DOMAINS_LISTENER)
            self._cancel_listener(_ENTITIES_LISTENER)
            self._setup_all_listener()
            return

        if had_all_listener:
            self._cancel_listener(_ALL_LISTENER)

        domains_changed = new_track_states.domains != last_track_states.domains

        if had_all_listener or domains_changed:
            domains_changed = True
            self._cancel_listener(_DOMAINS_LISTENER)
            self._setup_domains_listener(new_track_states.domains)

        if (
            had_all_listener
            or domains_changed
            or new_track_states.entities != last_track_states.entities
        ):
            self._cancel_listener(_ENTITIES_LISTENER)
            self._setup_entities_listener(
                new_track_states.domains, new_track_states.entities
            )

    @callback
    def async_remove(self) -> None:
        """Cancel the listeners."""
        for key in list(self._listeners):
            self._listeners.pop(key)()

    @callback
    def _cancel_listener(self, listener_name: str) -> None:
        if listener_name not in self._listeners:
            return

        self._listeners.pop(listener_name)()

    @callback
    def _setup_entities_listener(self, domains: set[str], entities: set[str]) -> None:
        if domains:
            entities = entities.copy()
            entities.update(self.hass.states.async_entity_ids(domains))

        # Entities has changed to none
        if not entities:
            return

        self._listeners[_ENTITIES_LISTENER] = _async_track_state_change_event(
            self.hass, entities, self._action, self._action_as_hassjob.job_type
        )

    @callback
    def _state_added(self, event: Event[EventStateChangedData]) -> None:
        self._cancel_listener(_ENTITIES_LISTENER)
        self._setup_entities_listener(
            self._last_track_states.domains, self._last_track_states.entities
        )
        self.hass.async_run_hass_job(self._action_as_hassjob, event)

    @callback
    def _setup_domains_listener(self, domains: set[str]) -> None:
        if not domains:
            return

        self._listeners[_DOMAINS_LISTENER] = _async_track_state_added_domain(
            self.hass, domains, self._state_added, HassJobType.Callback
        )

    @callback
    def _setup_all_listener(self) -> None:
        self._listeners[_ALL_LISTENER] = self.hass.bus.async_listen(
            EVENT_STATE_CHANGED, self._action
        )


@callback
@bind_hass
def async_track_state_change_filtered(
    hass: HomeAssistant,
    track_states: TrackStates,
    action: Callable[[Event[EventStateChangedData]], Any],
) -> _TrackStateChangeFiltered:
    """Track state changes with a TrackStates filter that can be updated.

    The action will not be called immediately, but will be scheduled to run
    in the next event loop iteration, even if the action is decorated with
    @callback.

    Args:
        hass:
            Home assistant object.
        track_states:
            A TrackStates data class.
        action:
            Callable to call with results.

    Returns:
        Object used to update the listeners (async_update_listeners) with a new
        TrackStates or cancel the tracking (async_remove).

    """
    tracker = _TrackStateChangeFiltered(hass, track_states, action)
    tracker.async_setup()
    return tracker


@callback
@bind_hass
def async_track_template(
    hass: HomeAssistant,
    template: Template,
    action: Callable[
        [str, State | None, State | None], Coroutine[Any, Any, None] | None
    ],
    variables: TemplateVarsType | None = None,
) -> CALLBACK_TYPE:
    """Add a listener that fires when a template evaluates to 'true'.

    Listen for the result of the template becoming true, or a true-like
    string result, such as 'On', 'Open', or 'Yes'. If the template results
    in an error state when the value changes, this will be logged and not
    passed through.

    If the initial check of the template is invalid and results in an
    exception, the listener will still be registered but will only
    fire if the template result becomes true without an exception.

    Action args:
        entity_id:
            ID of the entity that triggered the state change.
        old_state:
            The old state of the entity that changed.
        new_state:
            New state of the entity that changed.

    Args:
        hass:
            Home assistant object.
        template:
            The template to calculate.
        action:
            Callable to call with results. See above for arguments.
        variables:
            Variables to pass to the template.

    Returns:
        Callable to unregister the listener.

    """
    job = HassJob(action, f"track template {template}")

    @callback
    def _template_changed_listener(
        event: Event[EventStateChangedData] | None,
        updates: list[TrackTemplateResult],
    ) -> None:
        """Check if condition is correct and run action."""
        track_result = updates.pop()

        template = track_result.template
        last_result = track_result.last_result
        result = track_result.result

        if isinstance(result, TemplateError):
            _LOGGER.error(
                "Error while processing template: %s",
                template.template,
                exc_info=result,
            )
            return

        if (
            not isinstance(last_result, TemplateError)
            and result_as_boolean(last_result)
        ) or not result_as_boolean(result):
            return

        hass.async_run_hass_job(
            job,
            event and event.data["entity_id"],
            event and event.data["old_state"],
            event and event.data["new_state"],
        )

    info = async_track_template_result(
        hass, [TrackTemplate(template, variables)], _template_changed_listener
    )

    return info.async_remove


track_template = threaded_listener_factory(async_track_template)


class TrackTemplateResultInfo:
    """Handle removal / refresh of tracker."""

    def __init__(
        self,
        hass: HomeAssistant,
        track_templates: Sequence[TrackTemplate],
        action: TrackTemplateResultListener,
        has_super_template: bool = False,
    ) -> None:
        """Handle removal / refresh of tracker init."""
        self.hass = hass
        self._job = HassJob(action, f"track template result {track_templates}")

        self._track_templates = track_templates
        self._has_super_template = has_super_template

        self._last_result: dict[Template, bool | str | TemplateError] = {}

        for track_template_ in track_templates:
            if track_template_.template.hass:
                continue

            raise HomeAssistantError(
                "Calls async_track_template_result with template without hass"
            )

        self._rate_limit = KeyedRateLimit(hass)
        self._info: dict[Template, RenderInfo] = {}
        self._track_state_changes: _TrackStateChangeFiltered | None = None
        self._time_listeners: dict[Template, Callable[[], None]] = {}

    def __repr__(self) -> str:
        """Return the representation."""
        return f"<TrackTemplateResultInfo {self._info}>"

    def async_setup(
        self,
        strict: bool = False,
        log_fn: Callable[[int, str], None] | None = None,
    ) -> None:
        """Activation of template tracking."""
        block_render = False
        super_template = self._track_templates[0] if self._has_super_template else None

        # Render the super template first
        if super_template is not None:
            template = super_template.template
            variables = super_template.variables
            self._info[template] = info = template.async_render_to_info(
                variables, strict=strict, log_fn=log_fn
            )

            # If the super template did not render to True, don't update other templates
            try:
                super_result: str | TemplateError = info.result()
            except TemplateError as ex:
                super_result = ex
            if (
                super_result is not None
                and self._super_template_as_boolean(super_result) is not True
            ):
                block_render = True

        # Then update the remaining templates unless blocked by the super template
        for track_template_ in self._track_templates:
            if block_render or track_template_ == super_template:
                continue
            template = track_template_.template
            variables = track_template_.variables
            self._info[template] = info = template.async_render_to_info(
                variables, strict=strict, log_fn=log_fn
            )

            if info.exception:
                if not log_fn:
                    _LOGGER.error(
                        "Error while processing template: %s",
                        track_template_.template,
                        exc_info=info.exception,
                    )
                else:
                    log_fn(logging.ERROR, str(info.exception))

        self._track_state_changes = async_track_state_change_filtered(
            self.hass, _render_infos_to_track_states(self._info.values()), self._refresh
        )
        self._update_time_listeners()
        _LOGGER.debug(
            (
                "Template group %s listens for %s, first render blocked by super"
                " template: %s"
            ),
            self._track_templates,
            self.listeners,
            block_render,
        )

    @property
    def listeners(self) -> dict[str, bool | set[str]]:
        """State changes that will cause a re-render."""
        assert self._track_state_changes
        return {
            **self._track_state_changes.listeners,
            "time": bool(self._time_listeners),
        }

    @callback
    def _setup_time_listener(self, template: Template, has_time: bool) -> None:
        if not has_time:
            if template in self._time_listeners:
                # now() or utcnow() has left the scope of the template
                self._time_listeners.pop(template)()
            return

        if template in self._time_listeners:
            return

        track_templates = [
            track_template_
            for track_template_ in self._track_templates
            if track_template_.template == template
        ]

        @callback
        def _refresh_from_time(now: datetime) -> None:
            self._refresh(None, track_templates=track_templates)

        self._time_listeners[template] = async_track_utc_time_change(
            self.hass, _refresh_from_time, second=0
        )

    @callback
    def _update_time_listeners(self) -> None:
        for template, info in self._info.items():
            self._setup_time_listener(template, info.has_time)

    @callback
    def async_remove(self) -> None:
        """Cancel the listener."""
        assert self._track_state_changes
        self._track_state_changes.async_remove()
        self._rate_limit.async_remove()
        for template in list(self._time_listeners):
            self._time_listeners.pop(template)()

    @callback
    def async_refresh(self) -> None:
        """Force recalculate the template."""
        self._refresh(None)

    def _render_template_if_ready(
        self,
        track_template_: TrackTemplate,
        now: float,
        event: Event[EventStateChangedData] | None,
    ) -> bool | TrackTemplateResult:
        """Re-render the template if conditions match.

        Returns False if the template was not re-rendered.

        Returns True if the template re-rendered and did not
        change.

        Returns TrackTemplateResult if the template re-render
        generates a new result.
        """
        template = track_template_.template

        if event:
            info = self._info[template]

            if not _event_triggers_rerender(event, info):
                return False

            had_timer = self._rate_limit.async_has_timer(template)

            if self._rate_limit.async_schedule_action(
                template,
                _rate_limit_for_event(event, info, track_template_),
                now,
                self._refresh,
                event,
                (track_template_,),
                True,
            ):
                return not had_timer

            _LOGGER.debug(
                "Template update %s triggered by event: %s",
                template.template,
                event,
            )

        self._rate_limit.async_triggered(template, now)
        self._info[template] = info = template.async_render_to_info(
            track_template_.variables
        )

        try:
            result: str | TemplateError = info.result()
        except TemplateError as ex:
            result = ex

        last_result = self._last_result.get(template)

        # Check to see if the result has changed or is new
        if result == last_result and template in self._last_result:
            return True

        if isinstance(result, TemplateError) and isinstance(last_result, TemplateError):
            return True

        return TrackTemplateResult(template, last_result, result)

    @staticmethod
    def _super_template_as_boolean(result: bool | str | TemplateError) -> bool:
        """Return True if the result is truthy or a TemplateError."""
        if isinstance(result, TemplateError):
            return True

        return result_as_boolean(result)

    @callback
    def _apply_update(
        self,
        updates: list[TrackTemplateResult],
        update: bool | TrackTemplateResult,
        template: Template,
    ) -> bool:
        """Handle updates of a tracked template."""
        if not update:
            return False

        self._setup_time_listener(template, self._info[template].has_time)

        if isinstance(update, TrackTemplateResult):
            updates.append(update)

        return True

    @callback
    def _refresh(
        self,
        event: Event[EventStateChangedData] | None,
        track_templates: Iterable[TrackTemplate] | None = None,
        replayed: bool | None = False,
    ) -> None:
        """Refresh the template.

        The event is the state_changed event that caused the refresh
        to be considered.

        track_templates is an optional list of TrackTemplate objects
        to refresh.  If not provided, all tracked templates will be
        considered.

        replayed is True if the event is being replayed because the
        rate limit was hit.
        """
        updates: list[TrackTemplateResult] = []
        info_changed = False
        now = event.time_fired_timestamp if not replayed and event else time.time()

        block_updates = False
        super_template = self._track_templates[0] if self._has_super_template else None

        track_templates = track_templates or self._track_templates

        # Update the super template first
        if super_template is not None:
            update = self._render_template_if_ready(super_template, now, event)
            info_changed |= self._apply_update(updates, update, super_template.template)

            if isinstance(update, TrackTemplateResult):
                super_result = update.result
            else:
                super_result = self._last_result.get(super_template.template)

            # If the super template did not render to True, don't update other templates
            if (
                super_result is not None
                and self._super_template_as_boolean(super_result) is not True
            ):
                block_updates = True

            if (
                isinstance(update, TrackTemplateResult)
                and self._super_template_as_boolean(update.last_result) is not True
                and self._super_template_as_boolean(update.result) is True
            ):
                # Super template changed from not True to True, force re-render
                # of all templates in the group
                event = None
                track_templates = self._track_templates

        # Then update the remaining templates unless blocked by the super template
        if not block_updates:
            for track_template_ in track_templates:
                if track_template_ == super_template:
                    continue

                update = self._render_template_if_ready(track_template_, now, event)
                info_changed |= self._apply_update(
                    updates, update, track_template_.template
                )

        if info_changed:
            assert self._track_state_changes
            self._track_state_changes.async_update_listeners(
                _render_infos_to_track_states(
                    [
                        _suppress_domain_all_in_render_info(info)
                        if self._rate_limit.async_has_timer(template)
                        else info
                        for template, info in self._info.items()
                    ]
                )
            )
            _LOGGER.debug(
                (
                    "Template group %s listens for %s, re-render blocked by super"
                    " template: %s"
                ),
                self._track_templates,
                self.listeners,
                block_updates,
            )

        if not updates:
            return

        for track_result in updates:
            self._last_result[track_result.template] = track_result.result

        self.hass.async_run_hass_job(self._job, event, updates)


type TrackTemplateResultListener = Callable[
    [
        Event[EventStateChangedData] | None,
        list[TrackTemplateResult],
    ],
    Coroutine[Any, Any, None] | None,
]
"""Type for the listener for template results.

    Action arguments
    ----------------
    event
        Event that caused the template to change output. None if not
        triggered by an event.
    updates
        A list of TrackTemplateResult
"""


@callback
@bind_hass
def async_track_template_result(
    hass: HomeAssistant,
    track_templates: Sequence[TrackTemplate],
    action: TrackTemplateResultListener,
    strict: bool = False,
    log_fn: Callable[[int, str], None] | None = None,
    has_super_template: bool = False,
) -> TrackTemplateResultInfo:
    """Add a listener that fires when the result of a template changes.

    The action will fire with the initial result from the template, and
    then whenever the output from the template changes. The template will
    be reevaluated if any states referenced in the last run of the
    template change, or if manually triggered. If the result of the
    evaluation is different from the previous run, the action is passed
    the result.

    The action will not be called immediately, but will be scheduled to run
    in the next event loop iteration, even if the action is decorated with
    @callback.

    If the template results in an TemplateError, this will be returned to
    the listener the first time this happens but not for subsequent errors.
    Once the template returns to a non-error condition the result is sent
    to the action as usual.

    Args:
        hass:
            Home assistant object.
        track_templates:
            An iterable of TrackTemplate.
        action:
            Callable to call with results.
        strict:
            When set to True, raise on undefined variables.
        log_fn:
            If not None, template error messages will logging by calling log_fn
            instead of the normal logging facility.
        has_super_template:
            When set to True, the first template will block rendering of other
            templates if it doesn't render as True.

    Returns:
        Info object used to unregister the listener, and refresh the template.

    """
    tracker = TrackTemplateResultInfo(hass, track_templates, action, has_super_template)
    tracker.async_setup(strict=strict, log_fn=log_fn)
    return tracker


@callback
@bind_hass
def async_track_same_state(
    hass: HomeAssistant,
    period: timedelta,
    action: Callable[[], Coroutine[Any, Any, None] | None],
    async_check_same_func: Callable[[str, State | None, State | None], bool],
    entity_ids: str | Iterable[str] = MATCH_ALL,
) -> CALLBACK_TYPE:
    """Track the state of entities for a period and run an action.

    If async_check_func is None it use the state of orig_value.
    Without entity_ids we track all state changes.
    """
    async_remove_state_for_cancel: CALLBACK_TYPE | None = None
    async_remove_state_for_listener: CALLBACK_TYPE | None = None

    job = HassJob(action, f"track same state {period} {entity_ids}")

    @callback
    def clear_listener() -> None:
        """Clear all unsub listener."""
        nonlocal async_remove_state_for_cancel, async_remove_state_for_listener

        if async_remove_state_for_listener is not None:
            async_remove_state_for_listener()
            async_remove_state_for_listener = None
        if async_remove_state_for_cancel is not None:
            async_remove_state_for_cancel()
            async_remove_state_for_cancel = None

    @callback
    def state_for_listener(now: Any) -> None:
        """Fire on state changes after a delay and calls action."""
        nonlocal async_remove_state_for_listener
        async_remove_state_for_listener = None
        clear_listener()
        hass.async_run_hass_job(job)

    @callback
    def state_for_cancel_listener(event: Event[EventStateChangedData]) -> None:
        """Fire on changes and cancel for listener if changed."""
        entity = event.data["entity_id"]
        from_state = event.data["old_state"]
        to_state = event.data["new_state"]

        if not async_check_same_func(entity, from_state, to_state):
            clear_listener()

    async_remove_state_for_listener = async_call_later(hass, period, state_for_listener)

    if entity_ids == MATCH_ALL:
        async_remove_state_for_cancel = hass.bus.async_listen(
            EVENT_STATE_CHANGED, state_for_cancel_listener
        )
    else:
        async_remove_state_for_cancel = async_track_state_change_event(
            hass,
            entity_ids,
            state_for_cancel_listener,
        )

    return clear_listener


track_same_state = threaded_listener_factory(async_track_same_state)


@callback
@bind_hass
def async_track_point_in_time(
    hass: HomeAssistant,
    action: HassJob[[datetime], Coroutine[Any, Any, None] | None]
    | Callable[[datetime], Coroutine[Any, Any, None] | None],
    point_in_time: datetime,
) -> CALLBACK_TYPE:
    """Add a listener that fires once at or after a specific point in time.

    The listener is passed the time it fires in local time.
    """
    job = (
        action
        if isinstance(action, HassJob)
        else HassJob(action, f"track point in time {point_in_time}")
    )

    @callback
    def utc_converter(utc_now: datetime) -> None:
        """Convert passed in UTC now to local now."""
        hass.async_run_hass_job(job, dt_util.as_local(utc_now))

    track_job = HassJob(
        utc_converter,
        name=f"{job.name} UTC converter",
        cancel_on_shutdown=job.cancel_on_shutdown,
        job_type=HassJobType.Callback,
    )
    return async_track_point_in_utc_time(hass, track_job, point_in_time)


track_point_in_time = threaded_listener_factory(async_track_point_in_time)


@dataclass(slots=True)
class _TrackPointUTCTime:
    hass: HomeAssistant
    job: HassJob[[datetime], Coroutine[Any, Any, None] | None]
    utc_point_in_time: datetime
    expected_fire_timestamp: float
    _cancel_callback: asyncio.TimerHandle | None = None

    def async_attach(self) -> None:
        """Initialize track job."""
        loop = self.hass.loop
        self._cancel_callback = loop.call_at(
            loop.time() + self.expected_fire_timestamp - time.time(), self
        )

    @callback
    def __call__(self) -> None:
        """Call the action.

        We implement this as __call__ so when debug logging logs the object
        it shows the name of the job. This is especially helpful when asyncio
        debug logging is enabled as we can see the name of the job that is
        being called that is blocking the event loop.
        """
        # Depending on the available clock support (including timer hardware
        # and the OS kernel) it can happen that we fire a little bit too early
        # as measured by utcnow(). That is bad when callbacks have assumptions
        # about the current time. Thus, we rearm the timer for the remaining
        # time.
        if (delta := (self.expected_fire_timestamp - time_tracker_timestamp())) > 0:
            _LOGGER.debug("Called %f seconds too early, rearming", delta)
            loop = self.hass.loop
            self._cancel_callback = loop.call_at(loop.time() + delta, self)
            return

        self.hass.async_run_hass_job(self.job, self.utc_point_in_time)

    @callback
    def async_cancel(self) -> None:
        """Cancel the call_at."""
        if TYPE_CHECKING:
            assert self._cancel_callback is not None
        self._cancel_callback.cancel()


@callback
@bind_hass
def async_track_point_in_utc_time(
    hass: HomeAssistant,
    action: HassJob[[datetime], Coroutine[Any, Any, None] | None]
    | Callable[[datetime], Coroutine[Any, Any, None] | None],
    point_in_time: datetime,
) -> CALLBACK_TYPE:
    """Add a listener that fires once at or after a specific point in time.

    The listener is passed the time it fires in UTC time.
    """
    # Ensure point_in_time is UTC
    utc_point_in_time = dt_util.as_utc(point_in_time)
    expected_fire_timestamp = utc_point_in_time.timestamp()
    job = (
        action
        if isinstance(action, HassJob)
        else HassJob(action, f"track point in utc time {utc_point_in_time}")
    )
    track = _TrackPointUTCTime(hass, job, utc_point_in_time, expected_fire_timestamp)
    track.async_attach()
    return track.async_cancel


track_point_in_utc_time = threaded_listener_factory(async_track_point_in_utc_time)


def _run_async_call_action(
    hass: HomeAssistant, job: HassJob[[datetime], Coroutine[Any, Any, None] | None]
) -> None:
    """Run action."""
    hass.async_run_hass_job(job, time_tracker_utcnow())


@callback
@bind_hass
def async_call_at(
    hass: HomeAssistant,
    action: HassJob[[datetime], Coroutine[Any, Any, None] | None]
    | Callable[[datetime], Coroutine[Any, Any, None] | None],
    loop_time: float,
) -> CALLBACK_TYPE:
    """Add a listener that fires at or after <loop_time>.

    The listener is passed the time it fires in UTC time.
    """
    job = (
        action
        if isinstance(action, HassJob)
        else HassJob(action, f"call_at {loop_time}")
    )
    return hass.loop.call_at(loop_time, _run_async_call_action, hass, job).cancel


@callback
@bind_hass
def async_call_later(
    hass: HomeAssistant,
    delay: float | timedelta,
    action: HassJob[[datetime], Coroutine[Any, Any, None] | None]
    | Callable[[datetime], Coroutine[Any, Any, None] | None],
) -> CALLBACK_TYPE:
    """Add a listener that fires at or after <delay>.

    The listener is passed the time it fires in UTC time.
    """
    if isinstance(delay, timedelta):
        delay = delay.total_seconds()
    job = (
        action
        if isinstance(action, HassJob)
        else HassJob(action, f"call_later {delay}")
    )
    loop = hass.loop
    return loop.call_at(loop.time() + delay, _run_async_call_action, hass, job).cancel


call_later = threaded_listener_factory(async_call_later)


@dataclass(slots=True)
class _TrackTimeInterval:
    """Helper class to help listen to time interval events."""

    hass: HomeAssistant
    seconds: float
    job_name: str
    action: Callable[[datetime], Coroutine[Any, Any, None] | None]
    cancel_on_shutdown: bool | None
    _track_job: HassJob[[datetime], Coroutine[Any, Any, None] | None] | None = None
    _run_job: HassJob[[datetime], Coroutine[Any, Any, None] | None] | None = None
    _timer_handle: asyncio.TimerHandle | None = None

    def async_attach(self) -> None:
        """Initialize track job."""
        self._track_job = HassJob(
            self._interval_listener,
            self.job_name,
            job_type=HassJobType.Callback,
            cancel_on_shutdown=self.cancel_on_shutdown,
        )
        self._run_job = HassJob(
            self.action,
            f"track time interval {self.seconds}",
            cancel_on_shutdown=self.cancel_on_shutdown,
        )
        self._schedule_timer()

    def _schedule_timer(self) -> None:
        """Schedule the timer."""
        if TYPE_CHECKING:
            assert self._track_job is not None
        hass = self.hass
        loop = hass.loop
        self._timer_handle = loop.call_at(
            loop.time() + self.seconds, self._interval_listener, self._track_job
        )

    @callback
    def _interval_listener(self, _: Any) -> None:
        """Handle elapsed intervals."""
        if TYPE_CHECKING:
            assert self._run_job is not None
        self._schedule_timer()
        self.hass.async_run_hass_job(self._run_job, dt_util.utcnow(), background=True)

    @callback
    def async_cancel(self) -> None:
        """Cancel the call_at."""
        if TYPE_CHECKING:
            assert self._timer_handle is not None
        self._timer_handle.cancel()


@callback
@bind_hass
def async_track_time_interval(
    hass: HomeAssistant,
    action: Callable[[datetime], Coroutine[Any, Any, None] | None],
    interval: timedelta,
    *,
    name: str | None = None,
    cancel_on_shutdown: bool | None = None,
) -> CALLBACK_TYPE:
    """Add a listener that fires repetitively at every timedelta interval.

    The listener is passed the time it fires in UTC time.
    """
    seconds = interval.total_seconds()
    job_name = f"track time interval {seconds} {action}"
    if name:
        job_name = f"{name}: {job_name}"
    track = _TrackTimeInterval(hass, seconds, job_name, action, cancel_on_shutdown)
    track.async_attach()
    return track.async_cancel


track_time_interval = threaded_listener_factory(async_track_time_interval)


@dataclass(slots=True)
class SunListener:
    """Helper class to help listen to sun events."""

    hass: HomeAssistant
    job: HassJob[[], Coroutine[Any, Any, None] | None]
    event: str
    offset: timedelta | None
    _unsub_sun: CALLBACK_TYPE | None = None
    _unsub_config: CALLBACK_TYPE | None = None

    @callback
    def async_attach(self) -> None:
        """Attach a sun listener."""
        assert self._unsub_config is None

        self._unsub_config = self.hass.bus.async_listen(
            EVENT_CORE_CONFIG_UPDATE, self._handle_config_event
        )

        self._listen_next_sun_event()

    @callback
    def async_detach(self) -> None:
        """Detach the sun listener."""
        assert self._unsub_sun is not None
        assert self._unsub_config is not None

        self._unsub_sun()
        self._unsub_sun = None
        self._unsub_config()
        self._unsub_config = None

    @callback
    def _listen_next_sun_event(self) -> None:
        """Set up the sun event listener."""
        assert self._unsub_sun is None

        self._unsub_sun = async_track_point_in_utc_time(
            self.hass,
            self._handle_sun_event,
            get_astral_event_next(self.hass, self.event, offset=self.offset),
        )

    @callback
    def _handle_sun_event(self, _now: Any) -> None:
        """Handle solar event."""
        self._unsub_sun = None
        self._listen_next_sun_event()
        self.hass.async_run_hass_job(self.job, background=True)

    @callback
    def _handle_config_event(self, _event: Any) -> None:
        """Handle core config update."""
        assert self._unsub_sun is not None
        self._unsub_sun()
        self._unsub_sun = None
        self._listen_next_sun_event()


@callback
@bind_hass
def async_track_sunrise(
    hass: HomeAssistant, action: Callable[[], None], offset: timedelta | None = None
) -> CALLBACK_TYPE:
    """Add a listener that will fire a specified offset from sunrise daily."""
    listener = SunListener(
        hass, HassJob(action, "track sunrise"), SUN_EVENT_SUNRISE, offset
    )
    listener.async_attach()
    return listener.async_detach


track_sunrise = threaded_listener_factory(async_track_sunrise)


@callback
@bind_hass
def async_track_sunset(
    hass: HomeAssistant, action: Callable[[], None], offset: timedelta | None = None
) -> CALLBACK_TYPE:
    """Add a listener that will fire a specified offset from sunset daily."""
    listener = SunListener(
        hass, HassJob(action, "track sunset"), SUN_EVENT_SUNSET, offset
    )
    listener.async_attach()
    return listener.async_detach


track_sunset = threaded_listener_factory(async_track_sunset)

# For targeted patching in tests
time_tracker_utcnow = dt_util.utcnow
time_tracker_timestamp = time.time


@dataclass(slots=True)
class _TrackUTCTimeChange:
    hass: HomeAssistant
    time_match_expression: tuple[list[int], list[int], list[int]]
    microsecond: int
    local: bool
    job: HassJob[[datetime], Coroutine[Any, Any, None] | None]
    listener_job_name: str
    _pattern_time_change_listener_job: HassJob[[datetime], None] | None = None
    _cancel_callback: CALLBACK_TYPE | None = None

    def async_attach(self) -> None:
        """Initialize track job."""
        self._pattern_time_change_listener_job = HassJob(
            self._pattern_time_change_listener,
            self.listener_job_name,
            job_type=HassJobType.Callback,
        )
        self._cancel_callback = async_track_point_in_utc_time(
            self.hass,
            self._pattern_time_change_listener_job,
            self._calculate_next(dt_util.utcnow()),
        )

    def _calculate_next(self, utc_now: datetime) -> datetime:
        """Calculate and set the next time the trigger should fire."""
        localized_now = dt_util.as_local(utc_now) if self.local else utc_now
        return dt_util.find_next_time_expression_time(
            localized_now, *self.time_match_expression
        ).replace(microsecond=self.microsecond)

    @callback
    def _pattern_time_change_listener(self, _: datetime) -> None:
        """Listen for matching time_changed events."""
        hass = self.hass
        # Fetch time again because we want the actual time, not the
        # time when the timer was scheduled
        utc_now = time_tracker_utcnow()
        localized_now = dt_util.as_local(utc_now) if self.local else utc_now
        if TYPE_CHECKING:
            assert self._pattern_time_change_listener_job is not None
        self._cancel_callback = async_track_point_in_utc_time(
            hass,
            self._pattern_time_change_listener_job,
            self._calculate_next(utc_now + timedelta(seconds=1)),
        )
        hass.async_run_hass_job(self.job, localized_now, background=True)

    @callback
    def async_cancel(self) -> None:
        """Cancel the call_at."""
        if TYPE_CHECKING:
            assert self._cancel_callback is not None
        self._cancel_callback()


@callback
@bind_hass
def async_track_utc_time_change(
    hass: HomeAssistant,
    action: Callable[[datetime], Coroutine[Any, Any, None] | None],
    hour: Any | None = None,
    minute: Any | None = None,
    second: Any | None = None,
    local: bool = False,
) -> CALLBACK_TYPE:
    """Add a listener that will fire every time the UTC or local time matches a pattern.

    The listener is passed the time it fires in UTC or local time.
    """
    # We do not have to wrap the function with time pattern matching logic
    # if no pattern given
    if all(val is None or val == "*" for val in (hour, minute, second)):
        # Previously this relied on EVENT_TIME_FIRED
        # which meant it would not fire right away because
        # the caller would always be misaligned with the call
        # time vs the fire time by < 1s. To preserve this
        # misalignment we use async_track_time_interval here
        return async_track_time_interval(hass, action, timedelta(seconds=1))

    job = HassJob(action, f"track time change {hour}:{minute}:{second} local={local}")
    matching_seconds = dt_util.parse_time_expression(second, 0, 59)
    matching_minutes = dt_util.parse_time_expression(minute, 0, 59)
    matching_hours = dt_util.parse_time_expression(hour, 0, 23)
    # Avoid aligning all time trackers to the same fraction of a second
    # since it can create a thundering herd problem
    # https://github.com/home-assistant/core/issues/82231
    microsecond = randint(RANDOM_MICROSECOND_MIN, RANDOM_MICROSECOND_MAX)
    listener_job_name = f"time change listener {hour}:{minute}:{second} {action}"
    track = _TrackUTCTimeChange(
        hass,
        (matching_seconds, matching_minutes, matching_hours),
        microsecond,
        local,
        job,
        listener_job_name,
    )
    track.async_attach()
    return track.async_cancel


track_utc_time_change = threaded_listener_factory(async_track_utc_time_change)


@callback
@bind_hass
def async_track_time_change(
    hass: HomeAssistant,
    action: Callable[[datetime], Coroutine[Any, Any, None] | None],
    hour: Any | None = None,
    minute: Any | None = None,
    second: Any | None = None,
) -> CALLBACK_TYPE:
    """Add a listener that will fire every time the local time matches a pattern.

    The listener is passed the time it fires in local time.
    """
    return async_track_utc_time_change(hass, action, hour, minute, second, local=True)


track_time_change = threaded_listener_factory(async_track_time_change)


def process_state_match(
    parameter: str | Iterable[str] | None, invert: bool = False
) -> Callable[[str | None], bool]:
    """Convert parameter to function that matches input against parameter."""
    if parameter is None or parameter == MATCH_ALL:
        return lambda _: not invert

    if isinstance(parameter, str) or not hasattr(parameter, "__iter__"):
        return lambda state: invert is not (state == parameter)

    parameter_set = set(parameter)
    return lambda state: invert is not (state in parameter_set)


@callback
def _entities_domains_from_render_infos(
    render_infos: Iterable[RenderInfo],
) -> tuple[set[str], set[str]]:
    """Combine from multiple RenderInfo."""
    entities: set[str] = set()
    domains: set[str] = set()

    for render_info in render_infos:
        if render_info.entities:
            entities.update(render_info.entities)
        if render_info.domains:
            domains.update(render_info.domains)
        if render_info.domains_lifecycle:
            domains.update(render_info.domains_lifecycle)
    return entities, domains


@callback
def _render_infos_needs_all_listener(render_infos: Iterable[RenderInfo]) -> bool:
    """Determine if an all listener is needed from RenderInfo."""
    for render_info in render_infos:
        # Tracking all states
        if render_info.all_states or render_info.all_states_lifecycle:
            return True

    return False


@callback
def _render_infos_to_track_states(render_infos: Iterable[RenderInfo]) -> TrackStates:
    """Create a TrackStates dataclass from the latest RenderInfo."""
    if _render_infos_needs_all_listener(render_infos):
        return TrackStates(True, set(), set())

    return TrackStates(False, *_entities_domains_from_render_infos(render_infos))


@callback
def _event_triggers_rerender(
    event: Event[EventStateChangedData], info: RenderInfo
) -> bool:
    """Determine if a template should be re-rendered from an event."""
    entity_id = event.data["entity_id"]

    if info.filter(entity_id):
        return True

    if event.data["new_state"] is not None and event.data["old_state"] is not None:
        return False

    return bool(info.filter_lifecycle(entity_id))


@callback
def _rate_limit_for_event(
    event: Event[EventStateChangedData],
    info: RenderInfo,
    track_template_: TrackTemplate,
) -> float | None:
    """Determine the rate limit for an event."""
    # Specifically referenced entities are excluded
    # from the rate limit
    if event.data["entity_id"] in info.entities:
        return None

    if track_template_.rate_limit is not None:
        return track_template_.rate_limit

    rate_limit: float | None = info.rate_limit
    return rate_limit


def _suppress_domain_all_in_render_info(render_info: RenderInfo) -> RenderInfo:
    """Remove the domains and all_states from render info during a ratelimit."""
    rate_limited_render_info = copy.copy(render_info)
    rate_limited_render_info.all_states = False
    rate_limited_render_info.all_states_lifecycle = False
    rate_limited_render_info.domains = set()
    rate_limited_render_info.domains_lifecycle = set()
    return rate_limited_render_info
</file>

<file path="floor_registry.py">
"""Provide a way to assign areas to floors in one's home."""

from __future__ import annotations

from collections import defaultdict
from collections.abc import Iterable
import dataclasses
from dataclasses import dataclass
from datetime import datetime
import math
from typing import Any, Literal, TypedDict

from homeassistant.core import Event, HomeAssistant, callback
from homeassistant.util.dt import utc_from_timestamp, utcnow
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey

from .normalized_name_base_registry import (
    NormalizedNameBaseRegistryEntry,
    NormalizedNameBaseRegistryItems,
    normalize_name,
)
from .registry import BaseRegistry, RegistryIndexType
from .singleton import singleton
from .storage import Store
from .typing import UNDEFINED, UndefinedType

DATA_REGISTRY: HassKey[FloorRegistry] = HassKey("floor_registry")
EVENT_FLOOR_REGISTRY_UPDATED: EventType[EventFloorRegistryUpdatedData] = EventType(
    "floor_registry_updated"
)
STORAGE_KEY = "core.floor_registry"
STORAGE_VERSION_MAJOR = 1
STORAGE_VERSION_MINOR = 3


class _FloorStoreData(TypedDict):
    """Data type for individual floor. Used in FloorRegistryStoreData."""

    aliases: list[str]
    floor_id: str
    icon: str | None
    level: int | None
    name: str
    created_at: str
    modified_at: str


class FloorRegistryStoreData(TypedDict):
    """Store data type for FloorRegistry."""

    floors: list[_FloorStoreData]


class _EventFloorRegistryUpdatedData_Create_Remove_Update(TypedDict):
    """Event data for when the floor registry is updated."""

    action: Literal["create", "remove", "update"]
    floor_id: str


class _EventFloorRegistryUpdatedData_Reorder(TypedDict):
    """Event data for when the floor registry is updated."""

    action: Literal["reorder"]


type EventFloorRegistryUpdatedData = (
    _EventFloorRegistryUpdatedData_Create_Remove_Update
    | _EventFloorRegistryUpdatedData_Reorder
)

type EventFloorRegistryUpdated = Event[EventFloorRegistryUpdatedData]


@dataclass(slots=True, kw_only=True, frozen=True)
class FloorEntry(NormalizedNameBaseRegistryEntry):
    """Floor registry entry."""

    aliases: set[str]
    floor_id: str
    icon: str | None = None
    level: int | None = None


class FloorRegistryStore(Store[FloorRegistryStoreData]):
    """Store floor registry data."""

    async def _async_migrate_func(
        self,
        old_major_version: int,
        old_minor_version: int,
        old_data: dict[str, list[dict[str, Any]]],
    ) -> FloorRegistryStoreData:
        """Migrate to the new version."""
        if old_major_version > STORAGE_VERSION_MAJOR:
            raise ValueError("Can't migrate to future version")

        if old_major_version == 1:
            if old_minor_version < 2:
                # Version 1.2 implements migration and adds created_at and modified_at
                created_at = utc_from_timestamp(0).isoformat()
                for floor in old_data["floors"]:
                    floor["created_at"] = floor["modified_at"] = created_at

            if old_minor_version < 3:
                # Version 1.3 sorts the floors by their level attribute, then by name
                old_data["floors"] = sorted(
                    old_data["floors"],
                    key=lambda floor: (
                        math.inf if floor["level"] is None else -floor["level"],
                        floor["name"].casefold(),
                    ),
                )

        return old_data  # type: ignore[return-value]


class FloorRegistryItems(NormalizedNameBaseRegistryItems[FloorEntry]):
    """Class to hold floor registry items."""

    def __init__(self) -> None:
        """Initialize the floor registry items."""
        super().__init__()
        self._aliases_index: RegistryIndexType = defaultdict(dict)

    def _index_entry(self, key: str, entry: FloorEntry) -> None:
        """Index an entry."""
        super()._index_entry(key, entry)
        for normalized_alias in {normalize_name(alias) for alias in entry.aliases}:
            self._aliases_index[normalized_alias][key] = True

    def _unindex_entry(
        self, key: str, replacement_entry: FloorEntry | None = None
    ) -> None:
        # always call base class before other indices
        super()._unindex_entry(key, replacement_entry)
        entry = self.data[key]
        if aliases := entry.aliases:
            for normalized_alias in {normalize_name(alias) for alias in aliases}:
                self._unindex_entry_value(key, normalized_alias, self._aliases_index)

    def get_floors_for_alias(self, alias: str) -> list[FloorEntry]:
        """Get floors for alias."""
        data = self.data
        normalized_alias = normalize_name(alias)
        return [data[key] for key in self._aliases_index.get(normalized_alias, ())]


class FloorRegistry(BaseRegistry[FloorRegistryStoreData]):
    """Class to hold a registry of floors."""

    floors: FloorRegistryItems
    _floor_data: dict[str, FloorEntry]

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the floor registry."""
        self.hass = hass
        self._store = FloorRegistryStore(
            hass,
            STORAGE_VERSION_MAJOR,
            STORAGE_KEY,
            atomic_writes=True,
            minor_version=STORAGE_VERSION_MINOR,
        )

    @callback
    def async_get_floor(self, floor_id: str) -> FloorEntry | None:
        """Get floor by id.

        We retrieve the FloorEntry from the underlying dict to avoid
        the overhead of the UserDict __getitem__.
        """
        return self._floor_data.get(floor_id)

    @callback
    def async_get_floor_by_name(self, name: str) -> FloorEntry | None:
        """Get floor by name."""
        return self.floors.get_by_name(name)

    @callback
    def async_get_floors_by_alias(self, alias: str) -> list[FloorEntry]:
        """Get floors by alias."""
        return self.floors.get_floors_for_alias(alias)

    @callback
    def async_list_floors(self) -> Iterable[FloorEntry]:
        """Get all floors."""
        return self.floors.values()

    def _generate_id(self, name: str) -> str:
        """Generate floor ID."""
        return self.floors.generate_id_from_name(name)

    @callback
    def async_create(
        self,
        name: str,
        *,
        aliases: set[str] | None = None,
        icon: str | None = None,
        level: int | None = None,
    ) -> FloorEntry:
        """Create a new floor."""
        self.hass.verify_event_loop_thread("floor_registry.async_create")

        if floor := self.async_get_floor_by_name(name):
            raise ValueError(
                f"The name {name} ({floor.normalized_name}) is already in use"
            )

        floor = FloorEntry(
            aliases=aliases or set(),
            icon=icon,
            floor_id=self._generate_id(name),
            name=name,
            level=level,
        )
        floor_id = floor.floor_id
        self.floors[floor_id] = floor
        self.async_schedule_save()

        self.hass.bus.async_fire_internal(
            EVENT_FLOOR_REGISTRY_UPDATED,
            _EventFloorRegistryUpdatedData_Create_Remove_Update(
                action="create", floor_id=floor_id
            ),
        )
        return floor

    @callback
    def async_delete(self, floor_id: str) -> None:
        """Delete floor."""
        self.hass.verify_event_loop_thread("floor_registry.async_delete")
        del self.floors[floor_id]
        self.hass.bus.async_fire_internal(
            EVENT_FLOOR_REGISTRY_UPDATED,
            _EventFloorRegistryUpdatedData_Create_Remove_Update(
                action="remove",
                floor_id=floor_id,
            ),
        )
        self.async_schedule_save()

    @callback
    def async_update(
        self,
        floor_id: str,
        *,
        aliases: set[str] | UndefinedType = UNDEFINED,
        icon: str | None | UndefinedType = UNDEFINED,
        level: int | UndefinedType = UNDEFINED,
        name: str | UndefinedType = UNDEFINED,
    ) -> FloorEntry:
        """Update name of the floor."""
        old = self.floors[floor_id]
        changes: dict[str, Any] = {
            attr_name: value
            for attr_name, value in (
                ("aliases", aliases),
                ("icon", icon),
                ("level", level),
            )
            if value is not UNDEFINED and value != getattr(old, attr_name)
        }
        if name is not UNDEFINED and name != old.name:
            changes["name"] = name

        if not changes:
            return old

        changes["modified_at"] = utcnow()

        self.hass.verify_event_loop_thread("floor_registry.async_update")
        new = self.floors[floor_id] = dataclasses.replace(old, **changes)

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_FLOOR_REGISTRY_UPDATED,
            _EventFloorRegistryUpdatedData_Create_Remove_Update(
                action="update",
                floor_id=floor_id,
            ),
        )

        return new

    @callback
    def async_reorder(self, floor_ids: list[str]) -> None:
        """Reorder floors."""
        self.hass.verify_event_loop_thread("floor_registry.async_reorder")

        if set(floor_ids) != set(self.floors.data.keys()):
            raise ValueError(
                "The floor_ids list must contain all existing floor IDs exactly once"
            )

        reordered_data = {
            floor_id: self.floors.data[floor_id] for floor_id in floor_ids
        }
        self.floors.data.clear()
        self.floors.data.update(reordered_data)

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_FLOOR_REGISTRY_UPDATED,
            _EventFloorRegistryUpdatedData_Reorder(action="reorder"),
        )

    async def async_load(self) -> None:
        """Load the floor registry."""
        data = await self._store.async_load()
        floors = FloorRegistryItems()

        if data is not None:
            for floor in data["floors"]:
                floors[floor["floor_id"]] = FloorEntry(
                    aliases=set(floor["aliases"]),
                    icon=floor["icon"],
                    floor_id=floor["floor_id"],
                    name=floor["name"],
                    level=floor["level"],
                    created_at=datetime.fromisoformat(floor["created_at"]),
                    modified_at=datetime.fromisoformat(floor["modified_at"]),
                )

        self.floors = floors
        self._floor_data = floors.data

    @callback
    def _data_to_save(self) -> FloorRegistryStoreData:
        """Return data of floor registry to store in a file."""
        return {
            "floors": [
                {
                    "aliases": list(entry.aliases),
                    "floor_id": entry.floor_id,
                    "icon": entry.icon,
                    "level": entry.level,
                    "name": entry.name,
                    "created_at": entry.created_at.isoformat(),
                    "modified_at": entry.modified_at.isoformat(),
                }
                for entry in self.floors.values()
            ]
        }


@callback
@singleton(DATA_REGISTRY)
def async_get(hass: HomeAssistant) -> FloorRegistry:
    """Get floor registry."""
    return FloorRegistry(hass)


async def async_load(hass: HomeAssistant) -> None:
    """Load floor registry."""
    assert DATA_REGISTRY not in hass.data
    await async_get(hass).async_load()
</file>

<file path="frame.py">
"""Provide frame helper for finding the current frame context."""

from __future__ import annotations

from collections.abc import Callable
from dataclasses import dataclass
import enum
import functools
import inspect
import linecache
import logging
import sys
import threading
from types import FrameType
from typing import Any, cast

from propcache.api import cached_property

from homeassistant.core import HomeAssistant, callback
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import (
    Integration,
    async_get_issue_integration,
    async_suggest_report_issue,
)
from homeassistant.util.async_ import run_callback_threadsafe

_LOGGER = logging.getLogger(__name__)

# Keep track of integrations already reported to prevent flooding
_REPORTED_INTEGRATIONS: set[str] = set()


class _Hass:
    """Container which makes a HomeAssistant instance available to frame helper."""

    hass: HomeAssistant | None = None


_hass = _Hass()


@callback
def async_setup(hass: HomeAssistant) -> None:
    """Set up the frame helper."""
    _hass.hass = hass


@dataclass(kw_only=True)
class IntegrationFrame:
    """Integration frame container."""

    custom_integration: bool
    integration: str
    module: str | None
    relative_filename: str
    frame: FrameType

    @cached_property
    def line_number(self) -> int:
        """Return the line number of the frame."""
        return self.frame.f_lineno

    @cached_property
    def filename(self) -> str:
        """Return the filename of the frame."""
        return self.frame.f_code.co_filename

    @cached_property
    def line(self) -> str:
        """Return the line of the frame."""
        return (linecache.getline(self.filename, self.line_number) or "?").strip()


def get_integration_logger(fallback_name: str) -> logging.Logger:
    """Return a logger by checking the current integration frame.

    If Python is unable to access the sources files, the call stack frame
    will be missing information, so let's guard by requiring a fallback name.
    https://github.com/home-assistant/core/issues/24982
    """
    try:
        integration_frame = get_integration_frame()
    except MissingIntegrationFrame:
        return logging.getLogger(fallback_name)

    if integration_frame.custom_integration:
        logger_name = f"custom_components.{integration_frame.integration}"
    else:
        logger_name = f"homeassistant.components.{integration_frame.integration}"

    return logging.getLogger(logger_name)


def get_current_frame(depth: int = 0) -> FrameType:
    """Return the current frame."""
    # Add one to depth since get_current_frame is included
    return sys._getframe(depth + 1)  # noqa: SLF001


def get_integration_frame(exclude_integrations: set | None = None) -> IntegrationFrame:
    """Return the frame, integration and integration path of the current stack frame."""
    found_frame = None
    if not exclude_integrations:
        exclude_integrations = set()

    frame: FrameType | None = get_current_frame()
    while frame is not None:
        filename = frame.f_code.co_filename

        for path in ("custom_components/", "homeassistant/components/"):
            try:
                index = filename.index(path)
                start = index + len(path)
                end = filename.index("/", start)
                integration = filename[start:end]
                if integration not in exclude_integrations:
                    found_frame = frame

                break
            except ValueError:
                continue

        if found_frame is not None:
            break

        frame = frame.f_back

    if found_frame is None:
        raise MissingIntegrationFrame

    found_module: str | None = None
    for module, module_obj in dict(sys.modules).items():
        if not hasattr(module_obj, "__file__"):
            continue
        if module_obj.__file__ == found_frame.f_code.co_filename:
            found_module = module
            break

    return IntegrationFrame(
        custom_integration=path == "custom_components/",
        integration=integration,
        module=found_module,
        relative_filename=found_frame.f_code.co_filename[index:],
        frame=found_frame,
    )


class MissingIntegrationFrame(HomeAssistantError):
    """Raised when no integration is found in the frame."""


class ReportBehavior(enum.Enum):
    """Enum for behavior on code usage."""

    IGNORE = enum.auto()
    """Ignore the code usage."""
    LOG = enum.auto()
    """Log the code usage."""
    ERROR = enum.auto()
    """Raise an error on code usage."""


def report_usage(
    what: str,
    *,
    breaks_in_ha_version: str | None = None,
    core_behavior: ReportBehavior = ReportBehavior.ERROR,
    core_integration_behavior: ReportBehavior = ReportBehavior.LOG,
    custom_integration_behavior: ReportBehavior = ReportBehavior.LOG,
    exclude_integrations: set[str] | None = None,
    integration_domain: str | None = None,
    level: int = logging.WARNING,
) -> None:
    """Report incorrect code usage.

    :param what: will be wrapped with "Detected that integration 'integration' {what}.
    Please create a bug report at https://..."
    :param breaks_in_ha_version: if set, the report will be adjusted to specify the
    breaking version
    :param exclude_integrations: skip specified integration when reviewing the stack.
    If no integration is found, the core behavior will be applied
    :param integration_domain: domain of the integration causing the issue. If None, the
    stack frame will be searched to identify the integration causing the issue.
    """
    if (hass := _hass.hass) is None:
        raise RuntimeError("Frame helper not set up")
    integration_frame: IntegrationFrame | None = None
    integration_frame_err: MissingIntegrationFrame | None = None
    if not integration_domain:
        try:
            integration_frame = get_integration_frame(
                exclude_integrations=exclude_integrations
            )
        except MissingIntegrationFrame as err:
            # We need to be careful with assigning the error here as it affects the
            # cleanup of objects referenced from the stack trace as seen in
            # https://github.com/home-assistant/core/pull/148021#discussion_r2182379834
            # When core_behavior is ReportBehavior.ERROR, we will re-raise the error,
            # so we can safely assign it to integration_frame_err.
            if core_behavior is ReportBehavior.ERROR:
                integration_frame_err = err
    _report_usage_partial = functools.partial(
        _report_usage,
        hass,
        what,
        breaks_in_ha_version=breaks_in_ha_version,
        core_behavior=core_behavior,
        core_integration_behavior=core_integration_behavior,
        custom_integration_behavior=custom_integration_behavior,
        integration_domain=integration_domain,
        integration_frame=integration_frame,
        integration_frame_err=integration_frame_err,
        level=level,
    )
    if hass.loop_thread_id != threading.get_ident():
        future = run_callback_threadsafe(hass.loop, _report_usage_partial)
        future.result()
        return
    _report_usage_partial()


def _report_usage(
    hass: HomeAssistant,
    what: str,
    *,
    breaks_in_ha_version: str | None,
    core_behavior: ReportBehavior,
    core_integration_behavior: ReportBehavior,
    custom_integration_behavior: ReportBehavior,
    integration_domain: str | None,
    integration_frame: IntegrationFrame | None,
    integration_frame_err: MissingIntegrationFrame | None,
    level: int,
) -> None:
    """Report incorrect code usage.

    Must be called from the event loop.
    """
    if integration_domain:
        if integration := async_get_issue_integration(hass, integration_domain):
            _report_usage_integration_domain(
                hass,
                what,
                breaks_in_ha_version,
                integration,
                core_integration_behavior,
                custom_integration_behavior,
                level,
            )
            return
        _report_usage_no_integration(what, core_behavior, breaks_in_ha_version, None)
        return

    if not integration_frame:
        _report_usage_no_integration(
            what, core_behavior, breaks_in_ha_version, integration_frame_err
        )
        return

    integration_behavior = core_integration_behavior
    if integration_frame.custom_integration:
        integration_behavior = custom_integration_behavior

    if integration_behavior is not ReportBehavior.IGNORE:
        _report_usage_integration_frame(
            hass,
            what,
            breaks_in_ha_version,
            integration_frame,
            level,
            integration_behavior is ReportBehavior.ERROR,
        )


def _report_usage_integration_domain(
    hass: HomeAssistant | None,
    what: str,
    breaks_in_ha_version: str | None,
    integration: Integration,
    core_integration_behavior: ReportBehavior,
    custom_integration_behavior: ReportBehavior,
    level: int,
) -> None:
    """Report incorrect usage in an integration (identified via domain).

    Async friendly.
    """
    integration_behavior = core_integration_behavior
    if not integration.is_built_in:
        integration_behavior = custom_integration_behavior

    if integration_behavior is ReportBehavior.IGNORE:
        return

    # Keep track of integrations already reported to prevent flooding
    key = f"{integration.domain}:{what}"
    if (
        integration_behavior is not ReportBehavior.ERROR
        and key in _REPORTED_INTEGRATIONS
    ):
        return
    _REPORTED_INTEGRATIONS.add(key)

    report_issue = async_suggest_report_issue(hass, integration=integration)
    integration_type = "" if integration.is_built_in else "custom "
    _LOGGER.log(
        level,
        "Detected that %sintegration '%s' %s. %s %s",
        integration_type,
        integration.domain,
        what,
        f"This will stop working in Home Assistant {breaks_in_ha_version}, please"
        if breaks_in_ha_version
        else "Please",
        report_issue,
    )

    if integration_behavior is ReportBehavior.ERROR:
        raise RuntimeError(
            f"Detected that {integration_type}integration "
            f"'{integration.domain}' {what}. Please {report_issue}"
        )


def _report_usage_integration_frame(
    hass: HomeAssistant,
    what: str,
    breaks_in_ha_version: str | None,
    integration_frame: IntegrationFrame,
    level: int = logging.WARNING,
    error: bool = False,
) -> None:
    """Report incorrect usage in an integration (identified via frame).

    Async friendly.
    """
    # Keep track of integrations already reported to prevent flooding
    key = f"{integration_frame.filename}:{integration_frame.line_number}"
    if not error and key in _REPORTED_INTEGRATIONS:
        return
    _REPORTED_INTEGRATIONS.add(key)

    report_issue = async_suggest_report_issue(
        hass,
        integration_domain=integration_frame.integration,
        module=integration_frame.module,
    )
    integration_type = "custom " if integration_frame.custom_integration else ""
    _LOGGER.log(
        level,
        "Detected that %sintegration '%s' %s at %s, line %s: %s. %s %s",
        integration_type,
        integration_frame.integration,
        what,
        integration_frame.relative_filename,
        integration_frame.line_number,
        integration_frame.line,
        f"This will stop working in Home Assistant {breaks_in_ha_version}, please"
        if breaks_in_ha_version
        else "Please",
        report_issue,
    )
    if not error:
        return
    raise RuntimeError(
        f"Detected that {integration_type}integration "
        f"'{integration_frame.integration}' {what} at "
        f"{integration_frame.relative_filename}, line "
        f"{integration_frame.line_number}: {integration_frame.line}. "
        f"Please {report_issue}"
    )


def _report_usage_no_integration(
    what: str,
    core_behavior: ReportBehavior,
    breaks_in_ha_version: str | None,
    err: MissingIntegrationFrame | None,
) -> None:
    """Report incorrect usage without an integration.

    This could happen because the offending call happened outside of an integration,
    or because the integration could not be identified.
    """
    msg = f"Detected code that {what}. Please report this issue"
    if core_behavior is ReportBehavior.ERROR:
        raise RuntimeError(msg) from err
    if core_behavior is ReportBehavior.LOG:
        if breaks_in_ha_version:
            msg = (
                f"Detected code that {what}. This will stop working in Home "
                f"Assistant {breaks_in_ha_version}, please report this issue"
            )
        _LOGGER.warning(msg, stack_info=True)


def warn_use[_CallableT: Callable](func: _CallableT, what: str) -> _CallableT:
    """Mock a function to warn when it was about to be used."""
    if inspect.iscoroutinefunction(func):

        @functools.wraps(func)
        async def report_use(*args: Any, **kwargs: Any) -> None:
            report_usage(what)

    else:

        @functools.wraps(func)
        def report_use(*args: Any, **kwargs: Any) -> None:
            report_usage(what)

    return cast(_CallableT, report_use)


def report_non_thread_safe_operation(what: str) -> None:
    """Report a non-thread safe operation."""
    report_usage(
        f"calls {what} from a thread other than the event loop, "
        "which may cause Home Assistant to crash or data to corrupt. "
        "For more information, see "
        "https://developers.home-assistant.io/docs/asyncio_thread_safety/"
        f"#{what.replace('.', '')}",
        core_behavior=ReportBehavior.ERROR,
        core_integration_behavior=ReportBehavior.ERROR,
        custom_integration_behavior=ReportBehavior.ERROR,
    )
</file>

<file path="group.py">
"""Helper for groups."""

from __future__ import annotations

from collections.abc import Iterable
from typing import Any

from homeassistant.const import ATTR_ENTITY_ID, ENTITY_MATCH_ALL, ENTITY_MATCH_NONE
from homeassistant.core import HomeAssistant

ENTITY_PREFIX = "group."


def expand_entity_ids(hass: HomeAssistant, entity_ids: Iterable[Any]) -> list[str]:
    """Return entity_ids with group entity ids replaced by their members.

    Async friendly.
    """
    found_ids: list[str] = []
    for entity_id in entity_ids:
        if not isinstance(entity_id, str) or entity_id in (
            ENTITY_MATCH_NONE,
            ENTITY_MATCH_ALL,
        ):
            continue

        entity_id = entity_id.lower()
        # If entity_id points at a group, expand it
        if entity_id.startswith(ENTITY_PREFIX):
            child_entities = get_entity_ids(hass, entity_id)
            if entity_id in child_entities:
                child_entities = list(child_entities)
                child_entities.remove(entity_id)
            found_ids.extend(
                ent_id
                for ent_id in expand_entity_ids(hass, child_entities)
                if ent_id not in found_ids
            )
        elif entity_id not in found_ids:
            found_ids.append(entity_id)

    return found_ids


def get_entity_ids(
    hass: HomeAssistant, entity_id: str, domain_filter: str | None = None
) -> list[str]:
    """Get members of this group.

    Async friendly.
    """
    group = hass.states.get(entity_id)
    if not group or ATTR_ENTITY_ID not in group.attributes:
        return []
    entity_ids: list[str] = group.attributes[ATTR_ENTITY_ID]
    if not domain_filter:
        return entity_ids
    domain_filter = f"{domain_filter.lower()}."
    return [ent_id for ent_id in entity_ids if ent_id.startswith(domain_filter)]
</file>

<file path="hassio.py">
"""Hass.io helper."""

import os

from homeassistant.core import HomeAssistant, callback


@callback
def is_hassio(hass: HomeAssistant) -> bool:
    """Return true if Hass.io is loaded.

    Async friendly.
    """
    return "hassio" in hass.config.components


@callback
def get_supervisor_ip() -> str | None:
    """Return the supervisor ip address."""
    if "SUPERVISOR" not in os.environ:
        return None
    return os.environ["SUPERVISOR"].partition(":")[0]
</file>

<file path="helper_integration.py">
"""Helpers for helper integrations."""

from __future__ import annotations

from collections.abc import Callable, Coroutine
from typing import Any

from homeassistant.core import CALLBACK_TYPE, Event, HomeAssistant, valid_entity_id

from . import device_registry as dr, entity_registry as er
from .event import async_track_entity_registry_updated_event


def async_handle_source_entity_changes(
    hass: HomeAssistant,
    *,
    add_helper_config_entry_to_device: bool = True,
    helper_config_entry_id: str,
    set_source_entity_id_or_uuid: Callable[[str], None],
    source_device_id: str | None,
    source_entity_id_or_uuid: str,
    source_entity_removed: Callable[[], Coroutine[Any, Any, None]] | None = None,
) -> CALLBACK_TYPE:
    """Handle changes to a helper entity's source entity.

    The following changes are handled:
    - Entity removal: If the source entity is removed:
      - If source_entity_removed is provided, it is called to handle the removal.
      - If source_entity_removed is not provided, The helper entity is updated to
      not link to any device.
    - Entity ID changed: If the source entity's entity ID changes and the source
      entity is identified by an entity ID, the set_source_entity_id_or_uuid is
      called. If the source entity is identified by a UUID, the helper config entry
      is reloaded.
    - Source entity moved to another device: The helper entity is updated to link
      to the new device, and the helper config entry removed from the old device
      and added to the new device. Then the helper config entry is reloaded.
    - Source entity removed from the device: The helper entity is updated to link
      to no device, and the helper config entry removed from the old device. Then
      the helper config entry is reloaded.

    :param set_source_entity_id_or_uuid: A function which updates the source entity
        ID or UUID, e.g., in the helper config entry options.
    :param source_entity_removed: A function which is called when the source entity
        is removed. This can be used to clean up any resources related to the source
        entity or ask the user to select a new source entity.
    """

    async def async_registry_updated(
        event: Event[er.EventEntityRegistryUpdatedData],
    ) -> None:
        """Handle entity registry update."""
        nonlocal source_device_id

        data = event.data
        if data["action"] == "remove":
            if source_entity_removed:
                await source_entity_removed()
            else:
                for (
                    helper_entity_entry
                ) in entity_registry.entities.get_entries_for_config_entry_id(
                    helper_config_entry_id
                ):
                    # Update the helper entity to link to the new device (or no device)
                    entity_registry.async_update_entity(
                        helper_entity_entry.entity_id, device_id=None
                    )

        if data["action"] != "update":
            return

        if "entity_id" in data["changes"]:
            # Entity_id changed, update or reload the config entry
            if valid_entity_id(source_entity_id_or_uuid):
                # If the entity is pointed to by an entity ID, update the entry
                set_source_entity_id_or_uuid(data["entity_id"])
            else:
                await hass.config_entries.async_reload(helper_config_entry_id)

        if not source_device_id or "device_id" not in data["changes"]:
            return

        # Handle the source entity being moved to a different device or removed
        # from the device
        if (
            not (source_entity_entry := entity_registry.async_get(data["entity_id"]))
            or not device_registry.async_get(source_device_id)
            or source_entity_entry.device_id == source_device_id
        ):
            # No need to do any cleanup
            return

        # The source entity has been moved to a different device, update the helper
        # entities to link to the new device and the helper device to include the
        # helper config entry
        for helper_entity in entity_registry.entities.get_entries_for_config_entry_id(
            helper_config_entry_id
        ):
            # Update the helper entity to link to the new device (or no device)
            entity_registry.async_update_entity(
                helper_entity.entity_id, device_id=source_entity_entry.device_id
            )

        if add_helper_config_entry_to_device:
            if source_entity_entry.device_id is not None:
                device_registry.async_update_device(
                    source_entity_entry.device_id,
                    add_config_entry_id=helper_config_entry_id,
                )

            device_registry.async_update_device(
                source_device_id, remove_config_entry_id=helper_config_entry_id
            )

        source_device_id = source_entity_entry.device_id

        # Reload the config entry so the helper entity is recreated with
        # correct device info
        await hass.config_entries.async_reload(helper_config_entry_id)

    device_registry = dr.async_get(hass)
    entity_registry = er.async_get(hass)
    source_entity_id = er.async_validate_entity_id(
        entity_registry, source_entity_id_or_uuid
    )
    return async_track_entity_registry_updated_event(
        hass, source_entity_id, async_registry_updated
    )


def async_remove_helper_config_entry_from_source_device(
    hass: HomeAssistant,
    *,
    helper_config_entry_id: str,
    source_device_id: str,
) -> None:
    """Remove helper config entry from source device.

    This is a convenience function to migrate from helpers which added their config
    entry to the source device.
    """
    device_registry = dr.async_get(hass)

    if (
        not (source_device := device_registry.async_get(source_device_id))
        or helper_config_entry_id not in source_device.config_entries
    ):
        return

    entity_registry = er.async_get(hass)
    helper_entity_entries = er.async_entries_for_config_entry(
        entity_registry, helper_config_entry_id
    )

    # Disconnect helper entities from the device to prevent them from
    # being removed when the config entry link to the device is removed.
    modified_helpers: list[er.RegistryEntry] = []
    for helper in helper_entity_entries:
        if helper.device_id != source_device_id:
            continue
        modified_helpers.append(helper)
        entity_registry.async_update_entity(helper.entity_id, device_id=None)
    # Remove the helper config entry from the device
    device_registry.async_update_device(
        source_device_id, remove_config_entry_id=helper_config_entry_id
    )
    # Connect the helper entity to the device
    for helper in modified_helpers:
        entity_registry.async_update_entity(
            helper.entity_id, device_id=source_device_id
        )
</file>

<file path="http.py">
"""Helper to track the current http request."""

from __future__ import annotations

from collections.abc import Awaitable, Callable
from contextvars import ContextVar
from http import HTTPStatus
import inspect
import logging
from typing import Any, Final

from aiohttp import web
from aiohttp.typedefs import LooseHeaders
from aiohttp.web import AppKey, Request
from aiohttp.web_exceptions import (
    HTTPBadRequest,
    HTTPInternalServerError,
    HTTPUnauthorized,
)
from aiohttp.web_urldispatcher import AbstractResource, AbstractRoute
import voluptuous as vol

from homeassistant import exceptions
from homeassistant.const import CONTENT_TYPE_JSON
from homeassistant.core import Context, HomeAssistant, is_callback
from homeassistant.util.json import JSON_ENCODE_EXCEPTIONS, format_unserializable_data

from .json import find_paths_unserializable_data, json_bytes, json_dumps

_LOGGER = logging.getLogger(__name__)


type AllowCorsType = Callable[[AbstractRoute | AbstractResource], None]
KEY_AUTHENTICATED: Final = "ha_authenticated"
KEY_ALLOW_ALL_CORS = AppKey[AllowCorsType]("allow_all_cors")
KEY_ALLOW_CONFIGURED_CORS = AppKey[AllowCorsType]("allow_configured_cors")
KEY_HASS: AppKey[HomeAssistant] = AppKey("hass")

current_request: ContextVar[Request | None] = ContextVar(
    "current_request", default=None
)


def request_handler_factory(
    hass: HomeAssistant, view: HomeAssistantView, handler: Callable
) -> Callable[[web.Request], Awaitable[web.StreamResponse]]:
    """Wrap the handler classes."""
    is_coroutinefunction = inspect.iscoroutinefunction(handler)
    assert is_coroutinefunction or is_callback(handler), (
        "Handler should be a coroutine or a callback."
    )

    async def handle(request: web.Request) -> web.StreamResponse:
        """Handle incoming request."""
        if hass.is_stopping:
            return web.Response(status=HTTPStatus.SERVICE_UNAVAILABLE)

        authenticated = request.get(KEY_AUTHENTICATED, False)

        if view.requires_auth and not authenticated:
            raise HTTPUnauthorized

        if _LOGGER.isEnabledFor(logging.DEBUG):
            _LOGGER.debug(
                "Serving %s to %s (auth: %s)",
                request.path,
                request.remote,
                authenticated,
            )

        try:
            if is_coroutinefunction:
                result = await handler(request, **request.match_info)
            else:
                result = handler(request, **request.match_info)
        except vol.Invalid as err:
            raise HTTPBadRequest from err
        except exceptions.ServiceNotFound as err:
            raise HTTPInternalServerError from err
        except exceptions.Unauthorized as err:
            raise HTTPUnauthorized from err

        if isinstance(result, web.StreamResponse):
            # The method handler returned a ready-made Response, how nice of it
            return result

        status_code = HTTPStatus.OK
        if isinstance(result, tuple):
            result, status_code = result

        if isinstance(result, bytes):
            return web.Response(body=result, status=status_code)

        if isinstance(result, str):
            return web.Response(text=result, status=status_code)

        if result is None:
            return web.Response(body=b"", status=status_code)

        raise TypeError(
            f"Result should be None, string, bytes or StreamResponse. Got: {result}"
        )

    return handle


class HomeAssistantView:
    """Base view for all views."""

    url: str | None = None
    extra_urls: list[str] = []
    # Views inheriting from this class can override this
    requires_auth = True
    cors_allowed = False

    @staticmethod
    def context(request: web.Request) -> Context:
        """Generate a context from a request."""
        if (user := request.get("hass_user")) is None:
            return Context()

        return Context(user_id=user.id)

    @staticmethod
    def json(
        result: Any,
        status_code: HTTPStatus | int = HTTPStatus.OK,
        headers: LooseHeaders | None = None,
    ) -> web.Response:
        """Return a JSON response."""
        try:
            msg = json_bytes(result)
        except JSON_ENCODE_EXCEPTIONS as err:
            _LOGGER.error(
                "Unable to serialize to JSON. Bad data found at %s",
                format_unserializable_data(
                    find_paths_unserializable_data(result, dump=json_dumps)
                ),
            )
            raise HTTPInternalServerError from err
        response = web.Response(
            body=msg,
            content_type=CONTENT_TYPE_JSON,
            status=int(status_code),
            headers=headers,
            zlib_executor_size=32768,
        )
        response.enable_compression()
        return response

    def json_message(
        self,
        message: str,
        status_code: HTTPStatus | int = HTTPStatus.OK,
        message_code: str | None = None,
        headers: LooseHeaders | None = None,
    ) -> web.Response:
        """Return a JSON message response."""
        data = {"message": message}
        if message_code is not None:
            data["code"] = message_code
        return self.json(data, status_code, headers=headers)

    def register(
        self, hass: HomeAssistant, app: web.Application, router: web.UrlDispatcher
    ) -> None:
        """Register the view with a router."""
        assert self.url is not None, "No url set for view"
        urls = [self.url, *self.extra_urls]
        routes: list[AbstractRoute] = []

        for method in ("get", "post", "delete", "put", "patch", "head", "options"):
            if not (handler := getattr(self, method, None)):
                continue

            handler = request_handler_factory(hass, self, handler)

            routes.extend(router.add_route(method, url, handler) for url in urls)

        # Use `get` because CORS middleware is not be loaded in emulated_hue
        if self.cors_allowed:
            allow_cors = app.get(KEY_ALLOW_ALL_CORS)
        else:
            allow_cors = app.get(KEY_ALLOW_CONFIGURED_CORS)

        if allow_cors:
            for route in routes:
                allow_cors(route)
</file>

<file path="httpx_client.py">
"""Helper for httpx."""

from __future__ import annotations

from collections.abc import Callable, Coroutine
import sys
from types import TracebackType
from typing import Any, Self

# httpx dynamically imports httpcore, so we need to import it
# to avoid it being imported later when the event loop is running
import httpcore  # noqa: F401
import httpx

from homeassistant.const import APPLICATION_NAME, EVENT_HOMEASSISTANT_CLOSE, __version__
from homeassistant.core import Event, HomeAssistant, callback
from homeassistant.loader import bind_hass
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.ssl import (
    SSL_ALPN_HTTP11,
    SSL_ALPN_HTTP11_HTTP2,
    SSLALPNProtocols,
    SSLCipherList,
    client_context,
    create_no_verify_ssl_context,
)

from .frame import warn_use

# We have a lot of integrations that poll every 10-30 seconds
# and we want to keep the connection open for a while so we
# don't have to reconnect every time so we use 15s to match aiohttp.
KEEP_ALIVE_TIMEOUT = 15
# Shared httpx clients keyed by (verify_ssl, alpn_protocols)
DATA_ASYNC_CLIENT: HassKey[dict[tuple[bool, SSLALPNProtocols], httpx.AsyncClient]] = (
    HassKey("httpx_async_client")
)
DEFAULT_LIMITS = limits = httpx.Limits(keepalive_expiry=KEEP_ALIVE_TIMEOUT)
SERVER_SOFTWARE = (
    f"{APPLICATION_NAME}/{__version__} "
    f"httpx/{httpx.__version__} Python/{sys.version_info[0]}.{sys.version_info[1]}"
)
USER_AGENT = "User-Agent"


@callback
@bind_hass
def get_async_client(
    hass: HomeAssistant,
    verify_ssl: bool = True,
    alpn_protocols: SSLALPNProtocols = SSL_ALPN_HTTP11,
) -> httpx.AsyncClient:
    """Return default httpx AsyncClient.

    This method must be run in the event loop.

    Pass alpn_protocols=SSL_ALPN_HTTP11_HTTP2 to get a client configured for HTTP/2.
    Clients are cached separately by ALPN protocol to ensure proper SSL context
    configuration (ALPN protocols differ between HTTP versions).
    """
    client_key = (verify_ssl, alpn_protocols)
    clients = hass.data.setdefault(DATA_ASYNC_CLIENT, {})

    if (client := clients.get(client_key)) is None:
        client = clients[client_key] = create_async_httpx_client(
            hass, verify_ssl, alpn_protocols=alpn_protocols
        )

    return client


class HassHttpXAsyncClient(httpx.AsyncClient):
    """httpx AsyncClient that suppresses context management."""

    async def __aenter__(self) -> Self:
        """Prevent an integration from reopen of the client via context manager."""
        return self

    async def __aexit__(
        self,
        exc_type: type[BaseException] | None = None,
        exc_value: BaseException | None = None,
        traceback: TracebackType | None = None,
    ) -> None:
        """Prevent an integration from close of the client via context manager."""


@callback
def create_async_httpx_client(
    hass: HomeAssistant,
    verify_ssl: bool = True,
    auto_cleanup: bool = True,
    ssl_cipher_list: SSLCipherList = SSLCipherList.PYTHON_DEFAULT,
    alpn_protocols: SSLALPNProtocols = SSL_ALPN_HTTP11,
    **kwargs: Any,
) -> httpx.AsyncClient:
    """Create a new httpx.AsyncClient with kwargs, i.e. for cookies.

    If auto_cleanup is False, the client will be
    automatically closed on homeassistant_stop.

    Pass alpn_protocols=SSL_ALPN_HTTP11_HTTP2 for HTTP/2 support (automatically
    enables httpx http2 mode).

    This method must be run in the event loop.
    """
    # Use the requested ALPN protocols directly to ensure proper SSL context
    # bucketing. httpx/httpcore mutates SSL contexts by calling set_alpn_protocols(),
    # so we pre-set the correct protocols to prevent shared context corruption.
    ssl_context = (
        client_context(ssl_cipher_list, alpn_protocols)
        if verify_ssl
        else create_no_verify_ssl_context(ssl_cipher_list, alpn_protocols)
    )
    # Enable httpx HTTP/2 mode when HTTP/2 protocol is requested
    if alpn_protocols == SSL_ALPN_HTTP11_HTTP2:
        kwargs.setdefault("http2", True)
    client = HassHttpXAsyncClient(
        verify=ssl_context,
        headers={
            USER_AGENT: SERVER_SOFTWARE,
            **kwargs.pop("headers", {}),
        },
        limits=DEFAULT_LIMITS,
        **kwargs,
    )

    original_aclose = client.aclose

    client.aclose = warn_use(  # type: ignore[method-assign]
        client.aclose, "closes the Home Assistant httpx client"
    )

    if auto_cleanup:
        _async_register_async_client_shutdown(hass, client, original_aclose)

    return client


@callback
def _async_register_async_client_shutdown(
    hass: HomeAssistant,
    client: httpx.AsyncClient,
    original_aclose: Callable[[], Coroutine[Any, Any, None]],
) -> None:
    """Register httpx AsyncClient aclose on Home Assistant shutdown.

    This method must be run in the event loop.
    """

    async def _async_close_client(event: Event) -> None:
        """Close httpx client."""
        await original_aclose()

    hass.bus.async_listen_once(EVENT_HOMEASSISTANT_CLOSE, _async_close_client)
</file>

<file path="icon.py">
"""Icon helper methods."""

from __future__ import annotations

import asyncio
from collections.abc import Iterable
from functools import lru_cache
import logging
import pathlib
from typing import Any, cast

from homeassistant.core import HomeAssistant, callback
from homeassistant.loader import Integration, async_get_integrations
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.json import load_json_object

from .translation import build_resources

ICON_CACHE: HassKey[_IconsCache] = HassKey("icon_cache")

_LOGGER = logging.getLogger(__name__)


def convert_shorthand_service_icon(
    value: str | dict[str, str | dict[str, str]],
) -> dict[str, str | dict[str, str]]:
    """Convert shorthand service icon to dict."""
    if isinstance(value, str):
        return {"service": value}
    return value


def _load_icons_file(
    icons_file: pathlib.Path,
) -> dict[str, Any]:
    """Load and parse an icons.json file."""
    icons = load_json_object(icons_file)
    if "services" not in icons:
        return icons
    services = cast(dict[str, str | dict[str, str | dict[str, str]]], icons["services"])
    for service, service_icons in services.items():
        services[service] = convert_shorthand_service_icon(service_icons)
    return icons


def _load_icons_files(
    icons_files: dict[str, pathlib.Path],
) -> dict[str, dict[str, Any]]:
    """Load and parse icons.json files."""
    return {
        component: _load_icons_file(icons_file)
        for component, icons_file in icons_files.items()
    }


async def _async_get_component_icons(
    hass: HomeAssistant,
    components: set[str],
    integrations: dict[str, Integration],
) -> dict[str, Any]:
    """Load icons."""
    icons: dict[str, Any] = {}

    # Determine files to load
    files_to_load = {
        comp: integrations[comp].file_path / "icons.json" for comp in components
    }

    # Load files
    if files_to_load:
        icons.update(
            await hass.async_add_executor_job(_load_icons_files, files_to_load)
        )

    return icons


class _IconsCache:
    """Cache for icons."""

    __slots__ = ("_cache", "_hass", "_loaded", "_lock")

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the cache."""
        self._hass = hass
        self._loaded: set[str] = set()
        self._cache: dict[str, dict[str, Any]] = {}
        self._lock = asyncio.Lock()

    async def async_fetch(
        self,
        category: str,
        components: set[str],
    ) -> dict[str, dict[str, Any]]:
        """Load resources into the cache."""
        if components_to_load := components - self._loaded:
            # Icons are never unloaded so if there are no components to load
            # we can skip the lock which reduces contention
            async with self._lock:
                # Check components to load again, as another task might have loaded
                # them while we were waiting for the lock.
                if components_to_load := components - self._loaded:
                    await self._async_load(components_to_load)

        return {
            component: result
            for component in components
            if (result := self._cache.get(category, {}).get(component))
        }

    async def _async_load(self, components: set[str]) -> None:
        """Populate the cache for a given set of components."""
        _LOGGER.debug("Cache miss for: %s", components)

        integrations: dict[str, Integration] = {}
        ints_or_excs = await async_get_integrations(self._hass, components)
        for domain, int_or_exc in ints_or_excs.items():
            if isinstance(int_or_exc, Exception):
                raise int_or_exc
            integrations[domain] = int_or_exc

        icons = await _async_get_component_icons(self._hass, components, integrations)

        self._build_category_cache(components, icons)
        self._loaded.update(components)

    @callback
    def _build_category_cache(
        self,
        components: set[str],
        icons: dict[str, dict[str, Any]],
    ) -> None:
        """Extract resources into the cache."""
        categories = {
            category for component in icons.values() for category in component
        }
        for category in categories:
            self._cache.setdefault(category, {}).update(
                build_resources(icons, components, category)
            )


async def async_get_icons(
    hass: HomeAssistant,
    category: str,
    integrations: Iterable[str] | None = None,
) -> dict[str, Any]:
    """Return all icons of integrations.

    If integration specified, load it for that one; otherwise default to loaded
    integrations.
    """
    if integrations:
        components = set(integrations)
    else:
        components = hass.config.top_level_components

    if ICON_CACHE in hass.data:
        cache = hass.data[ICON_CACHE]
    else:
        cache = hass.data[ICON_CACHE] = _IconsCache(hass)

    return await cache.async_fetch(category, components)


@lru_cache
def icon_for_battery_level(
    battery_level: int | None = None, charging: bool = False
) -> str:
    """Return a battery icon valid identifier."""
    icon = "mdi:battery"
    if battery_level is None:
        return f"{icon}-unknown"
    if charging and battery_level > 10:
        icon += f"-charging-{int(round(battery_level / 20 - 0.01)) * 20}"
    elif charging:
        icon += "-outline"
    elif battery_level <= 5:
        icon += "-alert"
    elif 5 < battery_level < 95:
        icon += f"-{int(round(battery_level / 10 - 0.01)) * 10}"
    return icon


def icon_for_signal_level(signal_level: int | None = None) -> str:
    """Return a signal icon valid identifier."""
    if signal_level is None or signal_level == 0:
        return "mdi:signal-cellular-outline"
    if signal_level > 70:
        return "mdi:signal-cellular-3"
    if signal_level > 30:
        return "mdi:signal-cellular-2"
    return "mdi:signal-cellular-1"
</file>

<file path="importlib.py">
"""Helper to import modules from asyncio."""

from __future__ import annotations

import asyncio
from contextlib import suppress
import importlib
import logging
import sys
from types import ModuleType

from homeassistant.core import HomeAssistant
from homeassistant.util.hass_dict import HassKey

_LOGGER = logging.getLogger(__name__)

DATA_IMPORT_CACHE: HassKey[dict[str, ModuleType]] = HassKey("import_cache")
DATA_IMPORT_FUTURES: HassKey[dict[str, asyncio.Future[ModuleType]]] = HassKey(
    "import_futures"
)
DATA_IMPORT_FAILURES: HassKey[dict[str, bool]] = HassKey("import_failures")


def _get_module(cache: dict[str, ModuleType], name: str) -> ModuleType:
    """Get a module."""
    cache[name] = importlib.import_module(name)
    return cache[name]


async def async_import_module(hass: HomeAssistant, name: str) -> ModuleType:
    """Import a module or return it from the cache."""
    cache = hass.data.setdefault(DATA_IMPORT_CACHE, {})
    if module := cache.get(name):
        return module

    failure_cache = hass.data.setdefault(DATA_IMPORT_FAILURES, {})
    if name in failure_cache:
        raise ModuleNotFoundError(f"{name} not found", name=name)

    import_futures = hass.data.setdefault(DATA_IMPORT_FUTURES, {})
    if future := import_futures.get(name):
        return await future

    if name in sys.modules:
        return _get_module(cache, name)

    import_future = hass.loop.create_future()
    import_futures[name] = import_future
    try:
        module = await hass.async_add_import_executor_job(_get_module, cache, name)
        import_future.set_result(module)
    except BaseException as ex:
        if isinstance(ex, ModuleNotFoundError):
            failure_cache[name] = True
        import_future.set_exception(ex)
        with suppress(BaseException):
            # Set the exception retrieved flag on the future since
            # it will never be retrieved unless there
            # are concurrent calls
            import_future.result()
        raise
    finally:
        del import_futures[name]

    return module
</file>

<file path="instance_id.py">
"""Helper to create a unique instance ID."""

from __future__ import annotations

import logging
import uuid

from homeassistant.core import HomeAssistant

from . import singleton, storage

DATA_KEY = "core.uuid"
DATA_VERSION = 1

LEGACY_UUID_FILE = ".uuid"

_LOGGER = logging.getLogger(__name__)


@singleton.singleton(DATA_KEY)
async def async_get(hass: HomeAssistant) -> str:
    """Get unique ID for the hass instance."""
    store = storage.Store[dict[str, str]](hass, DATA_VERSION, DATA_KEY, True)

    data: dict[str, str] | None = None
    try:
        data = await storage.async_migrator(
            hass,
            hass.config.path(LEGACY_UUID_FILE),
            store,
        )
    except Exception:
        _LOGGER.exception(
            (
                "Could not read hass instance ID from '%s' or '%s', a new instance ID "
                "will be generated"
            ),
            DATA_KEY,
            LEGACY_UUID_FILE,
        )

    if data is not None:
        return data["uuid"]

    data = {"uuid": uuid.uuid4().hex}

    await store.async_save(data)

    return data["uuid"]


async def async_recreate(hass: HomeAssistant) -> str:
    """Recreate a new unique ID for the hass instance."""
    store = storage.Store[dict[str, str]](hass, DATA_VERSION, DATA_KEY, True)

    data = {"uuid": uuid.uuid4().hex}

    await store.async_save(data)

    return data["uuid"]
</file>

<file path="integration_platform.py">
"""Helpers to help with integration platforms."""

from __future__ import annotations

import asyncio
from collections.abc import Awaitable, Callable
from dataclasses import dataclass
from functools import partial
import logging
from types import ModuleType
from typing import Any

from homeassistant.const import EVENT_COMPONENT_LOADED
from homeassistant.core import Event, HassJob, HomeAssistant, callback
from homeassistant.loader import (
    Integration,
    async_get_integrations,
    async_get_loaded_integration,
    async_register_preload_platform,
    bind_hass,
)
from homeassistant.setup import ATTR_COMPONENT, EventComponentLoaded
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.logging import catch_log_exception

_LOGGER = logging.getLogger(__name__)
DATA_INTEGRATION_PLATFORMS: HassKey[list[IntegrationPlatform]] = HassKey(
    "integration_platforms"
)


@dataclass(slots=True, frozen=True)
class IntegrationPlatform:
    """An integration platform."""

    platform_name: str
    process_job: HassJob[[HomeAssistant, str, Any], Awaitable[None] | None]
    seen_components: set[str]


@callback
def _async_integration_platform_component_loaded(
    hass: HomeAssistant,
    integration_platforms: list[IntegrationPlatform],
    event: Event[EventComponentLoaded],
) -> None:
    """Process integration platforms for a component."""
    if "." in (component_name := event.data[ATTR_COMPONENT]):
        return

    integration = async_get_loaded_integration(hass, component_name)
    # First filter out platforms that the integration already processed.
    integration_platforms_by_name: dict[str, IntegrationPlatform] = {}
    for integration_platform in integration_platforms:
        if component_name in integration_platform.seen_components:
            continue
        integration_platform.seen_components.add(component_name)
        integration_platforms_by_name[integration_platform.platform_name] = (
            integration_platform
        )

    if not integration_platforms_by_name:
        return

    # Next, check which platforms exist for this integration.
    platforms_that_exist = integration.platforms_exists(integration_platforms_by_name)
    if not platforms_that_exist:
        return

    # If everything is already loaded, we can avoid creating a task.
    can_use_cache = True
    platforms: dict[str, ModuleType] = {}
    for platform_name in platforms_that_exist:
        if platform := integration.get_platform_cached(platform_name):
            platforms[platform_name] = platform
        else:
            can_use_cache = False
            break

    if can_use_cache:
        _process_integration_platforms(
            hass,
            integration,
            platforms,
            integration_platforms_by_name,
        )
        return

    # At least one of the platforms is not loaded, we need to load them
    # so we have to fall back to creating a task.
    hass.async_create_task_internal(
        _async_process_integration_platforms_for_component(
            hass, integration, platforms_that_exist, integration_platforms_by_name
        ),
        eager_start=True,
    )


async def _async_process_integration_platforms_for_component(
    hass: HomeAssistant,
    integration: Integration,
    platforms_that_exist: list[str],
    integration_platforms_by_name: dict[str, IntegrationPlatform],
) -> None:
    """Process integration platforms for a component."""
    # Now we know which platforms to load, let's load them.
    try:
        platforms = await integration.async_get_platforms(platforms_that_exist)
    except ImportError:
        _LOGGER.debug(
            "Unexpected error importing integration platforms for %s",
            integration.domain,
        )
        return

    if futures := _process_integration_platforms(
        hass,
        integration,
        platforms,
        integration_platforms_by_name,
    ):
        await asyncio.gather(*futures)


@callback
def _process_integration_platforms(
    hass: HomeAssistant,
    integration: Integration,
    platforms: dict[str, ModuleType],
    integration_platforms_by_name: dict[str, IntegrationPlatform],
) -> list[asyncio.Future[Awaitable[None] | None]]:
    """Process integration platforms for a component.

    Only the platforms that are passed in will be processed.
    """
    return [
        future
        for platform_name, platform in platforms.items()
        if (integration_platform := integration_platforms_by_name[platform_name])
        and (
            future := hass.async_run_hass_job(
                integration_platform.process_job,
                hass,
                integration.domain,
                platform,
            )
        )
    ]


def _format_err(name: str, platform_name: str, *args: Any) -> str:
    """Format error message."""
    return f"Exception in {name} when processing platform '{platform_name}': {args}"


@bind_hass
async def async_process_integration_platforms(
    hass: HomeAssistant,
    platform_name: str,
    # Any = platform.
    process_platform: Callable[[HomeAssistant, str, Any], Awaitable[None] | None],
    wait_for_platforms: bool = False,
) -> None:
    """Process a specific platform for all current and future loaded integrations."""
    if DATA_INTEGRATION_PLATFORMS not in hass.data:
        integration_platforms = hass.data[DATA_INTEGRATION_PLATFORMS] = []
        hass.bus.async_listen(
            EVENT_COMPONENT_LOADED,
            partial(
                _async_integration_platform_component_loaded,
                hass,
                integration_platforms,
            ),
        )
    else:
        integration_platforms = hass.data[DATA_INTEGRATION_PLATFORMS]

    # Tell the loader that it should try to pre-load the integration
    # for any future components that are loaded so we can reduce the
    # amount of import executor usage.
    async_register_preload_platform(hass, platform_name)
    top_level_components = hass.config.top_level_components.copy()
    process_job = HassJob(
        catch_log_exception(
            process_platform,
            partial(_format_err, str(process_platform), platform_name),
        ),
        f"process_platform {platform_name}",
    )
    integration_platform = IntegrationPlatform(
        platform_name, process_job, top_level_components
    )
    integration_platforms.append(integration_platform)
    if not top_level_components:
        return

    # We create a task here for two reasons:
    #
    # 1. We want the integration that provides the integration platform to
    #    not be delayed by waiting on each individual platform to be processed
    #    since the import or the integration platforms themselves may have to
    #    schedule I/O or executor jobs.
    #
    # 2. We want the behavior to be the same as if the integration that has
    #    the integration platform is loaded after the platform is processed.
    #
    # We use hass.async_create_task instead of asyncio.create_task because
    # we want to make sure that startup waits for the task to complete.
    #
    future = hass.async_create_task_internal(
        _async_process_integration_platforms(
            hass, platform_name, top_level_components.copy(), process_job
        ),
        eager_start=True,
    )
    if wait_for_platforms:
        await future


async def _async_process_integration_platforms(
    hass: HomeAssistant,
    platform_name: str,
    top_level_components: set[str],
    process_job: HassJob,
) -> None:
    """Process integration platforms for a component."""
    integrations = await async_get_integrations(hass, top_level_components)
    loaded_integrations: list[Integration] = [
        integration
        for integration in integrations.values()
        if not isinstance(integration, Exception)
    ]
    # Finally, fetch the platforms for each integration and process them.
    # This uses the import executor in a loop. If there are a lot
    # of integration with the integration platform to process,
    # this could be a bottleneck.
    futures: list[asyncio.Future[None]] = []
    for integration in loaded_integrations:
        if not integration.platforms_exists((platform_name,)):
            continue
        try:
            platform = await integration.async_get_platform(platform_name)
        except ImportError:
            _LOGGER.debug(
                "Unexpected error importing %s for %s",
                platform_name,
                integration.domain,
            )
            continue

        if future := hass.async_run_hass_job(
            process_job, hass, integration.domain, platform
        ):
            futures.append(future)

    if futures:
        await asyncio.gather(*futures)
</file>

<file path="intent.py">
"""Module to coordinate user intentions."""

from __future__ import annotations

from abc import abstractmethod
import asyncio
from collections.abc import Callable, Collection, Coroutine, Iterable
import dataclasses
from dataclasses import dataclass, field
from enum import Enum, StrEnum, auto
from itertools import groupby
import logging
from typing import Any

from propcache.api import cached_property
import voluptuous as vol

from homeassistant.components.homeassistant.exposed_entities import async_should_expose
from homeassistant.const import (
    ATTR_DEVICE_CLASS,
    ATTR_ENTITY_ID,
    ATTR_SUPPORTED_FEATURES,
)
from homeassistant.core import Context, HomeAssistant, State, callback
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import bind_hass
from homeassistant.util.hass_dict import HassKey

from . import (
    area_registry,
    config_validation as cv,
    device_registry,
    entity_registry,
    floor_registry,
)
from .deprecation import EnumWithDeprecatedMembers
from .typing import VolSchemaType

_LOGGER = logging.getLogger(__name__)
type _SlotsType = dict[str, Any]
type _IntentSlotsType = dict[
    str | tuple[str, str], IntentSlotInfo | VolSchemaType | Callable[[Any], Any]
]

INTENT_TURN_OFF = "HassTurnOff"
INTENT_TURN_ON = "HassTurnOn"
INTENT_TOGGLE = "HassToggle"
INTENT_GET_STATE = "HassGetState"
INTENT_NEVERMIND = "HassNevermind"
INTENT_SET_POSITION = "HassSetPosition"
INTENT_STOP_MOVING = "HassStopMoving"
INTENT_START_TIMER = "HassStartTimer"
INTENT_CANCEL_TIMER = "HassCancelTimer"
INTENT_CANCEL_ALL_TIMERS = "HassCancelAllTimers"
INTENT_INCREASE_TIMER = "HassIncreaseTimer"
INTENT_DECREASE_TIMER = "HassDecreaseTimer"
INTENT_PAUSE_TIMER = "HassPauseTimer"
INTENT_UNPAUSE_TIMER = "HassUnpauseTimer"
INTENT_TIMER_STATUS = "HassTimerStatus"
INTENT_GET_CURRENT_DATE = "HassGetCurrentDate"
INTENT_GET_CURRENT_TIME = "HassGetCurrentTime"
INTENT_RESPOND = "HassRespond"
INTENT_BROADCAST = "HassBroadcast"
INTENT_GET_TEMPERATURE = "HassClimateGetTemperature"

SLOT_SCHEMA = vol.Schema({}, extra=vol.ALLOW_EXTRA)

DATA_KEY: HassKey[dict[str, IntentHandler]] = HassKey("intent")

SPEECH_TYPE_PLAIN = "plain"
SPEECH_TYPE_SSML = "ssml"


@callback
@bind_hass
def async_register(hass: HomeAssistant, handler: IntentHandler) -> None:
    """Register an intent with Home Assistant."""
    if (intents := hass.data.get(DATA_KEY)) is None:
        intents = {}
        hass.data[DATA_KEY] = intents

    assert getattr(handler, "intent_type", None), "intent_type should be set"

    if handler.intent_type in intents:
        _LOGGER.warning(
            "Intent %s is being overwritten by %s", handler.intent_type, handler
        )

    intents[handler.intent_type] = handler


@callback
@bind_hass
def async_remove(hass: HomeAssistant, intent_type: str) -> None:
    """Remove an intent from Home Assistant."""
    if (intents := hass.data.get(DATA_KEY)) is None:
        return

    intents.pop(intent_type, None)


@callback
def async_get(hass: HomeAssistant) -> Iterable[IntentHandler]:
    """Return registered intents."""
    return hass.data.get(DATA_KEY, {}).values()


@bind_hass
async def async_handle(
    hass: HomeAssistant,
    platform: str,
    intent_type: str,
    slots: _SlotsType | None = None,
    text_input: str | None = None,
    context: Context | None = None,
    language: str | None = None,
    assistant: str | None = None,
    device_id: str | None = None,
    satellite_id: str | None = None,
    conversation_agent_id: str | None = None,
) -> IntentResponse:
    """Handle an intent."""
    handler = hass.data.get(DATA_KEY, {}).get(intent_type)

    if handler is None:
        raise UnknownIntent(f"Unknown intent {intent_type}")

    if context is None:
        context = Context()

    if language is None:
        language = hass.config.language

    intent = Intent(
        hass,
        platform=platform,
        intent_type=intent_type,
        slots=slots or {},
        text_input=text_input,
        context=context,
        language=language,
        assistant=assistant,
        device_id=device_id,
        satellite_id=satellite_id,
        conversation_agent_id=conversation_agent_id,
    )

    try:
        _LOGGER.info("Triggering intent handler %s", handler)
        result = await handler.async_handle(intent)
    except vol.Invalid as err:
        _LOGGER.warning("Received invalid slot info for %s: %s", intent_type, err)
        raise InvalidSlotInfo(f"Received invalid slot info for {intent_type}") from err
    except IntentError:
        raise  # bubble up intent related errors
    except Exception as err:
        _LOGGER.exception("Error handling %s", intent_type)
        raise IntentUnexpectedError(f"Error handling {intent_type}") from err
    return result


class IntentError(HomeAssistantError):
    """Base class for intent related errors."""


class UnknownIntent(IntentError):
    """When the intent is not registered."""


class InvalidSlotInfo(IntentError):
    """When the slot data is invalid."""


class IntentHandleError(IntentError):
    """Error while handling intent."""

    def __init__(self, message: str = "", response_key: str | None = None) -> None:
        """Initialize error."""
        super().__init__(message)
        self.response_key = response_key


class IntentUnexpectedError(IntentError):
    """Unexpected error while handling intent."""


class MatchFailedReason(Enum):
    """Possible reasons for match failure in async_match_targets."""

    NAME = auto()
    """No entities matched name constraint."""

    AREA = auto()
    """No entities matched area constraint."""

    FLOOR = auto()
    """No entities matched floor constraint."""

    DOMAIN = auto()
    """No entities matched domain constraint."""

    DEVICE_CLASS = auto()
    """No entities matched device class constraint."""

    FEATURE = auto()
    """No entities matched supported features constraint."""

    STATE = auto()
    """No entities matched required states constraint."""

    ASSISTANT = auto()
    """No entities matched exposed to assistant constraint."""

    INVALID_AREA = auto()
    """Area name from constraint does not exist."""

    INVALID_FLOOR = auto()
    """Floor name from constraint does not exist."""

    DUPLICATE_NAME = auto()
    """Two or more entities matched the same name constraint and could not be disambiguated."""

    MULTIPLE_TARGETS = auto()
    """Two or more entities matched when a single target is required."""

    def is_no_entities_reason(self) -> bool:
        """Return True if the match failed because no entities matched."""
        return self not in (
            MatchFailedReason.INVALID_AREA,
            MatchFailedReason.INVALID_FLOOR,
            MatchFailedReason.DUPLICATE_NAME,
        )


@dataclass
class MatchTargetsConstraints:
    """Constraints for async_match_targets."""

    name: str | None = None
    """Entity name or alias."""

    area_name: str | None = None
    """Area name, id, or alias."""

    floor_name: str | None = None
    """Floor name, id, or alias."""

    domains: Collection[str] | None = None
    """Domain names."""

    device_classes: Collection[str] | None = None
    """Device class names."""

    features: int | None = None
    """Required supported features."""

    states: Collection[str] | None = None
    """Required states for entities."""

    assistant: str | None = None
    """Name of assistant that entities should be exposed to."""

    allow_duplicate_names: bool = False
    """True if entities with duplicate names are allowed in result."""

    single_target: bool = False
    """True if result must contain a single target."""

    @property
    def has_constraints(self) -> bool:
        """Returns True if at least one constraint is set (ignores assistant)."""
        return bool(
            self.name
            or self.area_name
            or self.floor_name
            or self.domains
            or self.device_classes
            or self.features
            or self.states
            or self.single_target
        )


@dataclass
class MatchTargetsPreferences:
    """Preferences used to disambiguate duplicate name matches in async_match_targets."""

    area_id: str | None = None
    """Id of area to use when deduplicating names."""

    floor_id: str | None = None
    """Id of floor to use when deduplicating names."""


@dataclass
class MatchTargetsResult:
    """Result from async_match_targets."""

    is_match: bool
    """True if one or more entities matched."""

    no_match_reason: MatchFailedReason | None = None
    """Reason for failed match when is_match = False."""

    states: list[State] = field(default_factory=list)
    """List of matched entity states."""

    no_match_name: str | None = None
    """Name of invalid area/floor or duplicate name when match fails for those reasons."""

    areas: list[area_registry.AreaEntry] = field(default_factory=list)
    """Areas that were targeted."""

    floors: list[floor_registry.FloorEntry] = field(default_factory=list)
    """Floors that were targeted."""


class MatchFailedError(IntentError):
    """Error when target matching fails."""

    def __init__(
        self,
        result: MatchTargetsResult,
        constraints: MatchTargetsConstraints,
        preferences: MatchTargetsPreferences | None = None,
    ) -> None:
        """Initialize error."""
        super().__init__()

        self.result = result
        self.constraints = constraints
        self.preferences = preferences

    def __str__(self) -> str:
        """Return string representation."""
        return f"<MatchFailedError result={self.result}, constraints={self.constraints}, preferences={self.preferences}>"


class NoStatesMatchedError(MatchFailedError):
    """Error when no states match the intent's constraints."""

    def __init__(
        self,
        reason: MatchFailedReason,
        name: str | None = None,
        area: str | None = None,
        floor: str | None = None,
        domains: set[str] | None = None,
        device_classes: set[str] | None = None,
    ) -> None:
        """Initialize error."""
        super().__init__(
            result=MatchTargetsResult(False, reason),
            constraints=MatchTargetsConstraints(
                name=name,
                area_name=area,
                floor_name=floor,
                domains=domains,
                device_classes=device_classes,
            ),
        )


@dataclass
class MatchTargetsCandidate:
    """Candidate for async_match_targets."""

    state: State
    is_exposed: bool
    entity: entity_registry.RegistryEntry | None = None
    area: area_registry.AreaEntry | None = None
    device: device_registry.DeviceEntry | None = None
    matched_name: str | None = None


def find_areas(
    name: str, areas: area_registry.AreaRegistry
) -> Iterable[area_registry.AreaEntry]:
    """Find all areas matching a name (including aliases)."""
    name_norm = _normalize_name(name)
    for area in areas.async_list_areas():
        # Accept name or area id
        if (area.id == name) or (_normalize_name(area.name) == name_norm):
            yield area
            continue

        if not area.aliases:
            continue

        for alias in area.aliases:
            if _normalize_name(alias) == name_norm:
                yield area
                break


def find_floors(
    name: str, floors: floor_registry.FloorRegistry
) -> Iterable[floor_registry.FloorEntry]:
    """Find all floors matching a name (including aliases)."""
    name_norm = _normalize_name(name)
    for floor in floors.async_list_floors():
        # Accept name or floor id
        if (floor.floor_id == name) or (_normalize_name(floor.name) == name_norm):
            yield floor
            continue

        if not floor.aliases:
            continue

        for alias in floor.aliases:
            if _normalize_name(alias) == name_norm:
                yield floor
                break


def _normalize_name(name: str) -> str:
    """Normalize name for comparison."""
    return name.strip().casefold()


def _filter_by_name(
    name: str,
    candidates: Iterable[MatchTargetsCandidate],
) -> Iterable[MatchTargetsCandidate]:
    """Filter candidates by name."""
    name_norm = _normalize_name(name)

    for candidate in candidates:
        # Accept name or entity id
        if (candidate.state.entity_id == name) or _normalize_name(
            candidate.state.name
        ) == name_norm:
            candidate.matched_name = name
            yield candidate
            continue

        if candidate.entity is None:
            continue

        if candidate.entity.name and (
            _normalize_name(candidate.entity.name) == name_norm
        ):
            candidate.matched_name = name
            yield candidate
            continue

        # Check aliases
        if candidate.entity.aliases:
            for alias in candidate.entity.aliases:
                if _normalize_name(alias) == name_norm:
                    candidate.matched_name = name
                    yield candidate
                    break


def _filter_by_features(
    features: int,
    candidates: Iterable[MatchTargetsCandidate],
) -> Iterable[MatchTargetsCandidate]:
    """Filter candidates by supported features."""
    for candidate in candidates:
        if (candidate.entity is not None) and (
            (candidate.entity.supported_features & features) == features
        ):
            yield candidate
            continue

        supported_features = candidate.state.attributes.get(ATTR_SUPPORTED_FEATURES, 0)
        if (supported_features & features) == features:
            yield candidate


def _filter_by_device_classes(
    device_classes: Iterable[str],
    candidates: Iterable[MatchTargetsCandidate],
) -> Iterable[MatchTargetsCandidate]:
    """Filter candidates by device classes."""
    for candidate in candidates:
        if (
            (candidate.entity is not None)
            and candidate.entity.device_class
            and (candidate.entity.device_class in device_classes)
        ):
            yield candidate
            continue

        device_class = candidate.state.attributes.get(ATTR_DEVICE_CLASS)
        if device_class and (device_class in device_classes):
            yield candidate


def _add_areas(
    areas: area_registry.AreaRegistry,
    devices: device_registry.DeviceRegistry,
    candidates: Iterable[MatchTargetsCandidate],
) -> None:
    """Add area and device entries to match candidates."""
    for candidate in candidates:
        if candidate.entity is None:
            continue

        if candidate.entity.device_id:
            candidate.device = devices.async_get(candidate.entity.device_id)

        if candidate.entity.area_id:
            # Use entity area first
            candidate.area = areas.async_get_area(candidate.entity.area_id)
            assert candidate.area is not None
        elif (candidate.device is not None) and candidate.device.area_id:
            # Fall back to device area
            candidate.area = areas.async_get_area(candidate.device.area_id)


def _default_area_candidate_filter(
    candidate: MatchTargetsCandidate, possible_area_ids: Collection[str]
) -> bool:
    """Keep candidates in the possible areas."""
    return (candidate.area is not None) and (candidate.area.id in possible_area_ids)


@callback
def async_match_targets(  # noqa: C901
    hass: HomeAssistant,
    constraints: MatchTargetsConstraints,
    preferences: MatchTargetsPreferences | None = None,
    states: list[State] | None = None,
    area_candidate_filter: Callable[
        [MatchTargetsCandidate, Collection[str]], bool
    ] = _default_area_candidate_filter,
) -> MatchTargetsResult:
    """Match entities based on constraints in order to handle an intent."""
    preferences = preferences or MatchTargetsPreferences()
    filtered_by_domain = False

    if not states:
        # Get all states and filter by domain
        states = hass.states.async_all(constraints.domains)
        filtered_by_domain = True
        if not states:
            return MatchTargetsResult(False, MatchFailedReason.DOMAIN)

    candidates = [
        MatchTargetsCandidate(
            state=state,
            is_exposed=(
                async_should_expose(hass, constraints.assistant, state.entity_id)
                if constraints.assistant
                else True
            ),
        )
        for state in states
    ]

    if constraints.domains and (not filtered_by_domain):
        # Filter by domain (if we didn't already do it)
        candidates = [c for c in candidates if c.state.domain in constraints.domains]
        if not candidates:
            return MatchTargetsResult(False, MatchFailedReason.DOMAIN)

    if constraints.states:
        # Filter by state
        candidates = [c for c in candidates if c.state.state in constraints.states]
        if not candidates:
            return MatchTargetsResult(False, MatchFailedReason.STATE)

    # Try to exit early so we can avoid registry lookups
    if not (
        constraints.name
        or constraints.features
        or constraints.device_classes
        or constraints.area_name
        or constraints.floor_name
        or constraints.single_target
    ):
        if constraints.assistant:
            # Check exposure
            candidates = [c for c in candidates if c.is_exposed]
            if not candidates:
                return MatchTargetsResult(False, MatchFailedReason.ASSISTANT)

        return MatchTargetsResult(True, states=[c.state for c in candidates])

    # We need entity registry entries now
    er = entity_registry.async_get(hass)
    for candidate in candidates:
        candidate.entity = er.async_get(candidate.state.entity_id)

    if constraints.name:
        # Filter by entity name or alias
        candidates = list(_filter_by_name(constraints.name, candidates))
        if not candidates:
            return MatchTargetsResult(False, MatchFailedReason.NAME)

    if constraints.features:
        # Filter by supported features
        candidates = list(_filter_by_features(constraints.features, candidates))
        if not candidates:
            return MatchTargetsResult(False, MatchFailedReason.FEATURE)

    if constraints.device_classes:
        # Filter by device class
        candidates = list(
            _filter_by_device_classes(constraints.device_classes, candidates)
        )
        if not candidates:
            return MatchTargetsResult(False, MatchFailedReason.DEVICE_CLASS)

    # Check floor/area constraints
    targeted_floors: list[floor_registry.FloorEntry] | None = None
    targeted_areas: list[area_registry.AreaEntry] | None = None

    # True when area information has been added to candidates
    areas_added = False

    if constraints.floor_name or constraints.area_name:
        ar = area_registry.async_get(hass)
        dr = device_registry.async_get(hass)
        _add_areas(ar, dr, candidates)
        areas_added = True

        if constraints.floor_name:
            # Filter by areas associated with floor
            fr = floor_registry.async_get(hass)
            targeted_floors = list(find_floors(constraints.floor_name, fr))
            if not targeted_floors:
                return MatchTargetsResult(
                    False,
                    MatchFailedReason.INVALID_FLOOR,
                    no_match_name=constraints.floor_name,
                )

            possible_floor_ids = {floor.floor_id for floor in targeted_floors}
            possible_area_ids = {
                area.id
                for area in ar.async_list_areas()
                if area.floor_id in possible_floor_ids
            }

            candidates = [
                c for c in candidates if area_candidate_filter(c, possible_area_ids)
            ]
            if not candidates:
                return MatchTargetsResult(
                    False, MatchFailedReason.FLOOR, floors=targeted_floors
                )
        else:
            # All areas are possible
            possible_area_ids = {area.id for area in ar.async_list_areas()}

        if constraints.area_name:
            targeted_areas = list(find_areas(constraints.area_name, ar))
            if not targeted_areas:
                return MatchTargetsResult(
                    False,
                    MatchFailedReason.INVALID_AREA,
                    no_match_name=constraints.area_name,
                )

            matching_area_ids = {area.id for area in targeted_areas}

            # May be constrained by floors above
            possible_area_ids.intersection_update(matching_area_ids)
            candidates = [
                c for c in candidates if area_candidate_filter(c, possible_area_ids)
            ]
            if not candidates:
                return MatchTargetsResult(
                    False, MatchFailedReason.AREA, areas=targeted_areas
                )

    if constraints.assistant:
        # Check exposure
        candidates = [c for c in candidates if c.is_exposed]
        if not candidates:
            return MatchTargetsResult(False, MatchFailedReason.ASSISTANT)

    if constraints.name and (not constraints.allow_duplicate_names):
        # Check for duplicates
        if not areas_added:
            ar = area_registry.async_get(hass)
            dr = device_registry.async_get(hass)
            _add_areas(ar, dr, candidates)
            areas_added = True

        sorted_candidates = sorted(
            [c for c in candidates if c.matched_name],
            key=lambda c: c.matched_name or "",
        )
        final_candidates: list[MatchTargetsCandidate] = []
        for name, group in groupby(sorted_candidates, key=lambda c: c.matched_name):
            group_candidates = list(group)
            if len(group_candidates) < 2:
                # No duplicates for name
                final_candidates.extend(group_candidates)
                continue

            # Try to disambiguate by preferences
            if preferences.floor_id:
                group_candidates = [
                    c
                    for c in group_candidates
                    if (c.area is not None)
                    and (c.area.floor_id == preferences.floor_id)
                ]
                if len(group_candidates) < 2:
                    # Disambiguated by floor
                    final_candidates.extend(group_candidates)
                    continue

            if preferences.area_id:
                group_candidates = [
                    c
                    for c in group_candidates
                    if area_candidate_filter(c, {preferences.area_id})
                ]
                if len(group_candidates) < 2:
                    # Disambiguated by area
                    final_candidates.extend(group_candidates)
                    continue

            # Couldn't disambiguate duplicate names
            return MatchTargetsResult(
                False,
                MatchFailedReason.DUPLICATE_NAME,
                no_match_name=name,
                areas=targeted_areas or [],
                floors=targeted_floors or [],
            )

        if not final_candidates:
            return MatchTargetsResult(
                False,
                MatchFailedReason.NAME,
                areas=targeted_areas or [],
                floors=targeted_floors or [],
            )

        candidates = final_candidates

    if constraints.single_target and len(candidates) > 1:
        # Find best match using preferences
        if not (preferences.area_id or preferences.floor_id):
            # No preferences
            return MatchTargetsResult(
                False,
                MatchFailedReason.MULTIPLE_TARGETS,
                states=[c.state for c in candidates],
            )

        if not areas_added:
            ar = area_registry.async_get(hass)
            dr = device_registry.async_get(hass)
            _add_areas(ar, dr, candidates)
            areas_added = True

        filtered_candidates: list[MatchTargetsCandidate] = candidates
        if preferences.area_id:
            # Filter by area
            filtered_candidates = [
                c for c in candidates if area_candidate_filter(c, {preferences.area_id})
            ]

        if (len(filtered_candidates) > 1) and preferences.floor_id:
            # Filter by floor
            filtered_candidates = [
                c
                for c in candidates
                if c.area and (c.area.floor_id == preferences.floor_id)
            ]

        if len(filtered_candidates) != 1:
            # Filtering could not restrict to a single target
            return MatchTargetsResult(
                False,
                MatchFailedReason.MULTIPLE_TARGETS,
                states=[c.state for c in candidates],
            )

        # Filtering succeeded
        candidates = filtered_candidates

    return MatchTargetsResult(
        True,
        None,
        states=[c.state for c in candidates],
        areas=targeted_areas or [],
        floors=targeted_floors or [],
    )


@callback
@bind_hass
def async_match_states(
    hass: HomeAssistant,
    name: str | None = None,
    area_name: str | None = None,
    floor_name: str | None = None,
    domains: Collection[str] | None = None,
    device_classes: Collection[str] | None = None,
    states: list[State] | None = None,
    assistant: str | None = None,
) -> Iterable[State]:
    """Simplified interface to async_match_targets that returns states matching the constraints."""
    result = async_match_targets(
        hass,
        constraints=MatchTargetsConstraints(
            name=name,
            area_name=area_name,
            floor_name=floor_name,
            domains=domains,
            device_classes=device_classes,
            assistant=assistant,
        ),
        states=states,
    )
    return result.states


@callback
def async_test_feature(state: State, feature: int, feature_name: str) -> None:
    """Test if state supports a feature."""
    if state.attributes.get(ATTR_SUPPORTED_FEATURES, 0) & feature == 0:
        raise IntentHandleError(f"Entity {state.name} does not support {feature_name}")


class IntentHandler:
    """Intent handler registration."""

    intent_type: str
    platforms: set[str] | None = None
    description: str | None = None

    @property
    def slot_schema(self) -> dict | None:
        """Return a slot schema."""
        return None

    @callback
    def async_can_handle(self, intent_obj: Intent) -> bool:
        """Test if an intent can be handled."""
        return self.platforms is None or intent_obj.platform in self.platforms

    @callback
    def async_validate_slots(self, slots: _SlotsType) -> _SlotsType:
        """Validate slot information."""
        if self.slot_schema is None:
            return slots

        return self._slot_schema(slots)  # type: ignore[no-any-return]

    @cached_property
    def _slot_schema(self) -> vol.Schema:
        """Create validation schema for slots."""
        assert self.slot_schema is not None
        return vol.Schema(
            {
                key: SLOT_SCHEMA.extend({"value": validator})
                for key, validator in self.slot_schema.items()
            },
            extra=vol.ALLOW_EXTRA,
        )

    async def async_handle(self, intent_obj: Intent) -> IntentResponse:
        """Handle the intent."""
        raise NotImplementedError

    def __repr__(self) -> str:
        """Represent a string of an intent handler."""
        return f"<{self.__class__.__name__} - {self.intent_type}>"


def non_empty_string(value: Any) -> str:
    """Coerce value to string and fail if string is empty or whitespace."""
    value_str = cv.string(value)
    if not value_str.strip():
        raise vol.Invalid("string value is empty")

    return value_str


@dataclass(kw_only=True)
class IntentSlotInfo:
    """Details about how intent slots are processed and validated."""

    service_data_name: str | None = None
    """Optional name of the service data input to map to this slot."""

    description: str | None = None
    """Human readable description of the slot."""

    value_schema: VolSchemaType | Callable[[Any], Any] = vol.Any
    """Validator for the slot."""


def _convert_slot_info(
    key: str | tuple[str, str],
    value: IntentSlotInfo | VolSchemaType | Callable[[Any], Any],
) -> tuple[str, IntentSlotInfo]:
    """Create an IntentSlotInfo from the various supported input arguments."""
    if isinstance(value, IntentSlotInfo):
        if not isinstance(key, str):
            raise TypeError("Tuple key and IntentSlotDescription value not supported")
        return key, value
    if isinstance(key, tuple):
        return key[0], IntentSlotInfo(service_data_name=key[1], value_schema=value)
    return key, IntentSlotInfo(value_schema=value)


class DynamicServiceIntentHandler(IntentHandler):
    """Service Intent handler registration (dynamic).

    Service specific intent handler that calls a service by name/entity_id.
    """

    # We use a small timeout in service calls to (hopefully) pass validation
    # checks, but not try to wait for the call to fully complete.
    service_timeout: float = 0.2

    def __init__(
        self,
        intent_type: str,
        speech: str | None = None,
        required_slots: _IntentSlotsType | None = None,
        optional_slots: _IntentSlotsType | None = None,
        required_domains: set[str] | None = None,
        required_features: int | None = None,
        required_states: set[str] | None = None,
        description: str | None = None,
        platforms: set[str] | None = None,
        device_classes: set[type[StrEnum]] | None = None,
    ) -> None:
        """Create Service Intent Handler."""
        self.intent_type = intent_type
        self.speech = speech
        self.required_domains = required_domains
        self.required_features = required_features
        self.required_states = required_states
        self.description = description
        self.platforms = platforms
        self.device_classes = device_classes

        self.required_slots: dict[str, IntentSlotInfo] = dict(
            _convert_slot_info(key, value)
            for key, value in (required_slots or {}).items()
        )
        self.optional_slots: dict[str, IntentSlotInfo] = dict(
            _convert_slot_info(key, value)
            for key, value in (optional_slots or {}).items()
        )

    @cached_property
    def slot_schema(self) -> dict:
        """Return a slot schema."""
        domain_validator = (
            vol.In(list(self.required_domains)) if self.required_domains else cv.string
        )
        slot_schema = {
            vol.Any("name", "area", "floor"): non_empty_string,
            vol.Optional("domain"): vol.All(cv.ensure_list, [domain_validator]),
        }
        if self.device_classes:
            # The typical way to match enums is with vol.Coerce, but we build a
            # flat list to make the API simpler to describe programmatically
            flattened_device_classes = vol.In(
                [
                    device_class.value
                    for device_class_enum in self.device_classes
                    for device_class in device_class_enum
                ]
            )
            slot_schema.update(
                {
                    vol.Optional("device_class"): vol.All(
                        cv.ensure_list,
                        [flattened_device_classes],
                    )
                }
            )

        slot_schema.update(
            {
                vol.Optional("preferred_area_id"): cv.string,
                vol.Optional("preferred_floor_id"): cv.string,
            }
        )

        if self.required_slots:
            slot_schema.update(
                {
                    vol.Required(
                        key, description=slot_info.description
                    ): slot_info.value_schema
                    for key, slot_info in self.required_slots.items()
                }
            )

        if self.optional_slots:
            slot_schema.update(
                {
                    vol.Optional(
                        key, description=slot_info.description
                    ): slot_info.value_schema
                    for key, slot_info in self.optional_slots.items()
                }
            )

        return slot_schema

    @abstractmethod
    def get_domain_and_service(
        self, intent_obj: Intent, state: State
    ) -> tuple[str, str]:
        """Get the domain and service name to call."""
        raise NotImplementedError

    async def async_handle(self, intent_obj: Intent) -> IntentResponse:
        """Handle the hass intent."""
        hass = intent_obj.hass
        slots = self.async_validate_slots(intent_obj.slots)

        name_slot = slots.get("name", {})
        entity_name: str | None = name_slot.get("value")
        entity_text: str | None = name_slot.get("text")
        if entity_name == "all":
            # Don't match on name if targeting all entities
            entity_name = None

        # Get area/floor info
        area_slot = slots.get("area", {})
        area_id = area_slot.get("value")

        floor_slot = slots.get("floor", {})
        floor_id = floor_slot.get("value")

        # Optional domain/device class filters.
        # Convert to sets for speed.
        domains: set[str] | None = self.required_domains
        device_classes: set[str] | None = None

        if "domain" in slots:
            domains = set(slots["domain"]["value"])

        if "device_class" in slots:
            device_classes = set(slots["device_class"]["value"])

        match_constraints = MatchTargetsConstraints(
            name=entity_name,
            area_name=area_id,
            floor_name=floor_id,
            domains=domains,
            device_classes=device_classes,
            assistant=intent_obj.assistant,
            features=self.required_features,
            states=self.required_states,
        )
        if not match_constraints.has_constraints:
            # Fail if attempting to target all devices in the house
            raise IntentHandleError("Service handler cannot target all devices")

        match_preferences = MatchTargetsPreferences(
            area_id=slots.get("preferred_area_id", {}).get("value"),
            floor_id=slots.get("preferred_floor_id", {}).get("value"),
        )

        match_result = async_match_targets(hass, match_constraints, match_preferences)
        if not match_result.is_match:
            raise MatchFailedError(
                result=match_result,
                constraints=match_constraints,
                preferences=match_preferences,
            )

        # Ensure name is text
        if ("name" in slots) and entity_text:
            slots["name"]["value"] = entity_text

        # Replace area/floor values with the resolved ids for use in templates
        if ("area" in slots) and match_result.areas:
            slots["area"]["value"] = match_result.areas[0].id

        if ("floor" in slots) and match_result.floors:
            slots["floor"]["value"] = match_result.floors[0].floor_id

        # Update intent slots to include any transformations done by the schemas
        intent_obj.slots = slots

        response = await self.async_handle_states(
            intent_obj, match_result, match_constraints, match_preferences
        )

        # Make the matched states available in the response
        response.async_set_states(
            matched_states=match_result.states, unmatched_states=[]
        )

        return response

    async def async_handle_states(
        self,
        intent_obj: Intent,
        match_result: MatchTargetsResult,
        match_constraints: MatchTargetsConstraints,
        match_preferences: MatchTargetsPreferences | None = None,
    ) -> IntentResponse:
        """Complete action on matched entity states."""
        states = match_result.states
        response = intent_obj.create_response()

        hass = intent_obj.hass
        success_results: list[IntentResponseTarget] = []

        if match_result.floors:
            success_results.extend(
                IntentResponseTarget(
                    type=IntentResponseTargetType.FLOOR,
                    name=floor.name,
                    id=floor.floor_id,
                )
                for floor in match_result.floors
            )
            speech_name = match_result.floors[0].name
        elif match_result.areas:
            success_results.extend(
                IntentResponseTarget(
                    type=IntentResponseTargetType.AREA, name=area.name, id=area.id
                )
                for area in match_result.areas
            )
            speech_name = match_result.areas[0].name
        else:
            speech_name = states[0].name

        service_coros: list[Coroutine[Any, Any, None]] = []
        for state in states:
            domain, service = self.get_domain_and_service(intent_obj, state)
            service_coros.append(
                self.async_call_service(domain, service, intent_obj, state)
            )

        # Handle service calls in parallel, noting failures as they occur.
        failed_results: list[IntentResponseTarget] = []
        for state, service_coro in zip(
            states, asyncio.as_completed(service_coros), strict=False
        ):
            target = IntentResponseTarget(
                type=IntentResponseTargetType.ENTITY,
                name=state.name,
                id=state.entity_id,
            )

            try:
                await service_coro
                success_results.append(target)
            except Exception:
                failed_results.append(target)
                _LOGGER.exception("Service call failed for %s", state.entity_id)

        if not success_results:
            # If no entities succeeded, raise an error.
            failed_entity_ids = [target.id for target in failed_results]
            raise IntentHandleError(
                f"Failed to call {service} for: {failed_entity_ids}"
            )

        response.async_set_results(
            success_results=success_results, failed_results=failed_results
        )

        # Update all states
        states = [hass.states.get(state.entity_id) or state for state in states]
        response.async_set_states(states)

        if self.speech is not None:
            response.async_set_speech(self.speech.format(speech_name))

        return response

    async def async_call_service(
        self, domain: str, service: str, intent_obj: Intent, state: State
    ) -> None:
        """Call service on entity."""
        hass = intent_obj.hass

        service_data: dict[str, Any] = {ATTR_ENTITY_ID: state.entity_id}
        if self.required_slots:
            for key, slot_info in self.required_slots.items():
                service_data[slot_info.service_data_name or key] = intent_obj.slots[
                    key
                ]["value"]

        if self.optional_slots:
            for key, slot_info in self.optional_slots.items():
                if value := intent_obj.slots.get(key):
                    service_data[slot_info.service_data_name or key] = value["value"]

        await self._run_then_background(
            hass.async_create_task_internal(
                hass.services.async_call(
                    domain,
                    service,
                    service_data,
                    context=intent_obj.context,
                    blocking=True,
                ),
                f"intent_call_service_{domain}_{service}",
            )
        )

    async def _run_then_background(self, task: asyncio.Task[Any]) -> None:
        """Run task with timeout to (hopefully) catch validation errors.

        After the timeout the task will continue to run in the background.
        """
        try:
            await asyncio.wait({task}, timeout=self.service_timeout)
        except TimeoutError:
            pass
        except asyncio.CancelledError:
            # Task calling us was cancelled, so cancel service call task, and wait for
            # it to be cancelled, within reason, before leaving.
            _LOGGER.debug("Service call was cancelled: %s", task.get_name())
            task.cancel()
            await asyncio.wait({task}, timeout=5)
            raise


class ServiceIntentHandler(DynamicServiceIntentHandler):
    """Service Intent handler registration.

    Service specific intent handler that calls a service by name/entity_id.
    """

    def __init__(
        self,
        intent_type: str,
        domain: str,
        service: str,
        speech: str | None = None,
        required_slots: _IntentSlotsType | None = None,
        optional_slots: _IntentSlotsType | None = None,
        required_domains: set[str] | None = None,
        required_features: int | None = None,
        required_states: set[str] | None = None,
        description: str | None = None,
        platforms: set[str] | None = None,
        device_classes: set[type[StrEnum]] | None = None,
    ) -> None:
        """Create service handler."""
        super().__init__(
            intent_type,
            speech=speech,
            required_slots=required_slots,
            optional_slots=optional_slots,
            required_domains=required_domains,
            required_features=required_features,
            required_states=required_states,
            description=description,
            platforms=platforms,
            device_classes=device_classes,
        )
        self.domain = domain
        self.service = service

    def get_domain_and_service(
        self, intent_obj: Intent, state: State
    ) -> tuple[str, str]:
        """Get the domain and service name to call."""
        return (self.domain, self.service)


class Intent:
    """Hold the intent."""

    __slots__ = [
        "assistant",
        "context",
        "conversation_agent_id",
        "device_id",
        "hass",
        "intent_type",
        "language",
        "platform",
        "satellite_id",
        "slots",
        "text_input",
    ]

    def __init__(
        self,
        hass: HomeAssistant,
        platform: str,
        intent_type: str,
        slots: _SlotsType,
        text_input: str | None,
        context: Context,
        language: str,
        assistant: str | None = None,
        device_id: str | None = None,
        satellite_id: str | None = None,
        conversation_agent_id: str | None = None,
    ) -> None:
        """Initialize an intent."""
        self.hass = hass
        self.platform = platform
        self.intent_type = intent_type
        self.slots = slots
        self.text_input = text_input
        self.context = context
        self.language = language
        self.assistant = assistant
        self.device_id = device_id
        self.satellite_id = satellite_id
        self.conversation_agent_id = conversation_agent_id

    @callback
    def create_response(self) -> IntentResponse:
        """Create a response."""
        return IntentResponse(language=self.language, intent=self)


class IntentResponseType(
    Enum,
    metaclass=EnumWithDeprecatedMembers,
    deprecated={
        "PARTIAL_ACTION_DONE": (
            "IntentResponseType.ACTION_DONE or IntentResponseType.ERROR",
            "2026.3.0",
        ),
    },
):
    """Type of the intent response."""

    ACTION_DONE = "action_done"
    """Intent caused an action to occur"""

    PARTIAL_ACTION_DONE = "partial_action_done"
    """Deprecated. Intent caused an action, but it could only be partially done"""

    QUERY_ANSWER = "query_answer"
    """Response is an answer to a query"""

    ERROR = "error"
    """Response is an error"""


class IntentResponseErrorCode(str, Enum):
    """Reason for an intent response error."""

    NO_INTENT_MATCH = "no_intent_match"
    """Text could not be matched to an intent"""

    NO_VALID_TARGETS = "no_valid_targets"
    """Intent was matched, but no valid areas/devices/entities were targeted"""

    FAILED_TO_HANDLE = "failed_to_handle"
    """Unexpected error occurred while handling intent"""

    UNKNOWN = "unknown"
    """Error outside the scope of intent processing"""


class IntentResponseTargetType(str, Enum):
    """Type of target for an intent response."""

    AREA = "area"
    FLOOR = "floor"
    DEVICE = "device"
    ENTITY = "entity"
    DOMAIN = "domain"
    DEVICE_CLASS = "device_class"
    CUSTOM = "custom"


@dataclass(slots=True)
class IntentResponseTarget:
    """Target of the intent response."""

    name: str
    type: IntentResponseTargetType
    id: str | None = None


class IntentResponse:
    """Response to an intent."""

    def __init__(
        self,
        language: str,
        intent: Intent | None = None,
    ) -> None:
        """Initialize an IntentResponse."""
        self.language = language
        self.intent = intent
        self.speech: dict[str, dict[str, Any]] = {}
        self.reprompt: dict[str, dict[str, Any]] = {}
        self.card: dict[str, dict[str, str]] = {}
        self.error_code: IntentResponseErrorCode | None = None
        self.intent_targets: list[IntentResponseTarget] = []
        self.success_results: list[IntentResponseTarget] = []
        self.failed_results: list[IntentResponseTarget] = []
        self.matched_states: list[State] = []
        self.unmatched_states: list[State] = []
        self.speech_slots: dict[str, Any] = {}
        self.response_type = IntentResponseType.ACTION_DONE

    @callback
    def async_set_speech(
        self,
        speech: str,
        speech_type: str = "plain",
        extra_data: Any | None = None,
    ) -> None:
        """Set speech response."""
        self.speech[speech_type] = {
            "speech": speech,
            "extra_data": extra_data,
        }

    @callback
    def async_set_reprompt(
        self,
        speech: str,
        speech_type: str = "plain",
        extra_data: Any | None = None,
    ) -> None:
        """Set reprompt response."""
        self.reprompt[speech_type] = {
            "reprompt": speech,
            "extra_data": extra_data,
        }

    @callback
    def async_set_card(
        self, title: str, content: str, card_type: str = "simple"
    ) -> None:
        """Set card response."""
        self.card[card_type] = {"title": title, "content": content}

    @callback
    def async_set_error(self, code: IntentResponseErrorCode, message: str) -> None:
        """Set response error."""
        self.response_type = IntentResponseType.ERROR
        self.error_code = code

        # Speak error message
        self.async_set_speech(message)

    @callback
    def async_set_targets(
        self,
        intent_targets: list[IntentResponseTarget],
    ) -> None:
        """Set response targets."""
        self.intent_targets = intent_targets

    @callback
    def async_set_results(
        self,
        success_results: list[IntentResponseTarget],
        failed_results: list[IntentResponseTarget] | None = None,
    ) -> None:
        """Set response results."""
        self.success_results = success_results
        self.failed_results = failed_results if failed_results is not None else []

    @callback
    def async_set_states(
        self, matched_states: list[State], unmatched_states: list[State] | None = None
    ) -> None:
        """Set entity states that were matched or not matched during intent handling (query)."""
        self.matched_states = matched_states
        self.unmatched_states = unmatched_states or []

    @callback
    def async_set_speech_slots(self, speech_slots: dict[str, Any]) -> None:
        """Set slots that will be used in the response template of the default agent."""
        self.speech_slots = speech_slots

    @callback
    def as_dict(self) -> dict[str, Any]:
        """Return a dictionary representation of an intent response."""
        response_dict: dict[str, Any] = {
            "speech": self.speech,
            "card": self.card,
            "language": self.language,
            "response_type": self.response_type.value,
        }

        if self.reprompt:
            response_dict["reprompt"] = self.reprompt
        if self.speech_slots:
            response_dict["speech_slots"] = self.speech_slots

        response_data: dict[str, Any] = {}

        if self.response_type == IntentResponseType.ERROR:
            assert self.error_code is not None, "error code is required"
            response_data["code"] = self.error_code.value
        else:
            # action done or query answer
            response_data["targets"] = [
                dataclasses.asdict(target) for target in self.intent_targets
            ]

            # Add success/failed targets
            response_data["success"] = [
                dataclasses.asdict(target) for target in self.success_results
            ]

            response_data["failed"] = [
                dataclasses.asdict(target) for target in self.failed_results
            ]

        response_dict["data"] = response_data

        return response_dict
</file>

<file path="issue_registry.py">
"""Persistently store issues raised by integrations."""

from __future__ import annotations

import dataclasses
from datetime import datetime
from enum import StrEnum
import functools as ft
from typing import Any, Literal, TypedDict, cast

from awesomeversion import AwesomeVersion, AwesomeVersionStrategy

from homeassistant.const import __version__ as ha_version
from homeassistant.core import HomeAssistant, callback
from homeassistant.util import dt as dt_util
from homeassistant.util.async_ import run_callback_threadsafe
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey

from .registry import BaseRegistry
from .singleton import singleton
from .storage import Store

DATA_REGISTRY: HassKey[IssueRegistry] = HassKey("issue_registry")
EVENT_REPAIRS_ISSUE_REGISTRY_UPDATED: EventType[EventIssueRegistryUpdatedData] = (
    EventType("repairs_issue_registry_updated")
)
STORAGE_KEY = "repairs.issue_registry"
STORAGE_VERSION_MAJOR = 1
STORAGE_VERSION_MINOR = 2


class EventIssueRegistryUpdatedData(TypedDict):
    """Event data for when the issue registry is updated."""

    action: Literal["create", "remove", "update"]
    domain: str
    issue_id: str


class IssueSeverity(StrEnum):
    """Issue severity."""

    CRITICAL = "critical"
    ERROR = "error"
    WARNING = "warning"


@dataclasses.dataclass(slots=True, frozen=True)
class IssueEntry:
    """Issue Registry Entry."""

    active: bool
    breaks_in_ha_version: str | None
    created: datetime
    data: dict[str, str | int | float | None] | None
    dismissed_version: str | None
    domain: str
    is_fixable: bool | None
    is_persistent: bool
    # Used if an integration creates issues for other integrations (ie alerts)
    issue_domain: str | None
    issue_id: str
    learn_more_url: str | None
    severity: IssueSeverity | None
    translation_key: str | None
    translation_placeholders: dict[str, str] | None

    def to_json(self) -> dict[str, Any]:
        """Return a JSON serializable representation for storage."""
        result = {
            "created": self.created.isoformat(),
            "dismissed_version": self.dismissed_version,
            "domain": self.domain,
            "is_persistent": False,
            "issue_id": self.issue_id,
        }
        if not self.is_persistent:
            return result
        return {
            **result,
            "breaks_in_ha_version": self.breaks_in_ha_version,
            "data": self.data,
            "is_fixable": self.is_fixable,
            "is_persistent": True,
            "issue_domain": self.issue_domain,
            "issue_id": self.issue_id,
            "learn_more_url": self.learn_more_url,
            "severity": self.severity,
            "translation_key": self.translation_key,
            "translation_placeholders": self.translation_placeholders,
        }


class IssueRegistryStore(Store[dict[str, list[dict[str, Any]]]]):
    """Store entity registry data."""

    async def _async_migrate_func(
        self, old_major_version: int, old_minor_version: int, old_data: dict[str, Any]
    ) -> dict[str, Any]:
        """Migrate to the new version."""
        if old_major_version == 1 and old_minor_version < 2:
            # Version 1.2 adds is_persistent
            for issue in old_data["issues"]:
                issue["is_persistent"] = False
        return old_data


class IssueRegistry(BaseRegistry):
    """Class to hold a registry of issues."""

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the issue registry."""
        self.hass = hass
        self.issues: dict[tuple[str, str], IssueEntry] = {}
        self._store = IssueRegistryStore(
            hass,
            STORAGE_VERSION_MAJOR,
            STORAGE_KEY,
            atomic_writes=True,
            minor_version=STORAGE_VERSION_MINOR,
        )

    @callback
    def async_get_issue(self, domain: str, issue_id: str) -> IssueEntry | None:
        """Get issue by id."""
        return self.issues.get((domain, issue_id))

    @callback
    def async_get_or_create(
        self,
        domain: str,
        issue_id: str,
        *,
        breaks_in_ha_version: str | None = None,
        data: dict[str, str | int | float | None] | None = None,
        is_fixable: bool,
        is_persistent: bool,
        issue_domain: str | None = None,
        learn_more_url: str | None = None,
        severity: IssueSeverity,
        translation_key: str,
        translation_placeholders: dict[str, str] | None = None,
    ) -> IssueEntry:
        """Get issue. Create if it doesn't exist."""
        self.hass.verify_event_loop_thread("issue_registry.async_get_or_create")
        if (issue := self.async_get_issue(domain, issue_id)) is None:
            issue = IssueEntry(
                active=True,
                breaks_in_ha_version=breaks_in_ha_version,
                created=dt_util.utcnow(),
                data=data,
                dismissed_version=None,
                domain=domain,
                is_fixable=is_fixable,
                is_persistent=is_persistent,
                issue_domain=issue_domain,
                issue_id=issue_id,
                learn_more_url=learn_more_url,
                severity=severity,
                translation_key=translation_key,
                translation_placeholders=translation_placeholders,
            )
            self.issues[(domain, issue_id)] = issue
            self.async_schedule_save()
            self.hass.bus.async_fire_internal(
                EVENT_REPAIRS_ISSUE_REGISTRY_UPDATED,
                EventIssueRegistryUpdatedData(
                    action="create",
                    domain=domain,
                    issue_id=issue_id,
                ),
            )
        else:
            replacement = dataclasses.replace(
                issue,
                active=True,
                breaks_in_ha_version=breaks_in_ha_version,
                data=data,
                is_fixable=is_fixable,
                is_persistent=is_persistent,
                issue_domain=issue_domain,
                learn_more_url=learn_more_url,
                severity=severity,
                translation_key=translation_key,
                translation_placeholders=translation_placeholders,
            )
            # Only fire is something changed
            if replacement != issue:
                issue = self.issues[(domain, issue_id)] = replacement
                self.async_schedule_save()
                self.hass.bus.async_fire_internal(
                    EVENT_REPAIRS_ISSUE_REGISTRY_UPDATED,
                    EventIssueRegistryUpdatedData(
                        action="update",
                        domain=domain,
                        issue_id=issue_id,
                    ),
                )

        return issue

    @callback
    def async_delete(self, domain: str, issue_id: str) -> None:
        """Delete issue."""
        self.hass.verify_event_loop_thread("issue_registry.async_delete")
        if self.issues.pop((domain, issue_id), None) is None:
            return

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_REPAIRS_ISSUE_REGISTRY_UPDATED,
            EventIssueRegistryUpdatedData(
                action="remove",
                domain=domain,
                issue_id=issue_id,
            ),
        )

    @callback
    def async_ignore(self, domain: str, issue_id: str, ignore: bool) -> IssueEntry:
        """Ignore issue."""
        self.hass.verify_event_loop_thread("issue_registry.async_ignore")
        old = self.issues[(domain, issue_id)]
        dismissed_version = ha_version if ignore else None
        if old.dismissed_version == dismissed_version:
            return old

        issue = self.issues[(domain, issue_id)] = dataclasses.replace(
            old,
            dismissed_version=dismissed_version,
        )

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_REPAIRS_ISSUE_REGISTRY_UPDATED,
            EventIssueRegistryUpdatedData(
                action="update",
                domain=domain,
                issue_id=issue_id,
            ),
        )

        return issue

    @callback
    def make_read_only(self) -> None:
        """Make the registry read-only.

        This method is irreversible.
        """
        self._store.make_read_only()

    async def async_load(self) -> None:
        """Load the issue registry."""
        data = await self._store.async_load()

        issues: dict[tuple[str, str], IssueEntry] = {}

        if isinstance(data, dict):
            for issue in data["issues"]:
                created = cast(datetime, dt_util.parse_datetime(issue["created"]))
                if issue["is_persistent"]:
                    issues[(issue["domain"], issue["issue_id"])] = IssueEntry(
                        active=True,
                        breaks_in_ha_version=issue["breaks_in_ha_version"],
                        created=created,
                        data=issue["data"],
                        dismissed_version=issue["dismissed_version"],
                        domain=issue["domain"],
                        is_fixable=issue["is_fixable"],
                        is_persistent=issue["is_persistent"],
                        issue_id=issue["issue_id"],
                        issue_domain=issue["issue_domain"],
                        learn_more_url=issue["learn_more_url"],
                        severity=issue["severity"],
                        translation_key=issue["translation_key"],
                        translation_placeholders=issue["translation_placeholders"],
                    )
                else:
                    issues[(issue["domain"], issue["issue_id"])] = IssueEntry(
                        active=False,
                        breaks_in_ha_version=None,
                        created=created,
                        data=None,
                        dismissed_version=issue["dismissed_version"],
                        domain=issue["domain"],
                        is_fixable=None,
                        is_persistent=issue["is_persistent"],
                        issue_id=issue["issue_id"],
                        issue_domain=None,
                        learn_more_url=None,
                        severity=None,
                        translation_key=None,
                        translation_placeholders=None,
                    )

        self.issues = issues

    @callback
    def _data_to_save(self) -> dict[str, list[dict[str, str | None]]]:
        """Return data of issue registry to store in a file."""
        data = {}

        data["issues"] = [entry.to_json() for entry in self.issues.values()]

        return data


@callback
@singleton(DATA_REGISTRY)
def async_get(hass: HomeAssistant) -> IssueRegistry:
    """Get issue registry."""
    return IssueRegistry(hass)


async def async_load(hass: HomeAssistant, *, read_only: bool = False) -> None:
    """Load issue registry."""
    ir = async_get(hass)
    if read_only:  # only used in for check config script
        ir.make_read_only()
    return await ir.async_load()


@callback
def async_create_issue(
    hass: HomeAssistant,
    domain: str,
    issue_id: str,
    *,
    breaks_in_ha_version: str | None = None,
    data: dict[str, str | int | float | None] | None = None,
    is_fixable: bool,
    is_persistent: bool = False,
    issue_domain: str | None = None,
    learn_more_url: str | None = None,
    severity: IssueSeverity,
    translation_key: str,
    translation_placeholders: dict[str, str] | None = None,
) -> None:
    """Create an issue, or replace an existing one."""
    # Verify the breaks_in_ha_version is a valid version string
    if breaks_in_ha_version:
        AwesomeVersion(
            breaks_in_ha_version,
            ensure_strategy=AwesomeVersionStrategy.CALVER,
        )

    issue_registry = async_get(hass)
    issue_registry.async_get_or_create(
        domain,
        issue_id,
        breaks_in_ha_version=breaks_in_ha_version,
        data=data,
        is_fixable=is_fixable,
        is_persistent=is_persistent,
        issue_domain=issue_domain,
        learn_more_url=learn_more_url,
        severity=severity,
        translation_key=translation_key,
        translation_placeholders=translation_placeholders,
    )


def create_issue(
    hass: HomeAssistant,
    domain: str,
    issue_id: str,
    *,
    breaks_in_ha_version: str | None = None,
    data: dict[str, str | int | float | None] | None = None,
    is_fixable: bool,
    is_persistent: bool = False,
    issue_domain: str | None = None,
    learn_more_url: str | None = None,
    severity: IssueSeverity,
    translation_key: str,
    translation_placeholders: dict[str, str] | None = None,
) -> None:
    """Create an issue, or replace an existing one."""
    return run_callback_threadsafe(
        hass.loop,
        ft.partial(
            async_create_issue,
            hass,
            domain,
            issue_id,
            breaks_in_ha_version=breaks_in_ha_version,
            data=data,
            is_fixable=is_fixable,
            is_persistent=is_persistent,
            issue_domain=issue_domain,
            learn_more_url=learn_more_url,
            severity=severity,
            translation_key=translation_key,
            translation_placeholders=translation_placeholders,
        ),
    ).result()


@callback
def async_delete_issue(hass: HomeAssistant, domain: str, issue_id: str) -> None:
    """Delete an issue.

    It is not an error to delete an issue that does not exist.
    """
    issue_registry = async_get(hass)
    issue_registry.async_delete(domain, issue_id)


def delete_issue(hass: HomeAssistant, domain: str, issue_id: str) -> None:
    """Delete an issue.

    It is not an error to delete an issue that does not exist.
    """
    return run_callback_threadsafe(
        hass.loop, async_delete_issue, hass, domain, issue_id
    ).result()


@callback
def async_ignore_issue(
    hass: HomeAssistant, domain: str, issue_id: str, ignore: bool
) -> None:
    """Ignore an issue.

    Will raise if the issue does not exist.
    """
    issue_registry = async_get(hass)
    issue_registry.async_ignore(domain, issue_id, ignore)
</file>

<file path="json.py">
"""Helpers to help with encoding Home Assistant objects in JSON."""

from collections import deque
from collections.abc import Callable
import datetime
from functools import partial
import json
import logging
from pathlib import Path
from typing import TYPE_CHECKING, Any, Final

import orjson

from homeassistant.util.file import write_utf8_file, write_utf8_file_atomic
from homeassistant.util.json import SerializationError, format_unserializable_data

_LOGGER = logging.getLogger(__name__)


class JSONEncoder(json.JSONEncoder):
    """JSONEncoder that supports Home Assistant objects."""

    def default(self, o: Any) -> Any:
        """Convert Home Assistant objects.

        Hand other objects to the original method.
        """
        if isinstance(o, datetime.datetime):
            return o.isoformat()
        if isinstance(o, set):
            return list(o)
        if hasattr(o, "as_dict"):
            return o.as_dict()

        return json.JSONEncoder.default(self, o)


def json_encoder_default(obj: Any) -> Any:
    """Convert Home Assistant objects.

    Hand other objects to the original method.
    """
    if hasattr(obj, "json_fragment"):
        return obj.json_fragment
    if isinstance(obj, (set, tuple)):
        return list(obj)
    if isinstance(obj, float):
        return float(obj)
    if hasattr(obj, "as_dict"):
        return obj.as_dict()
    if isinstance(obj, Path):
        return obj.as_posix()
    if isinstance(obj, datetime.datetime):
        return obj.isoformat()
    raise TypeError


if TYPE_CHECKING:

    def json_bytes(obj: Any) -> bytes:
        """Dump json bytes."""

else:
    json_bytes = partial(
        orjson.dumps, option=orjson.OPT_NON_STR_KEYS, default=json_encoder_default
    )
    """Dump json bytes."""


class ExtendedJSONEncoder(JSONEncoder):
    """JSONEncoder that supports Home Assistant objects and falls back to repr(o)."""

    def default(self, o: Any) -> Any:
        """Convert certain objects.

        Fall back to repr(o).
        """
        if isinstance(o, datetime.timedelta):
            return {"__type": str(type(o)), "total_seconds": o.total_seconds()}
        if isinstance(o, datetime.datetime):
            return o.isoformat()
        if isinstance(o, (datetime.date, datetime.time)):
            return {"__type": str(type(o)), "isoformat": o.isoformat()}
        try:
            return super().default(o)
        except TypeError:
            return {"__type": str(type(o)), "repr": repr(o)}


def _strip_null(obj: Any) -> Any:
    """Strip NUL from an object."""
    if isinstance(obj, str):
        return obj.split("\0", 1)[0]
    if isinstance(obj, dict):
        return {key: _strip_null(o) for key, o in obj.items()}
    if isinstance(obj, list):
        return [_strip_null(o) for o in obj]
    return obj


def json_bytes_strip_null(data: Any) -> bytes:
    """Dump json bytes after terminating strings at the first NUL."""
    # We expect null-characters to be very rare, hence try encoding first and look
    # for an escaped null-character in the output.
    result = json_bytes(data)
    if b"\\u0000" not in result:
        return result

    # We work on the processed result so we don't need to worry about
    # Home Assistant extensions which allows encoding sets, tuples, etc.
    return json_bytes(_strip_null(orjson.loads(result)))


json_fragment = orjson.Fragment


def json_dumps(data: Any) -> str:
    r"""Dump json string.

    orjson supports serializing dataclasses natively which
    eliminates the need to implement as_dict in many places
    when the data is already in a dataclass. This works
    well as long as all the data in the dataclass can also
    be serialized.

    If it turns out to be a problem we can disable this
    with option \|= orjson.OPT_PASSTHROUGH_DATACLASS and it
    will fallback to as_dict
    """
    return json_bytes(data).decode("utf-8")


json_bytes_sorted = partial(
    orjson.dumps,
    option=orjson.OPT_NON_STR_KEYS | orjson.OPT_SORT_KEYS,
    default=json_encoder_default,
)
"""Dump json bytes with keys sorted."""


def json_dumps_sorted(data: Any) -> str:
    """Dump json string with keys sorted."""
    return json_bytes_sorted(data).decode("utf-8")


JSON_DUMP: Final = json_dumps


def _orjson_default_encoder(data: Any) -> str:
    """JSON encoder that uses orjson with hass defaults and returns a str."""
    return _orjson_bytes_default_encoder(data).decode("utf-8")


def _orjson_bytes_default_encoder(data: Any) -> bytes:
    """JSON encoder that uses orjson with hass defaults and returns bytes."""
    return orjson.dumps(
        data,
        option=orjson.OPT_INDENT_2 | orjson.OPT_NON_STR_KEYS,
        default=json_encoder_default,
    )


def prepare_save_json(
    data: list | dict,
    *,
    encoder: type[json.JSONEncoder] | None = None,
) -> tuple[str, str | bytes]:
    """Prepare JSON data for saving to a file.

    Returns a tuple of (mode, json_data) where mode is either 'w' or 'wb'
    and json_data is either a str or bytes depending on the mode.

    Args:
        data: Data to serialize.
        encoder: Optional custom JSON encoder.
    """
    dump: Callable[[Any], Any]
    try:
        # For backwards compatibility, if they pass in the
        # default json encoder we use _orjson_default_encoder
        # which is the orjson equivalent to the default encoder.
        if encoder and encoder is not JSONEncoder:
            # If they pass a custom encoder that is not the
            # default JSONEncoder, we use the slow path of json.dumps
            mode = "w"
            dump = json.dumps
            json_data: str | bytes = json.dumps(data, indent=2, cls=encoder)
        else:
            mode = "wb"
            dump = _orjson_default_encoder
            json_data = _orjson_bytes_default_encoder(data)
    except TypeError as error:
        formatted_data = format_unserializable_data(
            find_paths_unserializable_data(data, dump=dump)
        )
        raise SerializationError(f"Bad data at {formatted_data}") from error
    return (mode, json_data)


def save_json(
    filename: str,
    data: list | dict,
    private: bool = False,
    *,
    encoder: type[json.JSONEncoder] | None = None,
    atomic_writes: bool = False,
) -> None:
    """Save JSON data to a file."""
    try:
        mode, json_data = prepare_save_json(data, encoder=encoder)
    except SerializationError as err:
        _LOGGER.error("Failed to serialize to JSON: %s. %s", filename, err)
        raise
    method = write_utf8_file_atomic if atomic_writes else write_utf8_file
    method(filename, json_data, private, mode=mode)


def find_paths_unserializable_data(
    bad_data: Any, *, dump: Callable[[Any], str] = json.dumps
) -> dict[str, Any]:
    """Find the paths to unserializable data.

    This method is slow! Only use for error handling.
    """
    from homeassistant.core import Event, State  # noqa: PLC0415

    to_process = deque([(bad_data, "$")])
    invalid = {}

    while to_process:
        obj, obj_path = to_process.popleft()

        try:
            dump(obj)
            continue
        except (ValueError, TypeError):
            pass

        # We convert objects with as_dict to their dict values
        # so we can find bad data inside it
        if hasattr(obj, "as_dict"):
            desc = obj.__class__.__name__
            if isinstance(obj, State):
                desc += f": {obj.entity_id}"
            elif isinstance(obj, Event):
                desc += f": {obj.event_type}"

            obj_path += f"({desc})"
            obj = obj.as_dict()

        if isinstance(obj, dict):
            for key, value in obj.items():
                try:
                    # Is key valid?
                    dump({key: None})
                except TypeError:
                    invalid[f"{obj_path}<key: {key}>"] = key
                else:
                    # Process value
                    to_process.append((value, f"{obj_path}.{key}"))
        elif isinstance(obj, list):
            for idx, value in enumerate(obj):
                to_process.append((value, f"{obj_path}[{idx}]"))
        else:
            invalid[obj_path] = obj

    return invalid
</file>

<file path="label_registry.py">
"""Provide a way to label and group anything."""

from __future__ import annotations

from collections.abc import Iterable
import dataclasses
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Literal, TypedDict

from homeassistant.core import Event, HomeAssistant, callback
from homeassistant.util.dt import utc_from_timestamp, utcnow
from homeassistant.util.event_type import EventType
from homeassistant.util.hass_dict import HassKey

from .normalized_name_base_registry import (
    NormalizedNameBaseRegistryEntry,
    NormalizedNameBaseRegistryItems,
)
from .registry import BaseRegistry
from .singleton import singleton
from .storage import Store
from .typing import UNDEFINED, UndefinedType

DATA_REGISTRY: HassKey[LabelRegistry] = HassKey("label_registry")
EVENT_LABEL_REGISTRY_UPDATED: EventType[EventLabelRegistryUpdatedData] = EventType(
    "label_registry_updated"
)
STORAGE_KEY = "core.label_registry"
STORAGE_VERSION_MAJOR = 1
STORAGE_VERSION_MINOR = 2


class _LabelStoreData(TypedDict):
    """Data type for individual label. Used in LabelRegistryStoreData."""

    color: str | None
    description: str | None
    icon: str | None
    label_id: str
    name: str
    created_at: str
    modified_at: str


class LabelRegistryStoreData(TypedDict):
    """Store data type for LabelRegistry."""

    labels: list[_LabelStoreData]


class EventLabelRegistryUpdatedData(TypedDict):
    """Event data for when the label registry is updated."""

    action: Literal["create", "remove", "update"]
    label_id: str


type EventLabelRegistryUpdated = Event[EventLabelRegistryUpdatedData]


@dataclass(slots=True, frozen=True, kw_only=True)
class LabelEntry(NormalizedNameBaseRegistryEntry):
    """Label Registry Entry."""

    label_id: str
    description: str | None = None
    color: str | None = None
    icon: str | None = None


class LabelRegistryStore(Store[LabelRegistryStoreData]):
    """Store label registry data."""

    async def _async_migrate_func(
        self,
        old_major_version: int,
        old_minor_version: int,
        old_data: dict[str, list[dict[str, Any]]],
    ) -> LabelRegistryStoreData:
        """Migrate to the new version."""
        if old_major_version > STORAGE_VERSION_MAJOR:
            raise ValueError("Can't migrate to future version")

        if old_major_version == 1:
            if old_minor_version < 2:
                # Version 1.2 implements migration and adds created_at and modified_at
                created_at = utc_from_timestamp(0).isoformat()
                for label in old_data["labels"]:
                    label["created_at"] = label["modified_at"] = created_at

        return old_data  # type: ignore[return-value]


class LabelRegistry(BaseRegistry[LabelRegistryStoreData]):
    """Class to hold a registry of labels."""

    labels: NormalizedNameBaseRegistryItems[LabelEntry]
    _label_data: dict[str, LabelEntry]

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the label registry."""
        self.hass = hass
        self._store = LabelRegistryStore(
            hass,
            STORAGE_VERSION_MAJOR,
            STORAGE_KEY,
            atomic_writes=True,
            minor_version=STORAGE_VERSION_MINOR,
        )

    @callback
    def async_get_label(self, label_id: str) -> LabelEntry | None:
        """Get label by ID.

        We retrieve the LabelEntry from the underlying dict to avoid
        the overhead of the UserDict __getitem__.
        """
        return self._label_data.get(label_id)

    @callback
    def async_get_label_by_name(self, name: str) -> LabelEntry | None:
        """Get label by name."""
        return self.labels.get_by_name(name)

    @callback
    def async_list_labels(self) -> Iterable[LabelEntry]:
        """Get all labels."""
        return self.labels.values()

    def _generate_id(self, name: str) -> str:
        """Generate label ID."""
        return self.labels.generate_id_from_name(name)

    @callback
    def async_create(
        self,
        name: str,
        *,
        color: str | None = None,
        icon: str | None = None,
        description: str | None = None,
    ) -> LabelEntry:
        """Create a new label."""
        self.hass.verify_event_loop_thread("label_registry.async_create")

        if label := self.async_get_label_by_name(name):
            raise ValueError(
                f"The name {name} ({label.normalized_name}) is already in use"
            )

        label = LabelEntry(
            color=color,
            description=description,
            icon=icon,
            label_id=self._generate_id(name),
            name=name,
        )
        label_id = label.label_id
        self.labels[label_id] = label
        self.async_schedule_save()

        self.hass.bus.async_fire_internal(
            EVENT_LABEL_REGISTRY_UPDATED,
            EventLabelRegistryUpdatedData(action="create", label_id=label_id),
        )
        return label

    @callback
    def async_delete(self, label_id: str) -> None:
        """Delete label."""
        self.hass.verify_event_loop_thread("label_registry.async_delete")
        del self.labels[label_id]
        self.hass.bus.async_fire_internal(
            EVENT_LABEL_REGISTRY_UPDATED,
            EventLabelRegistryUpdatedData(
                action="remove",
                label_id=label_id,
            ),
        )
        self.async_schedule_save()

    @callback
    def async_update(
        self,
        label_id: str,
        *,
        color: str | None | UndefinedType = UNDEFINED,
        description: str | None | UndefinedType = UNDEFINED,
        icon: str | None | UndefinedType = UNDEFINED,
        name: str | UndefinedType = UNDEFINED,
    ) -> LabelEntry:
        """Update name of label."""
        old = self.labels[label_id]
        changes: dict[str, Any] = {
            attr_name: value
            for attr_name, value in (
                ("color", color),
                ("description", description),
                ("icon", icon),
            )
            if value is not UNDEFINED and getattr(old, attr_name) != value
        }

        if name is not UNDEFINED and name != old.name:
            changes["name"] = name

        if not changes:
            return old

        changes["modified_at"] = utcnow()

        self.hass.verify_event_loop_thread("label_registry.async_update")
        new = self.labels[label_id] = dataclasses.replace(old, **changes)

        self.async_schedule_save()
        self.hass.bus.async_fire_internal(
            EVENT_LABEL_REGISTRY_UPDATED,
            EventLabelRegistryUpdatedData(
                action="update",
                label_id=label_id,
            ),
        )

        return new

    async def async_load(self) -> None:
        """Load the label registry."""
        data = await self._store.async_load()
        labels = NormalizedNameBaseRegistryItems[LabelEntry]()

        if data is not None:
            for label in data["labels"]:
                labels[label["label_id"]] = LabelEntry(
                    color=label["color"],
                    description=label["description"],
                    icon=label["icon"],
                    label_id=label["label_id"],
                    name=label["name"],
                    created_at=datetime.fromisoformat(label["created_at"]),
                    modified_at=datetime.fromisoformat(label["modified_at"]),
                )

        self.labels = labels
        self._label_data = labels.data

    @callback
    def _data_to_save(self) -> LabelRegistryStoreData:
        """Return data of label registry to store in a file."""
        return {
            "labels": [
                {
                    "color": entry.color,
                    "description": entry.description,
                    "icon": entry.icon,
                    "label_id": entry.label_id,
                    "name": entry.name,
                    "created_at": entry.created_at.isoformat(),
                    "modified_at": entry.modified_at.isoformat(),
                }
                for entry in self.labels.values()
            ]
        }


@callback
@singleton(DATA_REGISTRY)
def async_get(hass: HomeAssistant) -> LabelRegistry:
    """Get label registry."""
    return LabelRegistry(hass)


async def async_load(hass: HomeAssistant) -> None:
    """Load label registry."""
    assert DATA_REGISTRY not in hass.data
    await async_get(hass).async_load()
</file>

<file path="llm.py">
"""Module to coordinate llm tools."""

from __future__ import annotations

from abc import ABC, abstractmethod
from collections.abc import Callable
from dataclasses import dataclass, field as dc_field
from datetime import timedelta
from decimal import Decimal
from enum import Enum
from functools import cache, partial
from operator import attrgetter
from typing import Any, cast

import slugify as unicode_slug
import voluptuous as vol
from voluptuous_openapi import UNSUPPORTED, convert

from homeassistant.components.calendar import (
    DOMAIN as CALENDAR_DOMAIN,
    SERVICE_GET_EVENTS,
)
from homeassistant.components.cover import INTENT_CLOSE_COVER, INTENT_OPEN_COVER
from homeassistant.components.homeassistant import async_should_expose
from homeassistant.components.intent import async_device_supports_timers
from homeassistant.components.script import DOMAIN as SCRIPT_DOMAIN
from homeassistant.components.todo import DOMAIN as TODO_DOMAIN, TodoServices
from homeassistant.components.weather import INTENT_GET_WEATHER
from homeassistant.const import (
    ATTR_DOMAIN,
    ATTR_SERVICE,
    EVENT_HOMEASSISTANT_CLOSE,
    EVENT_SERVICE_REMOVED,
)
from homeassistant.core import Context, Event, HomeAssistant, callback, split_entity_id
from homeassistant.exceptions import HomeAssistantError
from homeassistant.util import dt as dt_util, yaml as yaml_util
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.json import JsonObjectType
from homeassistant.util.ulid import ulid_now

from . import (
    area_registry as ar,
    config_validation as cv,
    device_registry as dr,
    entity_registry as er,
    floor_registry as fr,
    intent,
    selector,
    service,
)
from .singleton import singleton

ACTION_PARAMETERS_CACHE: HassKey[
    dict[str, dict[str, tuple[str | None, vol.Schema]]]
] = HassKey("llm_action_parameters_cache")


LLM_API_ASSIST = "assist"

DATE_TIME_PROMPT = (
    'Current time is {{ now().strftime("%H:%M:%S") }}. '
    'Today\'s date is {{ now().strftime("%Y-%m-%d") }}.\n'
)

DEFAULT_INSTRUCTIONS_PROMPT = """You are a voice assistant for Home Assistant.
Answer questions about the world truthfully.
Answer in plain text. Keep it simple and to the point.
"""

NO_ENTITIES_PROMPT = (
    "Only if the user wants to control a device, tell them to expose entities "
    "to their voice assistant in Home Assistant."
)

DYNAMIC_CONTEXT_PROMPT = """You ARE equipped to answer questions about the current state of
the home using the `GetLiveContext` tool. This is a primary function. Do not state you lack the
functionality if the question requires live data.
If the user asks about device existence/type (e.g., "Do I have lights in the bedroom?"): Answer
from the static context below.
If the user asks about the CURRENT state, value, or mode (e.g., "Is the lock locked?",
"Is the fan on?", "What mode is the thermostat in?", "What is the temperature outside?"):
    1.  Recognize this requires live data.
    2.  You MUST call `GetLiveContext`. This tool will provide the needed real-time information (like temperature from the local weather, lock status, etc.).
    3.  Use the tool's response** to answer the user accurately (e.g., "The temperature outside is [value from tool].").
For general knowledge questions not about the home: Answer truthfully from internal knowledge.
"""


@callback
def async_render_no_api_prompt(hass: HomeAssistant) -> str:
    """Return the prompt to be used when no API is configured.

    No longer used since Home Assistant 2024.7.
    """
    return ""


@singleton("llm")
@callback
def _async_get_apis(hass: HomeAssistant) -> dict[str, API]:
    """Get all the LLM APIs."""
    return {
        LLM_API_ASSIST: AssistAPI(hass=hass),
    }


@callback
def async_register_api(hass: HomeAssistant, api: API) -> Callable[[], None]:
    """Register an API to be exposed to LLMs."""
    apis = _async_get_apis(hass)

    if api.id in apis:
        raise HomeAssistantError(f"API {api.id} is already registered")

    apis[api.id] = api

    @callback
    def unregister() -> None:
        """Unregister the API."""
        apis.pop(api.id)

    return unregister


async def async_get_api(
    hass: HomeAssistant, api_id: str | list[str], llm_context: LLMContext
) -> APIInstance:
    """Get an API.

    This returns a single APIInstance for one or more API ids, merging into
    a single instance of necessary.
    """
    apis = _async_get_apis(hass)

    if isinstance(api_id, str):
        api_id = [api_id]

    for key in api_id:
        if key not in apis:
            raise HomeAssistantError(f"API {key} not found")

    api: API
    if len(api_id) == 1:
        api = apis[api_id[0]]
    else:
        api = MergedAPI([apis[key] for key in api_id])

    return await api.async_get_api_instance(llm_context)


@callback
def async_get_apis(hass: HomeAssistant) -> list[API]:
    """Get all the LLM APIs."""
    return list(_async_get_apis(hass).values())


@dataclass(slots=True)
class LLMContext:
    """Tool input to be processed."""

    platform: str
    """Integration that is handling the LLM request."""

    context: Context | None
    """Context of the LLM request."""

    language: str | None
    """Language of the LLM request."""

    assistant: str | None
    """Assistant domain that is handling the LLM request."""

    device_id: str | None
    """Device that is making the request."""


@dataclass(slots=True)
class ToolInput:
    """Tool input to be processed."""

    tool_name: str
    tool_args: dict[str, Any]
    # Using lambda for default to allow patching in tests
    id: str = dc_field(default_factory=lambda: ulid_now())  # pylint: disable=unnecessary-lambda
    external: bool = False


class Tool:
    """LLM Tool base class."""

    name: str
    description: str | None = None
    parameters: vol.Schema = vol.Schema({})

    @abstractmethod
    async def async_call(
        self, hass: HomeAssistant, tool_input: ToolInput, llm_context: LLMContext
    ) -> JsonObjectType:
        """Call the tool."""
        raise NotImplementedError

    def __repr__(self) -> str:
        """Represent a string of a Tool."""
        return f"<{self.__class__.__name__} - {self.name}>"


@dataclass
class APIInstance:
    """Instance of an API to be used by an LLM."""

    api: API
    api_prompt: str
    llm_context: LLMContext
    tools: list[Tool]
    custom_serializer: Callable[[Any], Any] | None = None

    async def async_call_tool(self, tool_input: ToolInput) -> JsonObjectType:
        """Call a LLM tool, validate args and return the response."""
        from homeassistant.components.conversation import (  # noqa: PLC0415
            ConversationTraceEventType,
            async_conversation_trace_append,
        )

        async_conversation_trace_append(
            ConversationTraceEventType.TOOL_CALL,
            {"tool_name": tool_input.tool_name, "tool_args": tool_input.tool_args},
        )

        for tool in self.tools:
            if tool.name == tool_input.tool_name:
                break
        else:
            raise HomeAssistantError(f'Tool "{tool_input.tool_name}" not found')

        return await tool.async_call(self.api.hass, tool_input, self.llm_context)


@dataclass(slots=True, kw_only=True)
class API(ABC):
    """An API to expose to LLMs."""

    hass: HomeAssistant
    id: str
    name: str

    @abstractmethod
    async def async_get_api_instance(self, llm_context: LLMContext) -> APIInstance:
        """Return the instance of the API."""
        raise NotImplementedError


class IntentTool(Tool):
    """LLM Tool representing an Intent."""

    def __init__(
        self,
        name: str,
        intent_handler: intent.IntentHandler,
    ) -> None:
        """Init the class."""
        self.name = name
        self.description = (
            intent_handler.description or f"Execute Home Assistant {self.name} intent"
        )
        self.extra_slots = None
        if not (slot_schema := intent_handler.slot_schema):
            return

        slot_schema = {**slot_schema}
        extra_slots = set()

        for field in ("preferred_area_id", "preferred_floor_id"):
            if field in slot_schema:
                extra_slots.add(field)
                del slot_schema[field]

        self.parameters = vol.Schema(slot_schema)
        if extra_slots:
            self.extra_slots = extra_slots

    async def async_call(
        self, hass: HomeAssistant, tool_input: ToolInput, llm_context: LLMContext
    ) -> JsonObjectType:
        """Handle the intent."""
        slots = {key: {"value": val} for key, val in tool_input.tool_args.items()}

        if self.extra_slots and llm_context.device_id:
            device_reg = dr.async_get(hass)
            device = device_reg.async_get(llm_context.device_id)

            area: ar.AreaEntry | None = None
            floor: fr.FloorEntry | None = None
            if device:
                area_reg = ar.async_get(hass)
                if device.area_id and (area := area_reg.async_get_area(device.area_id)):
                    if area.floor_id:
                        floor_reg = fr.async_get(hass)
                        floor = floor_reg.async_get_floor(area.floor_id)

            for slot_name, slot_value in (
                ("preferred_area_id", area.id if area else None),
                ("preferred_floor_id", floor.floor_id if floor else None),
            ):
                if slot_value and slot_name in self.extra_slots:
                    slots[slot_name] = {"value": slot_value}

        intent_response = await intent.async_handle(
            hass=hass,
            platform=llm_context.platform,
            intent_type=self.name,
            slots=slots,
            text_input=None,
            context=llm_context.context,
            language=llm_context.language,
            assistant=llm_context.assistant,
            device_id=llm_context.device_id,
        )
        return IntentResponseDict(intent_response)


class IntentResponseDict(dict):
    """Dictionary to represent an intent response resulting from a tool call."""

    def __init__(self, intent_response: Any) -> None:
        """Initialize the dictionary."""
        if not isinstance(intent_response, intent.IntentResponse):
            super().__init__(intent_response)
            return

        result = intent_response.as_dict()
        del result["language"]
        del result["card"]
        super().__init__(result)
        self.original = intent_response


class NamespacedTool(Tool):
    """A tool that wraps another tool, prepending a namespace.

    This is used to support tools from multiple API. This tool dispatches
    the original tool with the original non-namespaced name.
    """

    def __init__(self, namespace: str, tool: Tool) -> None:
        """Init the class."""
        self.namespace = namespace
        self.name = f"{namespace}__{tool.name}"
        self.description = tool.description
        self.parameters = tool.parameters
        self.tool = tool

    async def async_call(
        self, hass: HomeAssistant, tool_input: ToolInput, llm_context: LLMContext
    ) -> JsonObjectType:
        """Handle the intent."""
        return await self.tool.async_call(
            hass,
            ToolInput(
                tool_name=self.tool.name,
                tool_args=tool_input.tool_args,
                id=tool_input.id,
            ),
            llm_context,
        )


class MergedAPI(API):
    """An API that represents a merged view of multiple APIs."""

    def __init__(self, llm_apis: list[API]) -> None:
        """Init the class."""
        if not llm_apis:
            raise ValueError("No APIs provided")
        hass = llm_apis[0].hass
        api_ids = [unicode_slug.slugify(api.id) for api in llm_apis]
        if len(set(api_ids)) != len(api_ids):
            raise ValueError("API IDs must be unique")
        super().__init__(
            hass=hass,
            id="|".join(unicode_slug.slugify(api.id) for api in llm_apis),
            name="Merged LLM API",
        )
        self.llm_apis = llm_apis

    async def async_get_api_instance(self, llm_context: LLMContext) -> APIInstance:
        """Return the instance of the API."""
        # These usually don't do I/O and execute right away
        llm_apis = [
            await llm_api.async_get_api_instance(llm_context)
            for llm_api in self.llm_apis
        ]
        prompt_parts = []
        tools: list[Tool] = []
        for api_instance in llm_apis:
            namespace = unicode_slug.slugify(api_instance.api.name)
            prompt_parts.append(
                f'Follow these instructions for tools from "{namespace}":\n'
            )
            prompt_parts.append(api_instance.api_prompt)
            prompt_parts.append("\n\n")
            tools.extend(
                [NamespacedTool(namespace, tool) for tool in api_instance.tools]
            )

        return APIInstance(
            api=self,
            api_prompt="".join(prompt_parts),
            llm_context=llm_context,
            tools=tools,
            custom_serializer=self._custom_serializer(llm_apis),
        )

    def _custom_serializer(
        self, llm_apis: list[APIInstance]
    ) -> Callable[[Any], Any] | None:
        serializers = [
            api_instance.custom_serializer
            for api_instance in llm_apis
            if api_instance.custom_serializer is not None
        ]
        if not serializers:
            return None

        def merged(x: Any) -> Any:
            for serializer in serializers:
                if (result := serializer(x)) is not None:
                    return result
            return x

        return merged


class AssistAPI(API):
    """API exposing Assist API to LLMs."""

    IGNORE_INTENTS = {
        intent.INTENT_GET_TEMPERATURE,
        INTENT_GET_WEATHER,
        INTENT_OPEN_COVER,  # deprecated
        INTENT_CLOSE_COVER,  # deprecated
        intent.INTENT_GET_STATE,
        intent.INTENT_NEVERMIND,
        intent.INTENT_TOGGLE,
        intent.INTENT_GET_CURRENT_DATE,
        intent.INTENT_GET_CURRENT_TIME,
        intent.INTENT_RESPOND,
    }

    def __init__(self, hass: HomeAssistant) -> None:
        """Init the class."""
        super().__init__(
            hass=hass,
            id=LLM_API_ASSIST,
            name="Assist",
        )
        self.cached_slugify = cache(
            partial(unicode_slug.slugify, separator="_", lowercase=False)
        )

    async def async_get_api_instance(self, llm_context: LLMContext) -> APIInstance:
        """Return the instance of the API."""
        if llm_context.assistant:
            exposed_entities: dict | None = _get_exposed_entities(
                self.hass, llm_context.assistant, include_state=False
            )
        else:
            exposed_entities = None

        return APIInstance(
            api=self,
            api_prompt=self._async_get_api_prompt(llm_context, exposed_entities),
            llm_context=llm_context,
            tools=self._async_get_tools(llm_context, exposed_entities),
            custom_serializer=selector_serializer,
        )

    @callback
    def _async_get_api_prompt(
        self, llm_context: LLMContext, exposed_entities: dict | None
    ) -> str:
        if not exposed_entities or not exposed_entities["entities"]:
            return NO_ENTITIES_PROMPT
        return "\n".join(
            [
                *self._async_get_preable(llm_context),
                *self._async_get_exposed_entities_prompt(llm_context, exposed_entities),
            ]
        )

    @callback
    def _async_get_preable(self, llm_context: LLMContext) -> list[str]:
        """Return the prompt for the API."""

        prompt = [
            (
                "When controlling Home Assistant always call the intent tools. "
                "Use HassTurnOn to lock and HassTurnOff to unlock a lock. "
                "When controlling a device, prefer passing just name and domain. "
                "When controlling an area, prefer passing just area name and domain."
            )
        ]
        area: ar.AreaEntry | None = None
        floor: fr.FloorEntry | None = None
        if llm_context.device_id:
            device_reg = dr.async_get(self.hass)
            device = device_reg.async_get(llm_context.device_id)

            if device:
                area_reg = ar.async_get(self.hass)
                if device.area_id and (area := area_reg.async_get_area(device.area_id)):
                    floor_reg = fr.async_get(self.hass)
                    if area.floor_id:
                        floor = floor_reg.async_get_floor(area.floor_id)

            extra = "and all generic commands like 'turn on the lights' should target this area."

        if floor and area:
            prompt.append(f"You are in area {area.name} (floor {floor.name}) {extra}")
        elif area:
            prompt.append(f"You are in area {area.name} {extra}")
        else:
            prompt.append(
                "When a user asks to turn on all devices of a specific type, "
                "ask user to specify an area, unless there is only one device of that type."
            )

        if not llm_context.device_id or not async_device_supports_timers(
            self.hass, llm_context.device_id
        ):
            prompt.append("This device is not able to start timers.")

        prompt.append(DYNAMIC_CONTEXT_PROMPT)

        return prompt

    @callback
    def _async_get_exposed_entities_prompt(
        self, llm_context: LLMContext, exposed_entities: dict | None
    ) -> list[str]:
        """Return the prompt for the API for exposed entities."""
        prompt = []

        if exposed_entities and exposed_entities["entities"]:
            prompt.append(
                "Static Context: An overview of the areas and the devices in this smart home:"
            )
            prompt.append(yaml_util.dump(list(exposed_entities["entities"].values())))

        return prompt

    @callback
    def _async_get_tools(
        self, llm_context: LLMContext, exposed_entities: dict | None
    ) -> list[Tool]:
        """Return a list of LLM tools."""
        ignore_intents = self.IGNORE_INTENTS
        if not llm_context.device_id or not async_device_supports_timers(
            self.hass, llm_context.device_id
        ):
            ignore_intents = ignore_intents | {
                intent.INTENT_START_TIMER,
                intent.INTENT_CANCEL_TIMER,
                intent.INTENT_INCREASE_TIMER,
                intent.INTENT_DECREASE_TIMER,
                intent.INTENT_PAUSE_TIMER,
                intent.INTENT_UNPAUSE_TIMER,
                intent.INTENT_TIMER_STATUS,
            }

        intent_handlers = [
            intent_handler
            for intent_handler in intent.async_get(self.hass)
            if intent_handler.intent_type not in ignore_intents
        ]

        exposed_domains: set[str] | None = None
        if exposed_entities is not None:
            exposed_domains = {
                info["domain"] for info in exposed_entities["entities"].values()
            }

            intent_handlers = [
                intent_handler
                for intent_handler in intent_handlers
                if intent_handler.platforms is None
                or intent_handler.platforms & exposed_domains
            ]

        tools: list[Tool] = [
            IntentTool(self.cached_slugify(intent_handler.intent_type), intent_handler)
            for intent_handler in intent_handlers
        ]

        tools.append(GetDateTimeTool())

        if exposed_entities:
            if exposed_entities[CALENDAR_DOMAIN]:
                names = []
                for info in exposed_entities[CALENDAR_DOMAIN].values():
                    names.extend(info["names"].split(", "))
                tools.append(CalendarGetEventsTool(names))

            if exposed_domains is not None and TODO_DOMAIN in exposed_domains:
                names = []
                for info in exposed_entities["entities"].values():
                    if info["domain"] != TODO_DOMAIN:
                        continue
                    names.extend(info["names"].split(", "))
                tools.append(TodoGetItemsTool(names))

            tools.extend(
                ScriptTool(self.hass, script_entity_id)
                for script_entity_id in exposed_entities[SCRIPT_DOMAIN]
            )

        if exposed_domains:
            tools.append(GetLiveContextTool())

        return tools


def _get_exposed_entities(
    hass: HomeAssistant,
    assistant: str,
    include_state: bool = True,
) -> dict[str, dict[str, dict[str, Any]]]:
    """Get exposed entities.

    Splits out calendars and scripts.
    """
    area_registry = ar.async_get(hass)
    entity_registry = er.async_get(hass)
    device_registry = dr.async_get(hass)
    interesting_attributes = {
        "temperature",
        "current_temperature",
        "temperature_unit",
        "brightness",
        "humidity",
        "unit_of_measurement",
        "device_class",
        "current_position",
        "percentage",
        "volume_level",
        "media_title",
        "media_artist",
        "media_album_name",
    }

    entities = {}
    data: dict[str, dict[str, Any]] = {
        SCRIPT_DOMAIN: {},
        CALENDAR_DOMAIN: {},
    }

    for state in sorted(hass.states.async_all(), key=attrgetter("name")):
        if not async_should_expose(hass, assistant, state.entity_id):
            continue

        entity_entry = entity_registry.async_get(state.entity_id)
        names = [state.name]
        area_names = []

        if entity_entry is not None:
            names.extend(entity_entry.aliases)
            if entity_entry.area_id and (
                area := area_registry.async_get_area(entity_entry.area_id)
            ):
                # Entity is in area
                area_names.append(area.name)
                area_names.extend(area.aliases)
            elif entity_entry.device_id and (
                device := device_registry.async_get(entity_entry.device_id)
            ):
                # Check device area
                if device.area_id and (
                    area := area_registry.async_get_area(device.area_id)
                ):
                    area_names.append(area.name)
                    area_names.extend(area.aliases)

        info: dict[str, Any] = {
            "names": ", ".join(names),
            "domain": state.domain,
        }

        if include_state:
            info["state"] = state.state

            # Convert timestamp device_class states from UTC to local time
            if state.attributes.get("device_class") == "timestamp" and state.state:
                if (parsed_utc := dt_util.parse_datetime(state.state)) is not None:
                    info["state"] = dt_util.as_local(parsed_utc).isoformat()

        if area_names:
            info["areas"] = ", ".join(area_names)

        if include_state and (
            attributes := {
                attr_name: (
                    str(attr_value)
                    if isinstance(attr_value, (Enum, Decimal, int))
                    else attr_value
                )
                for attr_name, attr_value in state.attributes.items()
                if attr_name in interesting_attributes
            }
        ):
            info["attributes"] = attributes

        if state.domain in data:
            data[state.domain][state.entity_id] = info
        else:
            entities[state.entity_id] = info

    data["entities"] = entities
    return data


def selector_serializer(schema: Any) -> Any:  # noqa: C901
    """Convert selectors into OpenAPI schema."""
    if not isinstance(schema, selector.Selector):
        return UNSUPPORTED

    if isinstance(schema, selector.BackupLocationSelector):
        return {"type": "string", "pattern": "^(?:\\/backup|\\w+)$"}

    if isinstance(schema, selector.BooleanSelector):
        return {"type": "boolean"}

    if isinstance(schema, selector.ColorRGBSelector):
        return {
            "type": "array",
            "items": {"type": "number"},
            "minItems": 3,
            "maxItems": 3,
            "format": "RGB",
        }

    if isinstance(schema, selector.ConditionSelector):
        return convert(cv.CONDITIONS_SCHEMA)

    if isinstance(schema, selector.ConstantSelector):
        return convert(vol.Schema(schema.config["value"]))

    result: dict[str, Any]
    if isinstance(schema, selector.ColorTempSelector):
        result = {"type": "number"}
        if "min" in schema.config:
            result["minimum"] = schema.config["min"]
        elif "min_mireds" in schema.config:
            result["minimum"] = schema.config["min_mireds"]
        if "max" in schema.config:
            result["maximum"] = schema.config["max"]
        elif "max_mireds" in schema.config:
            result["maximum"] = schema.config["max_mireds"]
        return result

    if isinstance(schema, selector.CountrySelector):
        if schema.config.get("countries"):
            return {"type": "string", "enum": schema.config["countries"]}
        return {"type": "string", "format": "ISO 3166-1 alpha-2"}

    if isinstance(schema, selector.DateSelector):
        return {"type": "string", "format": "date"}

    if isinstance(schema, selector.DateTimeSelector):
        return {"type": "string", "format": "date-time"}

    if isinstance(schema, selector.DurationSelector):
        return convert(cv.time_period_dict)

    if isinstance(schema, selector.EntitySelector):
        if schema.config.get("multiple"):
            return {"type": "array", "items": {"type": "string", "format": "entity_id"}}

        return {"type": "string", "format": "entity_id"}

    if isinstance(schema, selector.LanguageSelector):
        if schema.config.get("languages"):
            return {"type": "string", "enum": schema.config["languages"]}
        return {"type": "string", "format": "RFC 5646"}

    if isinstance(schema, selector.LocationSelector):
        return convert(schema.DATA_SCHEMA)

    if isinstance(schema, selector.MediaSelector):
        item_schema = convert(schema.DATA_SCHEMA)
        # Media selector allows multiple when configured
        if schema.config.get("multiple"):
            return {
                "type": "array",
                "items": item_schema,
            }
        return item_schema

    if isinstance(schema, selector.NumberSelector):
        result = {"type": "number"}
        if "min" in schema.config:
            result["minimum"] = schema.config["min"]
        if "max" in schema.config:
            result["maximum"] = schema.config["max"]
        return result

    if isinstance(schema, selector.ObjectSelector):
        result = {"type": "object"}
        if fields := schema.config.get("fields"):
            properties = {}
            required = []
            for field, field_schema in fields.items():
                properties[field] = convert(
                    selector.selector(field_schema["selector"]),
                    custom_serializer=selector_serializer,
                )
                if field_schema.get("required"):
                    required.append(field)
            result["properties"] = properties

            if required:
                result["required"] = required
        else:
            result["additionalProperties"] = True
        if schema.config.get("multiple"):
            result = {
                "type": "array",
                "items": result,
            }
        return result

    if isinstance(schema, selector.SelectSelector):
        options = [
            x["value"] if isinstance(x, dict) else x for x in schema.config["options"]
        ]
        if schema.config.get("multiple"):
            return {
                "type": "array",
                "items": {"type": "string", "enum": options},
                "uniqueItems": True,
            }
        return {"type": "string", "enum": options}

    if isinstance(schema, selector.TargetSelector):
        return convert(cv.TARGET_FIELDS)

    if isinstance(schema, selector.TemplateSelector):
        return {"type": "string", "format": "jinja2"}

    if isinstance(schema, selector.TimeSelector):
        return {"type": "string", "format": "time"}

    if isinstance(schema, selector.TriggerSelector):
        return {"type": "array", "items": {"type": "string"}}

    if schema.config.get("multiple"):
        return {"type": "array", "items": {"type": "string"}}

    return {"type": "string"}


def _get_cached_action_parameters(
    hass: HomeAssistant, domain: str, action: str
) -> tuple[str | None, vol.Schema]:
    """Get action description and schema."""
    description = None
    parameters = vol.Schema({})

    parameters_cache = hass.data.get(ACTION_PARAMETERS_CACHE)

    if parameters_cache is None:
        parameters_cache = hass.data[ACTION_PARAMETERS_CACHE] = {}

        @callback
        def clear_cache(event: Event) -> None:
            """Clear action parameter cache on action removal."""
            if (
                event.data[ATTR_DOMAIN] in parameters_cache
                and event.data[ATTR_SERVICE]
                in parameters_cache[event.data[ATTR_DOMAIN]]
            ):
                parameters_cache[event.data[ATTR_DOMAIN]].pop(event.data[ATTR_SERVICE])

        cancel = hass.bus.async_listen(EVENT_SERVICE_REMOVED, clear_cache)

        @callback
        def on_homeassistant_close(event: Event) -> None:
            """Cleanup."""
            cancel()

        hass.bus.async_listen_once(EVENT_HOMEASSISTANT_CLOSE, on_homeassistant_close)

    if domain in parameters_cache and action in parameters_cache[domain]:
        return parameters_cache[domain][action]

    if action_desc := service.async_get_cached_service_description(
        hass, domain, action
    ):
        description = action_desc.get("description")
        schema: dict[vol.Marker, Any] = {}
        fields = action_desc.get("fields", {})

        for field, config in fields.items():
            field_description = config.get("description")
            if not field_description:
                field_description = config.get("name")
            key: vol.Marker
            if config.get("required"):
                key = vol.Required(field, description=field_description)
            else:
                key = vol.Optional(field, description=field_description)
            if "selector" in config:
                schema[key] = selector.selector(config["selector"])
            else:
                schema[key] = cv.string

        parameters = vol.Schema(schema)

        if domain == SCRIPT_DOMAIN:
            entity_registry = er.async_get(hass)
            if (
                entity_id := entity_registry.async_get_entity_id(domain, domain, action)
            ) and (entity_entry := entity_registry.async_get(entity_id)):
                aliases: list[str] = []
                if entity_entry.name:
                    aliases.append(entity_entry.name)
                if entity_entry.aliases:
                    aliases.extend(entity_entry.aliases)
                if aliases:
                    if description:
                        description = description + ". Aliases: " + str(list(aliases))
                    else:
                        description = "Aliases: " + str(list(aliases))

        parameters_cache.setdefault(domain, {})[action] = (description, parameters)

    return description, parameters


class ActionTool(Tool):
    """LLM Tool representing an action."""

    def __init__(
        self,
        hass: HomeAssistant,
        domain: str,
        action: str,
    ) -> None:
        """Init the class."""
        self._domain = domain
        self._action = action
        self.name = f"{domain}__{action}"
        # Note: _get_cached_action_parameters only works for services which
        # add their description directly to the service description cache.
        # This is not the case for most services, but it is for scripts.
        # If we want to use `ActionTool` for services other than scripts, we
        # need to add a coroutine function to fetch the non-cached description
        # and schema.
        self.description, self.parameters = _get_cached_action_parameters(
            hass, domain, action
        )

    async def async_call(
        self, hass: HomeAssistant, tool_input: ToolInput, llm_context: LLMContext
    ) -> JsonObjectType:
        """Call the action."""

        for field, validator in self.parameters.schema.items():
            if field not in tool_input.tool_args:
                continue
            if isinstance(validator, selector.AreaSelector):
                area_reg = ar.async_get(hass)
                if validator.config.get("multiple"):
                    areas: list[ar.AreaEntry] = []
                    for area in tool_input.tool_args[field]:
                        areas.extend(intent.find_areas(area, area_reg))
                    tool_input.tool_args[field] = list({area.id for area in areas})
                else:
                    area = tool_input.tool_args[field]
                    area = list(intent.find_areas(area, area_reg))[0].id
                    tool_input.tool_args[field] = area

            elif isinstance(validator, selector.FloorSelector):
                floor_reg = fr.async_get(hass)
                if validator.config.get("multiple"):
                    floors: list[fr.FloorEntry] = []
                    for floor in tool_input.tool_args[field]:
                        floors.extend(intent.find_floors(floor, floor_reg))
                    tool_input.tool_args[field] = list(
                        {floor.floor_id for floor in floors}
                    )
                else:
                    floor = tool_input.tool_args[field]
                    floor = list(intent.find_floors(floor, floor_reg))[0].floor_id
                    tool_input.tool_args[field] = floor

        result = await hass.services.async_call(
            self._domain,
            self._action,
            tool_input.tool_args,
            context=llm_context.context,
            blocking=True,
            return_response=True,
        )

        return {"success": True, "result": result}


class ScriptTool(ActionTool):
    """LLM Tool representing a Script."""

    def __init__(
        self,
        hass: HomeAssistant,
        script_entity_id: str,
    ) -> None:
        """Init the class."""
        script_name = split_entity_id(script_entity_id)[1]

        action = script_name
        entity_registry = er.async_get(hass)
        entity_entry = entity_registry.async_get(script_entity_id)
        if entity_entry and entity_entry.unique_id:
            action = entity_entry.unique_id

        super().__init__(hass, SCRIPT_DOMAIN, action)

        self.name = script_name
        if self.name[0].isdigit():
            self.name = "_" + self.name


class CalendarGetEventsTool(Tool):
    """LLM Tool allowing querying a calendar."""

    name = "calendar_get_events"
    description = (
        "Get events from a calendar. "
        "When asked if something happens, search the whole week. "
        "Results are RFC 5545 which means 'end' is exclusive."
    )

    def __init__(self, calendars: list[str]) -> None:
        """Init the get events tool."""
        self.parameters = vol.Schema(
            {
                vol.Required("calendar"): vol.In(calendars),
                vol.Required("range"): vol.In(["today", "week"]),
            }
        )

    async def async_call(
        self, hass: HomeAssistant, tool_input: ToolInput, llm_context: LLMContext
    ) -> JsonObjectType:
        """Query a calendar."""
        data = self.parameters(tool_input.tool_args)
        result = intent.async_match_targets(
            hass,
            intent.MatchTargetsConstraints(
                name=data["calendar"],
                domains=[CALENDAR_DOMAIN],
                assistant=llm_context.assistant,
            ),
        )
        if not result.is_match:
            return {"success": False, "error": "Calendar not found"}

        entity_id = result.states[0].entity_id
        if data["range"] == "today":
            start = dt_util.now()
            end = dt_util.start_of_local_day() + timedelta(days=1)
        elif data["range"] == "week":
            start = dt_util.now()
            end = dt_util.start_of_local_day() + timedelta(days=7)

        service_data = {
            "entity_id": entity_id,
            "start_date_time": start.isoformat(),
            "end_date_time": end.isoformat(),
        }

        service_result = await hass.services.async_call(
            CALENDAR_DOMAIN,
            SERVICE_GET_EVENTS,
            service_data,
            context=llm_context.context,
            blocking=True,
            return_response=True,
        )

        events = [
            event if "T" in event["start"] else {**event, "all_day": True}
            for event in cast(dict, service_result)[entity_id]["events"]
        ]

        return {"success": True, "result": events}


class TodoGetItemsTool(Tool):
    """LLM Tool allowing querying a to-do list."""

    name = "todo_get_items"
    description = (
        "Query a to-do list to find out what items are on it. "
        "Use this to answer questions like 'What's on my task list?' or 'Read my grocery list'. "
        "Filters items by status (needs_action, completed, all)."
    )

    def __init__(self, todo_lists: list[str]) -> None:
        """Init the get items tool."""
        self.parameters = vol.Schema(
            {
                vol.Required("todo_list"): vol.In(todo_lists),
                vol.Optional(
                    "status",
                    description="Filter returned items by status, by default returns incomplete items",
                    default="needs_action",
                ): vol.In(["needs_action", "completed", "all"]),
            }
        )

    async def async_call(
        self, hass: HomeAssistant, tool_input: ToolInput, llm_context: LLMContext
    ) -> JsonObjectType:
        """Query a to-do list."""
        data = self.parameters(tool_input.tool_args)
        result = intent.async_match_targets(
            hass,
            intent.MatchTargetsConstraints(
                name=data["todo_list"],
                domains=[TODO_DOMAIN],
                assistant=llm_context.assistant,
            ),
        )
        if not result.is_match:
            return {"success": False, "error": "To-do list not found"}
        entity_id = result.states[0].entity_id
        service_data: dict[str, Any] = {"entity_id": entity_id}
        if status := data.get("status"):
            if status == "all":
                service_data["status"] = ["needs_action", "completed"]
            else:
                service_data["status"] = [status]
        service_result = await hass.services.async_call(
            TODO_DOMAIN,
            TodoServices.GET_ITEMS,
            service_data,
            context=llm_context.context,
            blocking=True,
            return_response=True,
        )
        if not service_result:
            return {"success": False, "error": "To-do list not found"}
        items = cast(dict, service_result)[entity_id]["items"]
        return {"success": True, "result": items}


class GetLiveContextTool(Tool):
    """Tool for getting the current state of exposed entities.

    This returns state for all entities that have been exposed to
    the assistant. This is different than the GetState intent, which
    returns state for entities based on intent parameters.
    """

    name = "GetLiveContext"
    description = (
        "Provides real-time information about the CURRENT state, value, or mode of devices, sensors, entities, or areas. "
        "Use this tool for: "
        "1. Answering questions about current conditions (e.g., 'Is the light on?'). "
        "2. As the first step in conditional actions (e.g., 'If the weather is rainy, turn off sprinklers' requires checking the weather first)."
    )

    async def async_call(
        self,
        hass: HomeAssistant,
        tool_input: ToolInput,
        llm_context: LLMContext,
    ) -> JsonObjectType:
        """Get the current state of exposed entities."""
        if llm_context.assistant is None:
            # Note this doesn't happen in practice since this tool won't be
            # exposed if no assistant is configured.
            return {"success": False, "error": "No assistant configured"}

        exposed_entities = _get_exposed_entities(hass, llm_context.assistant)
        if not exposed_entities["entities"]:
            return {"success": False, "error": NO_ENTITIES_PROMPT}
        prompt = [
            "Live Context: An overview of the areas and the devices in this smart home:",
            yaml_util.dump(list(exposed_entities["entities"].values())),
        ]
        return {
            "success": True,
            "result": "\n".join(prompt),
        }


class GetDateTimeTool(Tool):
    """Tool for getting the current date and time."""

    name = "GetDateTime"
    description = "Provides the current date and time."

    async def async_call(
        self,
        hass: HomeAssistant,
        tool_input: ToolInput,
        llm_context: LLMContext,
    ) -> JsonObjectType:
        """Get the current date and time."""
        now = dt_util.now()

        return {
            "success": True,
            "result": {
                "date": now.strftime("%Y-%m-%d"),
                "time": now.strftime("%H:%M:%S"),
                "timezone": now.strftime("%Z"),
                "weekday": now.strftime("%A"),
            },
        }
</file>

<file path="location.py">
"""Location helpers for Home Assistant."""

from __future__ import annotations

from collections.abc import Iterable
import logging

from homeassistant.const import ATTR_LATITUDE, ATTR_LONGITUDE
from homeassistant.core import HomeAssistant, State
from homeassistant.util import location as location_util

_LOGGER = logging.getLogger(__name__)


def has_location(state: State) -> bool:
    """Test if state contains a valid location.

    Async friendly.
    """
    return (
        isinstance(state, State)
        and isinstance(state.attributes.get(ATTR_LATITUDE), (float, int))
        and isinstance(state.attributes.get(ATTR_LONGITUDE), (float, int))
    )


def closest(latitude: float, longitude: float, states: Iterable[State]) -> State | None:
    """Return closest state to point.

    Async friendly.
    """
    with_location = [state for state in states if has_location(state)]

    if not with_location:
        return None

    return min(
        with_location,
        key=lambda state: location_util.distance(
            state.attributes.get(ATTR_LATITUDE),
            state.attributes.get(ATTR_LONGITUDE),
            latitude,
            longitude,
        )
        or 0,
    )


def find_coordinates(
    hass: HomeAssistant, name: str, recursion_history: list | None = None
) -> str | None:
    """Try to resolve the a location from a supplied name or entity_id.

    Will recursively resolve an entity if pointed to by the state of the supplied
    entity.

    Returns coordinates in the form of '90.000,180.000', an address or
    the state of the last resolved entity.
    """
    # Check if a friendly name of a zone was supplied
    if (zone_coords := resolve_zone(hass, name)) is not None:
        return zone_coords

    # Check if an entity_id was supplied.
    if (entity_state := hass.states.get(name)) is None:
        _LOGGER.debug("Unable to find entity %s", name)
        return name

    # Check if the entity_state has location attributes
    if has_location(entity_state):
        return _get_location_from_attributes(entity_state)

    # Check if entity_state is a zone
    zone_entity = hass.states.get(f"zone.{entity_state.state}")
    if has_location(zone_entity):  # type: ignore[arg-type]
        _LOGGER.debug(
            "%s is in %s, getting zone location",
            name,
            zone_entity.entity_id,  # type: ignore[union-attr]
        )
        return _get_location_from_attributes(zone_entity)  # type: ignore[arg-type]

    # Check if entity_state is a friendly name of a zone
    if (zone_coords := resolve_zone(hass, entity_state.state)) is not None:
        return zone_coords

    # Check if entity_state is an entity_id
    if recursion_history is None:
        recursion_history = []
    recursion_history.append(name)
    if entity_state.state in recursion_history:
        _LOGGER.error(
            (
                "Circular reference detected while trying to find coordinates of an"
                " entity. The state of %s has already been checked"
            ),
            entity_state.state,
        )
        return None
    _LOGGER.debug("Getting nested entity for state: %s", entity_state.state)
    nested_entity = hass.states.get(entity_state.state)
    if nested_entity is not None:
        _LOGGER.debug("Resolving nested entity_id: %s", entity_state.state)
        return find_coordinates(hass, entity_state.state, recursion_history)

    # Might be an address, coordinates or anything else.
    # This has to be checked by the caller.
    return entity_state.state


def resolve_zone(hass: HomeAssistant, zone_name: str) -> str | None:
    """Get a lat/long from a zones friendly_name.

    None is returned if no zone is found by that friendly_name.
    """
    states = hass.states.async_all("zone")
    for state in states:
        if state.name == zone_name:
            return _get_location_from_attributes(state)

    return None


def _get_location_from_attributes(entity_state: State) -> str:
    """Get the lat/long string from an entities attributes."""
    attr = entity_state.attributes
    return f"{attr.get(ATTR_LATITUDE)},{attr.get(ATTR_LONGITUDE)}"
</file>

<file path="network.py">
"""Network helpers."""

from __future__ import annotations

from collections.abc import Callable
from contextlib import suppress
from ipaddress import ip_address

from aiohttp import hdrs
from hass_nabucasa import remote
import yarl

from homeassistant.core import HomeAssistant
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import bind_hass
from homeassistant.util.network import is_ip_address, is_loopback, normalize_url

from . import http
from .hassio import is_hassio

TYPE_URL_INTERNAL = "internal_url"
TYPE_URL_EXTERNAL = "external_url"
SUPERVISOR_NETWORK_HOST = "homeassistant"


class NoURLAvailableError(HomeAssistantError):
    """An URL to the Home Assistant instance is not available."""


@bind_hass
def is_internal_request(hass: HomeAssistant) -> bool:
    """Test if the current request is internal."""
    try:
        get_url(
            hass, allow_external=False, allow_cloud=False, require_current_request=True
        )
    except NoURLAvailableError:
        return False
    return True


@bind_hass
def get_supervisor_network_url(
    hass: HomeAssistant, *, allow_ssl: bool = False
) -> str | None:
    """Get URL for home assistant within supervisor network."""
    if hass.config.api is None or not is_hassio(hass):
        return None

    scheme = "http"
    if hass.config.api.use_ssl:
        # Certificate won't be valid for hostname so this URL usually won't work
        if not allow_ssl:
            return None

        scheme = "https"

    return str(
        yarl.URL.build(
            scheme=scheme,
            host=SUPERVISOR_NETWORK_HOST,
            port=hass.config.api.port,
        )
    )


def is_hass_url(hass: HomeAssistant, url: str) -> bool:
    """Return if the URL points at this Home Assistant instance."""
    parsed = yarl.URL(url)

    if not parsed.is_absolute():
        return False

    if parsed.is_default_port():
        parsed = parsed.with_port(None)

    def host_ip() -> str | None:
        if hass.config.api is None or is_loopback(ip_address(hass.config.api.local_ip)):
            return None

        return str(
            yarl.URL.build(
                scheme="http", host=hass.config.api.local_ip, port=hass.config.api.port
            )
        )

    def cloud_url() -> str | None:
        try:
            return _get_cloud_url(hass)
        except NoURLAvailableError:
            return None

    potential_base_factory: Callable[[], str | None]
    for potential_base_factory in (
        lambda: hass.config.internal_url,
        lambda: hass.config.external_url,
        cloud_url,
        host_ip,
        lambda: get_supervisor_network_url(hass, allow_ssl=True),
    ):
        potential_base = potential_base_factory()

        if potential_base is None:
            continue

        potential_parsed = yarl.URL(normalize_url(potential_base))

        if (
            parsed.scheme == potential_parsed.scheme
            and parsed.authority == potential_parsed.authority
        ):
            return True

    return False


@bind_hass
def get_url(
    hass: HomeAssistant,
    *,
    require_current_request: bool = False,
    require_ssl: bool = False,
    require_standard_port: bool = False,
    require_cloud: bool = False,
    allow_internal: bool = True,
    allow_external: bool = True,
    allow_cloud: bool = True,
    allow_ip: bool | None = None,
    prefer_external: bool | None = None,
    prefer_cloud: bool = False,
) -> str:
    """Get a URL to this instance."""
    if require_current_request and http.current_request.get() is None:
        raise NoURLAvailableError

    if prefer_external is None:
        prefer_external = hass.config.api is not None and hass.config.api.use_ssl

    if allow_ip is None:
        allow_ip = hass.config.api is None or not hass.config.api.use_ssl

    order = [TYPE_URL_INTERNAL, TYPE_URL_EXTERNAL]
    if prefer_external:
        order.reverse()

    # Try finding an URL in the order specified
    for url_type in order:
        if allow_internal and url_type == TYPE_URL_INTERNAL and not require_cloud:
            with suppress(NoURLAvailableError):
                return _get_internal_url(
                    hass,
                    allow_ip=allow_ip,
                    require_current_request=require_current_request,
                    require_ssl=require_ssl,
                    require_standard_port=require_standard_port,
                )

        if require_cloud or (allow_external and url_type == TYPE_URL_EXTERNAL):
            with suppress(NoURLAvailableError):
                return _get_external_url(
                    hass,
                    allow_cloud=allow_cloud,
                    allow_ip=allow_ip,
                    prefer_cloud=prefer_cloud,
                    require_current_request=require_current_request,
                    require_ssl=require_ssl,
                    require_standard_port=require_standard_port,
                    require_cloud=require_cloud,
                )
            if require_cloud:
                raise NoURLAvailableError

    # For current request, we accept loopback interfaces (e.g., 127.0.0.1),
    # the Supervisor hostname and localhost transparently
    request_host = _get_request_host()
    if (
        require_current_request
        and request_host is not None
        and hass.config.api is not None
    ):
        scheme = "https" if hass.config.api.use_ssl else "http"
        current_url = yarl.URL.build(
            scheme=scheme, host=request_host, port=hass.config.api.port
        )

        known_hostnames = ["localhost"]
        if is_hassio(hass):
            # Local import to avoid circular dependencies
            from homeassistant.components.hassio import get_host_info  # noqa: PLC0415

            if host_info := get_host_info(hass):
                known_hostnames.extend(
                    [host_info["hostname"], f"{host_info['hostname']}.local"]
                )

        if (
            (
                (
                    allow_ip
                    and is_ip_address(request_host)
                    and is_loopback(ip_address(request_host))
                )
                or request_host in known_hostnames
            )
            and (not require_ssl or current_url.scheme == "https")
            and (not require_standard_port or current_url.is_default_port())
        ):
            return normalize_url(str(current_url))

    # We have to be honest now, we have no viable option available
    raise NoURLAvailableError


def _get_request_host() -> str | None:
    """Get the host address of the current request."""
    if (request := http.current_request.get()) is None:
        raise NoURLAvailableError
    # partition the host to remove the port
    # because the raw host header can contain the port
    host = request.headers.get(hdrs.HOST)
    if host is None:
        return None
    # IPv6 addresses are enclosed in brackets
    # use same logic as yarl and urllib to extract the host
    if "[" in host:
        return (host.partition("[")[2]).partition("]")[0]
    if ":" in host:
        host = host.partition(":")[0]
    return host


@bind_hass
def _get_internal_url(
    hass: HomeAssistant,
    *,
    allow_ip: bool = True,
    require_current_request: bool = False,
    require_ssl: bool = False,
    require_standard_port: bool = False,
) -> str:
    """Get internal URL of this instance."""
    if hass.config.internal_url:
        internal_url = yarl.URL(hass.config.internal_url)
        if (
            (not require_current_request or internal_url.host == _get_request_host())
            and (not require_ssl or internal_url.scheme == "https")
            and (not require_standard_port or internal_url.is_default_port())
            and (allow_ip or not is_ip_address(str(internal_url.host)))
        ):
            return normalize_url(str(internal_url))

    # Fallback to detected local IP
    if allow_ip and not (
        require_ssl or hass.config.api is None or hass.config.api.use_ssl
    ):
        ip_url = yarl.URL.build(
            scheme="http", host=hass.config.api.local_ip, port=hass.config.api.port
        )
        if (
            ip_url.host
            and not is_loopback(ip_address(ip_url.host))
            and (not require_current_request or ip_url.host == _get_request_host())
            and (not require_standard_port or ip_url.is_default_port())
        ):
            return normalize_url(str(ip_url))

    raise NoURLAvailableError


@bind_hass
def _get_external_url(
    hass: HomeAssistant,
    *,
    allow_cloud: bool = True,
    allow_ip: bool = True,
    prefer_cloud: bool = False,
    require_current_request: bool = False,
    require_ssl: bool = False,
    require_standard_port: bool = False,
    require_cloud: bool = False,
) -> str:
    """Get external URL of this instance."""
    if require_cloud:
        return _get_cloud_url(hass, require_current_request=require_current_request)

    if prefer_cloud and allow_cloud:
        with suppress(NoURLAvailableError):
            return _get_cloud_url(hass)

    if hass.config.external_url:
        external_url = yarl.URL(hass.config.external_url)
        if (
            (allow_ip or not is_ip_address(str(external_url.host)))
            and (
                not require_current_request or external_url.host == _get_request_host()
            )
            and (not require_standard_port or external_url.is_default_port())
            and (
                not require_ssl
                or (
                    external_url.scheme == "https"
                    and not is_ip_address(str(external_url.host))
                )
            )
        ):
            return normalize_url(str(external_url))

    if allow_cloud:
        with suppress(NoURLAvailableError):
            return _get_cloud_url(hass, require_current_request=require_current_request)

    raise NoURLAvailableError


@bind_hass
def _get_cloud_url(hass: HomeAssistant, require_current_request: bool = False) -> str:
    """Get external Home Assistant Cloud URL of this instance."""
    if "cloud" in hass.config.components:
        # Local import to avoid circular dependencies
        from homeassistant.components.cloud import (  # noqa: PLC0415
            CloudNotAvailable,
            async_remote_ui_url,
        )

        try:
            cloud_url = yarl.URL(async_remote_ui_url(hass))
        except CloudNotAvailable as err:
            raise NoURLAvailableError from err

        if not require_current_request or cloud_url.host == _get_request_host():
            return normalize_url(str(cloud_url))

    raise NoURLAvailableError


def is_cloud_connection(hass: HomeAssistant) -> bool:
    """Return True if the current connection is a nabucasa cloud connection."""

    if "cloud" not in hass.config.components:
        return False

    return remote.is_cloud_request.get()
</file>

<file path="normalized_name_base_registry.py">
"""Provide a base class for registries that use a normalized name index."""

from dataclasses import dataclass, field
from datetime import datetime
from functools import lru_cache

from homeassistant.util import dt as dt_util, slugify

from .registry import BaseRegistryItems


@dataclass(slots=True, frozen=True, kw_only=True)
class NormalizedNameBaseRegistryEntry:
    """Normalized Name Base Registry Entry."""

    name: str
    normalized_name: str = field(init=False)
    created_at: datetime = field(default_factory=dt_util.utcnow)
    modified_at: datetime = field(default_factory=dt_util.utcnow)

    def __post_init__(self) -> None:
        """Post init."""
        object.__setattr__(self, "normalized_name", normalize_name(self.name))


@lru_cache(maxsize=1024)
def normalize_name(name: str) -> str:
    """Normalize a name by removing whitespace and case folding."""
    return name.casefold().replace(" ", "")


class NormalizedNameBaseRegistryItems[_VT: NormalizedNameBaseRegistryEntry](
    BaseRegistryItems[_VT]
):
    """Base container for normalized name registry items, maps key -> entry.

    Maintains an additional index:
    - normalized name -> entry
    """

    def __init__(self) -> None:
        """Initialize the container."""
        super().__init__()
        self._normalized_names: dict[str, _VT] = {}

    def _unindex_entry(self, key: str, replacement_entry: _VT | None = None) -> None:
        old_entry = self.data[key]
        if (
            replacement_entry is not None
            and (normalized_name := replacement_entry.normalized_name)
            != old_entry.normalized_name
            and normalized_name in self._normalized_names
        ):
            raise ValueError(
                f"The name {replacement_entry.name} ({normalized_name}) is already in use"
            )
        del self._normalized_names[old_entry.normalized_name]

    def _index_entry(self, key: str, entry: _VT) -> None:
        self._normalized_names[entry.normalized_name] = entry

    def get_by_name(self, name: str) -> _VT | None:
        """Get entry by name."""
        return self._normalized_names.get(normalize_name(name))

    def generate_id_from_name(self, name: str) -> str:
        """Generate ID from name."""
        suggestion = suggestion_base = slugify(name)
        tries = 1
        while suggestion in self:
            tries += 1
            suggestion = f"{suggestion_base}_{tries}"
        return suggestion
</file>

<file path="ratelimit.py">
"""Ratelimit helper."""

from __future__ import annotations

import asyncio
from collections.abc import Callable, Hashable
import logging
import time

from homeassistant.core import HomeAssistant, callback

_LOGGER = logging.getLogger(__name__)


class KeyedRateLimit:
    """Class to track rate limits."""

    def __init__(
        self,
        hass: HomeAssistant,
    ) -> None:
        """Initialize ratelimit tracker."""
        self.hass = hass
        self._last_triggered: dict[Hashable, float] = {}
        self._rate_limit_timers: dict[Hashable, asyncio.TimerHandle] = {}

    @callback
    def async_has_timer(self, key: Hashable) -> bool:
        """Check if a rate limit timer is running."""
        return key in self._rate_limit_timers

    @callback
    def async_triggered(self, key: Hashable, now: float | None = None) -> None:
        """Call when the action we are tracking was triggered."""
        self.async_cancel_timer(key)
        self._last_triggered[key] = now or time.time()

    @callback
    def async_cancel_timer(self, key: Hashable) -> None:
        """Cancel a rate limit time that will call the action."""
        if handle := self._rate_limit_timers.pop(key, None):
            handle.cancel()

    @callback
    def async_remove(self) -> None:
        """Remove all timers."""
        for timer in self._rate_limit_timers.values():
            timer.cancel()
        self._rate_limit_timers.clear()

    @callback
    def async_schedule_action[*_Ts](
        self,
        key: Hashable,
        rate_limit: float | None,
        now: float,
        action: Callable[[*_Ts], None],
        *args: *_Ts,
    ) -> float | None:
        """Check rate limits and schedule an action if we hit the limit.

        If the rate limit is hit:
            Schedules the action for when the rate limit expires
            if there are no pending timers. The action must
            be called in async.

            Returns the time the rate limit will expire

        If the rate limit is not hit:

            Return None
        """
        if rate_limit is None:
            return None

        if not (last_triggered := self._last_triggered.get(key)):
            return None

        next_call_time = last_triggered + rate_limit

        if next_call_time <= now:
            self.async_cancel_timer(key)
            return None

        _LOGGER.debug(
            "Reached rate limit of %s for %s and deferred action until %s",
            rate_limit,
            key,
            next_call_time,
        )

        if key not in self._rate_limit_timers:
            self._rate_limit_timers[key] = self.hass.loop.call_later(
                next_call_time - now,
                action,
                *args,
            )

        return next_call_time
</file>

<file path="recorder.py">
"""Helpers to check recorder."""

from __future__ import annotations

import asyncio
from collections.abc import Callable, Generator
from contextlib import contextmanager
from dataclasses import dataclass, field
import functools
import logging
from typing import TYPE_CHECKING, Any

from homeassistant.core import HomeAssistant, callback
from homeassistant.util.hass_dict import HassKey

if TYPE_CHECKING:
    from sqlalchemy.orm.session import Session

    from homeassistant.components.recorder import Recorder

_LOGGER = logging.getLogger(__name__)

DATA_RECORDER: HassKey[RecorderData] = HassKey("recorder")
DATA_INSTANCE: HassKey[Recorder] = HassKey("recorder_instance")


@dataclass(slots=True)
class RecorderData:
    """Recorder data stored in hass.data."""

    recorder_platforms: dict[str, Any] = field(default_factory=dict)
    db_connected: asyncio.Future[bool] = field(default_factory=asyncio.Future)


@callback
def async_migration_in_progress(hass: HomeAssistant) -> bool:
    """Check to see if a recorder migration is in progress."""
    from homeassistant.components import recorder  # noqa: PLC0415

    return recorder.util.async_migration_in_progress(hass)


@callback
def async_migration_is_live(hass: HomeAssistant) -> bool:
    """Check to see if a recorder migration is live."""
    from homeassistant.components import recorder  # noqa: PLC0415

    return recorder.util.async_migration_is_live(hass)


@callback
def async_initialize_recorder(hass: HomeAssistant) -> None:
    """Initialize recorder data.

    This creates the RecorderData instance stored in hass.data[DATA_RECORDER] and
    registers the basic recorder websocket API which is used by frontend to determine
    if the recorder is migrating the database.
    """
    from homeassistant.components.recorder.basic_websocket_api import (  # noqa: PLC0415
        async_setup,
    )

    hass.data[DATA_RECORDER] = RecorderData()
    async_setup(hass)


@functools.lru_cache(maxsize=1)
def get_instance(hass: HomeAssistant) -> Recorder:
    """Get the recorder instance."""
    return hass.data[DATA_INSTANCE]


@contextmanager
def session_scope(
    *,
    hass: HomeAssistant | None = None,
    session: Session | None = None,
    exception_filter: Callable[[Exception], bool] | None = None,
    read_only: bool = False,
) -> Generator[Session]:
    """Provide a transactional scope around a series of operations.

    read_only is used to indicate that the session is only used for reading
    data and that no commit is required. It does not prevent the session
    from writing and is not a security measure.
    """
    if session is None and hass is not None:
        session = get_instance(hass).get_session()

    if session is None:
        raise RuntimeError("Session required")

    need_rollback = False
    try:
        yield session
        if not read_only and session.get_transaction():
            need_rollback = True
            session.commit()
    except Exception as err:
        _LOGGER.exception("Error executing query")
        if need_rollback:
            session.rollback()
        if not exception_filter or not exception_filter(err):
            raise
    finally:
        session.close()
</file>

<file path="redact.py">
"""Helpers to redact sensitive data."""

from __future__ import annotations

from collections.abc import Callable, Iterable, Mapping
from typing import Any, cast, overload

from homeassistant.core import callback

REDACTED = "**REDACTED**"


def partial_redact(
    x: str | Any, unmasked_prefix: int = 4, unmasked_suffix: int = 4
) -> str:
    """Mask part of a string with *."""
    if not isinstance(x, str):
        return REDACTED

    unmasked = unmasked_prefix + unmasked_suffix
    if len(x) < unmasked * 2:
        return REDACTED

    if not unmasked_prefix and not unmasked_suffix:
        return REDACTED

    suffix = x[-unmasked_suffix:] if unmasked_suffix else ""
    return f"{x[:unmasked_prefix]}***{suffix}"


@overload
def async_redact_data[_ValueT](
    data: Mapping, to_redact: Iterable[Any] | Mapping[Any, Callable[[_ValueT], _ValueT]]
) -> dict: ...


@overload
def async_redact_data[_T, _ValueT](
    data: _T, to_redact: Iterable[Any] | Mapping[Any, Callable[[_ValueT], _ValueT]]
) -> _T: ...


@callback
def async_redact_data[_T, _ValueT](
    data: _T, to_redact: Iterable[Any] | Mapping[Any, Callable[[_ValueT], _ValueT]]
) -> _T:
    """Redact sensitive data in a dict."""
    if not isinstance(data, (Mapping, list)):
        return data

    if isinstance(data, list):
        return cast(_T, [async_redact_data(val, to_redact) for val in data])

    redacted = {**data}

    for key, value in redacted.items():
        if value is None:
            continue
        if isinstance(value, str) and not value:
            continue
        if key in to_redact:
            if isinstance(to_redact, Mapping):
                redacted[key] = to_redact[key](value)
            else:
                redacted[key] = REDACTED
        elif isinstance(value, Mapping):
            redacted[key] = async_redact_data(value, to_redact)
        elif isinstance(value, list):
            redacted[key] = [async_redact_data(item, to_redact) for item in value]

    return cast(_T, redacted)
</file>

<file path="registry.py">
"""Provide a base implementation for registries."""

from __future__ import annotations

from abc import ABC, abstractmethod
from collections import UserDict, defaultdict
from collections.abc import Mapping, Sequence, ValuesView
from typing import TYPE_CHECKING, Any, Literal

from homeassistant.core import CoreState, HomeAssistant, callback

if TYPE_CHECKING:
    from .storage import Store

SAVE_DELAY = 10
SAVE_DELAY_LONG = 180

type RegistryIndexType = defaultdict[str, dict[str, Literal[True]]]


class BaseRegistryItems[_DataT](UserDict[str, _DataT], ABC):
    """Base class for registry items."""

    data: dict[str, _DataT]

    def values(self) -> ValuesView[_DataT]:
        """Return the underlying values to avoid __iter__ overhead."""
        return self.data.values()

    @abstractmethod
    def _index_entry(self, key: str, entry: _DataT) -> None:
        """Index an entry."""

    @abstractmethod
    def _unindex_entry(self, key: str, replacement_entry: _DataT | None = None) -> None:
        """Unindex an entry."""

    def __setitem__(self, key: str, entry: _DataT) -> None:
        """Add an item."""
        data = self.data
        if key in data:
            self._unindex_entry(key, entry)
        data[key] = entry
        self._index_entry(key, entry)

    def _unindex_entry_value(
        self, key: str, value: str, index: RegistryIndexType
    ) -> None:
        """Unindex an entry value.

        key is the entry key
        value is the value to unindex such as config_entry_id or device_id.
        index is the index to unindex from.
        """
        entries = index[value]
        del entries[key]
        if not entries:
            del index[value]

    def __delitem__(self, key: str) -> None:
        """Remove an item."""
        self._unindex_entry(key)
        super().__delitem__(key)


class BaseRegistry[_StoreDataT: Mapping[str, Any] | Sequence[Any]](ABC):
    """Class to implement a registry."""

    hass: HomeAssistant
    _store: Store[_StoreDataT]

    @callback
    def async_schedule_save(self) -> None:
        """Schedule saving the registry."""
        # Schedule the save past startup to avoid writing
        # the file while the system is starting.
        delay = SAVE_DELAY if self.hass.state is CoreState.running else SAVE_DELAY_LONG
        self._store.async_delay_save(self._data_to_save, delay)

    @abstractmethod
    def _data_to_save(self) -> _StoreDataT:
        """Return data of registry to store in a file."""
</file>

<file path="reload.py">
"""Class to reload platforms."""

from __future__ import annotations

import asyncio
from collections.abc import Iterable
import logging
from typing import Any, Literal, overload

from homeassistant import config as conf_util
from homeassistant.const import SERVICE_RELOAD
from homeassistant.core import HomeAssistant, ServiceCall, callback
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import async_get_integration
from homeassistant.setup import async_setup_component

from .entity import Entity
from .entity_component import EntityComponent
from .entity_platform import EntityPlatform, async_get_platforms
from .service import async_register_admin_service
from .typing import ConfigType

_LOGGER = logging.getLogger(__name__)

PLATFORM_RESET_LOCK = "lock_async_reset_platform_{}"


async def async_reload_integration_platforms(
    hass: HomeAssistant, integration_domain: str, platform_domains: Iterable[str]
) -> None:
    """Reload an integration's platforms.

    The platform must support being re-setup.

    This functionality is only intended to be used for integrations that process
    Home Assistant data and make this available to other integrations.

    Examples are template, stats, derivative, utility meter.
    """
    try:
        unprocessed_conf = await conf_util.async_hass_config_yaml(hass)
    except HomeAssistantError as err:
        _LOGGER.error(err)
        return

    tasks = [
        _resetup_platform(hass, integration_domain, platform_domain, unprocessed_conf)
        for platform_domain in platform_domains
    ]

    await asyncio.gather(*tasks)


async def _resetup_platform(
    hass: HomeAssistant,
    integration_domain: str,
    platform_domain: str,
    unprocessed_config: ConfigType,
) -> None:
    """Resetup a platform."""
    integration = await async_get_integration(hass, platform_domain)

    conf = await conf_util.async_process_component_and_handle_errors(
        hass, unprocessed_config, integration
    )

    if not conf:
        return

    root_config: dict[str, list[ConfigType]] = {platform_domain: []}
    # Extract only the config for template, ignore the rest.
    for p_type, p_config in conf_util.config_per_platform(conf, platform_domain):
        if p_type != integration_domain:
            continue

        root_config[platform_domain].append(p_config)

    component = await integration.async_get_component()

    if hasattr(component, "async_reset_platform"):
        # If the integration has its own way to reset
        # use this method.
        async with hass.data.setdefault(
            PLATFORM_RESET_LOCK.format(platform_domain), asyncio.Lock()
        ):
            await component.async_reset_platform(hass, integration_domain)
            await component.async_setup(hass, root_config)
        return

    # If it's an entity platform, we use the entity_platform
    # async_reset method
    platform = async_get_platform_without_config_entry(
        hass, integration_domain, platform_domain
    )
    if platform:
        await _async_reconfig_platform(platform, root_config[platform_domain])
        return

    if not root_config[platform_domain]:
        # No config for this platform
        # and it's not loaded. Nothing to do.
        return

    await _async_setup_platform(
        hass, integration_domain, platform_domain, root_config[platform_domain]
    )


async def _async_setup_platform(
    hass: HomeAssistant,
    integration_domain: str,
    platform_domain: str,
    platform_configs: list[dict[str, Any]],
) -> None:
    """Platform for the first time when new configuration is added."""
    if platform_domain not in hass.data:
        await async_setup_component(
            hass, platform_domain, {platform_domain: platform_configs}
        )
        return

    entity_component: EntityComponent[Entity] = hass.data[platform_domain]
    tasks = [
        entity_component.async_setup_platform(integration_domain, p_config)
        for p_config in platform_configs
    ]
    await asyncio.gather(*tasks)


async def _async_reconfig_platform(
    platform: EntityPlatform, platform_configs: list[dict[str, Any]]
) -> None:
    """Reconfigure an already loaded platform."""
    await platform.async_reset()
    tasks = [platform.async_setup(p_config) for p_config in platform_configs]
    await asyncio.gather(*tasks)


@overload
async def async_integration_yaml_config(
    hass: HomeAssistant, integration_name: str
) -> ConfigType | None: ...


@overload
async def async_integration_yaml_config(
    hass: HomeAssistant,
    integration_name: str,
    *,
    raise_on_failure: Literal[True],
) -> ConfigType: ...


@overload
async def async_integration_yaml_config(
    hass: HomeAssistant,
    integration_name: str,
    *,
    raise_on_failure: Literal[False],
) -> ConfigType | None: ...


async def async_integration_yaml_config(
    hass: HomeAssistant, integration_name: str, *, raise_on_failure: bool = False
) -> ConfigType | None:
    """Fetch the latest yaml configuration for an integration."""
    integration = await async_get_integration(hass, integration_name)
    config = await conf_util.async_hass_config_yaml(hass)
    return await conf_util.async_process_component_and_handle_errors(
        hass, config, integration, raise_on_failure=raise_on_failure
    )


@callback
def async_get_platform_without_config_entry(
    hass: HomeAssistant, integration_name: str, integration_platform_name: str
) -> EntityPlatform | None:
    """Find an existing platform that is not a config entry."""
    for integration_platform in async_get_platforms(hass, integration_name):
        if integration_platform.config_entry is not None:
            continue
        if integration_platform.domain == integration_platform_name:
            platform: EntityPlatform = integration_platform
            return platform

    return None


async def async_setup_reload_service(
    hass: HomeAssistant, domain: str, platforms: Iterable[str]
) -> None:
    """Create the reload service for the domain."""
    if hass.services.has_service(domain, SERVICE_RELOAD):
        return

    async def _reload_config(call: ServiceCall) -> None:
        """Reload the platforms."""
        await async_reload_integration_platforms(hass, domain, platforms)
        hass.bus.async_fire(f"event_{domain}_reloaded", context=call.context)

    async_register_admin_service(hass, domain, SERVICE_RELOAD, _reload_config)


def setup_reload_service(
    hass: HomeAssistant, domain: str, platforms: Iterable[str]
) -> None:
    """Sync version of async_setup_reload_service."""
    asyncio.run_coroutine_threadsafe(
        async_setup_reload_service(hass, domain, platforms),
        hass.loop,
    ).result()
</file>

<file path="restore_state.py">
"""Support for restoring entity states on startup."""

from __future__ import annotations

from abc import ABC, abstractmethod
from datetime import datetime, timedelta
import logging
from typing import Any, Self, cast

from homeassistant.const import ATTR_RESTORED, EVENT_HOMEASSISTANT_STOP
from homeassistant.core import HomeAssistant, State, callback, valid_entity_id
from homeassistant.exceptions import HomeAssistantError
from homeassistant.util import dt as dt_util
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.json import json_loads

from . import start
from .entity import Entity
from .event import async_track_time_interval
from .json import JSONEncoder
from .singleton import singleton
from .storage import Store

DATA_RESTORE_STATE: HassKey[RestoreStateData] = HassKey("restore_state")

_LOGGER = logging.getLogger(__name__)

STORAGE_KEY = "core.restore_state"
STORAGE_VERSION = 1

# How long between periodically saving the current states to disk
STATE_DUMP_INTERVAL = timedelta(minutes=15)

# How long should a saved state be preserved if the entity no longer exists
STATE_EXPIRATION = timedelta(days=7)


class ExtraStoredData(ABC):
    """Object to hold extra stored data."""

    @abstractmethod
    def as_dict(self) -> dict[str, Any]:
        """Return a dict representation of the extra data.

        Must be serializable by Home Assistant's JSONEncoder.
        """


class RestoredExtraData(ExtraStoredData):
    """Object to hold extra stored data loaded from storage."""

    def __init__(self, json_dict: dict[str, Any]) -> None:
        """Object to hold extra stored data."""
        self.json_dict = json_dict

    def as_dict(self) -> dict[str, Any]:
        """Return a dict representation of the extra data."""
        return self.json_dict


class StoredState:
    """Object to represent a stored state."""

    def __init__(
        self,
        state: State,
        extra_data: ExtraStoredData | None,
        last_seen: datetime,
    ) -> None:
        """Initialize a new stored state."""
        self.extra_data = extra_data
        self.last_seen = last_seen
        self.state = state

    def as_dict(self) -> dict[str, Any]:
        """Return a dict representation of the stored state to be JSON serialized."""
        return {
            "state": self.state.json_fragment,
            "extra_data": self.extra_data.as_dict() if self.extra_data else None,
            "last_seen": self.last_seen,
        }

    @classmethod
    def from_dict(cls, json_dict: dict) -> Self:
        """Initialize a stored state from a dict."""
        extra_data_dict = json_dict.get("extra_data")
        extra_data = RestoredExtraData(extra_data_dict) if extra_data_dict else None
        last_seen = json_dict["last_seen"]

        if isinstance(last_seen, str):
            last_seen = dt_util.parse_datetime(last_seen)

        return cls(
            cast(State, State.from_dict(json_dict["state"])), extra_data, last_seen
        )


async def async_load(hass: HomeAssistant) -> None:
    """Load the restore state task."""
    await async_get(hass).async_setup()


@callback
@singleton(DATA_RESTORE_STATE)
def async_get(hass: HomeAssistant) -> RestoreStateData:
    """Get the restore state data helper."""
    return RestoreStateData(hass)


class RestoreStateData:
    """Helper class for managing the helper saved data."""

    @classmethod
    async def async_save_persistent_states(cls, hass: HomeAssistant) -> None:
        """Dump states now."""
        await async_get(hass).async_dump_states()

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the restore state data class."""
        self.hass: HomeAssistant = hass
        self.store = Store[list[dict[str, Any]]](
            hass, STORAGE_VERSION, STORAGE_KEY, encoder=JSONEncoder
        )
        self.last_states: dict[str, StoredState] = {}
        self.entities: dict[str, RestoreEntity] = {}

    async def async_setup(self) -> None:
        """Set up up the instance of this data helper."""
        await self.async_load()

        @callback
        def hass_start(hass: HomeAssistant) -> None:
            """Start the restore state task."""
            self.async_setup_dump()

        start.async_at_start(self.hass, hass_start)

    async def async_load(self) -> None:
        """Load the instance of this data helper."""
        try:
            stored_states = await self.store.async_load()
        except HomeAssistantError as exc:
            _LOGGER.error("Error loading last states", exc_info=exc)
            stored_states = None

        if stored_states is None:
            _LOGGER.debug("Not creating cache - no saved states found")
            self.last_states = {}
        else:
            self.last_states = {
                item["state"]["entity_id"]: StoredState.from_dict(item)
                for item in stored_states
                if valid_entity_id(item["state"]["entity_id"])
            }
            _LOGGER.debug("Created cache with %s", list(self.last_states))

    @callback
    def async_get_stored_states(self) -> list[StoredState]:
        """Get the set of states which should be stored.

        This includes the states of all registered entities, as well as the
        stored states from the previous run, which have not been created as
        entities on this run, and have not expired.
        """
        now = dt_util.utcnow()
        all_states = self.hass.states.async_all()
        # Entities currently backed by an entity object
        current_states_by_entity_id = {
            state.entity_id: state
            for state in all_states
            if not state.attributes.get(ATTR_RESTORED)
        }

        # Start with the currently registered states
        stored_states = [
            StoredState(
                current_states_by_entity_id[entity_id],
                entity.extra_restore_state_data,
                now,
            )
            for entity_id, entity in self.entities.items()
            if entity_id in current_states_by_entity_id
        ]
        expiration_time = now - STATE_EXPIRATION

        for entity_id, stored_state in self.last_states.items():
            # Don't save old states that have entities in the current run
            # They are either registered and already part of stored_states,
            # or no longer care about restoring.
            if entity_id in current_states_by_entity_id:
                continue

            # Don't save old states that have expired
            if stored_state.last_seen < expiration_time:
                continue

            stored_states.append(stored_state)

        return stored_states

    async def async_dump_states(self) -> None:
        """Save the current state machine to storage."""
        _LOGGER.debug("Dumping states")
        try:
            await self.store.async_save(
                [
                    stored_state.as_dict()
                    for stored_state in self.async_get_stored_states()
                ]
            )
        except HomeAssistantError as exc:
            _LOGGER.error("Error saving current states", exc_info=exc)

    @callback
    def async_setup_dump(self, *args: Any) -> None:
        """Set up the restore state listeners."""

        async def _async_dump_states(*_: Any) -> None:
            await self.async_dump_states()

        # Dump the initial states now. This helps minimize the risk of having
        # old states loaded by overwriting the last states once Home Assistant
        # has started and the old states have been read.
        self.hass.async_create_task_internal(
            _async_dump_states(), "RestoreStateData dump"
        )

        # Dump states periodically
        cancel_interval = async_track_time_interval(
            self.hass,
            _async_dump_states,
            STATE_DUMP_INTERVAL,
            name="RestoreStateData dump states",
        )

        async def _async_dump_states_at_stop(*_: Any) -> None:
            cancel_interval()
            await self.async_dump_states()

        # Dump states when stopping hass
        self.hass.bus.async_listen_once(
            EVENT_HOMEASSISTANT_STOP, _async_dump_states_at_stop
        )

    @callback
    def async_restore_entity_added(self, entity: RestoreEntity) -> None:
        """Store this entity's state when hass is shutdown."""
        self.entities[entity.entity_id] = entity

    @callback
    def async_restore_entity_removed(
        self, entity_id: str, extra_data: ExtraStoredData | None
    ) -> None:
        """Unregister this entity from saving state."""
        # When an entity is being removed from hass, store its last state. This
        # allows us to support state restoration if the entity is removed, then
        # re-added while hass is still running.
        state = self.hass.states.get(entity_id)
        # To fully mimic all the attribute data types when loaded from storage,
        # we're going to serialize it to JSON and then re-load it.
        if state is not None:
            state = State.from_dict(json_loads(state.as_dict_json))  # type: ignore[arg-type]
        if state is not None:
            self.last_states[entity_id] = StoredState(
                state, extra_data, dt_util.utcnow()
            )

        del self.entities[entity_id]


class RestoreEntity(Entity):
    """Mixin class for restoring previous entity state."""

    async def async_internal_added_to_hass(self) -> None:
        """Register this entity as a restorable entity."""
        await super().async_internal_added_to_hass()
        async_get(self.hass).async_restore_entity_added(self)

    async def async_internal_will_remove_from_hass(self) -> None:
        """Run when entity will be removed from hass."""
        async_get(self.hass).async_restore_entity_removed(
            self.entity_id, self.extra_restore_state_data
        )
        await super().async_internal_will_remove_from_hass()

    @callback
    def _async_get_restored_data(self) -> StoredState | None:
        """Get data stored for an entity, if any."""
        if self.hass is None or self.entity_id is None:
            # Return None if this entity isn't added to hass yet
            _LOGGER.warning(  # type: ignore[unreachable]
                "Cannot get last state. Entity not added to hass"
            )
            return None
        return async_get(self.hass).last_states.get(self.entity_id)

    async def async_get_last_state(self) -> State | None:
        """Get the entity state from the previous run."""
        if (stored_state := self._async_get_restored_data()) is None:
            return None
        return stored_state.state

    async def async_get_last_extra_data(self) -> ExtraStoredData | None:
        """Get the entity specific state data from the previous run."""
        if (stored_state := self._async_get_restored_data()) is None:
            return None
        return stored_state.extra_data

    @property
    def extra_restore_state_data(self) -> ExtraStoredData | None:
        """Return entity specific state data to be restored.

        Implemented by platform classes.
        """
        return None
</file>

<file path="schema_config_entry_flow.py">
"""Helpers for creating schema based data entry flows."""

from __future__ import annotations

from abc import ABC, abstractmethod
from collections.abc import Callable, Container, Coroutine, Mapping
import copy
from dataclasses import dataclass
import types
from typing import Any, cast

import voluptuous as vol

from homeassistant.config_entries import (
    ConfigEntry,
    ConfigFlow,
    ConfigFlowResult,
    OptionsFlow,
    OptionsFlowWithReload,
)
from homeassistant.core import HomeAssistant, callback, split_entity_id
from homeassistant.data_entry_flow import UnknownHandler

from . import entity_registry as er, selector
from .typing import UNDEFINED, UndefinedType


class SchemaFlowError(Exception):
    """Validation failed."""


@dataclass
class SchemaFlowStep:
    """Define a config or options flow step."""


@dataclass(slots=True)
class SchemaFlowFormStep(SchemaFlowStep):
    """Define a config or options flow form step."""

    schema: (
        vol.Schema
        | Callable[[SchemaCommonFlowHandler], Coroutine[Any, Any, vol.Schema | None]]
        | None
    ) = None
    """Optional voluptuous schema, or function which returns a schema or None, for
    requesting and validating user input.

    - If a function is specified, the function will be passed the current
    `SchemaCommonFlowHandler`.
    - If schema validation fails, the step will be retried. If the schema is None, no
    user input is requested.
    """

    validate_user_input: (
        Callable[
            [SchemaCommonFlowHandler, dict[str, Any]],
            Coroutine[Any, Any, dict[str, Any]],
        ]
        | None
    ) = None
    """Optional function to validate user input.

    - The `validate_user_input` function is called if the schema validates successfully.
    - The first argument is a reference to the current `SchemaCommonFlowHandler`.
    - The second argument is the user input from the current step.
    - The `validate_user_input` should raise `SchemaFlowError` if user input is invalid.
    """

    next_step: (
        Callable[[dict[str, Any]], Coroutine[Any, Any, str | None]] | str | None
    ) = None
    """Optional property to identify next step.

    - If `next_step` is a function, it is called if the schema validates successfully or
      if no schema is defined. The `next_step` function is passed the union of
      config entry options and user input from previous steps. If the function returns
      None, the flow is ended with `FlowResultType.CREATE_ENTRY`.
    - If `next_step` is None, the flow is ended with `FlowResultType.CREATE_ENTRY`.
    """

    suggested_values: (
        Callable[[SchemaCommonFlowHandler], Coroutine[Any, Any, dict[str, Any]]]
        | None
        | UndefinedType
    ) = UNDEFINED
    """Optional property to populate suggested values.

    - If `suggested_values` is UNDEFINED, each key in the schema will get a suggested
      value from an option with the same key.

    Note: if a step is retried due to a validation failure, then the user input will
    have priority over the suggested values.
    """

    preview: str | None = None
    """Optional preview component."""

    description_placeholders: (
        Callable[[SchemaCommonFlowHandler], Coroutine[Any, Any, dict[str, str]]]
        | UndefinedType
    ) = UNDEFINED
    """Optional property to populate description placeholders."""


@dataclass(slots=True)
class SchemaFlowMenuStep(SchemaFlowStep):
    """Define a config or options flow menu step."""

    # Menu options
    options: (
        Container[str]
        | Callable[[SchemaCommonFlowHandler], Coroutine[Any, Any, Container[str]]]
    )
    """Menu options, or function which returns menu options.

    - If a function is specified, the function will be passed the current
    `SchemaCommonFlowHandler`.
    """

    sort: bool = False
    """If true, menu options will be alphabetically sorted by the option label.
    """


class SchemaCommonFlowHandler:
    """Handle a schema based config or options flow."""

    def __init__(
        self,
        handler: SchemaConfigFlowHandler | SchemaOptionsFlowHandler,
        flow: Mapping[str, SchemaFlowStep],
        options: dict[str, Any] | None,
    ) -> None:
        """Initialize a common handler."""
        self._flow = flow
        self._handler = handler
        self._options = options if options is not None else {}
        self._flow_state: dict[str, Any] = {}

    @property
    def parent_handler(self) -> SchemaConfigFlowHandler | SchemaOptionsFlowHandler:
        """Return parent handler."""
        return self._handler

    @property
    def options(self) -> dict[str, Any]:
        """Return the options linked to the current flow handler."""
        return self._options

    @property
    def flow_state(self) -> dict[str, Any]:
        """Return the flow state, used to store temporary data.

        It can be used for example to store the key or the index of a sub-item
        that will be edited in the next step.
        """
        return self._flow_state

    async def async_step(
        self, step_id: str, user_input: dict[str, Any] | None = None
    ) -> ConfigFlowResult:
        """Handle a step."""
        if isinstance(self._flow[step_id], SchemaFlowFormStep):
            return await self._async_form_step(step_id, user_input)
        return await self._async_menu_step(step_id, user_input)

    async def _get_options(self, form_step: SchemaFlowMenuStep) -> Container[str]:
        if isinstance(form_step.options, Container):
            return form_step.options
        return await form_step.options(self)

    async def _get_schema(self, form_step: SchemaFlowFormStep) -> vol.Schema | None:
        if form_step.schema is None:
            return None
        if isinstance(form_step.schema, vol.Schema):
            return form_step.schema
        return await form_step.schema(self)

    async def _async_form_step(
        self, step_id: str, user_input: dict[str, Any] | None = None
    ) -> ConfigFlowResult:
        """Handle a form step."""
        form_step: SchemaFlowFormStep = cast(SchemaFlowFormStep, self._flow[step_id])

        if (
            user_input is not None
            and (data_schema := await self._get_schema(form_step))
            and data_schema.schema
            and not self._handler.show_advanced_options
        ):
            # Add advanced field default if not set
            for key in data_schema.schema:
                if isinstance(key, (vol.Optional, vol.Required)):
                    if (
                        key.description
                        and key.description.get("advanced")
                        and key.default is not vol.UNDEFINED
                        and key not in self._options
                    ):
                        user_input[str(key.schema)] = cast(
                            Callable[[], Any], key.default
                        )()

        if user_input is not None and form_step.validate_user_input is not None:
            # Do extra validation of user input
            try:
                user_input = await form_step.validate_user_input(self, user_input)
            except SchemaFlowError as exc:
                return await self._show_next_step(step_id, exc, user_input)

        if user_input is not None:
            # User input was validated successfully, update options
            self._update_and_remove_omitted_optional_keys(
                self._options, user_input, data_schema
            )

        if user_input is not None or form_step.schema is None:
            return await self._show_next_step_or_create_entry(form_step)

        return await self._show_next_step(step_id)

    def _update_and_remove_omitted_optional_keys(
        self,
        values: dict[str, Any],
        user_input: dict[str, Any],
        data_schema: vol.Schema | None,
    ) -> None:
        values.update(user_input)
        if data_schema and data_schema.schema:
            for key in data_schema.schema:
                if (
                    isinstance(key, vol.Optional)
                    and key not in user_input
                    and not (
                        # don't remove advanced keys, if they are hidden
                        key.description
                        and key.description.get("advanced")
                        and not self._handler.show_advanced_options
                    )
                    and not (
                        # don't remove read_only keys
                        isinstance(data_schema.schema[key], selector.Selector)
                        and data_schema.schema[key].config.get("read_only")
                    )
                ):
                    # Key not present, delete keys old value (if present) too
                    values.pop(key.schema, None)

    async def _show_next_step_or_create_entry(
        self, form_step: SchemaFlowFormStep
    ) -> ConfigFlowResult:
        next_step_id_or_end_flow: str | None

        if callable(form_step.next_step):
            next_step_id_or_end_flow = await form_step.next_step(self._options)
        else:
            next_step_id_or_end_flow = form_step.next_step

        if next_step_id_or_end_flow is None:
            # Flow done, create entry or update config entry options
            return self._handler.async_create_entry(data=self._options)
        return await self._show_next_step(next_step_id_or_end_flow)

    async def _show_next_step(
        self,
        next_step_id: str,
        error: SchemaFlowError | None = None,
        user_input: dict[str, Any] | None = None,
    ) -> ConfigFlowResult:
        """Show form for next step."""
        if isinstance(self._flow[next_step_id], SchemaFlowMenuStep):
            menu_step = cast(SchemaFlowMenuStep, self._flow[next_step_id])
            return self._handler.async_show_menu(
                step_id=next_step_id,
                menu_options=await self._get_options(menu_step),
                sort=menu_step.sort,
            )

        form_step = cast(SchemaFlowFormStep, self._flow[next_step_id])

        if (data_schema := await self._get_schema(form_step)) is None:
            return await self._show_next_step_or_create_entry(form_step)

        description_placeholders: dict[str, str] | None = None
        if form_step.description_placeholders is not UNDEFINED:
            description_placeholders = await form_step.description_placeholders(self)

        suggested_values: dict[str, Any] = {}
        if form_step.suggested_values is UNDEFINED:
            suggested_values = self._options
        elif form_step.suggested_values:
            suggested_values = await form_step.suggested_values(self)

        if user_input:
            # We don't want to mutate the existing options
            suggested_values = copy.deepcopy(suggested_values)
            self._update_and_remove_omitted_optional_keys(
                suggested_values, user_input, await self._get_schema(form_step)
            )

        if data_schema.schema:
            # Make a copy of the schema with suggested values set to saved options
            data_schema = self._handler.add_suggested_values_to_schema(
                data_schema, suggested_values
            )

        errors = {"base": str(error)} if error else None

        # Show form for next step
        last_step = None
        if not callable(form_step.next_step):
            last_step = form_step.next_step is None
        return self._handler.async_show_form(
            step_id=next_step_id,
            data_schema=data_schema,
            description_placeholders=description_placeholders,
            errors=errors,
            last_step=last_step,
            preview=form_step.preview,
        )

    async def _async_menu_step(
        self, step_id: str, user_input: dict[str, Any] | None = None
    ) -> ConfigFlowResult:
        """Handle a menu step."""
        menu_step: SchemaFlowMenuStep = cast(SchemaFlowMenuStep, self._flow[step_id])
        return self._handler.async_show_menu(
            step_id=step_id,
            menu_options=await self._get_options(menu_step),
            sort=menu_step.sort,
        )


class SchemaConfigFlowHandler(ConfigFlow, ABC):
    """Handle a schema based config flow."""

    config_flow: Mapping[str, SchemaFlowStep]
    options_flow: Mapping[str, SchemaFlowStep] | None = None
    options_flow_reloads: bool = False

    VERSION = 1

    def __init_subclass__(cls, **kwargs: Any) -> None:
        """Initialize a subclass."""
        super().__init_subclass__(**kwargs)

        @callback
        def _async_get_options_flow(
            config_entry: ConfigEntry,
        ) -> OptionsFlow:
            """Get the options flow for this handler."""
            if cls.options_flow is None:
                raise UnknownHandler

            if cls.options_flow_reloads:
                return SchemaOptionsFlowHandlerWithReload(
                    config_entry,
                    cls.options_flow,
                    cls.async_options_flow_finished,
                    cls.async_setup_preview,
                )
            return SchemaOptionsFlowHandler(
                config_entry,
                cls.options_flow,
                cls.async_options_flow_finished,
                cls.async_setup_preview,
            )

        # Create an async_get_options_flow method
        cls.async_get_options_flow = _async_get_options_flow  # type: ignore[method-assign]

        # Create flow step methods for each step defined in the flow schema
        for step in cls.config_flow:
            setattr(cls, f"async_step_{step}", cls._async_step(step))

    def __init__(self) -> None:
        """Initialize config flow."""
        self._common_handler = SchemaCommonFlowHandler(self, self.config_flow, None)

    @staticmethod
    async def async_setup_preview(hass: HomeAssistant) -> None:
        """Set up preview."""

    @classmethod
    @callback
    def async_supports_options_flow(cls, config_entry: ConfigEntry) -> bool:
        """Return options flow support for this handler."""
        return cls.options_flow is not None

    @staticmethod
    def _async_step(
        step_id: str,
    ) -> Callable[
        [SchemaConfigFlowHandler, dict[str, Any] | None],
        Coroutine[Any, Any, ConfigFlowResult],
    ]:
        """Generate a step handler."""

        async def _async_step(
            self: SchemaConfigFlowHandler, user_input: dict[str, Any] | None = None
        ) -> ConfigFlowResult:
            """Handle a config flow step."""
            return await self._common_handler.async_step(step_id, user_input)

        return _async_step

    @abstractmethod
    @callback
    def async_config_entry_title(self, options: Mapping[str, Any]) -> str:
        """Return config entry title.

        The options parameter contains config entry options, which is the union of user
        input from the config flow steps.
        """

    @callback
    def async_config_flow_finished(self, options: Mapping[str, Any]) -> None:
        """Take necessary actions after the config flow is finished, if needed.

        The options parameter contains config entry options, which is the union of user
        input from the config flow steps.
        """

    @callback
    @staticmethod
    def async_options_flow_finished(
        hass: HomeAssistant, options: Mapping[str, Any]
    ) -> None:
        """Take necessary actions after the options flow is finished, if needed.

        The options parameter contains config entry options, which is the union of
        stored options and user input from the options flow steps.
        """

    @callback
    def async_create_entry(
        self,
        data: Mapping[str, Any],
        **kwargs: Any,
    ) -> ConfigFlowResult:
        """Finish config flow and create a config entry."""
        self.async_config_flow_finished(data)
        return super().async_create_entry(
            data={}, options=data, title=self.async_config_entry_title(data), **kwargs
        )


class SchemaOptionsFlowHandler(OptionsFlow):
    """Handle a schema based options flow."""

    def __init__(
        self,
        config_entry: ConfigEntry,
        options_flow: Mapping[str, SchemaFlowStep],
        async_options_flow_finished: Callable[[HomeAssistant, Mapping[str, Any]], None]
        | None = None,
        async_setup_preview: Callable[[HomeAssistant], Coroutine[Any, Any, None]]
        | None = None,
    ) -> None:
        """Initialize options flow.

        If needed, `async_options_flow_finished` can be set to take necessary actions
        after the options flow is finished. The second parameter contains config entry
        options, which is the union of stored options and user input from the options
        flow steps.
        """
        self._options = copy.deepcopy(dict(config_entry.options))
        self._common_handler = SchemaCommonFlowHandler(self, options_flow, self.options)
        self._async_options_flow_finished = async_options_flow_finished

        for step in options_flow:
            setattr(
                self,
                f"async_step_{step}",
                types.MethodType(self._async_step(step), self),
            )

        if async_setup_preview:
            setattr(self, "async_setup_preview", async_setup_preview)

    @property
    def options(self) -> dict[str, Any]:
        """Return a mutable copy of the config entry options."""
        return self._options

    @staticmethod
    def _async_step(
        step_id: str,
    ) -> Callable[
        [SchemaConfigFlowHandler, dict[str, Any] | None],
        Coroutine[Any, Any, ConfigFlowResult],
    ]:
        """Generate a step handler."""

        async def _async_step(
            self: SchemaConfigFlowHandler, user_input: dict[str, Any] | None = None
        ) -> ConfigFlowResult:
            """Handle an options flow step."""
            return await self._common_handler.async_step(step_id, user_input)

        return _async_step

    @callback
    def async_create_entry(
        self,
        data: Mapping[str, Any],
        **kwargs: Any,
    ) -> ConfigFlowResult:
        """Finish config flow and create a config entry."""
        if self._async_options_flow_finished:
            self._async_options_flow_finished(self.hass, data)
        return super().async_create_entry(data=data, **kwargs)


class SchemaOptionsFlowHandlerWithReload(
    SchemaOptionsFlowHandler, OptionsFlowWithReload
):
    """Handle a schema based options flow which automatically reloads."""


@callback
def wrapped_entity_config_entry_title(
    hass: HomeAssistant, entity_id_or_uuid: str
) -> str:
    """Generate title for a config entry wrapping a single entity.

    If the entity is registered, use the registry entry's name.
    If the entity is in the state machine, use the name from the state.
    Otherwise, fall back to the object ID.
    """
    registry = er.async_get(hass)
    entity_id = er.async_validate_entity_id(registry, entity_id_or_uuid)
    object_id = split_entity_id(entity_id)[1]
    entry = registry.async_get(entity_id)
    if entry:
        return entry.name or entry.original_name or object_id
    state = hass.states.get(entity_id)
    if state:
        return state.name or object_id
    return object_id


@callback
def entity_selector_without_own_entities(
    handler: SchemaOptionsFlowHandler,
    entity_selector_config: selector.EntitySelectorConfig,
) -> selector.EntitySelector:
    """Return an entity selector which excludes own entities."""
    entity_registry = er.async_get(handler.hass)
    entities = er.async_entries_for_config_entry(
        entity_registry,
        handler.config_entry.entry_id,
    )
    entity_ids = [ent.entity_id for ent in entities]

    final_selector_config = entity_selector_config.copy()
    final_selector_config["exclude_entities"] = entity_ids

    return selector.EntitySelector(final_selector_config)
</file>

<file path="script_variables.py">
"""Script variables."""

from __future__ import annotations

from collections import ChainMap, UserDict
from collections.abc import Mapping
from dataclasses import dataclass, field
from typing import Any, cast

from homeassistant.core import HomeAssistant, callback

from . import template


class ScriptVariables:
    """Class to hold and render script variables."""

    def __init__(self, variables: dict[str, Any]) -> None:
        """Initialize script variables."""
        self.variables = variables
        self._has_template: bool | None = None

    @callback
    def async_render(
        self,
        hass: HomeAssistant,
        run_variables: Mapping[str, Any] | None,
        *,
        limited: bool = False,
    ) -> dict[str, Any]:
        """Render script variables.

        The run variables are included in the result.
        The run variables are used to compute the rendered variable values.
        The run variables will not be overridden.
        The rendering happens one at a time, with previous results influencing the next.
        """
        if self._has_template is None:
            self._has_template = template.is_complex(self.variables)

        if not self._has_template:
            rendered_variables = dict(self.variables)

            if run_variables is not None:
                rendered_variables.update(run_variables)

            return rendered_variables

        rendered_variables = {} if run_variables is None else dict(run_variables)

        for key, value in self.variables.items():
            # We can skip if we're going to override this key with
            # run variables anyway
            if key in rendered_variables:
                continue

            rendered_variables[key] = template.render_complex(
                value, rendered_variables, limited
            )

        return rendered_variables

    @callback
    def async_simple_render(self, run_variables: Mapping[str, Any]) -> dict[str, Any]:
        """Render script variables.

        Simply renders the variables, the run variables are not included in the result.
        The run variables are used to compute the rendered variable values.
        The rendering happens one at a time, with previous results influencing the next.
        """
        if self._has_template is None:
            self._has_template = template.is_complex(self.variables)

        if not self._has_template:
            return self.variables

        run_variables = dict(run_variables)
        rendered_variables = {}

        for key, value in self.variables.items():
            rendered_variable = template.render_complex(value, run_variables)
            rendered_variables[key] = rendered_variable
            run_variables[key] = rendered_variable

        return rendered_variables

    def as_dict(self) -> dict[str, Any]:
        """Return dict version of this class."""
        return self.variables


@dataclass
class _ParallelData:
    """Data used in each parallel sequence."""

    # `protected` is for variables that need special protection in parallel sequences.
    # What this means is that such a variable defined in one parallel sequence will not be
    # clobbered by the variable with the same name assigned in another parallel sequence.
    # It also means that such a variable will not be visible in the outer scope.
    # Currently the only such variable is `wait`.
    protected: dict[str, Any] = field(default_factory=dict)
    # `outer_scope_writes` is for variables that are written to the outer scope from
    # a parallel sequence. This is used for generating correct traces of changed variables
    # for each of the parallel sequences, isolating them from one another.
    outer_scope_writes: dict[str, Any] = field(default_factory=dict)


@dataclass(kw_only=True)
class ScriptRunVariables(UserDict[str, Any]):
    """Class to hold script run variables.

    The purpose of this class is to provide proper variable scoping semantics for scripts.
    Each instance institutes a new local scope, in which variables can be defined.
    Each instance has a reference to the previous instance, except for the top-level instance.
    The instances therefore form a chain, in which variable lookup and assignment is performed.
    The variables defined lower in the chain naturally override those defined higher up.
    """

    # _previous is the previous ScriptRunVariables in the chain
    _previous: ScriptRunVariables | None = None
    # _parent is the previous non-empty ScriptRunVariables in the chain
    _parent: ScriptRunVariables | None = None

    # _local_data is the store for local variables
    _local_data: dict[str, Any] | None = None
    # _parallel_data is used for each parallel sequence
    _parallel_data: _ParallelData | None = None

    # _non_parallel_scope includes all scopes all the way to the most recent parallel split
    _non_parallel_scope: ChainMap[str, Any]
    # _full_scope includes all scopes (all the way to the top-level)
    _full_scope: ChainMap[str, Any]

    @classmethod
    def create_top_level(
        cls,
        initial_data: Mapping[str, Any] | None = None,
    ) -> ScriptRunVariables:
        """Create a new top-level ScriptRunVariables."""
        local_data: dict[str, Any] = {}
        non_parallel_scope = full_scope = ChainMap(local_data)
        self = cls(
            _local_data=local_data,
            _non_parallel_scope=non_parallel_scope,
            _full_scope=full_scope,
        )
        if initial_data is not None:
            self.update(initial_data)
        return self

    def enter_scope(self, *, parallel: bool = False) -> ScriptRunVariables:
        """Return a new child scope.

        :param parallel: Whether the new scope starts a parallel sequence.
        """
        if self._local_data is not None or self._parallel_data is not None:
            parent = self
        else:
            parent = cast(  # top level always has local data, so we can cast safely
                ScriptRunVariables, self._parent
            )

        parallel_data: _ParallelData | None
        if not parallel:
            parallel_data = None
            non_parallel_scope = self._non_parallel_scope
            full_scope = self._full_scope
        else:
            parallel_data = _ParallelData()
            non_parallel_scope = ChainMap(
                parallel_data.protected, parallel_data.outer_scope_writes
            )
            full_scope = self._full_scope.new_child(parallel_data.protected)

        return ScriptRunVariables(
            _previous=self,
            _parent=parent,
            _parallel_data=parallel_data,
            _non_parallel_scope=non_parallel_scope,
            _full_scope=full_scope,
        )

    def exit_scope(self) -> ScriptRunVariables:
        """Exit the current scope.

        Does no clean-up, but simply returns the previous scope.
        """
        if self._previous is None:
            raise ValueError("Cannot exit top-level scope")
        return self._previous

    def __delitem__(self, key: str) -> None:
        """Delete a variable (disallowed)."""
        raise TypeError("Deleting items is not allowed in ScriptRunVariables.")

    def __setitem__(self, key: str, value: Any) -> None:
        """Assign value to a variable."""
        self._assign(key, value, parallel_protected=False)

    def assign_parallel_protected(self, key: str, value: Any) -> None:
        """Assign value to a variable which is to be protected in parallel sequences."""
        self._assign(key, value, parallel_protected=True)

    def _assign(self, key: str, value: Any, *, parallel_protected: bool) -> None:
        """Assign value to a variable.

        Value is always assigned to the variable in the nearest scope, in which it is defined.
        If the variable is not defined at all, it is created in the top-level scope.

        :param parallel_protected: Whether variable is to be protected in parallel sequences.
        """
        if self._local_data is not None and key in self._local_data:
            self._local_data[key] = value
            return

        if self._parent is None:
            assert self._local_data is not None  # top level always has local data
            self._local_data[key] = value
            return

        if self._parallel_data is not None:
            if parallel_protected:
                self._parallel_data.protected[key] = value
                return
            self._parallel_data.protected.pop(key, None)
            self._parallel_data.outer_scope_writes[key] = value

        self._parent._assign(key, value, parallel_protected=parallel_protected)  # noqa: SLF001

    def define_local(self, key: str, value: Any) -> None:
        """Define a local variable and assign value to it."""
        if self._local_data is None:
            self._local_data = {}
            self._non_parallel_scope = self._non_parallel_scope.new_child(
                self._local_data
            )
            self._full_scope = self._full_scope.new_child(self._local_data)
        self._local_data[key] = value

    @property
    def data(self) -> Mapping[str, Any]:  # type: ignore[override]
        """Return variables in full scope.

        Defined here for UserDict compatibility.
        """
        return self._full_scope

    @property
    def non_parallel_scope(self) -> Mapping[str, Any]:
        """Return variables in non-parallel scope."""
        return self._non_parallel_scope

    @property
    def local_scope(self) -> Mapping[str, Any]:
        """Return variables in local scope."""
        return self._local_data if self._local_data is not None else {}
</file>

<file path="script.py">
"""Helpers to execute scripts."""

from __future__ import annotations

import asyncio
from collections.abc import AsyncGenerator, Callable, Mapping, Sequence
from contextlib import asynccontextmanager
from contextvars import ContextVar
from copy import copy
from dataclasses import dataclass
from datetime import datetime, timedelta
from functools import partial
import itertools
import logging
from typing import Any, Literal, TypedDict, cast, overload

import async_interrupt
from propcache.api import cached_property
import voluptuous as vol

from homeassistant import exceptions
from homeassistant.components import scene
from homeassistant.components.device_automation import action as device_action
from homeassistant.components.logger import LOGSEVERITY
from homeassistant.const import (
    ATTR_AREA_ID,
    ATTR_DEVICE_ID,
    ATTR_ENTITY_ID,
    ATTR_FLOOR_ID,
    ATTR_LABEL_ID,
    CONF_ALIAS,
    CONF_CHOOSE,
    CONF_CONDITION,
    CONF_CONDITIONS,
    CONF_CONTINUE_ON_ERROR,
    CONF_CONTINUE_ON_TIMEOUT,
    CONF_COUNT,
    CONF_DEFAULT,
    CONF_DELAY,
    CONF_DEVICE_ID,
    CONF_DOMAIN,
    CONF_ELSE,
    CONF_ENABLED,
    CONF_ERROR,
    CONF_EVENT,
    CONF_EVENT_DATA,
    CONF_EVENT_DATA_TEMPLATE,
    CONF_FOR_EACH,
    CONF_IF,
    CONF_MODE,
    CONF_PARALLEL,
    CONF_REPEAT,
    CONF_RESPONSE_VARIABLE,
    CONF_SCENE,
    CONF_SEQUENCE,
    CONF_SERVICE,
    CONF_SERVICE_DATA,
    CONF_SERVICE_DATA_TEMPLATE,
    CONF_SET_CONVERSATION_RESPONSE,
    CONF_STOP,
    CONF_TARGET,
    CONF_THEN,
    CONF_TIMEOUT,
    CONF_UNTIL,
    CONF_VARIABLES,
    CONF_WAIT_FOR_TRIGGER,
    CONF_WAIT_TEMPLATE,
    CONF_WHILE,
    EVENT_HOMEASSISTANT_STOP,
    SERVICE_TURN_ON,
)
from homeassistant.core import (
    Context,
    Event,
    HassJob,
    HomeAssistant,
    ServiceResponse,
    State,
    SupportsResponse,
    callback,
)
from homeassistant.util import slugify
from homeassistant.util.async_ import create_eager_task
from homeassistant.util.dt import utcnow
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.signal_type import SignalType, SignalTypeFormat

from . import condition, config_validation as cv, service, template
from .condition import ConditionCheckerTypeOptional, trace_condition_function
from .dispatcher import async_dispatcher_connect, async_dispatcher_send_internal
from .event import async_call_later, async_track_template
from .script_variables import ScriptRunVariables, ScriptVariables
from .template import Template
from .trace import (
    TraceElement,
    async_trace_path,
    script_execution_set,
    trace_append_element,
    trace_id_get,
    trace_path,
    trace_path_get,
    trace_path_stack_cv,
    trace_set_result,
    trace_stack_cv,
    trace_stack_pop,
    trace_stack_push,
    trace_stack_top,
    trace_update_result,
)
from .trigger import async_initialize_triggers, async_validate_trigger_config
from .typing import UNDEFINED, ConfigType, TemplateVarsType, UndefinedType

SCRIPT_MODE_PARALLEL = "parallel"
SCRIPT_MODE_QUEUED = "queued"
SCRIPT_MODE_RESTART = "restart"
SCRIPT_MODE_SINGLE = "single"
SCRIPT_MODE_CHOICES = [
    SCRIPT_MODE_PARALLEL,
    SCRIPT_MODE_QUEUED,
    SCRIPT_MODE_RESTART,
    SCRIPT_MODE_SINGLE,
]
DEFAULT_SCRIPT_MODE = SCRIPT_MODE_SINGLE

CONF_MAX = "max"
DEFAULT_MAX = 10

CONF_MAX_EXCEEDED = "max_exceeded"
_MAX_EXCEEDED_CHOICES = [*LOGSEVERITY, "SILENT"]
DEFAULT_MAX_EXCEEDED = "WARNING"

ATTR_CUR = "current"
ATTR_MAX = "max"

DATA_SCRIPTS: HassKey[list[ScriptData]] = HassKey("helpers.script")
DATA_SCRIPT_BREAKPOINTS: HassKey[dict[str, dict[str, set[str]]]] = HassKey(
    "helpers.script_breakpoints"
)
DATA_NEW_SCRIPT_RUNS_NOT_ALLOWED: HassKey[None] = HassKey("helpers.script_not_allowed")
RUN_ID_ANY = "*"
NODE_ANY = "*"

_LOGGER = logging.getLogger(__name__)

_LOG_EXCEPTION = logging.ERROR + 1
_TIMEOUT_MSG = "Timeout reached, abort script."

_SHUTDOWN_MAX_WAIT = 60


ACTION_TRACE_NODE_MAX_LEN = 20  # Max length of a trace node for repeated actions

SCRIPT_BREAKPOINT_HIT = SignalType[str, str, str]("script_breakpoint_hit")
SCRIPT_DEBUG_CONTINUE_STOP: SignalTypeFormat[Literal["continue", "stop"]] = (
    SignalTypeFormat("script_debug_continue_stop_{}_{}")
)
SCRIPT_DEBUG_CONTINUE_ALL = "script_debug_continue_all"

script_stack_cv: ContextVar[list[str] | None] = ContextVar("script_stack", default=None)


class ScriptData(TypedDict):
    """Store data related to script instance."""

    instance: Script
    started_before_shutdown: bool


class ScriptStoppedError(Exception):
    """Error to indicate that the script has been stopped."""


def _set_result_unless_done(future: asyncio.Future[None]) -> None:
    """Set result of future unless it is done."""
    if not future.done():
        future.set_result(None)


def action_trace_append(variables: TemplateVarsType, path: str) -> TraceElement:
    """Append a TraceElement to trace[path]."""
    trace_element = TraceElement(variables, path)
    trace_append_element(trace_element, ACTION_TRACE_NODE_MAX_LEN)
    return trace_element


@asynccontextmanager
async def trace_action(
    hass: HomeAssistant,
    script_run: _ScriptRun,
    stop: asyncio.Future[None],
    variables: TemplateVarsType,
) -> AsyncGenerator[TraceElement]:
    """Trace action execution."""
    path = trace_path_get()
    trace_element = action_trace_append(variables, path)
    trace_stack_push(trace_stack_cv, trace_element)

    trace_id = trace_id_get()
    if trace_id:
        key = trace_id[0]
        run_id = trace_id[1]
        breakpoints = hass.data[DATA_SCRIPT_BREAKPOINTS]
        if key in breakpoints and (
            (
                run_id in breakpoints[key]
                and (
                    path in breakpoints[key][run_id]
                    or NODE_ANY in breakpoints[key][run_id]
                )
            )
            or (
                RUN_ID_ANY in breakpoints[key]
                and (
                    path in breakpoints[key][RUN_ID_ANY]
                    or NODE_ANY in breakpoints[key][RUN_ID_ANY]
                )
            )
        ):
            async_dispatcher_send_internal(
                hass, SCRIPT_BREAKPOINT_HIT, key, run_id, path
            )

            done = hass.loop.create_future()

            @callback
            def async_continue_stop(
                command: Literal["continue", "stop"] | None = None,
            ) -> None:
                if command == "stop":
                    _set_result_unless_done(stop)
                _set_result_unless_done(done)

            signal = SCRIPT_DEBUG_CONTINUE_STOP.format(key, run_id)
            remove_signal1 = async_dispatcher_connect(hass, signal, async_continue_stop)
            remove_signal2 = async_dispatcher_connect(
                hass, SCRIPT_DEBUG_CONTINUE_ALL, async_continue_stop
            )

            await asyncio.wait([stop, done], return_when=asyncio.FIRST_COMPLETED)
            remove_signal1()
            remove_signal2()

    try:
        yield trace_element
    except _AbortScript as ex:
        trace_element.set_error(ex.__cause__ or ex)
        raise
    except _ConditionFail:
        # Clear errors which may have been set when evaluating the condition
        trace_element.set_error(None)
        raise
    except _StopScript:
        raise
    except Exception as ex:
        trace_element.set_error(ex)
        raise
    finally:
        trace_stack_pop(trace_stack_cv)


def make_script_schema(
    schema: Mapping[Any, Any], default_script_mode: str, extra: int = vol.PREVENT_EXTRA
) -> vol.Schema:
    """Make a schema for a component that uses the script helper."""
    return vol.Schema(
        {
            **schema,
            vol.Optional(CONF_MODE, default=default_script_mode): vol.In(
                SCRIPT_MODE_CHOICES
            ),
            vol.Optional(CONF_MAX, default=DEFAULT_MAX): vol.All(
                vol.Coerce(int), vol.Range(min=2)
            ),
            vol.Optional(CONF_MAX_EXCEEDED, default=DEFAULT_MAX_EXCEEDED): vol.All(
                vol.Upper, vol.In(_MAX_EXCEEDED_CHOICES)
            ),
        },
        extra=extra,
    )


STATIC_VALIDATION_ACTION_TYPES = (
    cv.SCRIPT_ACTION_ACTIVATE_SCENE,
    cv.SCRIPT_ACTION_CALL_SERVICE,
    cv.SCRIPT_ACTION_DELAY,
    cv.SCRIPT_ACTION_FIRE_EVENT,
    cv.SCRIPT_ACTION_SET_CONVERSATION_RESPONSE,
    cv.SCRIPT_ACTION_STOP,
    cv.SCRIPT_ACTION_VARIABLES,
    cv.SCRIPT_ACTION_WAIT_TEMPLATE,
)

REPEAT_WARN_ITERATIONS = 5000
REPEAT_TERMINATE_ITERATIONS = 10000


async def async_validate_actions_config(
    hass: HomeAssistant, actions: list[ConfigType]
) -> list[ConfigType]:
    """Validate a list of actions."""
    # No gather here because async_validate_action_config is unlikely
    # to suspend and the overhead of creating many tasks is not worth it
    return [await async_validate_action_config(hass, action) for action in actions]


async def async_validate_action_config(
    hass: HomeAssistant, config: ConfigType
) -> ConfigType:
    """Validate config."""
    action_type = cv.determine_script_action(config)

    if action_type in STATIC_VALIDATION_ACTION_TYPES:
        pass

    elif action_type == cv.SCRIPT_ACTION_DEVICE_AUTOMATION:
        config = await device_action.async_validate_action_config(hass, config)

    elif action_type == cv.SCRIPT_ACTION_CHECK_CONDITION:
        config = await condition.async_validate_condition_config(hass, config)

    elif action_type == cv.SCRIPT_ACTION_WAIT_FOR_TRIGGER:
        config[CONF_WAIT_FOR_TRIGGER] = await async_validate_trigger_config(
            hass, config[CONF_WAIT_FOR_TRIGGER]
        )

    elif action_type == cv.SCRIPT_ACTION_REPEAT:
        if CONF_UNTIL in config[CONF_REPEAT]:
            conditions = await condition.async_validate_conditions_config(
                hass, config[CONF_REPEAT][CONF_UNTIL]
            )
            config[CONF_REPEAT][CONF_UNTIL] = conditions
        if CONF_WHILE in config[CONF_REPEAT]:
            conditions = await condition.async_validate_conditions_config(
                hass, config[CONF_REPEAT][CONF_WHILE]
            )
            config[CONF_REPEAT][CONF_WHILE] = conditions
        config[CONF_REPEAT][CONF_SEQUENCE] = await async_validate_actions_config(
            hass, config[CONF_REPEAT][CONF_SEQUENCE]
        )

    elif action_type == cv.SCRIPT_ACTION_CHOOSE:
        if CONF_DEFAULT in config:
            config[CONF_DEFAULT] = await async_validate_actions_config(
                hass, config[CONF_DEFAULT]
            )

        for choose_conf in config[CONF_CHOOSE]:
            conditions = await condition.async_validate_conditions_config(
                hass, choose_conf[CONF_CONDITIONS]
            )
            choose_conf[CONF_CONDITIONS] = conditions
            choose_conf[CONF_SEQUENCE] = await async_validate_actions_config(
                hass, choose_conf[CONF_SEQUENCE]
            )

    elif action_type == cv.SCRIPT_ACTION_IF:
        config[CONF_IF] = await condition.async_validate_conditions_config(
            hass, config[CONF_IF]
        )
        config[CONF_THEN] = await async_validate_actions_config(hass, config[CONF_THEN])
        if CONF_ELSE in config:
            config[CONF_ELSE] = await async_validate_actions_config(
                hass, config[CONF_ELSE]
            )

    elif action_type == cv.SCRIPT_ACTION_PARALLEL:
        for parallel_conf in config[CONF_PARALLEL]:
            parallel_conf[CONF_SEQUENCE] = await async_validate_actions_config(
                hass, parallel_conf[CONF_SEQUENCE]
            )

    elif action_type == cv.SCRIPT_ACTION_SEQUENCE:
        config[CONF_SEQUENCE] = await async_validate_actions_config(
            hass, config[CONF_SEQUENCE]
        )

    else:
        raise ValueError(f"No validation for {action_type}")

    return config


class _HaltScript(Exception):
    """Throw if script needs to stop executing."""


class _AbortScript(_HaltScript):
    """Throw if script needs to abort because of an unexpected error."""


class _ConditionFail(_HaltScript):
    """Throw if script needs to stop because a condition evaluated to False."""


class _StopScript(_HaltScript):
    """Throw if script needs to stop."""

    def __init__(self, message: str, response: Any) -> None:
        """Initialize a halt exception."""
        super().__init__(message)
        self.response = response


class _ScriptRun:
    """Manage Script sequence run."""

    _action: dict[str, Any]

    def __init__(
        self,
        hass: HomeAssistant,
        script: Script,
        variables: ScriptRunVariables,
        context: Context | None,
        log_exceptions: bool,
    ) -> None:
        self._hass = hass
        self._script = script
        self._variables = variables
        self._context = context
        self._log_exceptions = log_exceptions
        self._step = -1
        self._started = False
        self._stop = hass.loop.create_future()
        self._stopped = asyncio.Event()
        self._conversation_response: str | None | UndefinedType = UNDEFINED

    def _changed(self) -> None:
        if not self._stop.done():
            self._script._changed()  # noqa: SLF001

    def _log(
        self, msg: str, *args: Any, level: int = logging.INFO, **kwargs: Any
    ) -> None:
        self._script._log(msg, *args, level=level, **kwargs)  # noqa: SLF001

    def _step_log(self, default_message: str, timeout: float | None = None) -> None:
        self._script.last_action = self._action.get(CONF_ALIAS, default_message)
        _timeout = (
            "" if timeout is None else f" (timeout: {timedelta(seconds=timeout)})"
        )
        self._log("Executing step %s%s", self._script.last_action, _timeout)

    async def async_run(self) -> ScriptRunResult | None:
        """Run script."""
        self._started = True
        # Push the script to the script execution stack
        if (script_stack := script_stack_cv.get()) is None:
            script_stack = []
            script_stack_cv.set(script_stack)
        script_stack.append(self._script.unique_id)
        response = None

        try:
            self._log("Running %s", self._script.running_description)
            for self._step, self._action in enumerate(self._script.sequence):
                if self._stop.done():
                    script_execution_set("cancelled")
                    break
                await self._async_step(log_exceptions=False)
            else:
                script_execution_set("finished")
        except _AbortScript:
            script_execution_set("aborted")
            # Let the _AbortScript bubble up if this is a sub-script
            if not self._script.top_level:
                raise
        except _ConditionFail:
            script_execution_set("aborted")
        except _StopScript as err:
            script_execution_set("finished", err.response)

            # Let the _StopScript bubble up if this is a sub-script
            if not self._script.top_level:
                raise

            response = err.response

        except Exception:
            script_execution_set("error")
            raise
        finally:
            # Pop the script from the script execution stack
            script_stack.pop()
            self._finish()

        return ScriptRunResult(
            self._conversation_response, response, self._variables.local_scope
        )

    async def _async_step(self, log_exceptions: bool) -> None:
        continue_on_error = self._action.get(CONF_CONTINUE_ON_ERROR, False)

        with trace_path(str(self._step)):
            async with trace_action(
                self._hass, self, self._stop, self._variables.non_parallel_scope
            ) as trace_element:
                if self._stop.done():
                    return

                action = cv.determine_script_action(self._action)

                if CONF_ENABLED in self._action:
                    enabled = self._action[CONF_ENABLED]
                    if isinstance(enabled, Template):
                        try:
                            enabled = enabled.async_render(limited=True)
                        except exceptions.TemplateError as ex:
                            self._handle_exception(
                                ex,
                                continue_on_error,
                                self._log_exceptions or log_exceptions,
                            )
                    if not enabled:
                        self._log(
                            "Skipped disabled step %s",
                            self._action.get(CONF_ALIAS, action),
                        )
                        trace_set_result(enabled=False)
                        return

                handler = f"_async_step_{action}"
                try:
                    await getattr(self, handler)()
                except Exception as ex:  # noqa: BLE001
                    self._handle_exception(
                        ex, continue_on_error, self._log_exceptions or log_exceptions
                    )
                finally:
                    trace_element.update_variables(self._variables.non_parallel_scope)

    def _finish(self) -> None:
        self._script._runs.remove(self)  # noqa: SLF001
        if not self._script.is_running:
            self._script.last_action = None
        self._changed()
        self._stopped.set()

    async def async_stop(self) -> None:
        """Stop script run."""
        _set_result_unless_done(self._stop)
        # If the script was never started
        # the stopped event will never be
        # set because the script will never
        # start running
        if self._started:
            await self._stopped.wait()

    def _handle_exception(
        self, exception: Exception, continue_on_error: bool, log_exceptions: bool
    ) -> None:
        if not isinstance(exception, _HaltScript) and log_exceptions:
            self._log_exception(exception)

        if not continue_on_error:
            raise exception

        # An explicit request to stop the script has been raised.
        if isinstance(exception, _StopScript):
            raise exception

        # These are incorrect scripts, and not runtime errors that need to
        # be handled and thus cannot be stopped by `continue_on_error`.
        if isinstance(
            exception,
            (
                vol.Invalid,
                exceptions.TemplateError,
                exceptions.ServiceNotFound,
                exceptions.InvalidEntityFormatError,
                exceptions.NoEntitySpecifiedError,
                exceptions.ConditionError,
            ),
        ):
            raise exception

        # Only Home Assistant errors can be ignored.
        if not isinstance(exception, exceptions.HomeAssistantError):
            raise exception

    def _log_exception(self, exception: Exception) -> None:
        action_type = cv.determine_script_action(self._action)

        error = str(exception)
        level = logging.ERROR

        if isinstance(exception, vol.Invalid):
            error_desc = "Invalid data"

        elif isinstance(exception, exceptions.TemplateError):
            error_desc = "Error rendering template"

        elif isinstance(exception, exceptions.Unauthorized):
            error_desc = "Unauthorized"

        elif isinstance(exception, exceptions.ServiceNotFound):
            error_desc = "Service not found"

        elif isinstance(exception, exceptions.HomeAssistantError):
            error_desc = "Error"

        else:
            error_desc = "Unexpected error"
            level = _LOG_EXCEPTION

        self._log(
            "Error executing script. %s for %s at pos %s: %s",
            error_desc,
            action_type,
            self._step + 1,
            error,
            level=level,
        )

    async def _async_run_long_action[_T](
        self, long_task: asyncio.Task[_T]
    ) -> _T | None:
        """Run a long task while monitoring for stop request."""
        try:
            async with async_interrupt.interrupt(self._stop, ScriptStoppedError, None):
                # if stop is set, interrupt will cancel inside the context
                # manager which will cancel long_task, and raise
                # ScriptStoppedError outside the context manager
                return await long_task
        except ScriptStoppedError as ex:
            raise asyncio.CancelledError from ex

    async def _async_run_script(
        self, script: Script, *, parallel: bool = False
    ) -> None:
        """Execute a script."""
        if not script.enabled:
            self._log("Skipping disabled script: %s", script.name)
            trace_set_result(enabled=False)
            return
        result = await self._async_run_long_action(
            self._hass.async_create_task_internal(
                script.async_run(
                    self._variables.enter_scope(parallel=parallel), self._context
                ),
                eager_start=True,
            )
        )
        if result and result.conversation_response is not UNDEFINED:
            self._conversation_response = result.conversation_response

    ## Flow control actions ##

    ### Sequence actions ###

    @async_trace_path("parallel")
    async def _async_step_parallel(self) -> None:
        """Run a sequence in parallel."""
        scripts = await self._script._async_get_parallel_scripts(self._step)  # noqa: SLF001

        async def async_run_with_trace(idx: int, script: Script) -> None:
            """Run a script with a trace path."""
            trace_path_stack_cv.set(copy(trace_path_stack_cv.get()))
            with trace_path([str(idx), "sequence"]):
                await self._async_run_script(script, parallel=True)

        results = await asyncio.gather(
            *(async_run_with_trace(idx, script) for idx, script in enumerate(scripts)),
            return_exceptions=True,
        )
        for result in results:
            if isinstance(result, Exception):
                raise result

    @async_trace_path("sequence")
    async def _async_step_sequence(self) -> None:
        """Run a sequence."""
        sequence = await self._script._async_get_sequence_script(self._step)  # noqa: SLF001
        await self._async_run_script(sequence)

    ### Condition actions ###

    async def _async_get_condition(
        self, config: ConfigType
    ) -> ConditionCheckerTypeOptional:
        return await self._script._async_get_condition(config)  # noqa: SLF001

    def _test_conditions(
        self,
        conditions: list[ConditionCheckerTypeOptional],
        name: str,
        condition_path: str | None = None,
    ) -> bool | None:
        if condition_path is None:
            condition_path = name

        @trace_condition_function
        def traced_test_conditions(
            hass: HomeAssistant, variables: TemplateVarsType
        ) -> bool | None:
            try:
                with trace_path(condition_path):
                    for idx, cond in enumerate(conditions):
                        with trace_path(str(idx)):
                            if cond(hass, variables) is False:
                                return False
            except exceptions.ConditionError as ex:
                self._log(
                    "Error in '%s[%s]' evaluation: %s",
                    name,
                    idx,
                    ex,
                    level=logging.WARNING,
                )
                return None

            return True

        return traced_test_conditions(self._hass, self._variables)

    async def _async_step_choose(self) -> None:
        """Choose a sequence."""
        choose_data = await self._script._async_get_choose_data(self._step)  # noqa: SLF001

        with trace_path("choose"):
            for idx, (conditions, script) in enumerate(choose_data["choices"]):
                with trace_path(str(idx)):
                    try:
                        if self._test_conditions(conditions, "choose", "conditions"):
                            trace_set_result(choice=idx)
                            with trace_path("sequence"):
                                await self._async_run_script(script)
                                return
                    except exceptions.ConditionError as ex:
                        self._log(
                            "Error in 'choose' evaluation:\n%s",
                            ex,
                            level=logging.WARNING,
                        )

        if choose_data["default"] is not None:
            trace_set_result(choice="default")
            with trace_path(["default"]):
                await self._async_run_script(choose_data["default"])

    async def _async_step_condition(self) -> None:
        """Test if condition is matching."""
        self._script.last_action = self._action.get(
            CONF_ALIAS, self._action[CONF_CONDITION]
        )
        cond = await self._async_get_condition(self._action)
        try:
            trace_element = trace_stack_top(trace_stack_cv)
            if trace_element:
                trace_element.reuse_by_child = True
            check = cond(self._hass, self._variables)
        except exceptions.ConditionError as ex:
            self._log("Error in 'condition' evaluation:\n%s", ex, level=logging.WARNING)
            check = False

        self._log("Test condition %s: %s", self._script.last_action, check)
        trace_update_result(result=check)
        if not check:
            raise _ConditionFail

    async def _async_step_if(self) -> None:
        """If sequence."""
        if_data = await self._script._async_get_if_data(self._step)  # noqa: SLF001

        test_conditions: bool | None = False
        with trace_path("if"):
            test_conditions = self._test_conditions(
                if_data["if_conditions"], "if", "condition"
            )

        if test_conditions:
            trace_set_result(choice="then")
            with trace_path("then"):
                await self._async_run_script(if_data["if_then"])
                return

        if if_data["if_else"] is not None:
            trace_set_result(choice="else")
            with trace_path("else"):
                await self._async_run_script(if_data["if_else"])

    async def _async_do_step_repeat(self) -> None:  # noqa: C901
        """Repeat a sequence helper."""
        description = self._action.get(CONF_ALIAS, "sequence")
        repeat = self._action[CONF_REPEAT]

        def set_repeat_var(
            iteration: int, count: int | None = None, item: Any = None
        ) -> None:
            repeat_vars = {"first": iteration == 1, "index": iteration}
            if count:
                repeat_vars["last"] = iteration == count
            if item is not None:
                repeat_vars["item"] = item
            self._variables.define_local("repeat", repeat_vars)

        script = self._script._get_repeat_script(self._step)  # noqa: SLF001
        warned_too_many_loops = False

        async def async_run_sequence(iteration: int, extra_msg: str = "") -> None:
            self._log("Repeating %s: Iteration %i%s", description, iteration, extra_msg)
            with trace_path("sequence"):
                await self._async_run_script(script)

        if CONF_COUNT in repeat:
            count = repeat[CONF_COUNT]
            if isinstance(count, template.Template):
                try:
                    count = int(count.async_render(self._variables))
                except (exceptions.TemplateError, ValueError) as ex:
                    self._log(
                        "Error rendering %s repeat count template: %s",
                        self._script.name,
                        ex,
                        level=logging.ERROR,
                    )
                    raise _AbortScript from ex
            extra_msg = f" of {count}"
            for iteration in range(1, count + 1):
                set_repeat_var(iteration, count)
                await async_run_sequence(iteration, extra_msg)
                if self._stop.done():
                    break

        elif CONF_FOR_EACH in repeat:
            try:
                items = template.render_complex(repeat[CONF_FOR_EACH], self._variables)
            except (exceptions.TemplateError, ValueError) as ex:
                self._log(
                    "Error rendering %s repeat for each items template: %s",
                    self._script.name,
                    ex,
                    level=logging.ERROR,
                )
                raise _AbortScript from ex

            if not isinstance(items, list):
                self._log(
                    "Repeat 'for_each' must be a list of items in %s, got: %s",
                    self._script.name,
                    items,
                    level=logging.ERROR,
                )
                raise _AbortScript("Repeat 'for_each' must be a list of items")

            count = len(items)
            for iteration, item in enumerate(items, 1):
                set_repeat_var(iteration, count, item)
                extra_msg = f" of {count} with item: {item!r}"
                if self._stop.done():
                    break
                await async_run_sequence(iteration, extra_msg)

        elif CONF_WHILE in repeat:
            conditions = [
                await self._async_get_condition(config) for config in repeat[CONF_WHILE]
            ]
            for iteration in itertools.count(1):
                set_repeat_var(iteration)
                if self._stop.done():
                    break
                if not self._test_conditions(conditions, "while"):
                    break

                if iteration > 1:
                    if iteration > REPEAT_WARN_ITERATIONS:
                        if not warned_too_many_loops:
                            warned_too_many_loops = True
                            self._log(
                                "While condition %s looped %s times",
                                repeat[CONF_WHILE],
                                REPEAT_WARN_ITERATIONS,
                                level=logging.WARNING,
                            )

                        if iteration > REPEAT_TERMINATE_ITERATIONS:
                            self._log(
                                "While condition %s terminated because it looped %s times",
                                repeat[CONF_WHILE],
                                REPEAT_TERMINATE_ITERATIONS,
                                level=logging.CRITICAL,
                            )
                            raise _AbortScript(
                                f"While condition {repeat[CONF_WHILE]} "
                                "terminated because it looped "
                                f" {REPEAT_TERMINATE_ITERATIONS} times"
                            )

                    # If the user creates a script with a tight loop,
                    # yield to the event loop so the system stays
                    # responsive while all the cpu time is consumed.
                    await asyncio.sleep(0)

                await async_run_sequence(iteration)

        elif CONF_UNTIL in repeat:
            conditions = [
                await self._async_get_condition(config) for config in repeat[CONF_UNTIL]
            ]
            for iteration in itertools.count(1):
                set_repeat_var(iteration)
                await async_run_sequence(iteration)
                if self._stop.done():
                    break
                if self._test_conditions(conditions, "until") in [True, None]:
                    break

                if iteration >= REPEAT_WARN_ITERATIONS:
                    if not warned_too_many_loops:
                        warned_too_many_loops = True
                        self._log(
                            "Until condition %s looped %s times",
                            repeat[CONF_UNTIL],
                            REPEAT_WARN_ITERATIONS,
                            level=logging.WARNING,
                        )

                    if iteration >= REPEAT_TERMINATE_ITERATIONS:
                        self._log(
                            "Until condition %s terminated because it looped %s times",
                            repeat[CONF_UNTIL],
                            REPEAT_TERMINATE_ITERATIONS,
                            level=logging.CRITICAL,
                        )
                        raise _AbortScript(
                            f"Until condition {repeat[CONF_UNTIL]} "
                            "terminated because it looped "
                            f"{REPEAT_TERMINATE_ITERATIONS} times"
                        )

                # If the user creates a script with a tight loop,
                # yield to the event loop so the system stays responsive
                # while all the cpu time is consumed.
                await asyncio.sleep(0)

    @async_trace_path("repeat")
    async def _async_step_repeat(self) -> None:
        """Repeat a sequence."""
        self._variables = self._variables.enter_scope()
        try:
            await self._async_do_step_repeat()
        finally:
            self._variables = self._variables.exit_scope()

    ### Stop actions ###

    async def _async_step_stop(self) -> None:
        """Stop script execution."""
        stop = self._action[CONF_STOP]
        error = self._action.get(CONF_ERROR, False)
        trace_set_result(stop=stop, error=error)
        if error:
            self._log("Error script sequence: %s", stop)
            raise _AbortScript(stop)

        self._log("Stop script sequence: %s", stop)
        if CONF_RESPONSE_VARIABLE in self._action:
            try:
                response = self._variables[self._action[CONF_RESPONSE_VARIABLE]]
            except KeyError as ex:
                raise _AbortScript(
                    f"Response variable '{self._action[CONF_RESPONSE_VARIABLE]}' "
                    "is not defined"
                ) from ex
        else:
            response = None
        raise _StopScript(stop, response)

    ## Variable actions ##

    async def _async_step_variables(self) -> None:
        """Assign values to variables."""
        self._step_log("assigning variables")
        self._variables.update(
            self._action[CONF_VARIABLES].async_simple_render(self._variables)
        )

    ## External actions ##

    async def _async_step_call_service(self) -> None:
        """Call the service specified in the action."""
        self._step_log("call service")

        params = service.async_prepare_call_from_config(
            self._hass, self._action, self._variables
        )

        # Validate response data parameters. This check ignores services that do
        # not exist which will raise an appropriate error in the service call below.
        response_variable = self._action.get(CONF_RESPONSE_VARIABLE)
        return_response = response_variable is not None
        if self._hass.services.has_service(params[CONF_DOMAIN], params[CONF_SERVICE]):
            supports_response = self._hass.services.supports_response(
                params[CONF_DOMAIN], params[CONF_SERVICE]
            )
            if supports_response == SupportsResponse.ONLY and not return_response:
                raise vol.Invalid(
                    f"Script requires '{CONF_RESPONSE_VARIABLE}' for response data "
                    f"for service call {params[CONF_DOMAIN]}.{params[CONF_SERVICE]}"
                )
            if supports_response == SupportsResponse.NONE and return_response:
                raise vol.Invalid(
                    f"Script does not support '{CONF_RESPONSE_VARIABLE}' for service "
                    f"'{params[CONF_DOMAIN]}.{params[CONF_SERVICE]}' which does not support response data."
                )

        running_script = (
            params[CONF_DOMAIN] == "automation" and params[CONF_SERVICE] == "trigger"
        ) or params[CONF_DOMAIN] in ("python_script", "script")
        trace_set_result(params=params, running_script=running_script)
        response_data = await self._async_run_long_action(
            self._hass.async_create_task_internal(
                self._hass.services.async_call(
                    **params,
                    blocking=True,
                    context=self._context,
                    return_response=return_response,
                ),
                eager_start=True,
            )
        )
        if response_variable:
            self._variables[response_variable] = response_data

    async def _async_step_device(self) -> None:
        """Perform the device automation specified in the action."""
        self._step_log("device automation")
        await device_action.async_call_action_from_config(
            self._hass, self._action, dict(self._variables), self._context
        )

    async def _async_step_event(self) -> None:
        """Fire an event."""
        self._step_log(self._action.get(CONF_ALIAS, self._action[CONF_EVENT]))
        event_data = {}
        for conf in (CONF_EVENT_DATA, CONF_EVENT_DATA_TEMPLATE):
            if conf not in self._action:
                continue

            try:
                event_data.update(
                    template.render_complex(self._action[conf], self._variables)
                )
            except exceptions.TemplateError as ex:
                self._log(
                    "Error rendering event data template: %s", ex, level=logging.ERROR
                )

        trace_set_result(event=self._action[CONF_EVENT], event_data=event_data)
        self._hass.bus.async_fire_internal(
            self._action[CONF_EVENT], event_data, context=self._context
        )

    async def _async_step_scene(self) -> None:
        """Activate the scene specified in the action."""
        self._step_log("activate scene")
        trace_set_result(scene=self._action[CONF_SCENE])
        await self._hass.services.async_call(
            scene.DOMAIN,
            SERVICE_TURN_ON,
            {ATTR_ENTITY_ID: self._action[CONF_SCENE]},
            blocking=True,
            context=self._context,
        )

    ## Time-based actions ##

    @overload
    def _async_futures_with_timeout(
        self,
        timeout: float,
    ) -> tuple[
        list[asyncio.Future[None]],
        asyncio.TimerHandle,
        asyncio.Future[None],
    ]: ...

    @overload
    def _async_futures_with_timeout(
        self,
        timeout: None,
    ) -> tuple[
        list[asyncio.Future[None]],
        None,
        None,
    ]: ...

    def _async_futures_with_timeout(
        self,
        timeout: float | None,
    ) -> tuple[
        list[asyncio.Future[None]],
        asyncio.TimerHandle | None,
        asyncio.Future[None] | None,
    ]:
        """Return a list of futures to wait for.

        The list will contain the stop future.

        If timeout is set, a timeout future and handle will be created
        and will be added to the list of futures.
        """
        timeout_handle: asyncio.TimerHandle | None = None
        timeout_future: asyncio.Future[None] | None = None
        futures: list[asyncio.Future[None]] = [self._stop]
        if timeout:
            timeout_future = self._hass.loop.create_future()
            timeout_handle = self._hass.loop.call_later(
                timeout, _set_result_unless_done, timeout_future
            )
            futures.append(timeout_future)
        return futures, timeout_handle, timeout_future

    def _get_pos_time_period_template(self, key: str) -> timedelta:
        try:
            return cv.positive_time_period(  # type: ignore[no-any-return]
                template.render_complex(self._action[key], self._variables)
            )
        except (exceptions.TemplateError, vol.Invalid) as ex:
            self._log(
                "Error rendering %s %s template: %s",
                self._script.name,
                key,
                ex,
                level=logging.ERROR,
            )
            raise _AbortScript from ex

    async def _async_step_delay(self) -> None:
        """Handle delay."""
        delay_delta = self._get_pos_time_period_template(CONF_DELAY)

        self._step_log(f"delay {delay_delta}")

        delay = delay_delta.total_seconds()
        self._changed()
        if not delay:
            # Handle an empty delay
            trace_set_result(delay=delay, done=True)
            return

        trace_set_result(delay=delay, done=False)
        futures, timeout_handle, timeout_future = self._async_futures_with_timeout(
            delay
        )

        try:
            await asyncio.wait(futures, return_when=asyncio.FIRST_COMPLETED)
        finally:
            if timeout_future.done():
                trace_set_result(delay=delay, done=True)
            else:
                timeout_handle.cancel()

    def _get_timeout_seconds_from_action(self) -> float | None:
        """Get the timeout from the action."""
        if CONF_TIMEOUT in self._action:
            return self._get_pos_time_period_template(CONF_TIMEOUT).total_seconds()
        return None

    def _async_handle_timeout(self) -> None:
        """Handle timeout."""
        self._variables["wait"]["remaining"] = 0.0
        if not self._action.get(CONF_CONTINUE_ON_TIMEOUT, True):
            self._log(_TIMEOUT_MSG)
            trace_set_result(wait=self._variables["wait"], timeout=True)
            raise _AbortScript from TimeoutError()

    async def _async_wait_with_optional_timeout(
        self,
        futures: list[asyncio.Future[None]],
        timeout_handle: asyncio.TimerHandle | None,
        timeout_future: asyncio.Future[None] | None,
        unsub: Callable[[], None],
    ) -> None:
        try:
            await asyncio.wait(futures, return_when=asyncio.FIRST_COMPLETED)
            if timeout_future and timeout_future.done():
                self._async_handle_timeout()
        finally:
            if timeout_future and not timeout_future.done() and timeout_handle:
                timeout_handle.cancel()

            unsub()

    def _async_set_remaining_time_var(
        self, timeout_handle: asyncio.TimerHandle | None
    ) -> None:
        """Set the remaining time variable for a wait step."""
        wait_var = self._variables["wait"]
        if timeout_handle:
            wait_var["remaining"] = timeout_handle.when() - self._hass.loop.time()
        else:
            wait_var["remaining"] = None

    async def _async_step_wait_for_trigger(self) -> None:
        """Wait for a trigger event."""
        timeout = self._get_timeout_seconds_from_action()

        self._step_log("wait for trigger", timeout)

        variables = dict(self._variables)
        self._variables.assign_parallel_protected(
            "wait",
            {
                "remaining": timeout,
                "completed": False,
                "trigger": None,
            },
        )
        trace_set_result(wait=self._variables["wait"])

        if timeout == 0:
            self._changed()
            self._async_handle_timeout()
            return

        futures, timeout_handle, timeout_future = self._async_futures_with_timeout(
            timeout
        )
        done = self._hass.loop.create_future()
        futures.append(done)

        async def async_done(
            variables: dict[str, Any], context: Context | None = None
        ) -> None:
            self._async_set_remaining_time_var(timeout_handle)
            self._variables["wait"]["completed"] = True
            self._variables["wait"]["trigger"] = variables["trigger"]
            _set_result_unless_done(done)

        def log_cb(level: int, msg: str, **kwargs: Any) -> None:
            self._log(msg, level=level, **kwargs)

        remove_triggers = await async_initialize_triggers(
            self._hass,
            self._action[CONF_WAIT_FOR_TRIGGER],
            async_done,
            self._script.domain,
            self._script.name,
            log_cb,
            variables=variables,
        )
        if not remove_triggers:
            return
        self._changed()
        await self._async_wait_with_optional_timeout(
            futures, timeout_handle, timeout_future, remove_triggers
        )

    async def _async_step_wait_template(self) -> None:
        """Handle a wait template."""
        timeout = self._get_timeout_seconds_from_action()
        self._step_log("wait template", timeout)

        self._variables.assign_parallel_protected(
            "wait", {"remaining": timeout, "completed": False}
        )
        trace_set_result(wait=self._variables["wait"])

        wait_template = self._action[CONF_WAIT_TEMPLATE]

        # check if condition already okay
        if condition.async_template(self._hass, wait_template, self._variables, False):
            self._variables["wait"]["completed"] = True
            self._changed()
            return

        if timeout == 0:
            self._changed()
            self._async_handle_timeout()
            return

        futures, timeout_handle, timeout_future = self._async_futures_with_timeout(
            timeout
        )
        done = self._hass.loop.create_future()
        futures.append(done)

        @callback
        def async_script_wait(
            entity_id: str, from_s: State | None, to_s: State | None
        ) -> None:
            """Handle script after template condition is true."""
            self._async_set_remaining_time_var(timeout_handle)
            self._variables["wait"]["completed"] = True
            _set_result_unless_done(done)

        unsub = async_track_template(
            self._hass, wait_template, async_script_wait, self._variables
        )
        self._changed()
        await self._async_wait_with_optional_timeout(
            futures, timeout_handle, timeout_future, unsub
        )

    ## Conversation actions ##

    async def _async_step_set_conversation_response(self) -> None:
        """Set conversation response."""
        self._step_log("setting conversation response")
        resp: template.Template | None = self._action[CONF_SET_CONVERSATION_RESPONSE]
        if resp is None:
            self._conversation_response = None
        else:
            self._conversation_response = resp.async_render(
                variables=self._variables, parse_result=False
            )
        trace_set_result(conversation_response=self._conversation_response)


class _QueuedScriptRun(_ScriptRun):
    """Manage queued Script sequence run."""

    lock_acquired = False

    async def async_run(self) -> ScriptRunResult | None:
        """Run script."""
        # Wait for previous run, if any, to finish by attempting to acquire the script's
        # shared lock. At the same time monitor if we've been told to stop.
        try:
            async with async_interrupt.interrupt(self._stop, ScriptStoppedError, None):
                await self._script._queue_lck.acquire()  # noqa: SLF001
        except ScriptStoppedError as ex:
            # If we've been told to stop, then just finish up.
            self._finish()
            raise asyncio.CancelledError from ex

        self.lock_acquired = True
        # We've acquired the lock so we can go ahead and start the run.
        return await super().async_run()

    def _finish(self) -> None:
        if self.lock_acquired:
            self._script._queue_lck.release()  # noqa: SLF001
            self.lock_acquired = False
        super()._finish()


@callback
def _schedule_stop_scripts_after_shutdown(hass: HomeAssistant) -> None:
    """Stop running Script objects started after shutdown."""
    async_call_later(
        hass, _SHUTDOWN_MAX_WAIT, partial(_async_stop_scripts_after_shutdown, hass)
    )


async def _async_stop_scripts_after_shutdown(
    hass: HomeAssistant, point_in_time: datetime
) -> None:
    """Stop running Script objects started after shutdown."""
    hass.data[DATA_NEW_SCRIPT_RUNS_NOT_ALLOWED] = None
    running_scripts = [
        script for script in hass.data[DATA_SCRIPTS] if script["instance"].is_running
    ]
    if running_scripts:
        names = ", ".join([script["instance"].name for script in running_scripts])
        _LOGGER.warning("Stopping scripts running too long after shutdown: %s", names)
        await asyncio.gather(
            *(
                create_eager_task(script["instance"].async_stop(update_state=False))
                for script in running_scripts
            )
        )


async def _async_stop_scripts_at_shutdown(hass: HomeAssistant, event: Event) -> None:
    """Stop running Script objects started before shutdown."""
    _schedule_stop_scripts_after_shutdown(hass)

    running_scripts = [
        script
        for script in hass.data[DATA_SCRIPTS]
        if script["instance"].is_running and script["started_before_shutdown"]
    ]
    if running_scripts:
        names = ", ".join([script["instance"].name for script in running_scripts])
        _LOGGER.debug("Stopping scripts running at shutdown: %s", names)
        await asyncio.gather(
            *(
                create_eager_task(script["instance"].async_stop())
                for script in running_scripts
            )
        )


type _VarsType = dict[str, Any] | Mapping[str, Any] | ScriptRunVariables


def _referenced_extract_ids(data: Any, key: str, found: set[str]) -> None:
    """Extract referenced IDs."""
    # Data may not exist, or be a template
    if not isinstance(data, dict):
        return

    item_ids = data.get(key)

    if item_ids is None or isinstance(item_ids, template.Template):
        return

    if isinstance(item_ids, str):
        found.add(item_ids)
    else:
        for item_id in item_ids:
            found.add(item_id)


class _ChooseData(TypedDict):
    choices: list[tuple[list[ConditionCheckerTypeOptional], Script]]
    default: Script | None


class _IfData(TypedDict):
    if_conditions: list[ConditionCheckerTypeOptional]
    if_then: Script
    if_else: Script | None


@dataclass
class ScriptRunResult:
    """Container with the result of a script run."""

    conversation_response: str | None | UndefinedType
    service_response: ServiceResponse
    variables: Mapping[str, Any]


class Script:
    """Representation of a script."""

    def __init__(
        self,
        hass: HomeAssistant,
        sequence: Sequence[dict[str, Any]],
        name: str,
        domain: str,
        *,
        # Used in "Running <running_description>" log message
        change_listener: Callable[[], Any] | None = None,
        log_exceptions: bool = True,
        logger: logging.Logger | None = None,
        max_exceeded: str = DEFAULT_MAX_EXCEEDED,
        max_runs: int = DEFAULT_MAX,
        running_description: str | None = None,
        script_mode: str = DEFAULT_SCRIPT_MODE,
        top_level: bool = True,
        variables: ScriptVariables | None = None,
        enabled: bool = True,
    ) -> None:
        """Initialize the script.

        enabled attribute is only used for non-top-level scripts.
        """
        if not (all_scripts := hass.data.get(DATA_SCRIPTS)):
            all_scripts = hass.data[DATA_SCRIPTS] = []
            hass.bus.async_listen_once(
                EVENT_HOMEASSISTANT_STOP, partial(_async_stop_scripts_at_shutdown, hass)
            )
        self.top_level = top_level
        if top_level:
            all_scripts.append(
                {"instance": self, "started_before_shutdown": not hass.is_stopping}
            )
        if DATA_SCRIPT_BREAKPOINTS not in hass.data:
            hass.data[DATA_SCRIPT_BREAKPOINTS] = {}

        self._hass = hass
        self.sequence = sequence
        self.name = name
        self.unique_id = f"{domain}.{name}-{id(self)}"
        self.domain = domain
        self.enabled = enabled
        self.running_description = running_description or f"{domain} script"
        self._change_listener = change_listener
        self._change_listener_job = (
            None if change_listener is None else HassJob(change_listener)
        )

        self.script_mode = script_mode
        self._set_logger(logger)
        self._log_exceptions = log_exceptions

        self.last_action: str | None = None
        self.last_triggered: datetime | None = None

        self._runs: list[_ScriptRun] = []
        self.max_runs = max_runs
        self._max_exceeded = max_exceeded
        if script_mode == SCRIPT_MODE_QUEUED:
            self._queue_lck = asyncio.Lock()
        self._config_cache: dict[
            frozenset[tuple[str, str]], ConditionCheckerTypeOptional
        ] = {}
        self._repeat_script: dict[int, Script] = {}
        self._choose_data: dict[int, _ChooseData] = {}
        self._if_data: dict[int, _IfData] = {}
        self._parallel_scripts: dict[int, list[Script]] = {}
        self._sequence_scripts: dict[int, Script] = {}
        self.variables = variables

    @property
    def change_listener(self) -> Callable[..., Any] | None:
        """Return the change_listener."""
        return self._change_listener

    @change_listener.setter
    def change_listener(self, change_listener: Callable[[], Any]) -> None:
        """Update the change_listener."""
        self._change_listener = change_listener
        if (
            self._change_listener_job is None
            or change_listener != self._change_listener_job.target
        ):
            self._change_listener_job = HassJob(change_listener)

    def _set_logger(self, logger: logging.Logger | None = None) -> None:
        if logger:
            self._logger = logger
        else:
            self._logger = logging.getLogger(f"{__name__}.{slugify(self.name)}")

    def update_logger(self, logger: logging.Logger | None = None) -> None:
        """Update logger."""
        self._set_logger(logger)
        for script in self._repeat_script.values():
            script.update_logger(self._logger)
        for parallel_scripts in self._parallel_scripts.values():
            for parallel_script in parallel_scripts:
                parallel_script.update_logger(self._logger)
        for choose_data in self._choose_data.values():
            for _, script in choose_data["choices"]:
                script.update_logger(self._logger)
            if choose_data["default"] is not None:
                choose_data["default"].update_logger(self._logger)
        for if_data in self._if_data.values():
            if_data["if_then"].update_logger(self._logger)
            if if_data["if_else"] is not None:
                if_data["if_else"].update_logger(self._logger)

    def _changed(self) -> None:
        if self._change_listener_job:
            self._hass.async_run_hass_job(self._change_listener_job)

    @callback
    def _chain_change_listener(self, sub_script: Script) -> None:
        if sub_script.is_running:
            self.last_action = sub_script.last_action
            self._changed()

    @property
    def is_running(self) -> bool:
        """Return true if script is on."""
        return len(self._runs) > 0

    @property
    def runs(self) -> int:
        """Return the number of current runs."""
        return len(self._runs)

    @property
    def supports_max(self) -> bool:
        """Return true if the current mode support max."""
        return self.script_mode in (SCRIPT_MODE_PARALLEL, SCRIPT_MODE_QUEUED)

    @cached_property
    def referenced_labels(self) -> set[str]:
        """Return a set of referenced labels."""
        referenced_labels: set[str] = set()
        Script._find_referenced_target(ATTR_LABEL_ID, referenced_labels, self.sequence)
        return referenced_labels

    @cached_property
    def referenced_floors(self) -> set[str]:
        """Return a set of referenced fooors."""
        referenced_floors: set[str] = set()
        Script._find_referenced_target(ATTR_FLOOR_ID, referenced_floors, self.sequence)
        return referenced_floors

    @cached_property
    def referenced_areas(self) -> set[str]:
        """Return a set of referenced areas."""
        referenced_areas: set[str] = set()
        Script._find_referenced_target(ATTR_AREA_ID, referenced_areas, self.sequence)
        return referenced_areas

    @staticmethod
    def _find_referenced_target(
        target: Literal["area_id", "floor_id", "label_id"],
        referenced: set[str],
        sequence: Sequence[dict[str, Any]],
    ) -> None:
        """Find referenced target in a sequence."""
        for step in sequence:
            action = cv.determine_script_action(step)

            if action == cv.SCRIPT_ACTION_CALL_SERVICE:
                for data in (
                    step.get(CONF_TARGET),
                    step.get(CONF_SERVICE_DATA),
                    step.get(CONF_SERVICE_DATA_TEMPLATE),
                ):
                    _referenced_extract_ids(data, target, referenced)

            elif action == cv.SCRIPT_ACTION_CHECK_CONDITION:
                referenced |= condition.async_extract_targets(step, target)

            elif action == cv.SCRIPT_ACTION_CHOOSE:
                for choice in step[CONF_CHOOSE]:
                    for cond in choice[CONF_CONDITIONS]:
                        referenced |= condition.async_extract_targets(cond, target)
                    Script._find_referenced_target(
                        target, referenced, choice[CONF_SEQUENCE]
                    )
                if CONF_DEFAULT in step:
                    Script._find_referenced_target(
                        target, referenced, step[CONF_DEFAULT]
                    )

            elif action == cv.SCRIPT_ACTION_IF:
                for cond in step[CONF_IF]:
                    referenced |= condition.async_extract_targets(cond, target)
                Script._find_referenced_target(target, referenced, step[CONF_THEN])
                if CONF_ELSE in step:
                    Script._find_referenced_target(target, referenced, step[CONF_ELSE])

            elif action == cv.SCRIPT_ACTION_PARALLEL:
                for script in step[CONF_PARALLEL]:
                    Script._find_referenced_target(
                        target, referenced, script[CONF_SEQUENCE]
                    )

            elif action == cv.SCRIPT_ACTION_SEQUENCE:
                Script._find_referenced_target(target, referenced, step[CONF_SEQUENCE])

    @cached_property
    def referenced_devices(self) -> set[str]:
        """Return a set of referenced devices."""
        referenced_devices: set[str] = set()
        Script._find_referenced_devices(referenced_devices, self.sequence)
        return referenced_devices

    @staticmethod
    def _find_referenced_devices(
        referenced: set[str], sequence: Sequence[dict[str, Any]]
    ) -> None:
        for step in sequence:
            action = cv.determine_script_action(step)

            if action == cv.SCRIPT_ACTION_CALL_SERVICE:
                for data in (
                    step.get(CONF_TARGET),
                    step.get(CONF_SERVICE_DATA),
                    step.get(CONF_SERVICE_DATA_TEMPLATE),
                ):
                    _referenced_extract_ids(data, ATTR_DEVICE_ID, referenced)

            elif action == cv.SCRIPT_ACTION_CHECK_CONDITION:
                referenced |= condition.async_extract_devices(step)

            elif action == cv.SCRIPT_ACTION_DEVICE_AUTOMATION:
                referenced.add(step[CONF_DEVICE_ID])

            elif action == cv.SCRIPT_ACTION_CHOOSE:
                for choice in step[CONF_CHOOSE]:
                    for cond in choice[CONF_CONDITIONS]:
                        referenced |= condition.async_extract_devices(cond)
                    Script._find_referenced_devices(referenced, choice[CONF_SEQUENCE])
                if CONF_DEFAULT in step:
                    Script._find_referenced_devices(referenced, step[CONF_DEFAULT])

            elif action == cv.SCRIPT_ACTION_IF:
                for cond in step[CONF_IF]:
                    referenced |= condition.async_extract_devices(cond)
                Script._find_referenced_devices(referenced, step[CONF_THEN])
                if CONF_ELSE in step:
                    Script._find_referenced_devices(referenced, step[CONF_ELSE])

            elif action == cv.SCRIPT_ACTION_PARALLEL:
                for script in step[CONF_PARALLEL]:
                    Script._find_referenced_devices(referenced, script[CONF_SEQUENCE])

            elif action == cv.SCRIPT_ACTION_SEQUENCE:
                Script._find_referenced_devices(referenced, step[CONF_SEQUENCE])

    @cached_property
    def referenced_entities(self) -> set[str]:
        """Return a set of referenced entities."""
        referenced_entities: set[str] = set()
        Script._find_referenced_entities(referenced_entities, self.sequence)
        return referenced_entities

    @staticmethod
    def _find_referenced_entities(
        referenced: set[str], sequence: Sequence[dict[str, Any]]
    ) -> None:
        for step in sequence:
            action = cv.determine_script_action(step)

            if action == cv.SCRIPT_ACTION_CALL_SERVICE:
                for data in (
                    step,
                    step.get(CONF_TARGET),
                    step.get(CONF_SERVICE_DATA),
                    step.get(CONF_SERVICE_DATA_TEMPLATE),
                ):
                    _referenced_extract_ids(data, ATTR_ENTITY_ID, referenced)

            elif action == cv.SCRIPT_ACTION_CHECK_CONDITION:
                referenced |= condition.async_extract_entities(step)

            elif action == cv.SCRIPT_ACTION_ACTIVATE_SCENE:
                referenced.add(step[CONF_SCENE])

            elif action == cv.SCRIPT_ACTION_CHOOSE:
                for choice in step[CONF_CHOOSE]:
                    for cond in choice[CONF_CONDITIONS]:
                        referenced |= condition.async_extract_entities(cond)
                    Script._find_referenced_entities(referenced, choice[CONF_SEQUENCE])
                if CONF_DEFAULT in step:
                    Script._find_referenced_entities(referenced, step[CONF_DEFAULT])

            elif action == cv.SCRIPT_ACTION_IF:
                for cond in step[CONF_IF]:
                    referenced |= condition.async_extract_entities(cond)
                Script._find_referenced_entities(referenced, step[CONF_THEN])
                if CONF_ELSE in step:
                    Script._find_referenced_entities(referenced, step[CONF_ELSE])

            elif action == cv.SCRIPT_ACTION_PARALLEL:
                for script in step[CONF_PARALLEL]:
                    Script._find_referenced_entities(referenced, script[CONF_SEQUENCE])

            elif action == cv.SCRIPT_ACTION_SEQUENCE:
                Script._find_referenced_entities(referenced, step[CONF_SEQUENCE])

    def run(
        self, variables: _VarsType | None = None, context: Context | None = None
    ) -> None:
        """Run script."""
        asyncio.run_coroutine_threadsafe(
            self.async_run(variables, context), self._hass.loop
        ).result()

    async def async_run(
        self,
        run_variables: _VarsType | None = None,
        context: Context | None = None,
        started_action: Callable[..., Any] | None = None,
    ) -> ScriptRunResult | None:
        """Run script."""
        if context is None:
            self._log(
                "Running script requires passing in a context", level=logging.WARNING
            )
            context = Context()

        # Prevent spawning new script runs when Home Assistant is shutting down
        if DATA_NEW_SCRIPT_RUNS_NOT_ALLOWED in self._hass.data:
            self._log("Home Assistant is shutting down, starting script blocked")
            return None

        # Prevent spawning new script runs if not allowed by script mode
        if self.is_running:
            if self.script_mode == SCRIPT_MODE_SINGLE:
                if self._max_exceeded != "SILENT":
                    self._log("Already running", level=LOGSEVERITY[self._max_exceeded])
                script_execution_set("failed_single")
                return None
            if self.script_mode != SCRIPT_MODE_RESTART and self.runs == self.max_runs:
                if self._max_exceeded != "SILENT":
                    self._log(
                        "Maximum number of runs exceeded",
                        level=LOGSEVERITY[self._max_exceeded],
                    )
                script_execution_set("failed_max_runs")
                return None

        # If this is a top level Script then make a copy of the variables in case they
        # are read-only, but more importantly, so as not to leak any variables created
        # during the run back to the caller.
        if self.top_level:
            if self.variables:
                try:
                    run_variables = self.variables.async_render(
                        self._hass,
                        run_variables,
                    )
                except exceptions.TemplateError as err:
                    self._log("Error rendering variables: %s", err, level=logging.ERROR)
                    raise

            variables = ScriptRunVariables.create_top_level(run_variables)
            variables["context"] = context
        else:
            # This is not the top level script, run_variables is an instance of ScriptRunVariables
            variables = cast(ScriptRunVariables, run_variables)

        # Prevent non-allowed recursive calls which will cause deadlocks when we try to
        # stop (restart) or wait for (queued) our own script run.
        script_stack = script_stack_cv.get()
        if (
            self.script_mode in (SCRIPT_MODE_RESTART, SCRIPT_MODE_QUEUED)
            and script_stack is not None
            and self.unique_id in script_stack
        ):
            script_execution_set("disallowed_recursion_detected")
            formatted_stack = [
                f"- {name_id.partition('-')[0]}" for name_id in script_stack
            ]
            self._log(
                "Disallowed recursion detected, "
                f"{script_stack[-1].partition('-')[0]} tried to start "
                f"{self.domain}.{self.name} which is already running "
                "in the current execution path; "
                "Traceback (most recent call last):\n"
                f"{'\n'.join(formatted_stack)}",
                level=logging.WARNING,
            )
            return None

        if self.script_mode != SCRIPT_MODE_QUEUED:
            cls = _ScriptRun
        else:
            cls = _QueuedScriptRun
        run = cls(self._hass, self, variables, context, self._log_exceptions)
        has_existing_runs = bool(self._runs)
        self._runs.append(run)
        if self.script_mode == SCRIPT_MODE_RESTART and has_existing_runs:
            # When script mode is SCRIPT_MODE_RESTART, first add the new run and then
            # stop any other runs. If we stop other runs first, self.is_running will
            # return false after the other script runs were stopped until our task
            # resumes running. Its important that we check if there are existing
            # runs before sleeping as otherwise if two runs are started at the exact
            # same time they will cancel each other out.
            self._log("Restarting")
            await self.async_stop(update_state=False, spare=run)

        if started_action:
            started_action()
        self.last_triggered = utcnow()
        self._changed()

        try:
            return await asyncio.shield(create_eager_task(run.async_run()))
        except asyncio.CancelledError:
            await run.async_stop()
            self._changed()
            raise

    async def _async_stop(
        self, aws: list[asyncio.Task[None]], update_state: bool
    ) -> None:
        await asyncio.wait(aws)
        if update_state:
            self._changed()

    async def async_stop(
        self, update_state: bool = True, spare: _ScriptRun | None = None
    ) -> None:
        """Stop running script."""
        # Collect a list of script runs to stop. This must be done before calling
        # asyncio.shield as asyncio.shield yields to the event loop, which would cause
        # us to wait for script runs added after the call to async_stop.
        aws = [
            create_eager_task(run.async_stop()) for run in self._runs if run != spare
        ]
        if not aws:
            return
        await asyncio.shield(create_eager_task(self._async_stop(aws, update_state)))

    async def _async_get_condition(
        self, config: ConfigType
    ) -> ConditionCheckerTypeOptional:
        config_cache_key = frozenset((k, str(v)) for k, v in config.items())
        if not (cond := self._config_cache.get(config_cache_key)):
            cond = await condition.async_from_config(self._hass, config)
            self._config_cache[config_cache_key] = cond
        return cond

    def _prep_repeat_script(self, step: int) -> Script:
        action = self.sequence[step]
        step_name = action.get(CONF_ALIAS, f"Repeat at step {step + 1}")
        sub_script = Script(
            self._hass,
            action[CONF_REPEAT][CONF_SEQUENCE],
            f"{self.name}: {step_name}",
            self.domain,
            running_description=self.running_description,
            script_mode=SCRIPT_MODE_PARALLEL,
            max_runs=self.max_runs,
            logger=self._logger,
            top_level=False,
        )
        sub_script.change_listener = partial(self._chain_change_listener, sub_script)
        return sub_script

    def _get_repeat_script(self, step: int) -> Script:
        if not (sub_script := self._repeat_script.get(step)):
            sub_script = self._prep_repeat_script(step)
            self._repeat_script[step] = sub_script
        return sub_script

    async def _async_prep_choose_data(self, step: int) -> _ChooseData:
        action = self.sequence[step]
        step_name = action.get(CONF_ALIAS, f"Choose at step {step + 1}")
        choices = []
        for idx, choice in enumerate(action[CONF_CHOOSE], start=1):
            conditions = [
                await self._async_get_condition(config)
                for config in choice.get(CONF_CONDITIONS, [])
            ]
            choice_name = choice.get(CONF_ALIAS, f"choice {idx}")
            sub_script = Script(
                self._hass,
                choice[CONF_SEQUENCE],
                f"{self.name}: {step_name}: {choice_name}",
                self.domain,
                running_description=self.running_description,
                script_mode=SCRIPT_MODE_PARALLEL,
                max_runs=self.max_runs,
                logger=self._logger,
                top_level=False,
            )
            sub_script.change_listener = partial(
                self._chain_change_listener, sub_script
            )
            choices.append((conditions, sub_script))

        default_script: Script | None
        if CONF_DEFAULT in action:
            default_script = Script(
                self._hass,
                action[CONF_DEFAULT],
                f"{self.name}: {step_name}: default",
                self.domain,
                running_description=self.running_description,
                script_mode=SCRIPT_MODE_PARALLEL,
                max_runs=self.max_runs,
                logger=self._logger,
                top_level=False,
            )
            default_script.change_listener = partial(
                self._chain_change_listener, default_script
            )
        else:
            default_script = None

        return {"choices": choices, "default": default_script}

    async def _async_get_choose_data(self, step: int) -> _ChooseData:
        if not (choose_data := self._choose_data.get(step)):
            choose_data = await self._async_prep_choose_data(step)
            self._choose_data[step] = choose_data
        return choose_data

    async def _async_prep_if_data(self, step: int) -> _IfData:
        """Prepare data for an if statement."""
        action = self.sequence[step]
        step_name = action.get(CONF_ALIAS, f"If at step {step + 1}")

        conditions = [
            await self._async_get_condition(config) for config in action[CONF_IF]
        ]

        then_script = Script(
            self._hass,
            action[CONF_THEN],
            f"{self.name}: {step_name}",
            self.domain,
            running_description=self.running_description,
            script_mode=SCRIPT_MODE_PARALLEL,
            max_runs=self.max_runs,
            logger=self._logger,
            top_level=False,
        )
        then_script.change_listener = partial(self._chain_change_listener, then_script)

        if CONF_ELSE in action:
            else_script = Script(
                self._hass,
                action[CONF_ELSE],
                f"{self.name}: {step_name}",
                self.domain,
                running_description=self.running_description,
                script_mode=SCRIPT_MODE_PARALLEL,
                max_runs=self.max_runs,
                logger=self._logger,
                top_level=False,
            )
            else_script.change_listener = partial(
                self._chain_change_listener, else_script
            )
        else:
            else_script = None

        return _IfData(
            if_conditions=conditions,
            if_then=then_script,
            if_else=else_script,
        )

    async def _async_get_if_data(self, step: int) -> _IfData:
        if not (if_data := self._if_data.get(step)):
            if_data = await self._async_prep_if_data(step)
            self._if_data[step] = if_data
        return if_data

    async def _async_prep_parallel_scripts(self, step: int) -> list[Script]:
        action = self.sequence[step]
        step_name = action.get(CONF_ALIAS, f"Parallel action at step {step + 1}")
        parallel_scripts: list[Script] = []
        for idx, parallel_script in enumerate(action[CONF_PARALLEL], start=1):
            parallel_name = parallel_script.get(CONF_ALIAS, f"parallel {idx}")
            parallel_script = Script(
                self._hass,
                parallel_script[CONF_SEQUENCE],
                f"{self.name}: {step_name}: {parallel_name}",
                self.domain,
                running_description=self.running_description,
                script_mode=SCRIPT_MODE_PARALLEL,
                max_runs=self.max_runs,
                logger=self._logger,
                top_level=False,
                enabled=parallel_script.get(CONF_ENABLED, True),
            )
            parallel_script.change_listener = partial(
                self._chain_change_listener, parallel_script
            )
            parallel_scripts.append(parallel_script)

        return parallel_scripts

    async def _async_get_parallel_scripts(self, step: int) -> list[Script]:
        if not (parallel_scripts := self._parallel_scripts.get(step)):
            parallel_scripts = await self._async_prep_parallel_scripts(step)
            self._parallel_scripts[step] = parallel_scripts
        return parallel_scripts

    async def _async_prep_sequence_script(self, step: int) -> Script:
        """Prepare a sequence script."""
        action = self.sequence[step]
        step_name = action.get(CONF_ALIAS, f"Sequence action at step {step + 1}")

        sequence_script = Script(
            self._hass,
            action[CONF_SEQUENCE],
            f"{self.name}: {step_name}",
            self.domain,
            running_description=self.running_description,
            script_mode=SCRIPT_MODE_PARALLEL,
            max_runs=self.max_runs,
            logger=self._logger,
            top_level=False,
        )
        sequence_script.change_listener = partial(
            self._chain_change_listener, sequence_script
        )

        return sequence_script

    async def _async_get_sequence_script(self, step: int) -> Script:
        """Get a (cached) sequence script."""
        if not (sequence_script := self._sequence_scripts.get(step)):
            sequence_script = await self._async_prep_sequence_script(step)
            self._sequence_scripts[step] = sequence_script
        return sequence_script

    def _log(
        self, msg: str, *args: Any, level: int = logging.INFO, **kwargs: Any
    ) -> None:
        msg = f"%s: {msg}"
        args = (self.name, *args)

        if level == _LOG_EXCEPTION:
            self._logger.exception(msg, *args, **kwargs)
        else:
            self._logger.log(level, msg, *args, **kwargs)


@callback
def breakpoint_clear(
    hass: HomeAssistant, key: str, run_id: str | None, node: str
) -> None:
    """Clear a breakpoint."""
    run_id = run_id or RUN_ID_ANY
    breakpoints = hass.data[DATA_SCRIPT_BREAKPOINTS]
    if key not in breakpoints or run_id not in breakpoints[key]:
        return
    breakpoints[key][run_id].discard(node)


@callback
def breakpoint_clear_all(hass: HomeAssistant) -> None:
    """Clear all breakpoints."""
    hass.data[DATA_SCRIPT_BREAKPOINTS] = {}


@callback
def breakpoint_set(
    hass: HomeAssistant, key: str, run_id: str | None, node: str
) -> None:
    """Set a breakpoint."""
    run_id = run_id or RUN_ID_ANY
    breakpoints = hass.data[DATA_SCRIPT_BREAKPOINTS]
    if key not in breakpoints:
        breakpoints[key] = {}
    if run_id not in breakpoints[key]:
        breakpoints[key][run_id] = set()
    breakpoints[key][run_id].add(node)


@callback
def breakpoint_list(hass: HomeAssistant) -> list[dict[str, Any]]:
    """List breakpoints."""
    breakpoints = hass.data[DATA_SCRIPT_BREAKPOINTS]

    return [
        {"key": key, "run_id": run_id, "node": node}
        for key in breakpoints
        for run_id in breakpoints[key]
        for node in breakpoints[key][run_id]
    ]


@callback
def debug_continue(hass: HomeAssistant, key: str, run_id: str) -> None:
    """Continue execution of a halted script."""
    # Clear any wildcard breakpoint
    breakpoint_clear(hass, key, run_id, NODE_ANY)

    signal = SCRIPT_DEBUG_CONTINUE_STOP.format(key, run_id)
    async_dispatcher_send_internal(hass, signal, "continue")


@callback
def debug_step(hass: HomeAssistant, key: str, run_id: str) -> None:
    """Single step a halted script."""
    # Set a wildcard breakpoint
    breakpoint_set(hass, key, run_id, NODE_ANY)

    signal = SCRIPT_DEBUG_CONTINUE_STOP.format(key, run_id)
    async_dispatcher_send_internal(hass, signal, "continue")


@callback
def debug_stop(hass: HomeAssistant, key: str, run_id: str) -> None:
    """Stop execution of a running or halted script."""
    signal = SCRIPT_DEBUG_CONTINUE_STOP.format(key, run_id)
    async_dispatcher_send_internal(hass, signal, "stop")
</file>

<file path="selector.py">
"""Selectors for Home Assistant."""

from __future__ import annotations

from collections.abc import Callable, Mapping, Sequence
from copy import deepcopy
from enum import StrEnum
from functools import cache
import importlib
from typing import Any, Literal, Required, TypedDict, cast
from uuid import UUID

import voluptuous as vol

from homeassistant.const import CONF_MODE, CONF_UNIT_OF_MEASUREMENT
from homeassistant.core import split_entity_id, valid_entity_id
from homeassistant.generated.countries import COUNTRIES
from homeassistant.util import decorator
from homeassistant.util.yaml import dumper

from . import config_validation as cv

SELECTORS: decorator.Registry[str, type[Selector]] = decorator.Registry()


def _get_selector_type_and_class(config: Any) -> tuple[str, type[Selector]]:
    """Get selector type and class."""
    if not isinstance(config, dict):
        raise vol.Invalid("Expected a dictionary")

    if len(config) != 1:
        raise vol.Invalid(f"Only one type can be specified. Found {', '.join(config)}")

    selector_type: str = list(config)[0]

    if (selector_class := SELECTORS.get(selector_type)) is None:
        raise vol.Invalid(f"Unknown selector type {selector_type} found")

    return selector_type, selector_class


def selector(config: Any) -> Selector:
    """Instantiate a selector."""
    selector_type, selector_class = _get_selector_type_and_class(config)
    return selector_class(config[selector_type])


def validate_selector(config: Any) -> dict:
    """Validate a selector."""
    selector_type, selector_class = _get_selector_type_and_class(config)
    return {selector_type: selector_class.CONFIG_SCHEMA(config[selector_type])}


class Selector[_T: Mapping[str, Any]]:
    """Base class for selectors."""

    CONFIG_SCHEMA: Callable
    config: _T
    selector_type: str
    # Context keys that are allowed to be used in the selector, with list of allowed selector types.
    # Selectors can use the value of other fields in the same schema as context for filtering for example.
    # The selector defines which context keys it supports and what selector types are allowed for each key.
    allowed_context_keys: dict[str, set[str]] = {}

    def __init__(self, config: Mapping[str, Any] | None = None) -> None:
        """Instantiate a selector."""
        self.config = self.CONFIG_SCHEMA(config)

    def __eq__(self, other: object) -> bool:
        """Check equality."""
        if not isinstance(other, Selector):
            return NotImplemented

        return self.selector_type == other.selector_type and self.config == other.config

    def serialize(self) -> dict[str, dict[str, _T]]:
        """Serialize Selector for voluptuous_serialize."""
        return {"selector": {self.selector_type: self.config}}


@cache
def _entity_feature_flag(domain: str, enum_name: str, feature_name: str) -> int:
    """Return a cached lookup of an entity feature enum.

    This will import a module from disk and is run from an executor when
    loading the services schema files.
    """
    module = importlib.import_module(f"homeassistant.components.{domain}")
    enum = getattr(module, enum_name)
    feature = getattr(enum, feature_name)
    return cast(int, feature.value)


def _validate_supported_feature(supported_feature: str) -> int:
    """Validate a supported feature and resolve an enum string to its value."""

    try:
        domain, enum, feature = supported_feature.split(".", 2)
    except ValueError as exc:
        raise vol.Invalid(
            f"Invalid supported feature '{supported_feature}', expected "
            "<domain>.<enum>.<member>"
        ) from exc

    try:
        return _entity_feature_flag(domain, enum, feature)
    except (ModuleNotFoundError, AttributeError) as exc:
        raise vol.Invalid(f"Unknown supported feature '{supported_feature}'") from exc


def _validate_supported_features(supported_features: list[str]) -> int:
    """Validate supported features and resolve enum strings to their value."""

    feature_mask = 0

    for supported_feature in supported_features:
        feature_mask |= _validate_supported_feature(supported_feature)

    return feature_mask


def make_selector_config_schema(schema_dict: dict | None = None) -> vol.Schema:
    """Make selector config schema."""
    if schema_dict is None:
        schema_dict = {}

    def none_to_empty_dict(value: Any) -> Any:
        if value is None:
            return {}
        return value

    return vol.Schema(
        vol.All(
            none_to_empty_dict,
            {
                vol.Optional("read_only"): bool,
                **schema_dict,
            },
        )
    )


class BaseSelectorConfig(TypedDict, total=False):
    """Class to common options of all selectors."""

    read_only: bool


ENTITY_FILTER_SELECTOR_CONFIG_SCHEMA = vol.Schema(
    {
        # Integration that provided the entity
        vol.Optional("integration"): str,
        # Domain the entity belongs to
        vol.Optional("domain"): vol.All(cv.ensure_list, [str]),
        # Device class of the entity
        vol.Optional("device_class"): vol.All(cv.ensure_list, [str]),
        # Features supported by the entity
        vol.Optional("supported_features"): [
            vol.All(cv.ensure_list, [str], _validate_supported_features)
        ],
    }
)


# Legacy entity selector config schema used directly under entity selectors
# is provided for backwards compatibility and remains feature frozen.
# New filtering features should be added under the `filter` key instead.
# https://github.com/home-assistant/frontend/pull/15302
_LEGACY_ENTITY_SELECTOR_CONFIG_SCHEMA_DICT = {
    # Integration that provided the entity
    vol.Optional("integration"): str,
    # Domain the entity belongs to
    vol.Optional("domain"): vol.All(cv.ensure_list, [str]),
    # Device class of the entity
    vol.Optional("device_class"): vol.All(cv.ensure_list, [str]),
}


class EntityFilterSelectorConfig(TypedDict, total=False):
    """Class to represent a single entity selector config."""

    integration: str
    domain: str | list[str]
    device_class: str | list[str]
    supported_features: list[str]


DEVICE_FILTER_SELECTOR_CONFIG_SCHEMA = vol.Schema(
    {
        # Integration linked to it with a config entry
        vol.Optional("integration"): str,
        # Manufacturer of device
        vol.Optional("manufacturer"): str,
        # Model of device
        vol.Optional("model"): str,
        # Model ID of device
        vol.Optional("model_id"): str,
    }
)


# Legacy device selector config schema used directly under device selectors
# is provided for backwards compatibility and remains feature frozen.
# New filtering features should be added under the `filter` key instead.
# https://github.com/home-assistant/frontend/pull/15302
_LEGACY_DEVICE_SELECTOR_CONFIG_SCHEMA_DICT = {
    # Integration linked to it with a config entry
    vol.Optional("integration"): str,
    # Manufacturer of device
    vol.Optional("manufacturer"): str,
    # Model of device
    vol.Optional("model"): str,
}


class DeviceFilterSelectorConfig(TypedDict, total=False):
    """Class to represent a single device selector config."""

    integration: str
    manufacturer: str
    model: str
    model_id: str


class ActionSelectorConfig(BaseSelectorConfig):
    """Class to represent an action selector config."""


@SELECTORS.register("action")
class ActionSelector(Selector[ActionSelectorConfig]):
    """Selector of an action sequence (script syntax)."""

    selector_type = "action"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: ActionSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        return data


class AddonSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an addon selector config."""

    name: str
    slug: str


@SELECTORS.register("addon")
class AddonSelector(Selector[AddonSelectorConfig]):
    """Selector of a add-on."""

    selector_type = "addon"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("name"): str,
            vol.Optional("slug"): str,
        }
    )

    def __init__(self, config: AddonSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        addon: str = vol.Schema(str)(data)
        return addon


class AreaSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an area selector config."""

    entity: EntityFilterSelectorConfig | list[EntityFilterSelectorConfig]
    device: DeviceFilterSelectorConfig | list[DeviceFilterSelectorConfig]
    multiple: bool


@SELECTORS.register("area")
class AreaSelector(Selector[AreaSelectorConfig]):
    """Selector of a single or list of areas."""

    selector_type = "area"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("entity"): vol.All(
                cv.ensure_list,
                [ENTITY_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
            vol.Optional("device"): vol.All(
                cv.ensure_list,
                [DEVICE_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
            vol.Optional("multiple", default=False): cv.boolean,
        }
    )

    def __init__(self, config: AreaSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""
        if not self.config["multiple"]:
            area_id: str = vol.Schema(str)(data)
            return area_id
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [vol.Schema(str)(val) for val in data]


class AssistPipelineSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an assist pipeline selector config."""


@SELECTORS.register("assist_pipeline")
class AssistPipelineSelector(Selector[AssistPipelineSelectorConfig]):
    """Selector for an assist pipeline."""

    selector_type = "assist_pipeline"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: AssistPipelineSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        pipeline: str = vol.Schema(str)(data)
        return pipeline


class AttributeSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an attribute selector config."""

    entity_id: Required[str]
    hide_attributes: list[str]


@SELECTORS.register("attribute")
class AttributeSelector(Selector[AttributeSelectorConfig]):
    """Selector for an entity attribute."""

    selector_type = "attribute"

    allowed_context_keys = {
        # Filters the available attributes based on the selected entity
        "filter_entity": {"entity"}
    }

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Required("entity_id"): cv.entity_id,
            # hide_attributes is used to hide attributes in the frontend.
            # A hidden attribute can still be provided manually.
            vol.Optional("hide_attributes"): [str],
        }
    )

    def __init__(self, config: AttributeSelectorConfig) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        attribute: str = vol.Schema(str)(data)
        return attribute


class BackupLocationSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a backup location selector config."""


@SELECTORS.register("backup_location")
class BackupLocationSelector(Selector[BackupLocationSelectorConfig]):
    """Selector of a backup location."""

    selector_type = "backup_location"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: BackupLocationSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        name: str = vol.Match(r"^(?:\/backup|\w+)$")(data)
        return name


class BooleanSelectorConfig(BaseSelectorConfig):
    """Class to represent a boolean selector config."""


@SELECTORS.register("boolean")
class BooleanSelector(Selector[BooleanSelectorConfig]):
    """Selector of a boolean value."""

    selector_type = "boolean"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: BooleanSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> bool:
        """Validate the passed selection."""
        value: bool = vol.Coerce(bool)(data)
        return value


def reject_nested_choose_selector(config: dict[str, Any]) -> dict[str, Any]:
    """Reject nested choose selectors."""
    for choice in config.get("choices", {}).values():
        if isinstance(choice["selector"], dict):
            selector_type, _ = _get_selector_type_and_class(choice["selector"])
            if selector_type == "choose":
                raise vol.Invalid("Nested choose selectors are not allowed")
    return config


class ChooseSelectorChoiceConfig(TypedDict, total=False):
    """Class to represent a choose selector choice config."""

    selector: Required[Selector | dict[str, Any]]


class ChooseSelectorConfig(BaseSelectorConfig):
    """Class to represent a choose selector config."""

    choices: Required[dict[str, ChooseSelectorChoiceConfig]]
    translation_key: str


@SELECTORS.register("choose")
class ChooseSelector(Selector[ChooseSelectorConfig]):
    """Selector allowing to choose one of several selectors."""

    selector_type = "choose"

    CONFIG_SCHEMA = vol.All(
        make_selector_config_schema(
            {
                vol.Required("choices"): {
                    str: {
                        vol.Required("selector"): vol.Any(Selector, validate_selector),
                    }
                },
                vol.Optional("translation_key"): cv.string,
            },
        ),
        reject_nested_choose_selector,
    )

    def __init__(self, config: ChooseSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def serialize(self) -> dict[str, dict[str, ChooseSelectorConfig]]:
        """Serialize ChooseSelectorConfig for voluptuous_serialize."""
        _config = deepcopy(self.config)
        if "choices" in _config:
            for choice in _config["choices"].values():
                if isinstance(choice["selector"], Selector):
                    choice["selector"] = choice["selector"].serialize()["selector"]
        return {"selector": {self.selector_type: _config}}

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        if not isinstance(data, dict):
            for choice in self.config["choices"].values():
                try:
                    validated = selector(choice["selector"])(data)  # type: ignore[operator]
                except (vol.Invalid, vol.MultipleInvalid):
                    continue
                else:
                    return validated

            raise vol.Invalid("Value does not match any choice selector")

        if "active_choice" not in data:
            raise vol.Invalid("Missing active_choice key")
        if data["active_choice"] not in data:
            raise vol.Invalid("Missing value for active choice")

        choices = self.config.get("choices", {})
        if data["active_choice"] not in choices:
            raise vol.Invalid("Invalid active_choice key")
        return selector(choices[data["active_choice"]]["selector"])(  # type: ignore[operator]
            data[data["active_choice"]]
        )


class ColorRGBSelectorConfig(BaseSelectorConfig):
    """Class to represent a color RGB selector config."""


@SELECTORS.register("color_rgb")
class ColorRGBSelector(Selector[ColorRGBSelectorConfig]):
    """Selector of an RGB color value."""

    selector_type = "color_rgb"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: ColorRGBSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> list[int]:
        """Validate the passed selection."""
        value: list[int] = vol.All(list, vol.ExactSequence((cv.byte,) * 3))(data)
        return value


class ColorTempSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a color temp selector config."""

    unit: ColorTempSelectorUnit
    min: int
    max: int
    max_mireds: int
    min_mireds: int


class ColorTempSelectorUnit(StrEnum):
    """Possible units for a color temperature selector."""

    KELVIN = "kelvin"
    MIRED = "mired"


@SELECTORS.register("color_temp")
class ColorTempSelector(Selector[ColorTempSelectorConfig]):
    """Selector of an color temperature."""

    selector_type = "color_temp"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("unit", default=ColorTempSelectorUnit.MIRED): vol.All(
                vol.Coerce(ColorTempSelectorUnit), lambda val: val.value
            ),
            vol.Optional("min"): vol.Coerce(int),
            vol.Optional("max"): vol.Coerce(int),
            vol.Optional("max_mireds"): vol.Coerce(int),
            vol.Optional("min_mireds"): vol.Coerce(int),
        }
    )

    def __init__(self, config: ColorTempSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> int:
        """Validate the passed selection."""
        range_min = self.config.get("min")
        range_max = self.config.get("max")

        if range_min is None:
            range_min = self.config.get("min_mireds")

        if range_max is None:
            range_max = self.config.get("max_mireds")

        value: int = vol.All(
            vol.Coerce(float),
            vol.Range(
                min=range_min,
                max=range_max,
            ),
        )(data)
        return value


class ConditionSelectorConfig(BaseSelectorConfig):
    """Class to represent an condition selector config."""


@SELECTORS.register("condition")
class ConditionSelector(Selector[ConditionSelectorConfig]):
    """Selector of an condition sequence (script syntax)."""

    selector_type = "condition"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: ConditionSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        return vol.Schema(cv.CONDITIONS_SCHEMA)(data)


class ConfigEntrySelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a config entry selector config."""

    integration: str


@SELECTORS.register("config_entry")
class ConfigEntrySelector(Selector[ConfigEntrySelectorConfig]):
    """Selector of a config entry."""

    selector_type = "config_entry"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("integration"): str,
        }
    )

    def __init__(self, config: ConfigEntrySelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        config: str = vol.Schema(str)(data)
        return config


class ConstantSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a constant selector config."""

    label: str
    translation_key: str
    value: str | int | bool


@SELECTORS.register("constant")
class ConstantSelector(Selector[ConstantSelectorConfig]):
    """Constant selector."""

    selector_type = "constant"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("label"): str,
            vol.Optional("translation_key"): cv.string,
            vol.Required("value"): vol.Any(str, int, bool),
        }
    )

    def __init__(self, config: ConstantSelectorConfig) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        vol.Schema(self.config["value"])(data)
        return self.config["value"]


class ConversationAgentSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a conversation agent selector config."""

    language: str


@SELECTORS.register("conversation_agent")
class ConversationAgentSelector(Selector[ConversationAgentSelectorConfig]):
    """Selector for a conversation agent."""

    selector_type = "conversation_agent"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("language"): str,
        }
    )

    def __init__(self, config: ConversationAgentSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        agent: str = vol.Schema(str)(data)
        return agent


class CountrySelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a country selector config."""

    countries: list[str]
    no_sort: bool


@SELECTORS.register("country")
class CountrySelector(Selector[CountrySelectorConfig]):
    """Selector for a single-choice country select."""

    selector_type = "country"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("countries"): [str],
            vol.Optional("no_sort", default=False): cv.boolean,
        }
    )

    def __init__(self, config: CountrySelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        country: str = vol.Schema(str)(data)
        if "countries" in self.config and (
            country not in self.config["countries"] or country not in COUNTRIES
        ):
            raise vol.Invalid(f"Value {country} is not a valid option")
        return country


class DateSelectorConfig(BaseSelectorConfig):
    """Class to represent a date selector config."""


@SELECTORS.register("date")
class DateSelector(Selector[DateSelectorConfig]):
    """Selector of a date."""

    selector_type = "date"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: DateSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        cv.date(data)
        return data


class DateTimeSelectorConfig(BaseSelectorConfig):
    """Class to represent a date time selector config."""


@SELECTORS.register("datetime")
class DateTimeSelector(Selector[DateTimeSelectorConfig]):
    """Selector of a datetime."""

    selector_type = "datetime"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: DateTimeSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        cv.datetime(data)
        return data


class DeviceSelectorConfig(BaseSelectorConfig, DeviceFilterSelectorConfig, total=False):
    """Class to represent a device selector config."""

    entity: EntityFilterSelectorConfig | list[EntityFilterSelectorConfig]
    multiple: bool
    filter: DeviceFilterSelectorConfig | list[DeviceFilterSelectorConfig]


@SELECTORS.register("device")
class DeviceSelector(Selector[DeviceSelectorConfig]):
    """Selector of a single or list of devices."""

    selector_type = "device"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            **_LEGACY_DEVICE_SELECTOR_CONFIG_SCHEMA_DICT,
            # Device has to contain entities matching this selector
            vol.Optional("entity"): vol.All(
                cv.ensure_list, [ENTITY_FILTER_SELECTOR_CONFIG_SCHEMA]
            ),
            vol.Optional("multiple", default=False): cv.boolean,
            vol.Optional("filter"): vol.All(
                cv.ensure_list,
                [DEVICE_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
        },
    )

    def __init__(self, config: DeviceSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""
        if not self.config["multiple"]:
            device_id: str = vol.Schema(str)(data)
            return device_id
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [vol.Schema(str)(val) for val in data]


class DurationSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a duration selector config."""

    enable_day: bool
    enable_millisecond: bool
    allow_negative: bool


@SELECTORS.register("duration")
class DurationSelector(Selector[DurationSelectorConfig]):
    """Selector for a duration."""

    selector_type = "duration"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            # Enable day field in frontend. A selection with `days` set is allowed
            # even if `enable_day` is not set
            vol.Optional("enable_day"): cv.boolean,
            # Enable millisecond field in frontend.
            vol.Optional("enable_millisecond"): cv.boolean,
            # Allow negative durations. Will default to False in HA Core 2025.6.0.
            vol.Optional("allow_negative"): cv.boolean,
        }
    )

    def __init__(self, config: DurationSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> dict[str, float]:
        """Validate the passed selection."""
        if self.config.get("allow_negative", True):
            cv.time_period_dict(data)
        else:
            cv.positive_time_period_dict(data)
        return cast(dict[str, float], data)


class EntitySelectorConfig(BaseSelectorConfig, EntityFilterSelectorConfig, total=False):
    """Class to represent an entity selector config."""

    exclude_entities: list[str]
    include_entities: list[str]
    multiple: bool
    reorder: bool
    filter: EntityFilterSelectorConfig | list[EntityFilterSelectorConfig]


@SELECTORS.register("entity")
class EntitySelector(Selector[EntitySelectorConfig]):
    """Selector of a single or list of entities."""

    selector_type = "entity"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            **_LEGACY_ENTITY_SELECTOR_CONFIG_SCHEMA_DICT,
            vol.Optional("exclude_entities"): [str],
            vol.Optional("include_entities"): [str],
            vol.Optional("multiple", default=False): cv.boolean,
            vol.Optional("reorder", default=False): cv.boolean,
            vol.Optional("filter"): vol.All(
                cv.ensure_list,
                [ENTITY_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
        }
    )

    def __init__(self, config: EntitySelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""

        include_entities = self.config.get("include_entities")
        exclude_entities = self.config.get("exclude_entities")

        def validate(e_or_u: str) -> str:
            e_or_u = cv.entity_id_or_uuid(e_or_u)
            if not valid_entity_id(e_or_u):
                return e_or_u
            if allowed_domains := cv.ensure_list(self.config.get("domain")):
                domain = split_entity_id(e_or_u)[0]
                if domain not in allowed_domains:
                    raise vol.Invalid(
                        f"Entity {e_or_u} belongs to domain {domain}, "
                        f"expected {allowed_domains}"
                    )
            if include_entities:
                vol.In(include_entities)(e_or_u)
            if exclude_entities:
                vol.NotIn(exclude_entities)(e_or_u)
            return e_or_u

        if not self.config["multiple"]:
            return validate(data)
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return cast(list, vol.Schema([validate])(data))  # Output is a list


class FileSelectorConfig(BaseSelectorConfig):
    """Class to represent a file selector config."""

    accept: str  # required


@SELECTORS.register("file")
class FileSelector(Selector[FileSelectorConfig]):
    """Selector of a file."""

    selector_type = "file"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            # https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/file#accept
            vol.Required("accept"): str,
        }
    )

    def __init__(self, config: FileSelectorConfig) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        if not isinstance(data, str):
            raise vol.Invalid("Value should be a string")

        UUID(data)

        return data


class FloorSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an floor selector config."""

    entity: EntityFilterSelectorConfig | list[EntityFilterSelectorConfig]
    device: DeviceFilterSelectorConfig | list[DeviceFilterSelectorConfig]
    multiple: bool


@SELECTORS.register("floor")
class FloorSelector(Selector[FloorSelectorConfig]):
    """Selector of a single or list of floors."""

    selector_type = "floor"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("entity"): vol.All(
                cv.ensure_list,
                [ENTITY_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
            vol.Optional("device"): vol.All(
                cv.ensure_list,
                [DEVICE_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
            vol.Optional("multiple", default=False): cv.boolean,
        }
    )

    def __init__(self, config: FloorSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""
        if not self.config["multiple"]:
            floor_id: str = vol.Schema(str)(data)
            return floor_id
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [vol.Schema(str)(val) for val in data]


class IconSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an icon selector config."""

    placeholder: str


@SELECTORS.register("icon")
class IconSelector(Selector[IconSelectorConfig]):
    """Selector for an icon."""

    selector_type = "icon"

    CONFIG_SCHEMA = make_selector_config_schema(
        {vol.Optional("placeholder"): str}
        # Frontend also has a fallbackPath option, this is not used by core
    )

    def __init__(self, config: IconSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        icon: str = vol.Schema(str)(data)
        return icon


class LabelSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a label selector config."""

    multiple: bool


@SELECTORS.register("label")
class LabelSelector(Selector[LabelSelectorConfig]):
    """Selector of a single or list of labels."""

    selector_type = "label"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("multiple", default=False): cv.boolean,
        }
    )

    def __init__(self, config: LabelSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""
        if not self.config["multiple"]:
            label_id: str = vol.Schema(str)(data)
            return label_id
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [vol.Schema(str)(val) for val in data]


class LanguageSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an language selector config."""

    languages: list[str]
    native_name: bool
    no_sort: bool


@SELECTORS.register("language")
class LanguageSelector(Selector[LanguageSelectorConfig]):
    """Selector for an language."""

    selector_type = "language"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("languages"): [str],
            vol.Optional("native_name", default=False): cv.boolean,
            vol.Optional("no_sort", default=False): cv.boolean,
        }
    )

    def __init__(self, config: LanguageSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        language: str = vol.Schema(str)(data)
        if "languages" in self.config and language not in self.config["languages"]:
            raise vol.Invalid(f"Value {language} is not a valid option")
        return language


class LocationSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a location selector config."""

    radius: bool
    icon: str


@SELECTORS.register("location")
class LocationSelector(Selector[LocationSelectorConfig]):
    """Selector for a location."""

    selector_type = "location"

    CONFIG_SCHEMA = make_selector_config_schema(
        {vol.Optional("radius"): bool, vol.Optional("icon"): str}
    )
    DATA_SCHEMA = vol.Schema(
        {
            vol.Required("latitude"): vol.Coerce(float),
            vol.Required("longitude"): vol.Coerce(float),
            vol.Optional("radius"): vol.Coerce(float),
        }
    )

    def __init__(self, config: LocationSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> dict[str, float]:
        """Validate the passed selection."""
        location: dict[str, float] = self.DATA_SCHEMA(data)
        return location


class MediaSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a media selector config."""

    accept: list[str]
    multiple: bool


@SELECTORS.register("media")
class MediaSelector(Selector[MediaSelectorConfig]):
    """Selector for media."""

    selector_type = "media"

    allowed_context_keys = {
        # Filters the available media based on the selected entity
        "filter_entity": {EntitySelector.selector_type}
    }

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("accept"): [str],
            vol.Optional("multiple", default=False): cv.boolean,
        }
    )
    DATA_SCHEMA = vol.Schema(
        {
            # If accept is set, the entity_id field will not be present
            vol.Optional("entity_id"): cv.entity_id_or_uuid,
            # Although marked as optional in frontend, this field is required
            vol.Required("media_content_id"): str,
            # Although marked as optional in frontend, this field is required
            vol.Required("media_content_type"): str,
            vol.Remove("metadata"): dict,
        }
    )

    def __init__(self, config: MediaSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> dict[str, str] | list[dict[str, str]]:
        """Validate the passed selection."""
        item_schema_dict = {
            key: value
            for key, value in self.DATA_SCHEMA.schema.items()
            if key != "entity_id"
        }

        if "accept" not in self.config:
            # If accept is not set, the entity_id field is required
            item_schema_dict[vol.Required("entity_id")] = cv.entity_id_or_uuid

        item_schema = vol.Schema(item_schema_dict)

        if not self.config["multiple"]:
            media: dict[str, str] = item_schema(data)
            return media

        # Backwards compatibility for places that now accept multiple items
        if not isinstance(data, list):
            data = [data]

        return [item_schema(item) for item in data]


class NumberSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a number selector config."""

    min: float
    max: float
    step: float | Literal["any"]
    unit_of_measurement: str
    mode: NumberSelectorMode
    translation_key: str


class NumberSelectorMode(StrEnum):
    """Possible modes for a number selector."""

    BOX = "box"
    SLIDER = "slider"


def validate_slider(data: Any) -> Any:
    """Validate configuration."""
    has_min_max = "min" in data and "max" in data

    if "mode" not in data:
        data["mode"] = "slider" if has_min_max else "box"

    if data["mode"] == "slider" and not has_min_max:
        raise vol.Invalid("min and max are required in slider mode")

    return data


@SELECTORS.register("number")
class NumberSelector(Selector[NumberSelectorConfig]):
    """Selector of a numeric value."""

    selector_type = "number"

    CONFIG_SCHEMA = vol.All(
        make_selector_config_schema(
            {
                vol.Optional("min"): vol.Coerce(float),
                vol.Optional("max"): vol.Coerce(float),
                # Controls slider steps, and up/down keyboard binding for the box
                # user input is not rounded
                vol.Optional("step", default=1): vol.Any(
                    "any", vol.All(vol.Coerce(float), vol.Range(min=1e-3))
                ),
                vol.Optional(CONF_UNIT_OF_MEASUREMENT): str,
                vol.Optional(CONF_MODE): vol.All(
                    vol.Coerce(NumberSelectorMode), lambda val: val.value
                ),
                vol.Optional("translation_key"): str,
            }
        ),
        validate_slider,
    )

    def __init__(self, config: NumberSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> float:
        """Validate the passed selection."""
        value: float = vol.Coerce(float)(data)

        if "min" in self.config and value < self.config["min"]:
            raise vol.Invalid(f"Value {value} is too small")

        if "max" in self.config and value > self.config["max"]:
            raise vol.Invalid(f"Value {value} is too large")

        return value


class ObjectSelectorField(TypedDict, total=False):
    """Class to represent an object selector fields dict."""

    label: str
    required: bool
    selector: Required[Selector | dict[str, Any]]


class ObjectSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an object selector config."""

    fields: dict[str, ObjectSelectorField]
    multiple: bool
    label_field: str
    description_field: str
    translation_key: str


@SELECTORS.register("object")
class ObjectSelector(Selector[ObjectSelectorConfig]):
    """Selector for an arbitrary object."""

    selector_type = "object"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("fields"): {
                str: {
                    vol.Required("selector"): vol.Any(Selector, validate_selector),
                    vol.Optional("required"): bool,
                    vol.Optional("label"): str,
                }
            },
            vol.Optional("multiple", default=False): bool,
            vol.Optional("label_field"): str,
            vol.Optional("description_field"): str,
            vol.Optional("translation_key"): str,
        }
    )

    def __init__(self, config: ObjectSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def serialize(self) -> dict[str, dict[str, ObjectSelectorConfig]]:
        """Serialize ObjectSelector for voluptuous_serialize."""
        _config = deepcopy(self.config)
        if "fields" in _config:
            for field_items in _config["fields"].values():
                if isinstance(field_items["selector"], Selector):
                    field_items["selector"] = field_items["selector"].serialize()[
                        "selector"
                    ]
        return {"selector": {self.selector_type: _config}}

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        if "fields" not in self.config:
            # Return data if no fields are defined
            return data

        if not isinstance(data, (list, dict)):
            raise vol.Invalid("Value should be a dict or a list of dicts")
        if isinstance(data, list) and not self.config["multiple"]:
            raise vol.Invalid("Value should not be a list")

        test_data = data if isinstance(data, list) else [data]

        for _config in test_data:
            for field, field_data in self.config["fields"].items():
                if field_data.get("required") and field not in _config:
                    raise vol.Invalid(f"Field {field} is required")
                if field in _config:
                    selector(field_data["selector"])(_config[field])  # type: ignore[operator]

            for key in _config:
                if key not in self.config["fields"]:
                    raise vol.Invalid(f"Field {key} is not allowed")

        return data


class QrErrorCorrectionLevel(StrEnum):
    """Possible error correction levels for QR code selector."""

    LOW = "low"
    MEDIUM = "medium"
    QUARTILE = "quartile"
    HIGH = "high"


class QrCodeSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a QR code selector config."""

    data: str
    scale: int
    error_correction_level: QrErrorCorrectionLevel


@SELECTORS.register("qr_code")
class QrCodeSelector(Selector[QrCodeSelectorConfig]):
    """QR code selector."""

    selector_type = "qr_code"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Required("data"): str,
            vol.Optional("scale"): int,
            vol.Optional("error_correction_level"): vol.All(
                vol.Coerce(QrErrorCorrectionLevel), lambda val: val.value
            ),
        }
    )

    def __init__(self, config: QrCodeSelectorConfig) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        vol.Schema(vol.Any(str, None))(data)
        return self.config["data"]


select_option = vol.All(
    dict,
    vol.Schema(
        {
            vol.Required("value"): str,
            vol.Required("label"): str,
        }
    ),
)


class SelectOptionDict(TypedDict):
    """Class to represent a select option dict."""

    value: str
    label: str


class SelectSelectorMode(StrEnum):
    """Possible modes for a select selector."""

    LIST = "list"
    DROPDOWN = "dropdown"


class SelectSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a select selector config."""

    options: Required[Sequence[SelectOptionDict] | Sequence[str]]
    multiple: bool
    custom_value: bool
    mode: SelectSelectorMode
    translation_key: str
    sort: bool


@SELECTORS.register("select")
class SelectSelector(Selector[SelectSelectorConfig]):
    """Selector for an single-choice input select."""

    selector_type = "select"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Required("options"): vol.All(vol.Any([str], [select_option])),
            vol.Optional("multiple", default=False): cv.boolean,
            vol.Optional("custom_value", default=False): cv.boolean,
            vol.Optional("mode"): vol.All(
                vol.Coerce(SelectSelectorMode), lambda val: val.value
            ),
            vol.Optional("translation_key"): cv.string,
            vol.Optional("sort", default=False): cv.boolean,
        }
    )

    def __init__(self, config: SelectSelectorConfig) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        options: Sequence[str] = []
        if config_options := self.config["options"]:
            if isinstance(config_options[0], str):
                options = cast(Sequence[str], config_options)
            else:
                options = [
                    option["value"]
                    for option in cast(Sequence[SelectOptionDict], config_options)
                ]

        parent_schema: vol.In | vol.Any = vol.In(options)
        if self.config["custom_value"]:
            parent_schema = vol.Any(parent_schema, str)

        if not self.config["multiple"]:
            return parent_schema(vol.Schema(str)(data))
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [parent_schema(vol.Schema(str)(val)) for val in data]


class StateSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent an state selector config."""

    entity_id: str
    hide_states: list[str]
    multiple: bool


@SELECTORS.register("state")
class StateSelector(Selector[StateSelectorConfig]):
    """Selector for an entity state."""

    selector_type = "state"

    allowed_context_keys = {
        # Filters the available states based on the selected entity
        "filter_entity": {EntitySelector.selector_type},
        # Filters the available states based on the selected target
        "filter_target": {"target"},
        # Only show the attribute values of a specific attribute
        "filter_attribute": {AttributeSelector.selector_type},
    }

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("entity_id"): cv.entity_id,
            vol.Optional("hide_states"): [str],
            # The attribute to filter on, is currently deliberately not
            # configurable/exposed. We are considering separating state
            # selectors into two types: one for state and one for attribute.
            # Limiting the public use, prevents breaking changes in the future.
            # vol.Optional("attribute"): str,
            vol.Optional("multiple", default=False): cv.boolean,
        }
    )

    def __init__(self, config: StateSelectorConfig) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""
        if not self.config["multiple"]:
            state: str = vol.Schema(str)(data)
            return state
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [vol.Schema(str)(val) for val in data]


class StatisticSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a statistic selector config."""

    multiple: bool


@SELECTORS.register("statistic")
class StatisticSelector(Selector[StatisticSelectorConfig]):
    """Selector of a single or list of statistics."""

    selector_type = "statistic"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("multiple", default=False): cv.boolean,
        }
    )

    def __init__(self, config: StatisticSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""

        if not self.config["multiple"]:
            stat: str = vol.Schema(str)(data)
            return stat
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [vol.Schema(str)(val) for val in data]


class TargetSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a target selector config."""

    entity: EntityFilterSelectorConfig | list[EntityFilterSelectorConfig]
    device: DeviceFilterSelectorConfig | list[DeviceFilterSelectorConfig]


@SELECTORS.register("target")
class TargetSelector(Selector[TargetSelectorConfig]):
    """Selector of a target value (area ID, device ID, entity ID etc).

    Value should follow cv.TARGET_SERVICE_FIELDS format.
    """

    selector_type = "target"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("entity"): vol.All(
                cv.ensure_list,
                [ENTITY_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
            vol.Optional("device"): vol.All(
                cv.ensure_list,
                [DEVICE_FILTER_SELECTOR_CONFIG_SCHEMA],
            ),
        }
    )

    # We want to transition to not including templates in the target selector.
    TARGET_SELECTION_SCHEMA = vol.Schema(cv._TARGET_SERVICE_FIELDS_TEMPLATED)  # noqa: SLF001

    def __init__(self, config: TargetSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> dict[str, list[str]]:
        """Validate the passed selection."""
        target: dict[str, list[str]] = self.TARGET_SELECTION_SCHEMA(data)
        return target


class TemplateSelectorConfig(BaseSelectorConfig):
    """Class to represent an template selector config."""


@SELECTORS.register("template")
class TemplateSelector(Selector[TemplateSelectorConfig]):
    """Selector for an template."""

    selector_type = "template"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: TemplateSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        template = cv.template(data)
        return template.template


class TextSelectorConfig(BaseSelectorConfig, total=False):
    """Class to represent a text selector config."""

    multiline: bool
    prefix: str
    suffix: str
    type: TextSelectorType
    autocomplete: str
    multiple: bool


class TextSelectorType(StrEnum):
    """Enum for text selector types."""

    COLOR = "color"
    DATE = "date"
    DATETIME_LOCAL = "datetime-local"
    EMAIL = "email"
    MONTH = "month"
    NUMBER = "number"
    PASSWORD = "password"
    SEARCH = "search"
    TEL = "tel"
    TEXT = "text"
    TIME = "time"
    URL = "url"
    WEEK = "week"


@SELECTORS.register("text")
class TextSelector(Selector[TextSelectorConfig]):
    """Selector for a multi-line text string."""

    selector_type = "text"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("multiline", default=False): bool,
            vol.Optional("prefix"): str,
            vol.Optional("suffix"): str,
            # The "type" controls the input field in the browser, the resulting
            # data can be any string so we don't validate it.
            vol.Optional("type"): vol.All(
                vol.Coerce(TextSelectorType), lambda val: val.value
            ),
            vol.Optional("autocomplete"): str,
            vol.Optional("multiple", default=False): bool,
        }
    )

    def __init__(self, config: TextSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str | list[str]:
        """Validate the passed selection."""
        if not self.config["multiple"]:
            text: str = vol.Schema(str)(data)
            return text
        if not isinstance(data, list):
            raise vol.Invalid("Value should be a list")
        return [vol.Schema(str)(val) for val in data]


class ThemeSelectorConfig(BaseSelectorConfig):
    """Class to represent a theme selector config."""


@SELECTORS.register("theme")
class ThemeSelector(Selector[ThemeSelectorConfig]):
    """Selector for an theme."""

    selector_type = "theme"

    CONFIG_SCHEMA = make_selector_config_schema(
        {
            vol.Optional("include_default", default=False): cv.boolean,
        }
    )

    def __init__(self, config: ThemeSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        theme: str = vol.Schema(str)(data)
        return theme


class TimeSelectorConfig(BaseSelectorConfig):
    """Class to represent a time selector config."""


@SELECTORS.register("time")
class TimeSelector(Selector[TimeSelectorConfig]):
    """Selector of a time value."""

    selector_type = "time"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: TimeSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> str:
        """Validate the passed selection."""
        cv.time(data)
        return cast(str, data)


class TriggerSelectorConfig(BaseSelectorConfig):
    """Class to represent an trigger selector config."""


@SELECTORS.register("trigger")
class TriggerSelector(Selector[TriggerSelectorConfig]):
    """Selector of a trigger sequence (script syntax)."""

    selector_type = "trigger"

    CONFIG_SCHEMA = make_selector_config_schema()

    def __init__(self, config: TriggerSelectorConfig | None = None) -> None:
        """Instantiate a selector."""
        super().__init__(config)

    def __call__(self, data: Any) -> Any:
        """Validate the passed selection."""
        return vol.Schema(cv.TRIGGER_SCHEMA)(data)


dumper.add_representer(
    Selector,
    lambda dumper, value: dumper.represent_odict(
        dumper, "tag:yaml.org,2002:map", value.serialize()
    ),
)
</file>

<file path="sensor.py">
"""Common functions related to sensor device management."""

from __future__ import annotations

from typing import TYPE_CHECKING

from homeassistant import const

from .device_registry import DeviceInfo

if TYPE_CHECKING:
    # `sensor_state_data` is a second-party library (i.e. maintained by Home Assistant
    # core members) which is not strictly required by Home Assistant.
    # Therefore, we import it as a type hint only.
    from sensor_state_data import SensorDeviceInfo


def sensor_device_info_to_hass_device_info(
    sensor_device_info: SensorDeviceInfo,
) -> DeviceInfo:
    """Convert a sensor_state_data sensor device info to a HA device info."""
    device_info = DeviceInfo()
    if sensor_device_info.name is not None:
        device_info[const.ATTR_NAME] = sensor_device_info.name
    if sensor_device_info.manufacturer is not None:
        device_info[const.ATTR_MANUFACTURER] = sensor_device_info.manufacturer
    if sensor_device_info.model is not None:
        device_info[const.ATTR_MODEL] = sensor_device_info.model
    return device_info
</file>

<file path="service.py">
"""Service calling related helpers."""

from __future__ import annotations

import asyncio
from collections.abc import Callable, Coroutine, Iterable, Mapping
import dataclasses
from enum import Enum
from functools import cache, partial
import inspect
import logging
from types import ModuleType
from typing import TYPE_CHECKING, Any, TypedDict, cast, override

import voluptuous as vol

from homeassistant.auth.permissions.const import CAT_ENTITIES, POLICY_CONTROL
from homeassistant.const import (
    ATTR_ENTITY_ID,
    CONF_ACTION,
    CONF_ENTITY_ID,
    CONF_SELECTOR,
    CONF_SERVICE_DATA,
    CONF_SERVICE_DATA_TEMPLATE,
    CONF_SERVICE_TEMPLATE,
    CONF_TARGET,
    ENTITY_MATCH_ALL,
    ENTITY_MATCH_NONE,
)
from homeassistant.core import (
    Context,
    EntityServiceResponse,
    HassJob,
    HassJobType,
    HomeAssistant,
    ServiceCall,
    ServiceResponse,
    SupportsResponse,
    callback,
)
from homeassistant.exceptions import (
    HomeAssistantError,
    ServiceNotSupported,
    TemplateError,
    Unauthorized,
    UnknownUser,
)
from homeassistant.loader import Integration, async_get_integrations, bind_hass
from homeassistant.util.async_ import create_eager_task
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.yaml import load_yaml_dict
from homeassistant.util.yaml.loader import JSON_TYPE

from . import (
    config_validation as cv,
    device_registry,
    entity_registry,
    selector,
    target as target_helpers,
    template,
)
from .deprecation import deprecated_class, deprecated_function, deprecated_hass_argument
from .selector import TargetSelector
from .typing import ConfigType, TemplateVarsType, VolDictType, VolSchemaType

if TYPE_CHECKING:
    from .entity import Entity

CONF_SERVICE_ENTITY_ID = "entity_id"

_LOGGER = logging.getLogger(__name__)

SERVICE_DESCRIPTION_CACHE: HassKey[dict[tuple[str, str], dict[str, Any] | None]] = (
    HassKey("service_description_cache")
)
ALL_SERVICE_DESCRIPTIONS_CACHE: HassKey[
    tuple[set[tuple[str, str]], dict[str, dict[str, Any]]]
] = HassKey("all_service_descriptions_cache")


@cache
def _base_components() -> dict[str, ModuleType]:
    """Return a cached lookup of base components."""
    from homeassistant.components import (  # noqa: PLC0415
        ai_task,
        alarm_control_panel,
        assist_satellite,
        calendar,
        camera,
        climate,
        cover,
        fan,
        humidifier,
        light,
        lock,
        media_player,
        notify,
        remote,
        siren,
        todo,
        update,
        vacuum,
        water_heater,
    )

    return {
        "ai_task": ai_task,
        "alarm_control_panel": alarm_control_panel,
        "assist_satellite": assist_satellite,
        "calendar": calendar,
        "camera": camera,
        "climate": climate,
        "cover": cover,
        "fan": fan,
        "humidifier": humidifier,
        "light": light,
        "lock": lock,
        "media_player": media_player,
        "notify": notify,
        "remote": remote,
        "siren": siren,
        "todo": todo,
        "update": update,
        "vacuum": vacuum,
        "water_heater": water_heater,
    }


def _validate_option_or_feature(option_or_feature: str, label: str) -> Any:
    """Validate attribute option or supported feature."""
    try:
        domain, enum, option = option_or_feature.split(".", 2)
    except ValueError as exc:
        raise vol.Invalid(
            f"Invalid {label} '{option_or_feature}', expected <domain>.<enum>.<member>"
        ) from exc

    base_components = _base_components()
    if not (base_component := base_components.get(domain)):
        raise vol.Invalid(f"Unknown base component '{domain}'")

    try:
        attribute_enum = getattr(base_component, enum)
    except AttributeError as exc:
        raise vol.Invalid(f"Unknown {label} enum '{domain}.{enum}'") from exc

    if not issubclass(attribute_enum, Enum):
        raise vol.Invalid(f"Expected {label} '{domain}.{enum}' to be an enum")

    try:
        return getattr(attribute_enum, option).value
    except AttributeError as exc:
        raise vol.Invalid(f"Unknown {label} '{enum}.{option}'") from exc


def validate_attribute_option(attribute_option: str) -> Any:
    """Validate attribute option."""
    return _validate_option_or_feature(attribute_option, "attribute option")


def validate_supported_feature(supported_feature: str) -> Any:
    """Validate supported feature."""
    return _validate_option_or_feature(supported_feature, "supported feature")


# Basic schemas which translate attribute and supported feature enum names
# to their values. Full validation is done by hassfest.services
_FIELD_SCHEMA = vol.Schema(
    {
        vol.Optional(CONF_SELECTOR): selector.validate_selector,
        vol.Optional("filter"): {
            vol.Optional("attribute"): {
                vol.Required(str): [vol.All(str, validate_attribute_option)],
            },
            vol.Optional("supported_features"): [
                vol.All(str, validate_supported_feature)
            ],
        },
    },
    extra=vol.ALLOW_EXTRA,
)

_SECTION_SCHEMA = vol.Schema(
    {
        vol.Required("fields"): vol.Schema({str: _FIELD_SCHEMA}),
    },
    extra=vol.ALLOW_EXTRA,
)

_SERVICE_SCHEMA = vol.Schema(
    {
        vol.Optional("target"): TargetSelector.CONFIG_SCHEMA,
        vol.Optional("fields"): vol.Schema(
            {str: vol.Any(_SECTION_SCHEMA, _FIELD_SCHEMA)}
        ),
    },
    extra=vol.ALLOW_EXTRA,
)


def starts_with_dot(key: str) -> str:
    """Check if key starts with dot."""
    if not key.startswith("."):
        raise vol.Invalid("Key does not start with .")
    return key


_SERVICES_SCHEMA = vol.Schema(
    {
        vol.Remove(vol.All(str, starts_with_dot)): object,
        cv.slug: vol.Any(None, _SERVICE_SCHEMA),
    }
)


class ServiceParams(TypedDict):
    """Type for service call parameters."""

    domain: str
    service: str
    service_data: dict[str, Any]
    target: dict | None


@deprecated_class(
    "homeassistant.helpers.target.TargetSelection",
    breaks_in_ha_version="2026.8",
)
class ServiceTargetSelector(target_helpers.TargetSelection):
    """Class to hold a target selector for a service."""

    def __init__(self, service_call: ServiceCall) -> None:
        """Extract ids from service call data."""
        super().__init__(service_call.data)


@deprecated_class(
    "homeassistant.helpers.target.SelectedEntities",
    breaks_in_ha_version="2026.8",
)
class SelectedEntities(target_helpers.SelectedEntities):
    """Class to hold the selected entities."""

    @override
    def log_missing(
        self, missing_entities: set[str], logger: logging.Logger | None = None
    ) -> None:
        """Log about missing items."""
        super().log_missing(missing_entities, logger or _LOGGER)


@bind_hass
def call_from_config(
    hass: HomeAssistant,
    config: ConfigType,
    blocking: bool = False,
    variables: TemplateVarsType = None,
    validate_config: bool = True,
) -> None:
    """Call a service based on a config hash."""
    asyncio.run_coroutine_threadsafe(
        async_call_from_config(hass, config, blocking, variables, validate_config),
        hass.loop,
    ).result()


@bind_hass
async def async_call_from_config(
    hass: HomeAssistant,
    config: ConfigType,
    blocking: bool = False,
    variables: TemplateVarsType = None,
    validate_config: bool = True,
    context: Context | None = None,
) -> None:
    """Call a service based on a config hash."""
    try:
        params = async_prepare_call_from_config(
            hass, config, variables, validate_config
        )
    except HomeAssistantError as ex:
        if blocking:
            raise
        _LOGGER.error(ex)
    else:
        await hass.services.async_call(**params, blocking=blocking, context=context)


@callback
@bind_hass
def async_prepare_call_from_config(
    hass: HomeAssistant,
    config: ConfigType,
    variables: TemplateVarsType = None,
    validate_config: bool = False,
) -> ServiceParams:
    """Prepare to call a service based on a config hash."""
    if validate_config:
        try:
            config = cv.SERVICE_SCHEMA(config)
        except vol.Invalid as ex:
            raise HomeAssistantError(
                f"Invalid config for calling service: {ex}"
            ) from ex

    if CONF_ACTION in config:
        domain_service = config[CONF_ACTION]
    else:
        domain_service = config[CONF_SERVICE_TEMPLATE]

    if isinstance(domain_service, template.Template):
        try:
            domain_service = domain_service.async_render(variables)
            domain_service = cv.service(domain_service)
        except TemplateError as ex:
            raise HomeAssistantError(
                f"Error rendering service name template: {ex}"
            ) from ex
        except vol.Invalid as ex:
            raise HomeAssistantError(
                f"Template rendered invalid service: {domain_service}"
            ) from ex

    domain, _, service = domain_service.partition(".")

    target = {}
    if CONF_TARGET in config:
        conf = config[CONF_TARGET]
        try:
            if isinstance(conf, template.Template):
                target.update(conf.async_render(variables))
            else:
                target.update(template.render_complex(conf, variables))

            if CONF_ENTITY_ID in target:
                registry = entity_registry.async_get(hass)
                entity_ids = cv.comp_entity_ids_or_uuids(target[CONF_ENTITY_ID])
                if entity_ids not in (ENTITY_MATCH_ALL, ENTITY_MATCH_NONE):
                    entity_ids = entity_registry.async_validate_entity_ids(
                        registry, entity_ids
                    )
                target[CONF_ENTITY_ID] = entity_ids
        except TemplateError as ex:
            raise HomeAssistantError(
                f"Error rendering service target template: {ex}"
            ) from ex
        except vol.Invalid as ex:
            raise HomeAssistantError(
                f"Template rendered invalid entity IDs: {target[CONF_ENTITY_ID]}"
            ) from ex

    service_data = {}

    for conf in (CONF_SERVICE_DATA, CONF_SERVICE_DATA_TEMPLATE):
        if conf not in config:
            continue
        try:
            render = template.render_complex(config[conf], variables)
            if not isinstance(render, dict):
                raise HomeAssistantError(
                    "Error rendering data template: Result is not a Dictionary"
                )
            service_data.update(render)
        except TemplateError as ex:
            raise HomeAssistantError(f"Error rendering data template: {ex}") from ex

    if CONF_SERVICE_ENTITY_ID in config:
        if target:
            target[ATTR_ENTITY_ID] = config[CONF_SERVICE_ENTITY_ID]
        else:
            target = {ATTR_ENTITY_ID: config[CONF_SERVICE_ENTITY_ID]}

    return {
        "domain": domain,
        "service": service,
        "service_data": service_data,
        "target": target,
    }


@deprecated_hass_argument(breaks_in_ha_version="2026.10")
def extract_entity_ids(
    service_call: ServiceCall, expand_group: bool = True
) -> set[str]:
    """Extract a list of entity ids from a service call.

    Will convert group entity ids to the entity ids it represents.
    """
    return asyncio.run_coroutine_threadsafe(
        async_extract_entity_ids(service_call, expand_group), service_call.hass.loop
    ).result()


@deprecated_hass_argument(breaks_in_ha_version="2026.10")
async def async_extract_entities[_EntityT: Entity](
    entities: Iterable[_EntityT],
    service_call: ServiceCall,
    expand_group: bool = True,
) -> list[_EntityT]:
    """Extract a list of entity objects from a service call.

    Will convert group entity ids to the entity ids it represents.
    """
    data_ent_id = service_call.data.get(ATTR_ENTITY_ID)

    if data_ent_id == ENTITY_MATCH_ALL:
        return [entity for entity in entities if entity.available]

    target_selection = target_helpers.TargetSelection(service_call.data)
    referenced = target_helpers.async_extract_referenced_entity_ids(
        service_call.hass, target_selection, expand_group
    )
    combined = referenced.referenced | referenced.indirectly_referenced

    found = []

    for entity in entities:
        if entity.entity_id not in combined:
            continue

        combined.remove(entity.entity_id)

        if not entity.available:
            continue

        found.append(entity)

    referenced.log_missing(referenced.referenced & combined, _LOGGER)

    return found


@deprecated_hass_argument(breaks_in_ha_version="2026.10")
async def async_extract_entity_ids(
    service_call: ServiceCall, expand_group: bool = True
) -> set[str]:
    """Extract a set of entity ids from a service call.

    Will convert group entity ids to the entity ids it represents.
    """
    target_selection = target_helpers.TargetSelection(service_call.data)
    referenced = target_helpers.async_extract_referenced_entity_ids(
        service_call.hass, target_selection, expand_group
    )
    return referenced.referenced | referenced.indirectly_referenced


@deprecated_function(
    "homeassistant.helpers.target.async_extract_referenced_entity_ids",
    breaks_in_ha_version="2026.8",
)
@bind_hass
def async_extract_referenced_entity_ids(
    hass: HomeAssistant, service_call: ServiceCall, expand_group: bool = True
) -> SelectedEntities:
    """Extract referenced entity IDs from a service call."""
    target_selection = target_helpers.TargetSelection(service_call.data)
    selected = target_helpers.async_extract_referenced_entity_ids(
        hass, target_selection, expand_group
    )
    return SelectedEntities(**dataclasses.asdict(selected))


@deprecated_hass_argument(breaks_in_ha_version="2026.10")
async def async_extract_config_entry_ids(
    service_call: ServiceCall, expand_group: bool = True
) -> set[str]:
    """Extract referenced config entry ids from a service call."""
    target_selection = target_helpers.TargetSelection(service_call.data)
    referenced = target_helpers.async_extract_referenced_entity_ids(
        service_call.hass, target_selection, expand_group
    )
    ent_reg = entity_registry.async_get(service_call.hass)
    dev_reg = device_registry.async_get(service_call.hass)
    config_entry_ids: set[str] = set()

    # Some devices may have no entities
    for device_id in referenced.referenced_devices:
        if (
            device_id in dev_reg.devices
            and (device := dev_reg.async_get(device_id)) is not None
        ):
            config_entry_ids.update(device.config_entries)

    for entity_id in referenced.referenced | referenced.indirectly_referenced:
        entry = ent_reg.async_get(entity_id)
        if entry is not None and entry.config_entry_id is not None:
            config_entry_ids.add(entry.config_entry_id)

    return config_entry_ids


def _load_services_file(integration: Integration) -> JSON_TYPE:
    """Load services file for an integration."""
    try:
        return cast(
            JSON_TYPE,
            _SERVICES_SCHEMA(
                load_yaml_dict(str(integration.file_path / "services.yaml"))
            ),
        )
    except FileNotFoundError:
        _LOGGER.warning(
            "Unable to find services.yaml for the %s integration", integration.domain
        )
        return {}
    except (HomeAssistantError, vol.Invalid) as ex:
        _LOGGER.warning(
            "Unable to parse services.yaml for the %s integration: %s",
            integration.domain,
            ex,
        )
        return {}


def _load_services_files(integrations: Iterable[Integration]) -> dict[str, JSON_TYPE]:
    """Load service files for multiple integrations."""
    return {
        integration.domain: _load_services_file(integration)
        for integration in integrations
    }


@callback
def async_get_cached_service_description(
    hass: HomeAssistant, domain: str, service: str
) -> dict[str, Any] | None:
    """Return the cached description for a service."""
    return hass.data.get(SERVICE_DESCRIPTION_CACHE, {}).get((domain, service))


@bind_hass
async def async_get_all_descriptions(
    hass: HomeAssistant,
) -> dict[str, dict[str, Any]]:
    """Return descriptions (i.e. user documentation) for all service calls."""
    descriptions_cache = hass.data.setdefault(SERVICE_DESCRIPTION_CACHE, {})

    # We don't mutate services here so we avoid calling
    # async_services which makes a copy of every services
    # dict.
    services = hass.services.async_services_internal()

    # See if there are new services not seen before.
    # Any service that we saw before already has an entry in description_cache.
    all_services = {
        (domain, service_name)
        for domain, services_by_domain in services.items()
        for service_name in services_by_domain
    }
    # If we have a complete cache, check if it is still valid
    if all_cache := hass.data.get(ALL_SERVICE_DESCRIPTIONS_CACHE):
        previous_all_services, previous_descriptions_cache = all_cache
        # If the services are the same, we can return the cache
        if previous_all_services == all_services:
            return previous_descriptions_cache

    # Files we loaded for missing descriptions
    loaded: dict[str, JSON_TYPE] = {}
    # We try to avoid making a copy in the event the cache is good,
    # but now we must make a copy in case new services get added
    # while we are loading the missing ones so we do not
    # add the new ones to the cache without their descriptions
    services = {domain: service.copy() for domain, service in services.items()}

    if domains_with_missing_services := {
        domain for domain, _ in all_services.difference(descriptions_cache)
    }:
        ints_or_excs = await async_get_integrations(hass, domains_with_missing_services)
        integrations: list[Integration] = []
        for domain, int_or_exc in ints_or_excs.items():
            if type(int_or_exc) is Integration and int_or_exc.has_services:
                integrations.append(int_or_exc)
                continue
            if TYPE_CHECKING:
                assert isinstance(int_or_exc, Exception)
            _LOGGER.error(
                "Failed to load services.yaml for integration: %s",
                domain,
                exc_info=int_or_exc,
            )

        if integrations:
            loaded = await hass.async_add_executor_job(
                _load_services_files, integrations
            )

    # Build response
    descriptions: dict[str, dict[str, Any]] = {}
    for domain, services_map in services.items():
        descriptions[domain] = {}
        domain_descriptions = descriptions[domain]

        for service_name, service in services_map.items():
            cache_key = (domain, service_name)
            description = descriptions_cache.get(cache_key)
            if description is not None:
                domain_descriptions[service_name] = description
                continue

            # Cache missing descriptions
            domain_yaml = loaded.get(domain) or {}
            # The YAML may be empty for dynamically defined
            # services (e.g. shell_command) that never call
            # service.async_set_service_schema for the dynamic
            # service

            yaml_description = (
                domain_yaml.get(service_name) or {}  # type: ignore[union-attr]
            )

            # Don't warn for missing services, because it triggers false
            # positives for things like scripts, that register as a service
            description = {"fields": yaml_description.get("fields", {})}
            if description_placeholders := service.description_placeholders:
                description["description_placeholders"] = description_placeholders

            for item in ("description", "name", "target"):
                if item in yaml_description:
                    description[item] = yaml_description[item]

            response = service.supports_response
            if response is not SupportsResponse.NONE:
                description["response"] = {
                    "optional": response is SupportsResponse.OPTIONAL,
                }

            descriptions_cache[cache_key] = description

            domain_descriptions[service_name] = description

    hass.data[ALL_SERVICE_DESCRIPTIONS_CACHE] = (all_services, descriptions)
    return descriptions


@callback
def remove_entity_service_fields(call: ServiceCall) -> dict[Any, Any]:
    """Remove entity service fields."""
    return {
        key: val
        for key, val in call.data.items()
        if key not in cv.ENTITY_SERVICE_FIELDS
    }


@callback
@bind_hass
def async_set_service_schema(
    hass: HomeAssistant, domain: str, service: str, schema: dict[str, Any]
) -> None:
    """Register a description for a service."""
    domain = domain.lower()
    service = service.lower()

    descriptions_cache = hass.data.setdefault(SERVICE_DESCRIPTION_CACHE, {})

    description = {
        "name": schema.get("name", ""),
        "description": schema.get("description", ""),
        "fields": schema.get("fields", {}),
    }

    if "target" in schema:
        description["target"] = schema["target"]

    if (
        response := hass.services.supports_response(domain, service)
    ) != SupportsResponse.NONE:
        description["response"] = {
            "optional": response == SupportsResponse.OPTIONAL,
        }

    hass.data.pop(ALL_SERVICE_DESCRIPTIONS_CACHE, None)
    descriptions_cache[(domain, service)] = description


def _get_permissible_entity_candidates(
    call: ServiceCall,
    entities: dict[str, Entity],
    entity_perms: Callable[[str, str], bool] | None,
    target_all_entities: bool,
    all_referenced: set[str] | None,
) -> list[Entity]:
    """Get entity candidates that the user is allowed to access."""
    if entity_perms is not None:
        # Check the permissions since entity_perms is set
        if target_all_entities:
            # If we target all entities, we will select all entities the user
            # is allowed to control.
            return [
                entity
                for entity_id, entity in entities.items()
                if entity_perms(entity_id, POLICY_CONTROL)
            ]

        assert all_referenced is not None
        # If they reference specific entities, we will check if they are all
        # allowed to be controlled.
        for entity_id in all_referenced:
            if not entity_perms(entity_id, POLICY_CONTROL):
                raise Unauthorized(
                    context=call.context,
                    entity_id=entity_id,
                    permission=POLICY_CONTROL,
                )

    elif target_all_entities:
        return list(entities.values())

    # We have already validated they have permissions to control all_referenced
    # entities so we do not need to check again.
    if TYPE_CHECKING:
        assert all_referenced is not None
    if (
        len(all_referenced) == 1
        and (single_entity := list(all_referenced)[0])
        and (entity := entities.get(single_entity)) is not None
    ):
        return [entity]

    return [entities[entity_id] for entity_id in all_referenced.intersection(entities)]


@bind_hass
async def entity_service_call(
    hass: HomeAssistant,
    registered_entities: dict[str, Entity] | Callable[[], dict[str, Entity]],
    func: str | HassJob,
    call: ServiceCall,
    required_features: Iterable[int] | None = None,
    *,
    entity_device_classes: Iterable[str | None] | None = None,
) -> EntityServiceResponse | None:
    """Handle an entity service call.

    Calls all platforms simultaneously.
    """
    entity_perms: Callable[[str, str], bool] | None = None
    return_response = call.return_response

    if call.context.user_id:
        user = await hass.auth.async_get_user(call.context.user_id)
        if user is None:
            raise UnknownUser(context=call.context)
        if not user.is_admin:
            entity_perms = user.permissions.check_entity

    target_all_entities = call.data.get(ATTR_ENTITY_ID) == ENTITY_MATCH_ALL

    if target_all_entities:
        referenced: target_helpers.SelectedEntities | None = None
        all_referenced: set[str] | None = None
    else:
        # A set of entities we're trying to target.
        target_selection = target_helpers.TargetSelection(call.data)
        referenced = target_helpers.async_extract_referenced_entity_ids(
            hass, target_selection, True
        )
        all_referenced = referenced.referenced | referenced.indirectly_referenced

    # If the service function is a string, we'll pass it the service call data
    if isinstance(func, str):
        data: dict | ServiceCall = remove_entity_service_fields(call)
    # If the service function is not a string, we pass the service call
    else:
        data = call

    if callable(registered_entities):
        _registered_entities = registered_entities()
    else:
        _registered_entities = registered_entities

    # A list with entities to call the service on.
    entity_candidates = _get_permissible_entity_candidates(
        call,
        _registered_entities,
        entity_perms,
        target_all_entities,
        all_referenced,
    )

    if not target_all_entities:
        assert referenced is not None
        # Only report on explicit referenced entities
        missing = referenced.referenced.copy()
        for entity in entity_candidates:
            missing.discard(entity.entity_id)
        referenced.log_missing(missing, _LOGGER)

    entities: list[Entity] = []
    for entity in entity_candidates:
        if not entity.available:
            continue

        # Skip entities that don't have the required device class.
        if (
            entity_device_classes is not None
            and entity.device_class not in entity_device_classes
        ):
            # If entity explicitly referenced, raise an error
            if referenced is not None and entity.entity_id in referenced.referenced:
                raise ServiceNotSupported(call.domain, call.service, entity.entity_id)

            continue

        # Skip entities that don't have the required feature.
        if required_features is not None and (
            entity.supported_features is None
            or not any(
                entity.supported_features & feature_set == feature_set
                for feature_set in required_features
            )
        ):
            # If entity explicitly referenced, raise an error
            if referenced is not None and entity.entity_id in referenced.referenced:
                raise ServiceNotSupported(call.domain, call.service, entity.entity_id)

            continue

        entities.append(entity)

    if not entities:
        if return_response:
            raise HomeAssistantError(
                "Service call requested response data but did not match any entities"
            )
        return None

    if len(entities) == 1:
        # Single entity case avoids creating task
        entity = entities[0]
        single_response = await _handle_entity_call(
            hass, entity, func, data, call.context
        )
        if entity.should_poll:
            # Context expires if the turn on commands took a long time.
            # Set context again so it's there when we update
            entity.async_set_context(call.context)
            await entity.async_update_ha_state(True)
        return {entity.entity_id: single_response} if return_response else None

    # Use asyncio.gather here to ensure the returned results
    # are in the same order as the entities list
    results: list[ServiceResponse | BaseException] = await asyncio.gather(
        *[
            entity.async_request_call(
                _handle_entity_call(hass, entity, func, data, call.context)
            )
            for entity in entities
        ],
        return_exceptions=True,
    )

    response_data: EntityServiceResponse = {}
    for entity, result in zip(entities, results, strict=False):
        if isinstance(result, BaseException):
            raise result from None
        response_data[entity.entity_id] = result

    tasks: list[asyncio.Task[None]] = []

    for entity in entities:
        if not entity.should_poll:
            continue

        # Context expires if the turn on commands took a long time.
        # Set context again so it's there when we update
        entity.async_set_context(call.context)
        tasks.append(create_eager_task(entity.async_update_ha_state(True)))

    if tasks:
        done, pending = await asyncio.wait(tasks)
        assert not pending
        for future in done:
            future.result()  # pop exception if have

    return response_data if return_response and response_data else None


async def _handle_entity_call(
    hass: HomeAssistant,
    entity: Entity,
    func: str | HassJob,
    data: dict | ServiceCall,
    context: Context,
) -> ServiceResponse:
    """Handle calling service method."""
    entity.async_set_context(context)

    task: asyncio.Future[ServiceResponse] | None
    if isinstance(func, str):
        job = HassJob(
            partial(getattr(entity, func), **data),  # type: ignore[arg-type]
            job_type=entity.get_hassjob_type(func),
        )
        task = hass.async_run_hass_job(job)
    else:
        task = hass.async_run_hass_job(func, entity, data)

    # Guard because callback functions do not return a task when passed to
    # async_run_job.
    result: ServiceResponse = None
    if task is not None:
        result = await task

    if asyncio.iscoroutine(result):
        _LOGGER.error(  # type: ignore[unreachable]
            (
                "Service %s for %s incorrectly returns a coroutine object. Await result"
                " instead in service handler. Report bug to integration author"
            ),
            func,
            entity.entity_id,
        )
        result = await result

    return result


async def _async_admin_handler(
    hass: HomeAssistant,
    service_job: HassJob[
        [ServiceCall],
        Coroutine[Any, Any, ServiceResponse | EntityServiceResponse]
        | ServiceResponse
        | EntityServiceResponse
        | None,
    ],
    call: ServiceCall,
) -> ServiceResponse | EntityServiceResponse | None:
    """Run an admin service."""
    if call.context.user_id:
        user = await hass.auth.async_get_user(call.context.user_id)
        if user is None:
            raise UnknownUser(context=call.context)
        if not user.is_admin:
            raise Unauthorized(context=call.context)

    task = hass.async_run_hass_job(service_job, call)
    if task is not None:
        return await task
    return None


@bind_hass
@callback
def async_register_admin_service(
    hass: HomeAssistant,
    domain: str,
    service: str,
    service_func: Callable[
        [ServiceCall],
        Coroutine[Any, Any, ServiceResponse | EntityServiceResponse]
        | ServiceResponse
        | EntityServiceResponse
        | None,
    ],
    schema: VolSchemaType = vol.Schema({}, extra=vol.PREVENT_EXTRA),
    supports_response: SupportsResponse = SupportsResponse.NONE,
    *,
    description_placeholders: Mapping[str, str] | None = None,
) -> None:
    """Register a service that requires admin access."""
    hass.services.async_register(
        domain,
        service,
        partial(
            _async_admin_handler,
            hass,
            HassJob(service_func, f"admin service {domain}.{service}"),
        ),
        schema,
        supports_response,
        description_placeholders=description_placeholders,
    )


@deprecated_hass_argument(breaks_in_ha_version="2026.10")
@callback
def verify_domain_control(
    domain: str,
) -> Callable[[Callable[[ServiceCall], Any]], Callable[[ServiceCall], Any]]:
    """Ensure permission to access any entity under domain in service call."""

    def decorator(
        service_handler: Callable[[ServiceCall], Any],
    ) -> Callable[[ServiceCall], Any]:
        """Decorate."""
        if not inspect.iscoroutinefunction(service_handler):
            raise HomeAssistantError("Can only decorate async functions.")

        async def check_permissions(call: ServiceCall) -> Any:
            """Check user permission and raise before call if unauthorized."""
            if not call.context.user_id:
                return await service_handler(call)

            hass = call.hass
            user = await hass.auth.async_get_user(call.context.user_id)

            if user is None:
                raise UnknownUser(
                    context=call.context,
                    permission=POLICY_CONTROL,
                    user_id=call.context.user_id,
                )

            reg = entity_registry.async_get(hass)

            authorized = False

            for entity in reg.entities.values():
                if entity.platform != domain:
                    continue

                if user.permissions.check_entity(entity.entity_id, POLICY_CONTROL):
                    authorized = True
                    break

            if not authorized:
                raise Unauthorized(
                    context=call.context,
                    permission=POLICY_CONTROL,
                    user_id=call.context.user_id,
                    perm_category=CAT_ENTITIES,
                )

            return await service_handler(call)

        return check_permissions

    return decorator


class ReloadServiceHelper[_T]:
    """Helper for reload services.

    The helper has the following purposes:
    - Make sure reloads do not happen in parallel
    - Avoid redundant reloads of the same target
    """

    def __init__(
        self,
        service_func: Callable[[ServiceCall], Coroutine[Any, Any, Any]],
        reload_targets_func: Callable[[ServiceCall], set[_T]],
    ) -> None:
        """Initialize ReloadServiceHelper."""
        self._service_func = service_func
        self._service_running = False
        self._service_condition = asyncio.Condition()
        self._pending_reload_targets: set[_T] = set()
        self._reload_targets_func = reload_targets_func

    async def execute_service(self, service_call: ServiceCall) -> None:
        """Execute the service.

        If a previous reload task is currently in progress, wait for it to finish first.
        Once the previous reload task has finished, one of the waiting tasks will be
        assigned to execute the reload of the targets it is assigned to reload. The
        other tasks will wait if they should reload the same target, otherwise they
        will wait for the next round.
        """

        do_reload = False
        reload_targets = None
        async with self._service_condition:
            if self._service_running:
                # A previous reload task is already in progress, wait for it to finish,
                # because that task may be reloading a stale version of the resource.
                await self._service_condition.wait()

        while True:
            async with self._service_condition:
                # Once we've passed this point, we assume the version of the resource is
                # the one our task was assigned to reload, or a newer one. Regardless of
                # which, our task is happy as long as the target is reloaded at least
                # once.
                if reload_targets is None:
                    reload_targets = self._reload_targets_func(service_call)
                    self._pending_reload_targets |= reload_targets
                if not self._service_running:
                    # This task will do a reload
                    self._service_running = True
                    do_reload = True
                    break
                # Another task will perform a reload, wait for it to finish
                await self._service_condition.wait()
                # Check if the reload this task is waiting for has been completed
                if reload_targets.isdisjoint(self._pending_reload_targets):
                    break

        if do_reload:
            # Reload, then notify other tasks
            await self._service_func(service_call)
            async with self._service_condition:
                self._service_running = False
                self._pending_reload_targets -= reload_targets
                self._service_condition.notify_all()


def _validate_entity_service_schema(
    schema: VolDictType | VolSchemaType | None, service: str
) -> VolSchemaType:
    """Validate that a schema is an entity service schema."""
    if schema is None or isinstance(schema, dict):
        return cv.make_entity_service_schema(schema)
    if not cv.is_entity_service_schema(schema):
        raise HomeAssistantError(
            f"The {service} service registers an entity service with a non entity service schema"
        )
    return schema


@callback
def async_register_entity_service(
    hass: HomeAssistant,
    domain: str,
    name: str,
    *,
    description_placeholders: Mapping[str, str] | None = None,
    entity_device_classes: Iterable[str | None] | None = None,
    entities: dict[str, Entity],
    func: str | Callable[..., Any],
    job_type: HassJobType | None,
    required_features: Iterable[int] | None = None,
    schema: VolDictType | VolSchemaType | None,
    supports_response: SupportsResponse = SupportsResponse.NONE,
) -> None:
    """Help registering an entity service.

    This is called by EntityComponent.async_register_entity_service and
    EntityPlatform.async_register_entity_service and should not be called
    directly by integrations.
    """
    schema = _validate_entity_service_schema(schema, f"{domain}.{name}")

    service_func: str | HassJob[..., Any]
    service_func = func if isinstance(func, str) else HassJob(func)

    hass.services.async_register(
        domain,
        name,
        partial(
            entity_service_call,
            hass,
            entities,
            service_func,
            entity_device_classes=entity_device_classes,
            required_features=required_features,
        ),
        schema,
        supports_response,
        job_type=job_type,
        description_placeholders=description_placeholders,
    )


@callback
def async_register_platform_entity_service(
    hass: HomeAssistant,
    service_domain: str,
    service_name: str,
    *,
    description_placeholders: Mapping[str, str] | None = None,
    entity_device_classes: Iterable[str | None] | None = None,
    entity_domain: str,
    func: str | Callable[..., Any],
    required_features: Iterable[int] | None = None,
    schema: VolDictType | VolSchemaType | None,
    supports_response: SupportsResponse = SupportsResponse.NONE,
) -> None:
    """Help registering a platform entity service."""
    from .entity_platform import DATA_DOMAIN_PLATFORM_ENTITIES  # noqa: PLC0415

    schema = _validate_entity_service_schema(schema, f"{service_domain}.{service_name}")

    service_func: str | HassJob[..., Any]
    service_func = func if isinstance(func, str) else HassJob(func)

    def get_entities() -> dict[str, Entity]:
        entities = hass.data.get(DATA_DOMAIN_PLATFORM_ENTITIES, {}).get(
            (entity_domain, service_domain)
        )
        if entities is None:
            return {}
        return entities

    hass.services.async_register(
        service_domain,
        service_name,
        partial(
            entity_service_call,
            hass,
            get_entities,
            service_func,
            entity_device_classes=entity_device_classes,
            required_features=required_features,
        ),
        schema,
        supports_response,
        job_type=HassJobType.Coroutinefunction,
        description_placeholders=description_placeholders,
    )
</file>

<file path="signal.py">
"""Signal handling related helpers."""

import asyncio
import logging
import signal

from homeassistant.const import RESTART_EXIT_CODE
from homeassistant.core import HomeAssistant, callback
from homeassistant.loader import bind_hass
from homeassistant.util.hass_dict import HassKey

_LOGGER = logging.getLogger(__name__)

KEY_HA_STOP: HassKey[asyncio.Task[None]] = HassKey("homeassistant_stop")


@callback
@bind_hass
def async_register_signal_handling(hass: HomeAssistant) -> None:
    """Register system signal handler for core."""

    @callback
    def async_signal_handle(exit_code: int) -> None:
        """Wrap signal handling.

        * queue call to shutdown task
        * re-instate default handler
        """
        hass.loop.remove_signal_handler(signal.SIGTERM)
        hass.loop.remove_signal_handler(signal.SIGINT)
        hass.data[KEY_HA_STOP] = asyncio.create_task(hass.async_stop(exit_code))

    try:
        hass.loop.add_signal_handler(signal.SIGTERM, async_signal_handle, 0)
    except ValueError:
        _LOGGER.warning("Could not bind to SIGTERM")

    try:
        hass.loop.add_signal_handler(signal.SIGINT, async_signal_handle, 0)
    except ValueError:
        _LOGGER.warning("Could not bind to SIGINT")

    try:
        hass.loop.add_signal_handler(
            signal.SIGHUP, async_signal_handle, RESTART_EXIT_CODE
        )
    except ValueError:
        _LOGGER.warning("Could not bind to SIGHUP")
</file>

<file path="significant_change.py">
"""Helpers to help find if an entity has changed significantly.

Does this with help of the integration. Looks at significant_change.py
platform for a function `async_check_significant_change`:

```python
from typing import Optional
from homeassistant.core import HomeAssistant

async def async_check_significant_change(
    hass: HomeAssistant,
    old_state: str,
    old_attrs: dict,
    new_state: str,
    new_attrs: dict,
    **kwargs,
) -> bool | None
```

Return boolean to indicate if significantly changed. If don't know, return None.

**kwargs will allow us to expand this feature in the future, like passing in a
level of significance.

The following cases will never be passed to your function:
- if either state is unknown/unavailable
- state adding/removing
"""

from __future__ import annotations

from collections.abc import Callable, Mapping
import math
from types import MappingProxyType
from typing import Any, Protocol

from homeassistant.const import STATE_UNAVAILABLE, STATE_UNKNOWN
from homeassistant.core import HomeAssistant, State, callback
from homeassistant.util.hass_dict import HassKey

from .integration_platform import async_process_integration_platforms

PLATFORM = "significant_change"
DATA_FUNCTIONS: HassKey[dict[str, CheckTypeFunc]] = HassKey("significant_change")
type CheckTypeFunc = Callable[
    [
        HomeAssistant,
        str,
        dict | MappingProxyType,
        str,
        dict | MappingProxyType,
    ],
    bool | None,
]

type ExtraCheckTypeFunc = Callable[
    [
        HomeAssistant,
        str,
        dict | MappingProxyType,
        Any,
        str,
        dict | MappingProxyType,
        Any,
    ],
    bool | None,
]


class SignificantChangeProtocol(Protocol):
    """Define the format of significant_change platforms."""

    def async_check_significant_change(
        self,
        hass: HomeAssistant,
        old_state: str,
        old_attrs: Mapping[str, Any],
        new_state: str,
        new_attrs: Mapping[str, Any],
    ) -> bool | None:
        """Test if state significantly changed."""


async def create_checker(
    hass: HomeAssistant,
    _domain: str,
    extra_significant_check: ExtraCheckTypeFunc | None = None,
) -> SignificantlyChangedChecker:
    """Create a significantly changed checker for a domain."""
    await _initialize(hass)
    return SignificantlyChangedChecker(hass, extra_significant_check)


# Marked as singleton so multiple calls all wait for same output.
async def _initialize(hass: HomeAssistant) -> None:
    """Initialize the functions."""
    if DATA_FUNCTIONS in hass.data:
        return

    functions = hass.data[DATA_FUNCTIONS] = {}

    @callback
    def process_platform(
        hass: HomeAssistant,
        component_name: str,
        platform: SignificantChangeProtocol,
    ) -> None:
        """Process a significant change platform."""
        functions[component_name] = platform.async_check_significant_change

    await async_process_integration_platforms(hass, PLATFORM, process_platform)


def either_one_none(val1: Any | None, val2: Any | None) -> bool:
    """Test if exactly one value is None."""
    return (val1 is None and val2 is not None) or (val1 is not None and val2 is None)


def _check_numeric_change(
    old_state: float | None,
    new_state: float | None,
    change: float,
    metric: Callable[[int | float, int | float], int | float],
) -> bool:
    """Check if two numeric values have changed."""
    if old_state is None and new_state is None:
        return False

    if either_one_none(old_state, new_state):
        return True

    assert old_state is not None
    assert new_state is not None

    if metric(old_state, new_state) >= change:
        return True

    return False


def check_absolute_change(
    val1: float | None,
    val2: float | None,
    change: float,
) -> bool:
    """Check if two numeric values have changed."""
    return _check_numeric_change(
        val1, val2, change, lambda val1, val2: abs(val1 - val2)
    )


def check_percentage_change(
    old_state: float | None,
    new_state: float | None,
    change: float,
) -> bool:
    """Check if two numeric values have changed."""

    def percentage_change(old_state: float, new_state: float) -> float:
        if old_state == new_state:
            return 0
        try:
            return (abs(new_state - old_state) / old_state) * 100.0
        except ZeroDivisionError:
            return math.inf

    return _check_numeric_change(old_state, new_state, change, percentage_change)


def check_valid_float(value: str | float) -> bool:
    """Check if given value is a valid float."""
    try:
        float(value)
    except ValueError:
        return False
    return True


class SignificantlyChangedChecker:
    """Class to keep track of entities to see if they have significantly changed.

    Will always compare the entity to the last entity that was considered significant.
    """

    def __init__(
        self,
        hass: HomeAssistant,
        extra_significant_check: ExtraCheckTypeFunc | None = None,
    ) -> None:
        """Test if an entity has significantly changed."""
        self.hass = hass
        self.last_approved_entities: dict[str, tuple[State, Any]] = {}
        self.extra_significant_check = extra_significant_check

    @callback
    def async_is_significant_change(
        self, new_state: State, *, extra_arg: Any | None = None
    ) -> bool:
        """Return if this was a significant change.

        Extra kwargs are passed to the extra significant checker.
        """
        old_data: tuple[State, Any] | None = self.last_approved_entities.get(
            new_state.entity_id
        )

        # First state change is always ok to report
        if old_data is None:
            self.last_approved_entities[new_state.entity_id] = (new_state, extra_arg)
            return True

        old_state, old_extra_arg = old_data

        # Handle state unknown or unavailable
        if new_state.state in (STATE_UNKNOWN, STATE_UNAVAILABLE):
            if new_state.state == old_state.state:
                return False

            self.last_approved_entities[new_state.entity_id] = (new_state, extra_arg)
            return True

        # If last state was unknown/unavailable, also significant.
        if old_state.state in (STATE_UNKNOWN, STATE_UNAVAILABLE):
            self.last_approved_entities[new_state.entity_id] = (new_state, extra_arg)
            return True

        functions = self.hass.data.get(DATA_FUNCTIONS)

        if functions is None:
            raise RuntimeError("Significant Change not initialized")

        check_significantly_changed = functions.get(new_state.domain)

        if check_significantly_changed is not None:
            result = check_significantly_changed(
                self.hass,
                old_state.state,
                old_state.attributes,
                new_state.state,
                new_state.attributes,
            )

            if result is False:
                return False

        if self.extra_significant_check is not None:
            result = self.extra_significant_check(
                self.hass,
                old_state.state,
                old_state.attributes,
                old_extra_arg,
                new_state.state,
                new_state.attributes,
                extra_arg,
            )

            if result is False:
                return False

        # Result is either True or None.
        # None means the function doesn't know. For now assume it's True
        self.last_approved_entities[new_state.entity_id] = (
            new_state,
            extra_arg,
        )
        return True
</file>

<file path="singleton.py">
"""Helper to help coordinating calls."""

from __future__ import annotations

import asyncio
from collections.abc import Callable, Coroutine
import functools
import inspect
from typing import Any, Literal, assert_type, cast, overload

from homeassistant.core import HomeAssistant
from homeassistant.loader import bind_hass
from homeassistant.util.hass_dict import HassKey

type _FuncType[_T] = Callable[[HomeAssistant], _T]
type _Coro[_T] = Coroutine[Any, Any, _T]


@overload
def singleton[_T](
    data_key: HassKey[_T], *, async_: Literal[True]
) -> Callable[[_FuncType[_Coro[_T]]], _FuncType[_Coro[_T]]]: ...


@overload
def singleton[_T](
    data_key: HassKey[_T],
) -> Callable[[_FuncType[_T]], _FuncType[_T]]: ...


@overload
def singleton[_T](data_key: str) -> Callable[[_FuncType[_T]], _FuncType[_T]]: ...


def singleton[_S, _T, _U](
    data_key: Any, *, async_: bool = False
) -> Callable[[_FuncType[_S]], _FuncType[_S]]:
    """Decorate a function that should be called once per instance.

    Result will be cached and simultaneous calls will be handled.
    """

    @overload
    def wrapper(func: _FuncType[_Coro[_T]]) -> _FuncType[_Coro[_T]]: ...

    @overload
    def wrapper(func: _FuncType[_U]) -> _FuncType[_U]: ...

    def wrapper(func: _FuncType[_Coro[_T] | _U]) -> _FuncType[_Coro[_T] | _U]:
        """Wrap a function with caching logic."""
        if not inspect.iscoroutinefunction(func):

            @functools.lru_cache(maxsize=1)
            @bind_hass
            @functools.wraps(func)
            def wrapped(hass: HomeAssistant) -> _U:
                if data_key not in hass.data:
                    hass.data[data_key] = func(hass)
                return cast(_U, hass.data[data_key])

            return wrapped

        @bind_hass
        @functools.wraps(func)
        async def async_wrapped(hass: HomeAssistant) -> _T:
            if data_key not in hass.data:
                evt = hass.data[data_key] = asyncio.Event()
                result = await func(hass)
                hass.data[data_key] = result
                evt.set()
                return cast(_T, result)

            obj_or_evt = hass.data[data_key]

            if isinstance(obj_or_evt, asyncio.Event):
                await obj_or_evt.wait()
                return cast(_T, hass.data[data_key])

            return cast(_T, obj_or_evt)

        return async_wrapped

    return wrapper


async def _test_singleton_typing(hass: HomeAssistant) -> None:
    """Test singleton overloads work as intended.

    This is tested during the mypy run. Do not move it to 'tests'!
    """
    # Test HassKey
    key = HassKey[int]("key")

    @singleton(key)
    def func(hass: HomeAssistant) -> int:
        return 2

    @singleton(key, async_=True)
    async def async_func(hass: HomeAssistant) -> int:
        return 2

    assert_type(func(hass), int)
    assert_type(await async_func(hass), int)

    # Test invalid use of 'async_' with sync function
    @singleton(key, async_=True)  # type: ignore[arg-type]
    def func_error(hass: HomeAssistant) -> int:
        return 2

    # Test string key
    other_key = "key"

    @singleton(other_key)
    def func2(hass: HomeAssistant) -> str:
        return ""

    @singleton(other_key)
    async def async_func2(hass: HomeAssistant) -> str:
        return ""

    assert_type(func2(hass), str)
    assert_type(await async_func2(hass), str)
</file>

<file path="start.py">
"""Helpers to help during startup."""

from __future__ import annotations

from collections.abc import Callable, Coroutine
from typing import Any

from homeassistant.const import EVENT_HOMEASSISTANT_START, EVENT_HOMEASSISTANT_STARTED
from homeassistant.core import (
    CALLBACK_TYPE,
    CoreState,
    Event,
    HassJob,
    HomeAssistant,
    callback,
)
from homeassistant.util.event_type import EventType

from .typing import NoEventData


@callback
def _async_at_core_state(
    hass: HomeAssistant,
    at_start_cb: Callable[[HomeAssistant], Coroutine[Any, Any, None] | None],
    event_type: EventType[NoEventData],
    check_state: Callable[[HomeAssistant], bool],
) -> CALLBACK_TYPE:
    """Execute a job at_start_cb when Home Assistant has the wanted state.

    The job is executed immediately if Home Assistant is in the wanted state.
    Will wait for event specified by event_type if it isn't.
    """
    at_start_job = HassJob(at_start_cb)
    if check_state(hass):
        hass.async_run_hass_job(at_start_job, hass)
        return lambda: None

    unsub: CALLBACK_TYPE | None = None

    @callback
    def _matched_event(event: Event) -> None:
        """Call the callback when Home Assistant started."""
        hass.async_run_hass_job(at_start_job, hass)
        nonlocal unsub
        unsub = None

    @callback
    def cancel() -> None:
        if unsub:
            unsub()

    unsub = hass.bus.async_listen_once(event_type, _matched_event)
    return cancel


@callback
def async_at_start(
    hass: HomeAssistant,
    at_start_cb: Callable[[HomeAssistant], Coroutine[Any, Any, None] | None],
) -> CALLBACK_TYPE:
    """Execute a job at_start_cb when Home Assistant is starting.

    The job is executed immediately if Home Assistant is already starting or started.
    Will wait for EVENT_HOMEASSISTANT_START if it isn't.
    """

    def _is_running(hass: HomeAssistant) -> bool:
        return hass.is_running

    return _async_at_core_state(
        hass, at_start_cb, EVENT_HOMEASSISTANT_START, _is_running
    )


@callback
def async_at_started(
    hass: HomeAssistant,
    at_start_cb: Callable[[HomeAssistant], Coroutine[Any, Any, None] | None],
) -> CALLBACK_TYPE:
    """Execute a job at_start_cb when Home Assistant has started.

    The job is executed immediately if Home Assistant is already started.
    Will wait for EVENT_HOMEASSISTANT_STARTED if it isn't.
    """

    def _is_started(hass: HomeAssistant) -> bool:
        return hass.state is CoreState.running

    return _async_at_core_state(
        hass, at_start_cb, EVENT_HOMEASSISTANT_STARTED, _is_started
    )
</file>

<file path="state.py">
"""Helpers that help with state related things."""

from __future__ import annotations

import asyncio
from collections import defaultdict
from collections.abc import Iterable
import logging
from types import ModuleType
from typing import Any

from homeassistant.components.lock import LockState
from homeassistant.components.sun import STATE_ABOVE_HORIZON, STATE_BELOW_HORIZON
from homeassistant.const import (
    STATE_CLOSED,
    STATE_HOME,
    STATE_NOT_HOME,
    STATE_OFF,
    STATE_ON,
    STATE_OPEN,
    STATE_UNKNOWN,
)
from homeassistant.core import Context, HomeAssistant, State
from homeassistant.loader import IntegrationNotFound, async_get_integration, bind_hass

_LOGGER = logging.getLogger(__name__)


@bind_hass
async def async_reproduce_state(
    hass: HomeAssistant,
    states: State | Iterable[State],
    *,
    context: Context | None = None,
    reproduce_options: dict[str, Any] | None = None,
) -> None:
    """Reproduce a list of states on multiple domains."""
    if isinstance(states, State):
        states = [states]

    to_call: dict[str, list[State]] = defaultdict(list)

    for state in states:
        to_call[state.domain].append(state)

    async def worker(domain: str, states_by_domain: list[State]) -> None:
        try:
            integration = await async_get_integration(hass, domain)
        except IntegrationNotFound:
            _LOGGER.warning(
                "Trying to reproduce state for unknown integration: %s", domain
            )
            return

        try:
            platform: ModuleType = await integration.async_get_platform(
                "reproduce_state"
            )
        except ImportError:
            _LOGGER.warning("Integration %s does not support reproduce state", domain)
            return

        await platform.async_reproduce_states(
            hass, states_by_domain, context=context, reproduce_options=reproduce_options
        )

    if to_call:
        # run all domains in parallel
        await asyncio.gather(
            *(worker(domain, data) for domain, data in to_call.items())
        )


def state_as_number(state: State) -> float:
    """Try to coerce our state to a number.

    Raises ValueError if this is not possible.
    """
    if state.state in (
        STATE_ON,
        LockState.LOCKED,
        STATE_ABOVE_HORIZON,
        STATE_OPEN,
        STATE_HOME,
    ):
        return 1
    if state.state in (
        STATE_OFF,
        LockState.UNLOCKED,
        STATE_UNKNOWN,
        STATE_BELOW_HORIZON,
        STATE_CLOSED,
        STATE_NOT_HOME,
    ):
        return 0

    return float(state.state)
</file>

<file path="storage.py">
"""Helper to help store data."""

from __future__ import annotations

import asyncio
from collections.abc import Callable, Iterable, Mapping, Sequence
from contextlib import suppress
from copy import deepcopy
import inspect
from json import JSONDecodeError, JSONEncoder
import logging
import os
from pathlib import Path
from typing import Any

from propcache.api import cached_property

from homeassistant.const import (
    EVENT_HOMEASSISTANT_FINAL_WRITE,
    EVENT_HOMEASSISTANT_STARTED,
    EVENT_HOMEASSISTANT_STOP,
)
from homeassistant.core import (
    CALLBACK_TYPE,
    DOMAIN as HOMEASSISTANT_DOMAIN,
    CoreState,
    Event,
    HomeAssistant,
    callback,
)
from homeassistant.exceptions import HomeAssistantError
from homeassistant.loader import bind_hass
from homeassistant.util import dt as dt_util, json as json_util
from homeassistant.util.file import WriteError, write_utf8_file, write_utf8_file_atomic
from homeassistant.util.hass_dict import HassKey

from . import json as json_helper

# mypy: allow-untyped-calls, allow-untyped-defs, no-warn-return-any
# mypy: no-check-untyped-defs
MAX_LOAD_CONCURRENTLY = 6

STORAGE_DIR = ".storage"
_LOGGER = logging.getLogger(__name__)

STORAGE_SEMAPHORE: HassKey[asyncio.Semaphore] = HassKey("storage_semaphore")
STORAGE_MANAGER: HassKey[_StoreManager] = HassKey("storage_manager")

MANAGER_CLEANUP_DELAY = 60


@bind_hass
async def async_migrator[_T: Mapping[str, Any] | Sequence[Any]](
    hass: HomeAssistant,
    old_path: str,
    store: Store[_T],
    *,
    old_conf_load_func: Callable | None = None,
    old_conf_migrate_func: Callable | None = None,
) -> _T | None:
    """Migrate old data to a store and then load data.

    async def old_conf_migrate_func(old_data)
    """
    # If we already have store data we have already migrated in the past.
    if (store_data := await store.async_load()) is not None:
        return store_data

    def load_old_config():
        """Load old config."""
        if not os.path.isfile(old_path):
            return None

        if old_conf_load_func is not None:
            return old_conf_load_func(old_path)

        return json_util.load_json(old_path)

    config = await hass.async_add_executor_job(load_old_config)

    if config is None:
        return None

    if old_conf_migrate_func is not None:
        config = await old_conf_migrate_func(config)

    await store.async_save(config)
    await hass.async_add_executor_job(os.remove, old_path)
    return config


def get_internal_store_manager(hass: HomeAssistant) -> _StoreManager:
    """Get the store manager.

    This function is not part of the API and should only be
    used in the Home Assistant core internals. It is not
    guaranteed to be stable.
    """
    if STORAGE_MANAGER not in hass.data:
        manager = _StoreManager(hass)
        hass.data[STORAGE_MANAGER] = manager
    return hass.data[STORAGE_MANAGER]


class _StoreManager:
    """Class to help storing data.

    The store manager is used to cache and manage storage files.
    """

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize storage manager class."""
        self._hass = hass
        self._invalidated: set[str] = set()
        self._files: set[str] | None = None
        self._data_preload: dict[str, json_util.JsonValueType] = {}
        self._storage_path: Path = Path(hass.config.config_dir).joinpath(STORAGE_DIR)
        self._cancel_cleanup: asyncio.TimerHandle | None = None

    async def async_initialize(self) -> None:
        """Initialize the storage manager."""
        hass = self._hass
        await hass.async_add_executor_job(self._initialize_files)
        hass.bus.async_listen_once(
            EVENT_HOMEASSISTANT_STARTED,
            self._async_schedule_cleanup,
        )

    @callback
    def async_invalidate(self, key: str) -> None:
        """Invalidate cache.

        Store calls this when its going to save data
        to ensure that the cache is not used after that.
        """
        if "/" not in key:
            self._invalidated.add(key)
            self._data_preload.pop(key, None)

    @callback
    def async_fetch(
        self, key: str
    ) -> tuple[bool, json_util.JsonValueType | None] | None:
        """Fetch data from cache."""
        #
        # If the key is invalidated, we don't need to check the cache
        # If async_initialize has not been called yet, we don't know
        # if the file exists or not so its a cache miss
        #
        # It is very important that we check if self._files is None
        # because we do not want to incorrectly return a cache miss
        # because async_initialize has not been called yet as it would
        # cause the Store to return None when it should not.
        #
        # The "/" in key check is to prevent the cache from being used
        # for subdirs in case we have a key like "hacs/XXX"
        #
        if "/" in key or key in self._invalidated or self._files is None:
            _LOGGER.debug("%s: Cache miss", key)
            return None

        # If async_initialize has been called and the key is not in self._files
        # then the file does not exist
        if key not in self._files:
            _LOGGER.debug("%s: Cache hit, does not exist", key)
            return (False, None)

        # If the key is in the preload cache, return it
        if data := self._data_preload.pop(key, None):
            _LOGGER.debug("%s: Cache hit data", key)
            return (True, data)

        _LOGGER.debug("%s: Cache miss, not preloaded", key)
        return None

    @callback
    def _async_schedule_cleanup(self, _event: Event) -> None:
        """Schedule the cleanup of old files."""
        self._cancel_cleanup = self._hass.loop.call_later(
            MANAGER_CLEANUP_DELAY, self._async_cleanup
        )
        # Handle the case where we stop in the first 60s
        self._hass.bus.async_listen_once(
            EVENT_HOMEASSISTANT_STOP,
            self._async_cancel_and_cleanup,
        )

    @callback
    def _async_cancel_and_cleanup(self, _event: Event) -> None:
        """Cancel the cleanup of old files."""
        self._async_cleanup()
        if self._cancel_cleanup:
            self._cancel_cleanup.cancel()
            self._cancel_cleanup = None

    @callback
    def _async_cleanup(self) -> None:
        """Cleanup unused cache.

        If nothing consumes the cache 60s after startup or when we
        stop Home Assistant, we'll clear the cache.
        """
        self._data_preload.clear()

    async def async_preload(self, keys: Iterable[str]) -> None:
        """Cache the keys."""
        # If async_initialize has not been called yet, we can't preload
        if self._files is not None and (existing := self._files.intersection(keys)):
            await self._hass.async_add_executor_job(self._preload, existing)

    def _preload(self, keys: Iterable[str]) -> None:
        """Cache the keys."""
        storage_path = self._storage_path
        data_preload = self._data_preload
        for key in keys:
            storage_file: Path = storage_path.joinpath(key)
            try:
                if storage_file.is_file():
                    data_preload[key] = json_util.load_json(storage_file)
            except Exception as ex:  # noqa: BLE001
                _LOGGER.debug("Error loading %s: %s", key, ex)

    def _initialize_files(self) -> None:
        """Initialize the cache."""
        if self._storage_path.exists():
            self._files = set(os.listdir(self._storage_path))


@bind_hass
class Store[_T: Mapping[str, Any] | Sequence[Any]]:
    """Class to help storing data."""

    def __init__(
        self,
        hass: HomeAssistant,
        version: int,
        key: str,
        private: bool = False,
        *,
        atomic_writes: bool = False,
        encoder: type[JSONEncoder] | None = None,
        minor_version: int = 1,
        read_only: bool = False,
        serialize_in_event_loop: bool = True,
    ) -> None:
        """Initialize storage class.

        Args:
            serialize_in_event_loop: Whether to serialize data in the event loop.
            Set to True (default) if data passed to async_save and data produced by
            data_func passed to async_delay_save needs to be serialized in the event
            loop because it is not thread safe.

            Set to False if the data passed to async_save and data produced by
            data_func passed to async_delay_save can safely be accessed from a
            separate thread, i.e. the data is thread safe and not mutated by other
            code while serialization is in progress.

            Users should support serializing in a separate thread for stores which
            are expected to store large amounts of data to avoid blocking the event
            loop during serialization.
        """
        self.version = version
        self.minor_version = minor_version
        self.key = key
        self.hass = hass
        self._private = private
        self._data: dict[str, Any] | None = None
        self._delay_handle: asyncio.TimerHandle | None = None
        self._unsub_final_write_listener: CALLBACK_TYPE | None = None
        self._write_lock = asyncio.Lock()
        self._load_future: asyncio.Future[_T | None] | None = None
        self._encoder = encoder
        self._atomic_writes = atomic_writes
        self._read_only = read_only
        self._next_write_time = 0.0
        self._manager = get_internal_store_manager(hass)
        self._serialize_in_event_loop = serialize_in_event_loop

    @cached_property
    def path(self):
        """Return the config path."""
        return self.hass.config.path(STORAGE_DIR, self.key)

    def make_read_only(self) -> None:
        """Make the store read-only.

        This method is irreversible.
        """
        self._read_only = True

    async def async_load(self) -> _T | None:
        """Load data.

        If the expected version and minor version do not match the given
        versions, the migrate function will be invoked with
        migrate_func(version, minor_version, config).

        Will ensure that when a call comes in while another one is in progress,
        the second call will wait and return the result of the first call.
        """
        if self._load_future:
            return await self._load_future

        self._load_future = self.hass.loop.create_future()
        try:
            result = await self._async_load()
        except BaseException as ex:
            self._load_future.set_exception(ex)
            # Ensure the future is marked as retrieved
            # since if there is no concurrent call it
            # will otherwise never be retrieved.
            self._load_future.exception()
            raise
        else:
            self._load_future.set_result(result)
        finally:
            self._load_future = None

        return result

    async def _async_load(self) -> _T | None:
        """Load the data and ensure the task is removed."""
        if STORAGE_SEMAPHORE not in self.hass.data:
            self.hass.data[STORAGE_SEMAPHORE] = asyncio.Semaphore(MAX_LOAD_CONCURRENTLY)
        async with self.hass.data[STORAGE_SEMAPHORE]:
            return await self._async_load_data()

    async def _async_load_data(self):
        """Load the data."""
        # Check if we have a pending write
        if self._data is not None:
            data = self._data

            # If we didn't generate data yet, do it now.
            if "data_func" in data:
                data["data"] = data.pop("data_func")()

            # We make a copy because code might assume it's safe to mutate loaded data
            # and we don't want that to mess with what we're trying to store.
            data = deepcopy(data)
        elif cache := self._manager.async_fetch(self.key):
            exists, data = cache
            if not exists:
                return None
        else:
            try:
                data = await self.hass.async_add_executor_job(
                    json_util.load_json, self.path
                )
            except HomeAssistantError as err:
                if isinstance(err.__cause__, JSONDecodeError):
                    # If we have a JSONDecodeError, it means the file is corrupt.
                    # We can't recover from this, so we'll log an error, rename the file and
                    # return None so that we can start with a clean slate which will
                    # allow startup to continue so they can restore from a backup.
                    isotime = dt_util.utcnow().isoformat()
                    corrupt_postfix = f".corrupt.{isotime}"
                    corrupt_path = f"{self.path}{corrupt_postfix}"
                    await self.hass.async_add_executor_job(
                        os.rename, self.path, corrupt_path
                    )
                    storage_key = self.key
                    _LOGGER.error(
                        "Unrecoverable error decoding storage %s at %s; "
                        "This may indicate an unclean shutdown, invalid syntax "
                        "from manual edits, or disk corruption; "
                        "The corrupt file has been saved as %s; "
                        "It is recommended to restore from backup: %s",
                        storage_key,
                        self.path,
                        corrupt_path,
                        err,
                    )
                    from .issue_registry import (  # noqa: PLC0415
                        IssueSeverity,
                        async_create_issue,
                    )

                    issue_domain = HOMEASSISTANT_DOMAIN
                    if (
                        domain := (storage_key.partition(".")[0])
                    ) and domain in self.hass.config.components:
                        issue_domain = domain

                    async_create_issue(
                        self.hass,
                        HOMEASSISTANT_DOMAIN,
                        f"storage_corruption_{storage_key}_{isotime}",
                        is_fixable=True,
                        issue_domain=issue_domain,
                        translation_key="storage_corruption",
                        is_persistent=True,
                        severity=IssueSeverity.CRITICAL,
                        translation_placeholders={
                            "storage_key": storage_key,
                            "original_path": self.path,
                            "corrupt_path": corrupt_path,
                            "error": str(err),
                        },
                    )
                    return None
                raise

            if data == {}:
                return None

        # Add minor_version if not set
        if "minor_version" not in data:
            data["minor_version"] = 1

        if (
            data["version"] == self.version
            and data["minor_version"] == self.minor_version
        ):
            stored = data["data"]
        else:
            _LOGGER.info(
                "Migrating %s storage from %s.%s to %s.%s",
                self.key,
                data["version"],
                data["minor_version"],
                self.version,
                self.minor_version,
            )
            if len(inspect.signature(self._async_migrate_func).parameters) == 2:
                stored = await self._async_migrate_func(data["version"], data["data"])
            else:
                try:
                    stored = await self._async_migrate_func(
                        data["version"], data["minor_version"], data["data"]
                    )
                except NotImplementedError:
                    if data["version"] != self.version:
                        raise
                    stored = data["data"]
            await self.async_save(stored)

        return stored

    async def async_save(self, data: _T) -> None:
        """Save data."""
        self._data = {
            "version": self.version,
            "minor_version": self.minor_version,
            "key": self.key,
            "data": data,
        }

        if self.hass.state is CoreState.stopping:
            self._async_ensure_final_write_listener()
            return

        await self._async_handle_write_data()

    @callback
    def async_delay_save(
        self,
        data_func: Callable[[], _T],
        delay: float = 0,
    ) -> None:
        """Save data with an optional delay.

        data_func: A function that returns the data to save. If serialize_in_event_loop
        is True, it will be called from and the returned data will be serialized in the
        in the event loop. If serialize_in_event_loop is False, it will be called from
        and the returned data will be serialized by a separate thread.
        """
        self._data = {
            "version": self.version,
            "minor_version": self.minor_version,
            "key": self.key,
            "data_func": data_func,
        }

        next_when = self.hass.loop.time() + delay
        if self._delay_handle and self._delay_handle.when() < next_when:
            self._next_write_time = next_when
            return

        self._async_cleanup_delay_listener()
        self._async_ensure_final_write_listener()

        if self.hass.state is CoreState.stopping:
            return

        # We use call_later directly here to avoid a circular import
        self._async_reschedule_delayed_write(next_when)

    @callback
    def _async_reschedule_delayed_write(self, when: float) -> None:
        """Reschedule a delayed write."""
        self._delay_handle = self.hass.loop.call_at(
            when, self._async_schedule_callback_delayed_write
        )

    @callback
    def _async_schedule_callback_delayed_write(self) -> None:
        """Schedule the delayed write in a task."""
        if self.hass.loop.time() < self._next_write_time:
            # Timer fired too early because there were multiple
            # calls to async_delay_save before the first one
            # wrote. Reschedule the timer to the next write time.
            self._async_reschedule_delayed_write(self._next_write_time)
            return
        self.hass.async_create_task_internal(
            self._async_callback_delayed_write(), eager_start=True
        )

    @callback
    def _async_ensure_final_write_listener(self) -> None:
        """Ensure that we write if we quit before delay has passed."""
        if self._unsub_final_write_listener is None:
            self._unsub_final_write_listener = self.hass.bus.async_listen_once(
                EVENT_HOMEASSISTANT_FINAL_WRITE,
                self._async_callback_final_write,
            )

    @callback
    def _async_cleanup_final_write_listener(self) -> None:
        """Clean up a stop listener."""
        if self._unsub_final_write_listener is not None:
            self._unsub_final_write_listener()
            self._unsub_final_write_listener = None

    @callback
    def _async_cleanup_delay_listener(self) -> None:
        """Clean up a delay listener."""
        if self._delay_handle is not None:
            self._delay_handle.cancel()
            self._delay_handle = None

    async def _async_callback_delayed_write(self) -> None:
        """Handle a delayed write callback."""
        # catch the case where a call is scheduled and then we stop Home Assistant
        if self.hass.state is CoreState.stopping:
            self._async_ensure_final_write_listener()
            return
        await self._async_handle_write_data()

    async def _async_callback_final_write(self, _event: Event) -> None:
        """Handle a write because Home Assistant is in final write state."""
        self._unsub_final_write_listener = None
        await self._async_handle_write_data()

    async def _async_handle_write_data(self, *_args):
        """Handle writing the config."""
        async with self._write_lock:
            self._manager.async_invalidate(self.key)
            self._async_cleanup_delay_listener()
            self._async_cleanup_final_write_listener()

            if self._data is None:
                # Another write already consumed the data
                return

            data = self._data
            self._data = None

            if self._read_only:
                return

            try:
                await self._async_write_data(data)
            except (json_util.SerializationError, WriteError) as err:
                _LOGGER.error("Error writing config for %s: %s", self.key, err)

    async def _async_write_data(self, data: dict) -> None:
        if self._serialize_in_event_loop:
            if "data_func" in data:
                data["data"] = data.pop("data_func")()
            mode, json_data = json_helper.prepare_save_json(data, encoder=self._encoder)
            await self.hass.async_add_executor_job(
                self._write_prepared_data, mode, json_data
            )
            return
        await self.hass.async_add_executor_job(self._write_data, data)

    def _write_data(self, data: dict) -> None:
        """Write the data."""
        if "data_func" in data:
            data["data"] = data.pop("data_func")()
        mode, json_data = json_helper.prepare_save_json(data, encoder=self._encoder)
        self._write_prepared_data(mode, json_data)

    def _write_prepared_data(self, mode: str, json_data: str | bytes) -> None:
        """Write the data."""
        path = self.path
        os.makedirs(os.path.dirname(path), exist_ok=True)

        _LOGGER.debug("Writing data for %s to %s", self.key, path)
        write_method = (
            write_utf8_file_atomic if self._atomic_writes else write_utf8_file
        )
        write_method(path, json_data, self._private, mode=mode)

    async def _async_migrate_func(self, old_major_version, old_minor_version, old_data):
        """Migrate to the new version."""
        raise NotImplementedError

    async def async_remove(self) -> None:
        """Remove all data."""
        self._manager.async_invalidate(self.key)
        self._async_cleanup_delay_listener()
        self._async_cleanup_final_write_listener()

        with suppress(FileNotFoundError):
            await self.hass.async_add_executor_job(os.unlink, self.path)
</file>

<file path="sun.py">
"""Helpers for sun events."""

from __future__ import annotations

from collections.abc import Callable
import datetime
from typing import TYPE_CHECKING, Any, cast

from homeassistant.const import SUN_EVENT_SUNRISE, SUN_EVENT_SUNSET
from homeassistant.core import HomeAssistant, callback
from homeassistant.loader import bind_hass
from homeassistant.util import dt as dt_util
from homeassistant.util.hass_dict import HassKey

if TYPE_CHECKING:
    import astral
    import astral.location

DATA_LOCATION_CACHE: HassKey[
    dict[tuple[str, str, str, float, float], astral.location.Location]
] = HassKey("astral_location_cache")

ELEVATION_AGNOSTIC_EVENTS = ("noon", "midnight")

type _AstralSunEventCallable = Callable[..., datetime.datetime]


@callback
@bind_hass
def get_astral_location(
    hass: HomeAssistant,
) -> tuple[astral.location.Location, astral.Elevation]:
    """Get an astral location for the current Home Assistant configuration."""
    from astral import LocationInfo  # noqa: PLC0415
    from astral.location import Location  # noqa: PLC0415

    latitude = hass.config.latitude
    longitude = hass.config.longitude
    timezone = str(hass.config.time_zone)
    elevation = hass.config.elevation
    info = ("", "", timezone, latitude, longitude)

    # Cache astral locations so they aren't recreated with the same args
    if DATA_LOCATION_CACHE not in hass.data:
        hass.data[DATA_LOCATION_CACHE] = {}

    if info not in hass.data[DATA_LOCATION_CACHE]:
        hass.data[DATA_LOCATION_CACHE][info] = Location(LocationInfo(*info))

    return hass.data[DATA_LOCATION_CACHE][info], elevation


@callback
@bind_hass
def get_astral_event_next(
    hass: HomeAssistant,
    event: str,
    utc_point_in_time: datetime.datetime | None = None,
    offset: datetime.timedelta | None = None,
) -> datetime.datetime:
    """Calculate the next specified solar event."""
    location, elevation = get_astral_location(hass)
    return get_location_astral_event_next(
        location, elevation, event, utc_point_in_time, offset
    )


@callback
def get_location_astral_event_next(
    location: astral.location.Location,
    elevation: astral.Elevation,
    event: str,
    utc_point_in_time: datetime.datetime | None = None,
    offset: datetime.timedelta | None = None,
) -> datetime.datetime:
    """Calculate the next specified solar event."""

    if offset is None:
        offset = datetime.timedelta()

    if utc_point_in_time is None:
        utc_point_in_time = dt_util.utcnow()

    kwargs: dict[str, Any] = {"local": False}
    if event not in ELEVATION_AGNOSTIC_EVENTS:
        kwargs["observer_elevation"] = elevation

    mod = -1
    first_err = None
    while mod < 367:
        try:
            next_dt = (
                cast(_AstralSunEventCallable, getattr(location, event))(
                    dt_util.as_local(utc_point_in_time).date()
                    + datetime.timedelta(days=mod),
                    **kwargs,
                )
                + offset
            )
            if next_dt > utc_point_in_time:
                return next_dt
        except ValueError as err:
            if not first_err:
                first_err = err
        mod += 1
    raise ValueError(
        f"Unable to find event after one year, initial ValueError: {first_err}"
    ) from first_err


@callback
@bind_hass
def get_astral_event_date(
    hass: HomeAssistant,
    event: str,
    date: datetime.date | datetime.datetime | None = None,
) -> datetime.datetime | None:
    """Calculate the astral event time for the specified date."""
    location, elevation = get_astral_location(hass)

    if date is None:
        date = dt_util.now().date()

    if isinstance(date, datetime.datetime):
        date = dt_util.as_local(date).date()

    kwargs: dict[str, Any] = {"local": False}
    if event not in ELEVATION_AGNOSTIC_EVENTS:
        kwargs["observer_elevation"] = elevation

    try:
        return cast(_AstralSunEventCallable, getattr(location, event))(date, **kwargs)
    except ValueError:
        # Event never occurs for specified date.
        return None


@callback
@bind_hass
def is_up(
    hass: HomeAssistant, utc_point_in_time: datetime.datetime | None = None
) -> bool:
    """Calculate if the sun is currently up."""
    if utc_point_in_time is None:
        utc_point_in_time = dt_util.utcnow()

    next_sunrise = get_astral_event_next(hass, SUN_EVENT_SUNRISE, utc_point_in_time)
    next_sunset = get_astral_event_next(hass, SUN_EVENT_SUNSET, utc_point_in_time)

    return next_sunrise > next_sunset
</file>

<file path="system_info.py">
"""Helper to gather system info."""

from __future__ import annotations

from functools import cache
from getpass import getuser
import logging
import platform
from typing import TYPE_CHECKING, Any

from homeassistant.const import __version__ as current_version
from homeassistant.core import HomeAssistant
from homeassistant.loader import bind_hass
from homeassistant.util.package import is_docker_env, is_virtual_env
from homeassistant.util.system_info import is_official_image

from .hassio import is_hassio
from .importlib import async_import_module
from .singleton import singleton

_LOGGER = logging.getLogger(__name__)

_DATA_MAC_VER = "system_info_mac_ver"
_DATA_CONTAINER_ARCH = "system_info_container_arch"


@singleton(_DATA_MAC_VER)
async def async_get_mac_ver(hass: HomeAssistant) -> str:
    """Return the macOS version."""
    return (await hass.async_add_executor_job(platform.mac_ver))[0]


@singleton(_DATA_CONTAINER_ARCH)
async def async_get_container_arch(hass: HomeAssistant) -> str:
    """Return the container architecture."""

    def _read_arch_file() -> str:
        """Read the architecture from /etc/apk/arch."""
        with open("/etc/apk/arch", encoding="utf-8") as arch_file:
            return arch_file.read().strip()

    try:
        raw_arch = await hass.async_add_executor_job(_read_arch_file)
    except FileNotFoundError:
        return "unknown"
    return {"x86": "i386", "x86_64": "amd64"}.get(raw_arch, raw_arch)


# Cache the result of getuser() because it can call getpwuid() which
# can do blocking I/O to look up the username in /etc/passwd.
cached_get_user = cache(getuser)


@bind_hass
async def async_get_system_info(hass: HomeAssistant) -> dict[str, Any]:
    """Return info about the system."""
    # Local import to avoid circular dependencies
    # We use the import helper because hassio
    # may not be loaded yet and we don't want to
    # do blocking I/O in the event loop to import it.
    if TYPE_CHECKING:
        from homeassistant.components import hassio  # noqa: PLC0415
    else:
        hassio = await async_import_module(hass, "homeassistant.components.hassio")

    is_hassio_ = is_hassio(hass)

    info_object = {
        "installation_type": "Unknown",
        "version": current_version,
        "dev": "dev" in current_version,
        "hassio": is_hassio_,
        "virtualenv": is_virtual_env(),
        "python_version": platform.python_version(),
        "docker": False,
        "arch": platform.machine(),
        "timezone": str(hass.config.time_zone),
        "os_name": platform.system(),
        "os_version": platform.release(),
    }

    try:
        info_object["user"] = cached_get_user()
    except (KeyError, OSError):
        # OSError on python >= 3.13, KeyError on python < 3.13
        # KeyError can be removed when 3.12 support is dropped
        # see https://docs.python.org/3/whatsnew/3.13.html
        info_object["user"] = None

    if platform.system() == "Darwin":
        info_object["os_version"] = await async_get_mac_ver(hass)
    elif platform.system() == "Linux":
        info_object["docker"] = is_docker_env()

    # Determine installation type on current data
    if info_object["docker"]:
        if info_object["user"] == "root" and is_official_image():
            info_object["installation_type"] = "Home Assistant Container"
            info_object["container_arch"] = await async_get_container_arch(hass)
        else:
            info_object["installation_type"] = "Unsupported Third Party Container"

    elif is_virtual_env():
        info_object["installation_type"] = "Home Assistant Core"

    # Enrich with Supervisor information
    if is_hassio_:
        if not (info := hassio.get_info(hass)):
            _LOGGER.warning("No Home Assistant Supervisor info available")
            info = {}

        host = hassio.get_host_info(hass) or {}
        info_object["supervisor"] = info.get("supervisor")
        info_object["host_os"] = host.get("operating_system")
        info_object["docker_version"] = info.get("docker")
        info_object["chassis"] = host.get("chassis")

        if info.get("hassos") is not None:
            info_object["installation_type"] = "Home Assistant OS"
        else:
            info_object["installation_type"] = "Home Assistant Supervised"

    return info_object
</file>

<file path="target.py">
"""Helpers for dealing with entity targets."""

from __future__ import annotations

import abc
from collections.abc import Callable
import dataclasses
import logging
from logging import Logger
from typing import Any, TypeGuard

from homeassistant.const import (
    ATTR_AREA_ID,
    ATTR_DEVICE_ID,
    ATTR_ENTITY_ID,
    ATTR_FLOOR_ID,
    ATTR_LABEL_ID,
    ENTITY_MATCH_NONE,
)
from homeassistant.core import (
    CALLBACK_TYPE,
    Event,
    EventStateChangedData,
    HomeAssistant,
    callback,
)
from homeassistant.exceptions import HomeAssistantError

from . import (
    area_registry as ar,
    config_validation as cv,
    device_registry as dr,
    entity_registry as er,
    floor_registry as fr,
    group,
    label_registry as lr,
)
from .deprecation import deprecated_class
from .event import async_track_state_change_event
from .typing import ConfigType

_LOGGER = logging.getLogger(__name__)


@dataclasses.dataclass(slots=True, frozen=True)
class TargetStateChangedData:
    """Data for state change events related to targets."""

    state_change_event: Event[EventStateChangedData]
    targeted_entity_ids: set[str]


def _has_match(ids: str | list[str] | None) -> TypeGuard[str | list[str]]:
    """Check if ids can match anything."""
    return ids not in (None, ENTITY_MATCH_NONE)


class TargetSelection:
    """Class to represent target selection."""

    __slots__ = ("area_ids", "device_ids", "entity_ids", "floor_ids", "label_ids")

    def __init__(self, config: ConfigType) -> None:
        """Extract ids from the config."""
        entity_ids: str | list | None = config.get(ATTR_ENTITY_ID)
        device_ids: str | list | None = config.get(ATTR_DEVICE_ID)
        area_ids: str | list | None = config.get(ATTR_AREA_ID)
        floor_ids: str | list | None = config.get(ATTR_FLOOR_ID)
        label_ids: str | list | None = config.get(ATTR_LABEL_ID)

        self.entity_ids = (
            set(cv.ensure_list(entity_ids)) if _has_match(entity_ids) else set()
        )
        self.device_ids = (
            set(cv.ensure_list(device_ids)) if _has_match(device_ids) else set()
        )
        self.area_ids = set(cv.ensure_list(area_ids)) if _has_match(area_ids) else set()
        self.floor_ids = (
            set(cv.ensure_list(floor_ids)) if _has_match(floor_ids) else set()
        )
        self.label_ids = (
            set(cv.ensure_list(label_ids)) if _has_match(label_ids) else set()
        )

    @property
    def has_any_target(self) -> bool:
        """Determine if any target is present."""
        return bool(
            self.entity_ids
            or self.device_ids
            or self.area_ids
            or self.floor_ids
            or self.label_ids
        )


@deprecated_class("TargetSelection", breaks_in_ha_version="2026.12.0")
class TargetSelectorData(TargetSelection):
    """Class to represent target selector data."""

    @property
    def has_any_selector(self) -> bool:
        """Determine if any selectors are present."""
        return super().has_any_target


@dataclasses.dataclass(slots=True)
class SelectedEntities:
    """Class to hold the selected entities."""

    # Entity IDs of entities that were explicitly mentioned.
    referenced: set[str] = dataclasses.field(default_factory=set)

    # Entity IDs of entities that were referenced via device/area/floor/label ID.
    # Should not trigger a warning when they don't exist.
    indirectly_referenced: set[str] = dataclasses.field(default_factory=set)

    # Referenced items that could not be found.
    missing_devices: set[str] = dataclasses.field(default_factory=set)
    missing_areas: set[str] = dataclasses.field(default_factory=set)
    missing_floors: set[str] = dataclasses.field(default_factory=set)
    missing_labels: set[str] = dataclasses.field(default_factory=set)

    referenced_devices: set[str] = dataclasses.field(default_factory=set)
    referenced_areas: set[str] = dataclasses.field(default_factory=set)

    def log_missing(self, missing_entities: set[str], logger: Logger) -> None:
        """Log about missing items."""
        parts = []
        for label, items in (
            ("floors", self.missing_floors),
            ("areas", self.missing_areas),
            ("devices", self.missing_devices),
            ("entities", missing_entities),
            ("labels", self.missing_labels),
        ):
            if items:
                parts.append(f"{label} {', '.join(sorted(items))}")

        if not parts:
            return

        logger.warning(
            "Referenced %s are missing or not currently available",
            ", ".join(parts),
        )


def async_extract_referenced_entity_ids(
    hass: HomeAssistant, target_selection: TargetSelection, expand_group: bool = True
) -> SelectedEntities:
    """Extract referenced entity IDs from a target selection."""
    selected = SelectedEntities()

    if not target_selection.has_any_target:
        return selected

    entity_ids: set[str] | list[str] = target_selection.entity_ids
    if expand_group:
        entity_ids = group.expand_entity_ids(hass, entity_ids)

    selected.referenced.update(entity_ids)

    if (
        not target_selection.device_ids
        and not target_selection.area_ids
        and not target_selection.floor_ids
        and not target_selection.label_ids
    ):
        return selected

    entities = er.async_get(hass).entities
    dev_reg = dr.async_get(hass)
    area_reg = ar.async_get(hass)

    if target_selection.floor_ids:
        floor_reg = fr.async_get(hass)
        for floor_id in target_selection.floor_ids:
            if floor_id not in floor_reg.floors:
                selected.missing_floors.add(floor_id)

    for area_id in target_selection.area_ids:
        if area_id not in area_reg.areas:
            selected.missing_areas.add(area_id)

    for device_id in target_selection.device_ids:
        if device_id not in dev_reg.devices:
            selected.missing_devices.add(device_id)

    if target_selection.label_ids:
        label_reg = lr.async_get(hass)
        for label_id in target_selection.label_ids:
            if label_id not in label_reg.labels:
                selected.missing_labels.add(label_id)

            for entity_entry in entities.get_entries_for_label(label_id):
                if entity_entry.hidden_by is None:
                    selected.indirectly_referenced.add(entity_entry.entity_id)

            for device_entry in dev_reg.devices.get_devices_for_label(label_id):
                selected.referenced_devices.add(device_entry.id)

            for area_entry in area_reg.areas.get_areas_for_label(label_id):
                selected.referenced_areas.add(area_entry.id)

    # Find areas for targeted floors
    if target_selection.floor_ids:
        selected.referenced_areas.update(
            area_entry.id
            for floor_id in target_selection.floor_ids
            for area_entry in area_reg.areas.get_areas_for_floor(floor_id)
        )

    selected.referenced_areas.update(target_selection.area_ids)
    selected.referenced_devices.update(target_selection.device_ids)

    if not selected.referenced_areas and not selected.referenced_devices:
        return selected

    # Add indirectly referenced by device
    selected.indirectly_referenced.update(
        entry.entity_id
        for device_id in selected.referenced_devices
        for entry in entities.get_entries_for_device_id(device_id)
        # Do not add entities which are hidden or which are config
        # or diagnostic entities.
        if (entry.entity_category is None and entry.hidden_by is None)
    )

    # Find devices for targeted areas
    referenced_devices_by_area: set[str] = set()
    if selected.referenced_areas:
        for area_id in selected.referenced_areas:
            referenced_devices_by_area.update(
                device_entry.id
                for device_entry in dev_reg.devices.get_devices_for_area_id(area_id)
            )
    selected.referenced_devices.update(referenced_devices_by_area)

    # Add indirectly referenced by area
    selected.indirectly_referenced.update(
        entry.entity_id
        for area_id in selected.referenced_areas
        # The entity's area matches a targeted area
        for entry in entities.get_entries_for_area_id(area_id)
        # Do not add entities which are hidden or which are config
        # or diagnostic entities.
        if entry.entity_category is None and entry.hidden_by is None
    )
    # Add indirectly referenced by area through device
    selected.indirectly_referenced.update(
        entry.entity_id
        for device_id in referenced_devices_by_area
        for entry in entities.get_entries_for_device_id(device_id)
        # Do not add entities which are hidden or which are config
        # or diagnostic entities.
        if (
            entry.entity_category is None
            and entry.hidden_by is None
            and (
                # The entity's device matches a device referenced
                # by an area and the entity
                # has no explicitly set area
                not entry.area_id
            )
        )
    )

    return selected


class TargetEntityChangeTracker(abc.ABC):
    """Helper class to manage entity change tracking for targets."""

    def __init__(
        self,
        hass: HomeAssistant,
        target_selection: TargetSelection,
        entity_filter: Callable[[set[str]], set[str]],
    ) -> None:
        """Initialize the state change tracker."""
        self._hass = hass
        self._target_selection = target_selection
        self._entity_filter = entity_filter

        self._registry_unsubs: list[CALLBACK_TYPE] = []

    def async_setup(self) -> Callable[[], None]:
        """Set up the state change tracking."""
        self._setup_registry_listeners()
        self._handle_target_update()
        return self._unsubscribe

    @abc.abstractmethod
    @callback
    def _handle_entities_update(self, tracked_entities: set[str]) -> None:
        """Called when there's an update to the list of entities of the tracked targets."""

    @callback
    def _handle_target_update(self, event: Event[Any] | None = None) -> None:
        """Handle updates in the tracked targets."""
        selected = async_extract_referenced_entity_ids(
            self._hass, self._target_selection, expand_group=False
        )
        filtered_entities = self._entity_filter(
            selected.referenced | selected.indirectly_referenced
        )
        self._handle_entities_update(filtered_entities)

    def _setup_registry_listeners(self) -> None:
        """Set up listeners for registry changes that require resubscription."""

        # Subscribe to registry updates that can change the entities to track:
        # - Entity registry: entity added/removed; entity labels changed; entity area changed.
        # - Device registry: device labels changed; device area changed.
        # - Area registry: area floor changed.
        #
        # We don't track other registries (like floor or label registries) because their
        # changes don't affect which entities are tracked.
        self._registry_unsubs = [
            self._hass.bus.async_listen(
                er.EVENT_ENTITY_REGISTRY_UPDATED, self._handle_target_update
            ),
            self._hass.bus.async_listen(
                dr.EVENT_DEVICE_REGISTRY_UPDATED, self._handle_target_update
            ),
            self._hass.bus.async_listen(
                ar.EVENT_AREA_REGISTRY_UPDATED, self._handle_target_update
            ),
        ]

    def _unsubscribe(self) -> None:
        """Unsubscribe from all events."""
        for registry_unsub in self._registry_unsubs:
            registry_unsub()
        self._registry_unsubs.clear()


class TargetStateChangeTracker(TargetEntityChangeTracker):
    """Helper class to manage state change tracking for targets."""

    def __init__(
        self,
        hass: HomeAssistant,
        target_selection: TargetSelection,
        action: Callable[[TargetStateChangedData], Any],
        entity_filter: Callable[[set[str]], set[str]],
    ) -> None:
        """Initialize the state change tracker."""
        super().__init__(hass, target_selection, entity_filter)
        self._action = action
        self._state_change_unsub: CALLBACK_TYPE | None = None

    def _handle_entities_update(self, tracked_entities: set[str]) -> None:
        """Handle the tracked entities."""

        @callback
        def state_change_listener(event: Event[EventStateChangedData]) -> None:
            """Handle state change events."""
            if event.data["entity_id"] in tracked_entities:
                self._action(TargetStateChangedData(event, tracked_entities))

        _LOGGER.debug("Tracking state changes for entities: %s", tracked_entities)
        if self._state_change_unsub:
            self._state_change_unsub()
        self._state_change_unsub = async_track_state_change_event(
            self._hass, tracked_entities, state_change_listener
        )

    def _unsubscribe(self) -> None:
        """Unsubscribe from all events."""
        super()._unsubscribe()
        if self._state_change_unsub:
            self._state_change_unsub()
            self._state_change_unsub = None


def async_track_target_selector_state_change_event(
    hass: HomeAssistant,
    target_selector_config: ConfigType,
    action: Callable[[TargetStateChangedData], Any],
    entity_filter: Callable[[set[str]], set[str]] = lambda x: x,
) -> CALLBACK_TYPE:
    """Track state changes for entities referenced directly or indirectly in a target selector."""
    target_selection = TargetSelection(target_selector_config)
    if not target_selection.has_any_target:
        raise HomeAssistantError(
            f"Target selector {target_selector_config} does not have any selectors defined"
        )
    tracker = TargetStateChangeTracker(hass, target_selection, action, entity_filter)
    return tracker.async_setup()
</file>

<file path="temperature.py">
"""Temperature helpers for Home Assistant."""

from __future__ import annotations

from numbers import Number

from homeassistant.const import PRECISION_HALVES, PRECISION_TENTHS
from homeassistant.core import HomeAssistant
from homeassistant.util.unit_conversion import TemperatureConverter


def display_temp(
    hass: HomeAssistant, temperature: float | None, unit: str, precision: float
) -> float | None:
    """Convert temperature into preferred units/precision for display."""
    temperature_unit = unit
    ha_unit = hass.config.units.temperature_unit

    if temperature is None:
        return temperature

    # If the temperature is not a number this can cause issues
    # with Polymer components, so bail early there.
    if not isinstance(temperature, Number):
        raise TypeError(f"Temperature is not a number: {temperature}")

    if temperature_unit != ha_unit:
        temperature = TemperatureConverter.converter_factory(temperature_unit, ha_unit)(
            temperature
        )

    # Round in the units appropriate
    if precision == PRECISION_HALVES:
        return round(temperature * 2) / 2.0
    if precision == PRECISION_TENTHS:
        return round(temperature, 1)
    # Integer as a fall back (PRECISION_WHOLE)
    return round(temperature)
</file>

<file path="trace.py">
"""Helpers for script and condition tracing."""

from __future__ import annotations

from collections import deque
from collections.abc import Callable, Coroutine, Generator
from contextlib import contextmanager
from contextvars import ContextVar
from functools import wraps
from typing import Any

from homeassistant.core import ServiceResponse
from homeassistant.util import dt as dt_util

from .typing import TemplateVarsType


class TraceElement:
    """Container for trace data."""

    __slots__ = (
        "_child_key",
        "_child_run_id",
        "_error",
        "_last_variables",
        "_result",
        "_timestamp",
        "_variables",
        "path",
        "reuse_by_child",
    )

    def __init__(self, variables: TemplateVarsType, path: str) -> None:
        """Container for trace data."""
        self._child_key: str | None = None
        self._child_run_id: str | None = None
        self._error: BaseException | None = None
        self.path: str = path
        self._result: dict[str, Any] | None = None
        self.reuse_by_child = False
        self._timestamp = dt_util.utcnow()

        self._last_variables = variables_cv.get() or {}
        self.update_variables(variables)

    def __repr__(self) -> str:
        """Container for trace data."""
        return str(self.as_dict())

    def set_child_id(self, child_key: str, child_run_id: str) -> None:
        """Set trace id of a nested script run."""
        self._child_key = child_key
        self._child_run_id = child_run_id

    def set_error(self, ex: BaseException | None) -> None:
        """Set error."""
        self._error = ex

    def set_result(self, **kwargs: Any) -> None:
        """Set result."""
        self._result = {**kwargs}

    def update_result(self, **kwargs: Any) -> None:
        """Set result."""
        old_result = self._result or {}
        self._result = {**old_result, **kwargs}

    def update_variables(self, variables: TemplateVarsType) -> None:
        """Update variables."""
        if variables is None:
            variables = {}
        last_variables = self._last_variables
        variables_cv.set(dict(variables))
        changed_variables = {
            key: value
            for key, value in variables.items()
            if key not in last_variables or last_variables[key] != value
        }
        self._variables = changed_variables

    def as_dict(self) -> dict[str, Any]:
        """Return dictionary version of this TraceElement."""
        result: dict[str, Any] = {"path": self.path, "timestamp": self._timestamp}
        if self._child_key is not None:
            domain, _, item_id = self._child_key.partition(".")
            result["child_id"] = {
                "domain": domain,
                "item_id": item_id,
                "run_id": str(self._child_run_id),
            }
        if self._variables:
            result["changed_variables"] = self._variables
        if self._error is not None:
            result["error"] = str(self._error) or self._error.__class__.__name__
        if self._result is not None:
            result["result"] = self._result
        return result


# Context variables for tracing
# Current trace
trace_cv: ContextVar[dict[str, deque[TraceElement]] | None] = ContextVar(
    "trace_cv", default=None
)
# Stack of TraceElements
trace_stack_cv: ContextVar[list[TraceElement] | None] = ContextVar(
    "trace_stack_cv", default=None
)
# Current location in config tree
trace_path_stack_cv: ContextVar[list[str] | None] = ContextVar(
    "trace_path_stack_cv", default=None
)
# Copy of last variables
variables_cv: ContextVar[Any | None] = ContextVar("variables_cv", default=None)
# (domain.item_id, Run ID)
trace_id_cv: ContextVar[tuple[str, str] | None] = ContextVar(
    "trace_id_cv", default=None
)
# Reason for stopped script execution
script_execution_cv: ContextVar[StopReason | None] = ContextVar(
    "script_execution_cv", default=None
)


def trace_id_set(trace_id: tuple[str, str]) -> None:
    """Set id of the current trace."""
    trace_id_cv.set(trace_id)


def trace_id_get() -> tuple[str, str] | None:
    """Get id if the current trace."""
    return trace_id_cv.get()


def trace_stack_push[_T](
    trace_stack_var: ContextVar[list[_T] | None], node: _T
) -> None:
    """Push an element to the top of a trace stack."""
    trace_stack: list[_T] | None
    if (trace_stack := trace_stack_var.get()) is None:
        trace_stack = []
        trace_stack_var.set(trace_stack)
    trace_stack.append(node)


def trace_stack_pop(trace_stack_var: ContextVar[list[Any] | None]) -> None:
    """Remove the top element from a trace stack."""
    trace_stack = trace_stack_var.get()
    if trace_stack is not None:
        trace_stack.pop()


def trace_stack_top[_T](trace_stack_var: ContextVar[list[_T] | None]) -> _T | None:
    """Return the element at the top of a trace stack."""
    trace_stack = trace_stack_var.get()
    return trace_stack[-1] if trace_stack else None


def trace_path_push(suffix: str | list[str]) -> int:
    """Go deeper in the config tree."""
    if isinstance(suffix, str):
        suffix = [suffix]
    for node in suffix:
        trace_stack_push(trace_path_stack_cv, node)
    return len(suffix)


def trace_path_pop(count: int) -> None:
    """Go n levels up in the config tree."""
    for _ in range(count):
        trace_stack_pop(trace_path_stack_cv)


def trace_path_get() -> str:
    """Return a string representing the current location in the config tree."""
    if not (path := trace_path_stack_cv.get()):
        return ""
    return "/".join(path)


def trace_append_element(
    trace_element: TraceElement,
    maxlen: int | None = None,
) -> None:
    """Append a TraceElement to trace[path]."""
    if (trace := trace_cv.get()) is None:
        trace = {}
        trace_cv.set(trace)
    if (path := trace_element.path) not in trace:
        trace[path] = deque(maxlen=maxlen)
    trace[path].append(trace_element)


def trace_get(clear: bool = True) -> dict[str, deque[TraceElement]] | None:
    """Return the current trace."""
    if clear:
        trace_clear()
    return trace_cv.get()


def trace_clear() -> None:
    """Clear the trace."""
    trace_cv.set({})
    trace_stack_cv.set(None)
    trace_path_stack_cv.set(None)
    variables_cv.set(None)
    script_execution_cv.set(StopReason())


def trace_set_child_id(child_key: str, child_run_id: str) -> None:
    """Set child trace_id of TraceElement at the top of the stack."""
    if node := trace_stack_top(trace_stack_cv):
        node.set_child_id(child_key, child_run_id)


def trace_set_result(**kwargs: Any) -> None:
    """Set the result of TraceElement at the top of the stack."""
    if node := trace_stack_top(trace_stack_cv):
        node.set_result(**kwargs)


def trace_update_result(**kwargs: Any) -> None:
    """Update the result of TraceElement at the top of the stack."""
    if node := trace_stack_top(trace_stack_cv):
        node.update_result(**kwargs)


class StopReason:
    """Mutable container class for script_execution."""

    script_execution: str | None = None
    response: ServiceResponse = None


def script_execution_set(reason: str, response: ServiceResponse = None) -> None:
    """Set stop reason."""
    if (data := script_execution_cv.get()) is None:
        return
    data.script_execution = reason
    data.response = response


def script_execution_get() -> str | None:
    """Return the stop reason."""
    if (data := script_execution_cv.get()) is None:
        return None
    return data.script_execution


@contextmanager
def trace_path(suffix: str | list[str]) -> Generator[None]:
    """Go deeper in the config tree.

    Can not be used as a decorator on couroutine functions.
    """
    count = trace_path_push(suffix)
    try:
        yield
    finally:
        trace_path_pop(count)


def async_trace_path[*_Ts](
    suffix: str | list[str],
) -> Callable[
    [Callable[[*_Ts], Coroutine[Any, Any, None]]],
    Callable[[*_Ts], Coroutine[Any, Any, None]],
]:
    """Go deeper in the config tree.

    To be used as a decorator on coroutine functions.
    """

    def _trace_path_decorator(
        func: Callable[[*_Ts], Coroutine[Any, Any, None]],
    ) -> Callable[[*_Ts], Coroutine[Any, Any, None]]:
        """Decorate a coroutine function."""

        @wraps(func)
        async def async_wrapper(*args: *_Ts) -> None:
            """Catch and log exception."""
            with trace_path(suffix):
                await func(*args)

        return async_wrapper

    return _trace_path_decorator
</file>

<file path="translation.py">
"""Translation string lookup helpers."""

from __future__ import annotations

import asyncio
from collections.abc import Iterable, Mapping
from contextlib import suppress
from dataclasses import dataclass
import logging
import pathlib
import string
from typing import Any

from homeassistant.const import (
    EVENT_CORE_CONFIG_UPDATE,
    STATE_UNAVAILABLE,
    STATE_UNKNOWN,
)
from homeassistant.core import Event, HomeAssistant, async_get_hass, callback
from homeassistant.loader import (
    Integration,
    async_get_config_flows,
    async_get_integrations,
    bind_hass,
)
from homeassistant.util.json import load_json

from . import singleton

_LOGGER = logging.getLogger(__name__)

TRANSLATION_FLATTEN_CACHE = "translation_flatten_cache"
LOCALE_EN = "en"


def recursive_flatten(
    prefix: str, data: dict[str, dict[str, Any] | str]
) -> dict[str, str]:
    """Return a flattened representation of dict data."""
    output: dict[str, str] = {}
    for key, value in data.items():
        if isinstance(value, dict):
            output.update(recursive_flatten(f"{prefix}{key}.", value))
        else:
            output[f"{prefix}{key}"] = value
    return output


def _load_translations_files_by_language(
    translation_files: dict[str, dict[str, pathlib.Path]],
) -> dict[str, dict[str, Any]]:
    """Load and parse translation.json files."""
    loaded: dict[str, dict[str, Any]] = {}
    for language, component_translation_file in translation_files.items():
        loaded_for_language: dict[str, Any] = {}
        loaded[language] = loaded_for_language

        for component, translation_file in component_translation_file.items():
            loaded_json = load_json(translation_file)

            if not isinstance(loaded_json, dict):
                _LOGGER.warning(
                    "Translation file is unexpected type %s. Expected dict for %s",
                    type(loaded_json),
                    translation_file,
                )
                continue

            loaded_for_language[component] = loaded_json

    return loaded


def build_resources(
    translation_strings: dict[str, dict[str, dict[str, Any] | str]],
    components: set[str],
    category: str,
) -> dict[str, dict[str, Any] | str]:
    """Build the resources response for the given components."""
    # Build response
    return {
        component: category_strings
        for component in components
        if (component_strings := translation_strings.get(component))
        and (category_strings := component_strings.get(category))
    }


async def _async_get_component_strings(
    hass: HomeAssistant,
    languages: Iterable[str],
    components: set[str],
    integrations: dict[str, Integration],
) -> dict[str, dict[str, Any]]:
    """Load translations."""
    translations_by_language: dict[str, dict[str, Any]] = {}
    # Determine paths of missing components/platforms
    files_to_load_by_language: dict[str, dict[str, pathlib.Path]] = {}
    loaded_translations_by_language: dict[str, dict[str, Any]] = {}
    has_files_to_load = False
    for language in languages:
        file_name = f"{language}.json"
        files_to_load: dict[str, pathlib.Path] = {
            domain: integration.file_path / "translations" / file_name
            for domain in components
            if (
                (integration := integrations.get(domain))
                and integration.has_translations
            )
        }
        files_to_load_by_language[language] = files_to_load
        has_files_to_load |= bool(files_to_load)

    if has_files_to_load:
        loaded_translations_by_language = await hass.async_add_executor_job(
            _load_translations_files_by_language, files_to_load_by_language
        )

    for language in languages:
        loaded_translations = loaded_translations_by_language.setdefault(language, {})
        for domain in components:
            # Translations that miss "title" will get integration put in.
            component_translations = loaded_translations.setdefault(domain, {})
            if "title" not in component_translations and (
                integration := integrations.get(domain)
            ):
                component_translations["title"] = integration.name

        translations_by_language.setdefault(language, {}).update(loaded_translations)

    return translations_by_language


@dataclass(slots=True)
class _TranslationsCacheData:
    """Data for the translation cache.

    This class contains data that is designed to be shared
    between multiple instances of the translation cache so
    we only have to load the data once.
    """

    loaded: dict[str, set[str]]
    cache: dict[str, dict[str, dict[str, dict[str, str]]]]


class _TranslationCache:
    """Cache for flattened translations."""

    __slots__ = ("cache_data", "hass", "lock")

    def __init__(self, hass: HomeAssistant) -> None:
        """Initialize the cache."""
        self.hass = hass
        self.cache_data = _TranslationsCacheData({}, {})
        self.lock = asyncio.Lock()

    @callback
    def async_is_loaded(self, language: str, components: set[str]) -> bool:
        """Return if the given components are loaded for the language."""
        return components.issubset(self.cache_data.loaded.get(language, set()))

    async def async_load(
        self,
        language: str,
        components: set[str],
    ) -> None:
        """Load resources into the cache."""
        loaded = self.cache_data.loaded.setdefault(language, set())
        if components_to_load := components - loaded:
            # Translations are never unloaded so if there are no components to load
            # we can skip the lock which reduces contention when multiple different
            # translations categories are being fetched at the same time which is
            # common from the frontend.
            async with self.lock:
                # Check components to load again, as another task might have loaded
                # them while we were waiting for the lock.
                if components_to_load := components - loaded:
                    await self._async_load(language, components_to_load)

    async def async_fetch(
        self,
        language: str,
        category: str,
        components: set[str],
    ) -> dict[str, str]:
        """Load resources into the cache and return them."""
        await self.async_load(language, components)

        return self.get_cached(language, category, components)

    def get_cached(
        self,
        language: str,
        category: str,
        components: set[str],
    ) -> dict[str, str]:
        """Read resources from the cache."""
        category_cache = self.cache_data.cache.get(language, {}).get(category, {})
        # If only one component was requested, return it directly
        # to avoid merging the dictionaries and keeping additional
        # copies of the same data in memory.
        if len(components) == 1 and (component := next(iter(components))):
            return category_cache.get(component, {})

        result: dict[str, str] = {}
        for component in components.intersection(category_cache):
            result.update(category_cache[component])
        return result

    async def _async_load(self, language: str, components: set[str]) -> None:
        """Populate the cache for a given set of components."""
        loaded = self.cache_data.loaded
        _LOGGER.debug(
            "Cache miss for %s: %s",
            language,
            components,
        )
        # Fetch the English resources, as a fallback for missing keys
        languages = [LOCALE_EN] if language == LOCALE_EN else [LOCALE_EN, language]

        integrations: dict[str, Integration] = {}
        ints_or_excs = await async_get_integrations(self.hass, components)
        for domain, int_or_exc in ints_or_excs.items():
            if isinstance(int_or_exc, Exception):
                _LOGGER.warning(
                    "Failed to load integration for translation: %s", int_or_exc
                )
                continue
            integrations[domain] = int_or_exc

        translation_by_language_strings = await _async_get_component_strings(
            self.hass, languages, components, integrations
        )

        # English is always the fallback language so we load them first
        self._build_category_cache(
            language, components, translation_by_language_strings[LOCALE_EN]
        )

        if language != LOCALE_EN:
            # Now overlay the requested language on top of the English
            self._build_category_cache(
                language, components, translation_by_language_strings[language]
            )

            loaded_english_components = loaded.setdefault(LOCALE_EN, set())
            # Since we just loaded english anyway we can avoid loading
            # again if they switch back to english.
            if loaded_english_components.isdisjoint(components):
                self._build_category_cache(
                    LOCALE_EN, components, translation_by_language_strings[LOCALE_EN]
                )
                loaded_english_components.update(components)

        loaded[language].update(components)

    def _validate_placeholders(
        self,
        language: str,
        updated_resources: dict[str, str],
        cached_resources: dict[str, str] | None = None,
    ) -> dict[str, str]:
        """Validate if updated resources have same placeholders as cached resources."""
        if cached_resources is None:
            return updated_resources

        mismatches: set[str] = set()

        for key, value in updated_resources.items():
            if key not in cached_resources:
                continue
            try:
                tuples = list(string.Formatter().parse(value))
            except ValueError:
                _LOGGER.error(
                    ("Error while parsing localized (%s) string %s"), language, key
                )
                continue
            updated_placeholders = {tup[1] for tup in tuples if tup[1] is not None}

            tuples = list(string.Formatter().parse(cached_resources[key]))
            cached_placeholders = {tup[1] for tup in tuples if tup[1] is not None}
            if updated_placeholders != cached_placeholders:
                _LOGGER.error(
                    (
                        "Validation of translation placeholders for localized (%s) string "
                        "%s failed: (%s != %s)"
                    ),
                    language,
                    key,
                    updated_placeholders,
                    cached_placeholders,
                )
                mismatches.add(key)

        for mismatch in mismatches:
            del updated_resources[mismatch]

        return updated_resources

    @callback
    def _build_category_cache(
        self,
        language: str,
        components: set[str],
        translation_strings: dict[str, dict[str, Any]],
    ) -> None:
        """Extract resources into the cache."""
        resource: dict[str, Any] | str
        cached = self.cache_data.cache.setdefault(language, {})
        categories = {
            category
            for component in translation_strings.values()
            for category in component
        }

        for category in categories:
            new_resources = build_resources(translation_strings, components, category)
            category_cache = cached.setdefault(category, {})

            for component, resource in new_resources.items():
                component_cache = category_cache.setdefault(component, {})

                if not isinstance(resource, dict):
                    component_cache[f"component.{component}.{category}"] = resource
                    continue

                prefix = f"component.{component}.{category}."
                flat = recursive_flatten(prefix, resource)
                flat = self._validate_placeholders(language, flat, component_cache)
                component_cache.update(flat)


@bind_hass
async def async_get_translations(
    hass: HomeAssistant,
    language: str,
    category: str,
    integrations: Iterable[str] | None = None,
    config_flow: bool | None = None,
) -> dict[str, str]:
    """Return all backend translations.

    If integration is specified, load it for that one.
    Otherwise, default to loaded integrations combined with config flow
    integrations if config_flow is true.
    """
    if integrations is None and config_flow:
        components = (await async_get_config_flows(hass)) - hass.config.components
    elif integrations is not None:
        components = set(integrations)
    else:
        components = hass.config.top_level_components

    return await _async_get_translations_cache(hass).async_fetch(
        language, category, components
    )


@callback
def async_get_cached_translations(
    hass: HomeAssistant,
    language: str,
    category: str,
    integration: str | None = None,
) -> dict[str, str]:
    """Return all cached backend translations.

    If integration is specified, return translations for it.
    Otherwise, default to all loaded integrations.
    """
    components = {integration} if integration else hass.config.top_level_components
    return _async_get_translations_cache(hass).get_cached(
        language, category, components
    )


@singleton.singleton(TRANSLATION_FLATTEN_CACHE)
def _async_get_translations_cache(hass: HomeAssistant) -> _TranslationCache:
    """Return the translation cache."""
    return _TranslationCache(hass)


@callback
def async_setup(hass: HomeAssistant) -> None:
    """Create translation cache and register listeners for translation loaders.

    Listeners load translations for every loaded component and after config change.
    """
    cache = _TranslationCache(hass)
    current_language = hass.config.language
    _async_get_translations_cache(hass)

    @callback
    def _async_load_translations_filter(event_data: Mapping[str, Any]) -> bool:
        """Filter out unwanted events."""
        nonlocal current_language
        if (
            new_language := event_data.get("language")
        ) and new_language != current_language:
            current_language = new_language
            return True
        return False

    async def _async_load_translations(event: Event) -> None:
        new_language = event.data["language"]
        _LOGGER.debug("Loading translations for language: %s", new_language)
        await cache.async_load(new_language, hass.config.components)

    hass.bus.async_listen(
        EVENT_CORE_CONFIG_UPDATE,
        _async_load_translations,
        event_filter=_async_load_translations_filter,
    )


async def async_load_integrations(hass: HomeAssistant, integrations: set[str]) -> None:
    """Load translations for integrations."""
    await _async_get_translations_cache(hass).async_load(
        hass.config.language, integrations
    )


@callback
def async_translations_loaded(hass: HomeAssistant, components: set[str]) -> bool:
    """Return if the given components are loaded for the language."""
    return _async_get_translations_cache(hass).async_is_loaded(
        hass.config.language, components
    )


@callback
def async_get_exception_message(
    translation_domain: str,
    translation_key: str,
    translation_placeholders: dict[str, str] | None = None,
) -> str:
    """Return a translated exception message.

    Defaults to English, requires translations to already be cached.
    """
    language = "en"
    hass = async_get_hass()
    localize_key = (
        f"component.{translation_domain}.exceptions.{translation_key}.message"
    )
    translations = async_get_cached_translations(hass, language, "exceptions")
    if localize_key in translations:
        if message := translations[localize_key]:
            message = message.rstrip(".")
        if not translation_placeholders:
            return message
        with suppress(KeyError):
            message = message.format(**translation_placeholders)
        return message

    # We return the translation key when was not found in the cache
    return translation_key


@callback
def async_translate_state(
    hass: HomeAssistant,
    state: str,
    domain: str,
    platform: str | None,
    translation_key: str | None,
    device_class: str | None,
) -> str:
    """Translate provided state using cached translations for currently selected language."""
    if state in [STATE_UNAVAILABLE, STATE_UNKNOWN]:
        return state
    language = hass.config.language
    if platform is not None and translation_key is not None:
        localize_key = (
            f"component.{platform}.entity.{domain}.{translation_key}.state.{state}"
        )
        translations = async_get_cached_translations(hass, language, "entity")
        if localize_key in translations:
            return translations[localize_key]

    translations = async_get_cached_translations(hass, language, "entity_component")
    if device_class is not None:
        localize_key = (
            f"component.{domain}.entity_component.{device_class}.state.{state}"
        )
        if localize_key in translations:
            return translations[localize_key]
    localize_key = f"component.{domain}.entity_component._.state.{state}"
    if localize_key in translations:
        return translations[localize_key]

    return state
</file>

<file path="trigger_template_entity.py">
"""TemplateEntity utility class."""

from __future__ import annotations

import itertools
import logging
from typing import Any

import jinja2
import voluptuous as vol

from homeassistant.components.sensor import (
    CONF_STATE_CLASS,
    DEVICE_CLASSES_SCHEMA,
    STATE_CLASSES_SCHEMA,
    SensorDeviceClass,
    SensorEntity,
)
from homeassistant.components.sensor.helpers import (  # pylint: disable=hass-component-root-import
    async_parse_date_datetime,
)
from homeassistant.const import (
    ATTR_ENTITY_PICTURE,
    ATTR_FRIENDLY_NAME,
    ATTR_ICON,
    CONF_DEVICE_CLASS,
    CONF_ICON,
    CONF_NAME,
    CONF_UNIQUE_ID,
    CONF_UNIT_OF_MEASUREMENT,
)
from homeassistant.core import HomeAssistant, State, callback
from homeassistant.exceptions import TemplateError
from homeassistant.util.json import JSON_DECODE_EXCEPTIONS, json_loads

from . import config_validation as cv
from .entity import Entity
from .template import (
    _SENTINEL,
    Template,
    TemplateStateFromEntityId,
    render_complex,
    result_as_boolean,
)
from .template.context import render_with_context
from .typing import ConfigType

CONF_AVAILABILITY = "availability"
CONF_ATTRIBUTES = "attributes"
CONF_PICTURE = "picture"

CONF_TO_ATTRIBUTE = {
    CONF_ICON: ATTR_ICON,
    CONF_NAME: ATTR_FRIENDLY_NAME,
    CONF_PICTURE: ATTR_ENTITY_PICTURE,
}

TEMPLATE_ENTITY_BASE_SCHEMA = vol.Schema(
    {
        vol.Optional(CONF_ICON): cv.template,
        vol.Optional(CONF_NAME): cv.template,
        vol.Optional(CONF_PICTURE): cv.template,
        vol.Optional(CONF_UNIQUE_ID): cv.string,
    }
)


def make_template_entity_base_schema(default_name: str) -> vol.Schema:
    """Return a schema with default name."""
    return vol.Schema(
        {
            vol.Optional(CONF_ICON): cv.template,
            vol.Optional(CONF_NAME, default=default_name): cv.template,
            vol.Optional(CONF_PICTURE): cv.template,
            vol.Optional(CONF_UNIQUE_ID): cv.string,
        }
    )


def log_triggered_template_error(
    entity_id: str,
    err: TemplateError,
    key: str | None = None,
    attribute: str | None = None,
) -> None:
    """Log a trigger entity template error."""
    target = ""
    if key:
        target = f" {key}"
    elif attribute:
        target = f" {CONF_ATTRIBUTES}.{attribute}"

    logging.getLogger(f"{__package__}.{entity_id.split('.')[0]}").error(
        "Error rendering%s template for %s: %s",
        target,
        entity_id,
        err,
    )


TEMPLATE_SENSOR_BASE_SCHEMA = vol.Schema(
    {
        vol.Optional(CONF_DEVICE_CLASS): DEVICE_CLASSES_SCHEMA,
        vol.Optional(CONF_STATE_CLASS): STATE_CLASSES_SCHEMA,
        vol.Optional(CONF_UNIT_OF_MEASUREMENT): cv.string,
    }
).extend(TEMPLATE_ENTITY_BASE_SCHEMA.schema)


class ValueTemplate(Template):
    """Class to hold a value_template and manage caching and rendering it with 'value' in variables."""

    @classmethod
    def from_template(cls, template: Template) -> ValueTemplate:
        """Create a ValueTemplate object from a Template object."""
        return cls(template.template, template.hass)

    @callback
    def async_render_as_value_template(
        self, entity_id: str, variables: dict[str, Any], error_value: Any
    ) -> Any:
        """Render template that requires 'value' and optionally 'value_json'.

        Template errors will be suppressed when an error_value is supplied.

        This method must be run in the event loop.
        """
        self._renders += 1

        if self.is_static:
            return self.template

        compiled = self._compiled or self._ensure_compiled()

        try:
            render_result = render_with_context(
                self.template, compiled, **variables
            ).strip()
        except jinja2.TemplateError as ex:
            message = f"Error parsing value for {entity_id}: {ex} (value: {variables['value']}, template: {self.template})"
            logger = logging.getLogger(f"{__package__}.{entity_id.split('.')[0]}")
            logger.debug(message)
            return error_value

        return render_result


class TriggerBaseEntity(Entity):
    """Template Base entity based on trigger data."""

    domain: str
    extra_template_keys: tuple[str, ...] | None = None
    extra_template_keys_complex: tuple[str, ...] | None = None
    _unique_id: str | None

    def __init__(
        self,
        hass: HomeAssistant,
        config: ConfigType,
    ) -> None:
        """Initialize the entity."""
        self.hass = hass

        self._set_unique_id(config.get(CONF_UNIQUE_ID))

        self._config = config

        self._static_rendered = {}
        self._to_render_simple: list[str] = []
        self._to_render_complex: list[str] = []

        for itm in (
            CONF_AVAILABILITY,
            CONF_ICON,
            CONF_NAME,
            CONF_PICTURE,
        ):
            if itm not in config or config[itm] is None:
                continue
            if config[itm].is_static:
                self._static_rendered[itm] = config[itm].template
            else:
                self._to_render_simple.append(itm)

        if self.extra_template_keys is not None:
            self._to_render_simple.extend(self.extra_template_keys)

        if self.extra_template_keys_complex is not None:
            self._to_render_complex.extend(self.extra_template_keys_complex)

        # We make a copy so our initial render is 'unknown' and not 'unavailable'
        self._rendered = dict(self._static_rendered)
        self._parse_result = {CONF_AVAILABILITY}
        self._attr_device_class = config.get(CONF_DEVICE_CLASS)

        self._availability_template = config.get(CONF_AVAILABILITY)
        self._available = True

    @property
    def name(self) -> str | None:
        """Name of the entity."""
        return self._rendered.get(CONF_NAME)

    @property
    def unique_id(self) -> str | None:
        """Return unique ID of the entity."""
        return self._unique_id

    @property
    def icon(self) -> str | None:
        """Return icon."""
        return self._rendered.get(CONF_ICON)

    @property
    def entity_picture(self) -> str | None:
        """Return entity picture."""
        return self._rendered.get(CONF_PICTURE)

    @property
    def available(self) -> bool:
        """Return availability of the entity."""
        if self._availability_template is None:
            return True

        return self._available

    @property
    def extra_state_attributes(self) -> dict[str, Any] | None:
        """Return extra attributes."""
        return self._rendered.get(CONF_ATTRIBUTES)

    def _set_unique_id(self, unique_id: str | None) -> None:
        """Set unique id."""
        self._unique_id = unique_id

    def restore_attributes(self, last_state: State) -> None:
        """Restore attributes."""
        for conf_key, attr in CONF_TO_ATTRIBUTE.items():
            if conf_key not in self._config or attr not in last_state.attributes:
                continue
            self._rendered[conf_key] = last_state.attributes[attr]

        if CONF_ATTRIBUTES in self._config:
            extra_state_attributes = {}
            for attr in self._config[CONF_ATTRIBUTES]:
                if attr not in last_state.attributes:
                    continue
                extra_state_attributes[attr] = last_state.attributes[attr]
            self._rendered[CONF_ATTRIBUTES] = extra_state_attributes

    def _template_variables(self, run_variables: dict[str, Any] | None = None) -> dict:
        """Render template variables."""
        return {
            "this": TemplateStateFromEntityId(self.hass, self.entity_id),
            **(run_variables or {}),
        }

    def _render_single_template(
        self,
        key: str,
        variables: dict[str, Any],
        strict: bool = False,
    ) -> Any:
        """Render a single template."""
        try:
            if key in self._to_render_complex:
                return render_complex(self._config[key], variables)

            return self._config[key].async_render(
                variables, parse_result=key in self._parse_result, strict=strict
            )
        except TemplateError as err:
            log_triggered_template_error(self.entity_id, err, key=key)

        return _SENTINEL

    def _render_availability_template(self, variables: dict[str, Any]) -> bool:
        """Render availability template."""
        if not self._availability_template:
            return True

        try:
            if (
                available := self._availability_template.async_render(
                    variables, parse_result=True, strict=True
                )
            ) is False:
                self._rendered = dict(self._static_rendered)

            self._available = result_as_boolean(available)

        except TemplateError as err:
            # The entity will be available when an error is rendered. This
            # ensures functionality is consistent between template and trigger template
            # entities.
            self._available = True
            log_triggered_template_error(self.entity_id, err, key=CONF_AVAILABILITY)

        return self._available

    def _render_attributes(self, rendered: dict, variables: dict[str, Any]) -> None:
        """Render template attributes."""
        if CONF_ATTRIBUTES in self._config:
            attributes = {}
            for attribute, attribute_template in self._config[CONF_ATTRIBUTES].items():
                try:
                    value = render_complex(attribute_template, variables)
                    attributes[attribute] = value
                    variables.update({attribute: value})
                except TemplateError as err:
                    log_triggered_template_error(
                        self.entity_id, err, attribute=attribute
                    )
            rendered[CONF_ATTRIBUTES] = attributes

    def _render_single_templates(
        self,
        rendered: dict,
        variables: dict[str, Any],
        filtered: list[str] | None = None,
    ) -> None:
        """Render all single templates."""
        for key in itertools.chain(self._to_render_simple, self._to_render_complex):
            if filtered and key in filtered:
                continue

            if (
                result := self._render_single_template(key, variables)
            ) is not _SENTINEL:
                rendered[key] = result

    def _render_templates(self, variables: dict[str, Any]) -> None:
        """Render templates."""
        rendered = dict(self._static_rendered)
        self._render_single_templates(rendered, variables)
        self._render_attributes(rendered, variables)
        self._rendered = rendered


class ManualTriggerEntity(TriggerBaseEntity):
    """Template entity based on manual trigger data."""

    def __init__(
        self,
        hass: HomeAssistant,
        config: ConfigType,
    ) -> None:
        """Initialize the entity."""
        TriggerBaseEntity.__init__(self, hass, config)
        # Need initial rendering on `name` as it influence the `entity_id`
        self._rendered[CONF_NAME] = config[CONF_NAME].async_render(
            {},
            parse_result=CONF_NAME in self._parse_result,
        )

    def _template_variables_with_value(
        self, value: str | None = None
    ) -> dict[str, Any]:
        """Render template variables.

        Implementing class should call this first in update method to render variables for templates.
        Ex: variables = self._render_template_variables_with_value(payload)
        """
        run_variables: dict[str, Any] = {"value": value}

        # Silently try if variable is a json and store result in `value_json` if it is.
        try:  # noqa: SIM105 - suppress is much slower
            run_variables["value_json"] = json_loads(value)  # type: ignore[arg-type]
        except JSON_DECODE_EXCEPTIONS:
            pass

        return self._template_variables(run_variables)

    @callback
    def _process_manual_data(self, variables: dict[str, Any]) -> None:
        """Process new data manually.

        Implementing class should call this last in update method to render templates.
        Ex: self._process_manual_data(variables)
        """
        self._render_templates(variables)


class ManualTriggerSensorEntity(ManualTriggerEntity, SensorEntity):
    """Template entity based on manual trigger data for sensor."""

    def __init__(
        self,
        hass: HomeAssistant,
        config: ConfigType,
    ) -> None:
        """Initialize the sensor entity."""
        ManualTriggerEntity.__init__(self, hass, config)
        self._attr_native_unit_of_measurement = config.get(CONF_UNIT_OF_MEASUREMENT)
        self._attr_state_class = config.get(CONF_STATE_CLASS)

    @callback
    def _set_native_value_with_possible_timestamp(self, value: Any) -> None:
        """Set native value with possible timestamp.

        If self.device_class is `date` or `timestamp`,
        it will try to parse the value to a date/datetime object.
        """
        if self.device_class not in (
            SensorDeviceClass.DATE,
            SensorDeviceClass.TIMESTAMP,
        ):
            self._attr_native_value = value
        elif value is not None:
            self._attr_native_value = async_parse_date_datetime(
                value, self.entity_id, self.device_class
            )
</file>

<file path="trigger.py">
"""Triggers."""

from __future__ import annotations

import abc
import asyncio
from collections import defaultdict
from collections.abc import Callable, Coroutine, Iterable
from dataclasses import dataclass, field
from enum import StrEnum
import functools
import inspect
import logging
from typing import TYPE_CHECKING, Any, Final, Protocol, TypedDict, cast, override

import voluptuous as vol

from homeassistant.const import (
    ATTR_ENTITY_ID,
    CONF_ABOVE,
    CONF_ALIAS,
    CONF_BELOW,
    CONF_ENABLED,
    CONF_ID,
    CONF_OPTIONS,
    CONF_PLATFORM,
    CONF_SELECTOR,
    CONF_TARGET,
    CONF_VARIABLES,
    STATE_UNAVAILABLE,
    STATE_UNKNOWN,
)
from homeassistant.core import (
    CALLBACK_TYPE,
    Context,
    HassJob,
    HassJobType,
    HomeAssistant,
    State,
    callback,
    get_hassjob_callable_job_type,
    is_callback,
    split_entity_id,
)
from homeassistant.exceptions import HomeAssistantError, TemplateError
from homeassistant.loader import (
    Integration,
    IntegrationNotFound,
    async_get_integration,
    async_get_integrations,
)
from homeassistant.util.async_ import create_eager_task
from homeassistant.util.hass_dict import HassKey
from homeassistant.util.yaml import load_yaml_dict

from . import config_validation as cv, selector
from .automation import (
    get_absolute_description_key,
    get_relative_description_key,
    move_options_fields_to_top_level,
)
from .integration_platform import async_process_integration_platforms
from .selector import TargetSelector
from .target import (
    TargetStateChangedData,
    async_track_target_selector_state_change_event,
)
from .template import Template
from .typing import ConfigType, TemplateVarsType

_LOGGER = logging.getLogger(__name__)

_PLATFORM_ALIASES = {
    "device": "device_automation",
    "event": "homeassistant",
    "numeric_state": "homeassistant",
    "state": "homeassistant",
    "time_pattern": "homeassistant",
    "time": "homeassistant",
}

DATA_PLUGGABLE_ACTIONS: HassKey[defaultdict[tuple, PluggableActionsEntry]] = HassKey(
    "pluggable_actions"
)

TRIGGER_DESCRIPTION_CACHE: HassKey[dict[str, dict[str, Any] | None]] = HassKey(
    "trigger_description_cache"
)
TRIGGER_DISABLED_TRIGGERS: HassKey[set[str]] = HassKey("trigger_disabled_triggers")
TRIGGER_PLATFORM_SUBSCRIPTIONS: HassKey[
    list[Callable[[set[str]], Coroutine[Any, Any, None]]]
] = HassKey("trigger_platform_subscriptions")
TRIGGERS: HassKey[dict[str, str]] = HassKey("triggers")


# Basic schemas to sanity check the trigger descriptions,
# full validation is done by hassfest.triggers
_FIELD_DESCRIPTION_SCHEMA = vol.Schema(
    {
        vol.Optional(CONF_SELECTOR): selector.validate_selector,
    },
    extra=vol.ALLOW_EXTRA,
)

_TRIGGER_DESCRIPTION_SCHEMA = vol.Schema(
    {
        vol.Optional("target"): TargetSelector.CONFIG_SCHEMA,
        vol.Optional("fields"): vol.Schema({str: _FIELD_DESCRIPTION_SCHEMA}),
    },
    extra=vol.ALLOW_EXTRA,
)


def starts_with_dot(key: str) -> str:
    """Check if key starts with dot."""
    if not key.startswith("."):
        raise vol.Invalid("Key does not start with .")
    return key


_TRIGGERS_DESCRIPTION_SCHEMA = vol.Schema(
    {
        vol.Remove(vol.All(str, starts_with_dot)): object,
        cv.underscore_slug: vol.Any(None, _TRIGGER_DESCRIPTION_SCHEMA),
    }
)


async def async_setup(hass: HomeAssistant) -> None:
    """Set up the trigger helper."""
    from homeassistant.components import automation, labs  # noqa: PLC0415

    hass.data[TRIGGER_DESCRIPTION_CACHE] = {}
    hass.data[TRIGGER_DISABLED_TRIGGERS] = set()
    hass.data[TRIGGER_PLATFORM_SUBSCRIPTIONS] = []
    hass.data[TRIGGERS] = {}

    @callback
    def new_triggers_conditions_listener() -> None:
        """Handle new_triggers_conditions flag change."""
        # Invalidate the cache
        hass.data[TRIGGER_DESCRIPTION_CACHE] = {}
        hass.data[TRIGGER_DISABLED_TRIGGERS] = set()

    labs.async_listen(
        hass,
        automation.DOMAIN,
        automation.NEW_TRIGGERS_CONDITIONS_FEATURE_FLAG,
        new_triggers_conditions_listener,
    )

    await async_process_integration_platforms(
        hass, "trigger", _register_trigger_platform, wait_for_platforms=True
    )


@callback
def async_subscribe_platform_events(
    hass: HomeAssistant,
    on_event: Callable[[set[str]], Coroutine[Any, Any, None]],
) -> Callable[[], None]:
    """Subscribe to trigger platform events."""
    trigger_platform_event_subscriptions = hass.data[TRIGGER_PLATFORM_SUBSCRIPTIONS]

    def remove_subscription() -> None:
        trigger_platform_event_subscriptions.remove(on_event)

    trigger_platform_event_subscriptions.append(on_event)
    return remove_subscription


async def _register_trigger_platform(
    hass: HomeAssistant, integration_domain: str, platform: TriggerProtocol
) -> None:
    """Register a trigger platform and notify listeners.

    If the trigger platform does not provide any triggers, or it is disabled,
    listeners will not be notified.
    """
    from homeassistant.components import automation  # noqa: PLC0415

    new_triggers: set[str] = set()

    if hasattr(platform, "async_get_triggers"):
        for trigger_key in await platform.async_get_triggers(hass):
            trigger_key = get_absolute_description_key(integration_domain, trigger_key)
            hass.data[TRIGGERS][trigger_key] = integration_domain
            new_triggers.add(trigger_key)
        if not new_triggers:
            _LOGGER.debug(
                "Integration %s returned no triggers in async_get_triggers",
                integration_domain,
            )
            return
    elif hasattr(platform, "async_validate_trigger_config") or hasattr(
        platform, "TRIGGER_SCHEMA"
    ):
        hass.data[TRIGGERS][integration_domain] = integration_domain
        new_triggers.add(integration_domain)
    else:
        _LOGGER.debug(
            "Integration %s does not provide trigger support, skipping",
            integration_domain,
        )
        return

    if automation.is_disabled_experimental_trigger(hass, integration_domain):
        _LOGGER.debug("Triggers for integration %s are disabled", integration_domain)
        return

    # We don't use gather here because gather adds additional overhead
    # when wrapping each coroutine in a task, and we expect our listeners
    # to call trigger.async_get_all_descriptions which will only yield
    # the first time it's called, after that it returns cached data.
    for listener in hass.data[TRIGGER_PLATFORM_SUBSCRIPTIONS]:
        try:
            await listener(new_triggers)
        except Exception:
            _LOGGER.exception("Error while notifying trigger platform listener")


_TRIGGER_SCHEMA = cv.TRIGGER_BASE_SCHEMA.extend(
    {
        vol.Optional(CONF_OPTIONS): object,
        vol.Optional(CONF_TARGET): cv.TARGET_FIELDS,
    }
)


class Trigger(abc.ABC):
    """Trigger class."""

    _hass: HomeAssistant

    @classmethod
    async def async_validate_complete_config(
        cls, hass: HomeAssistant, complete_config: ConfigType
    ) -> ConfigType:
        """Validate complete config.

        The complete config includes fields that are generic to all triggers,
        such as the alias or the ID.
        This method should be overridden by triggers that need to migrate
        from the old-style config.
        """
        complete_config = _TRIGGER_SCHEMA(complete_config)

        specific_config: ConfigType = {}
        for key in (CONF_OPTIONS, CONF_TARGET):
            if key in complete_config:
                specific_config[key] = complete_config.pop(key)
        specific_config = await cls.async_validate_config(hass, specific_config)

        for key in (CONF_OPTIONS, CONF_TARGET):
            if key in specific_config:
                complete_config[key] = specific_config[key]

        return complete_config

    @classmethod
    @abc.abstractmethod
    async def async_validate_config(
        cls, hass: HomeAssistant, config: ConfigType
    ) -> ConfigType:
        """Validate config."""

    def __init__(self, hass: HomeAssistant, config: TriggerConfig) -> None:
        """Initialize trigger."""
        self._hass = hass

    async def async_attach_action(
        self,
        action: TriggerAction,
        action_payload_builder: TriggerActionPayloadBuilder,
    ) -> CALLBACK_TYPE:
        """Attach the trigger to an action."""

        @callback
        def run_action(
            extra_trigger_payload: dict[str, Any],
            description: str,
            context: Context | None = None,
        ) -> asyncio.Task[Any]:
            """Run action with trigger variables."""

            payload = action_payload_builder(extra_trigger_payload, description)
            return self._hass.async_create_task(action(payload, context))

        return await self.async_attach_runner(run_action)

    @abc.abstractmethod
    async def async_attach_runner(
        self, run_action: TriggerActionRunner
    ) -> CALLBACK_TYPE:
        """Attach the trigger to an action runner."""


ATTR_BEHAVIOR: Final = "behavior"
BEHAVIOR_FIRST: Final = "first"
BEHAVIOR_LAST: Final = "last"
BEHAVIOR_ANY: Final = "any"

ENTITY_STATE_TRIGGER_SCHEMA = vol.Schema(
    {
        vol.Required(CONF_TARGET): cv.TARGET_FIELDS,
    }
)

ENTITY_STATE_TRIGGER_SCHEMA_FIRST_LAST = ENTITY_STATE_TRIGGER_SCHEMA.extend(
    {
        vol.Required(CONF_OPTIONS): {
            vol.Required(ATTR_BEHAVIOR, default=BEHAVIOR_ANY): vol.In(
                [BEHAVIOR_FIRST, BEHAVIOR_LAST, BEHAVIOR_ANY]
            ),
        },
        vol.Required(CONF_TARGET): cv.TARGET_FIELDS,
    }
)


class EntityTriggerBase(Trigger):
    """Trigger for entity state changes."""

    _domain: str
    _schema: vol.Schema = ENTITY_STATE_TRIGGER_SCHEMA_FIRST_LAST

    @override
    @classmethod
    async def async_validate_config(
        cls, hass: HomeAssistant, config: ConfigType
    ) -> ConfigType:
        """Validate config."""
        return cast(ConfigType, cls._schema(config))

    def __init__(self, hass: HomeAssistant, config: TriggerConfig) -> None:
        """Initialize the state trigger."""
        super().__init__(hass, config)
        if TYPE_CHECKING:
            assert config.target is not None
        self._options = config.options or {}
        self._target = config.target

    def is_valid_transition(self, from_state: State, to_state: State) -> bool:
        """Check if the origin state is valid and the state has changed."""
        if from_state.state in (STATE_UNAVAILABLE, STATE_UNKNOWN):
            return False

        return from_state.state != to_state.state

    @abc.abstractmethod
    def is_valid_state(self, state: State) -> bool:
        """Check if the new state matches the expected state(s)."""

    def check_all_match(self, entity_ids: set[str]) -> bool:
        """Check if all entity states match."""
        return all(
            self.is_valid_state(state)
            for entity_id in entity_ids
            if (state := self._hass.states.get(entity_id)) is not None
        )

    def check_one_match(self, entity_ids: set[str]) -> bool:
        """Check that only one entity state matches."""
        return (
            sum(
                self.is_valid_state(state)
                for entity_id in entity_ids
                if (state := self._hass.states.get(entity_id)) is not None
            )
            == 1
        )

    def entity_filter(self, entities: set[str]) -> set[str]:
        """Filter entities of this domain."""
        return {
            entity_id
            for entity_id in entities
            if split_entity_id(entity_id)[0] == self._domain
        }

    @override
    async def async_attach_runner(
        self, run_action: TriggerActionRunner
    ) -> CALLBACK_TYPE:
        """Attach the trigger to an action runner."""

        behavior = self._options.get(ATTR_BEHAVIOR)

        @callback
        def state_change_listener(
            target_state_change_data: TargetStateChangedData,
        ) -> None:
            """Listen for state changes and call action."""
            event = target_state_change_data.state_change_event
            entity_id = event.data["entity_id"]
            from_state = event.data["old_state"]
            to_state = event.data["new_state"]

            if not from_state or not to_state:
                return

            # The trigger should never fire if the new state is not valid
            if not self.is_valid_state(to_state):
                return

            # The trigger should never fire if the transition is not valid
            if not self.is_valid_transition(from_state, to_state):
                return

            if behavior == BEHAVIOR_LAST:
                if not self.check_all_match(
                    target_state_change_data.targeted_entity_ids
                ):
                    return
            elif behavior == BEHAVIOR_FIRST:
                if not self.check_one_match(
                    target_state_change_data.targeted_entity_ids
                ):
                    return

            run_action(
                {
                    ATTR_ENTITY_ID: entity_id,
                    "from_state": from_state,
                    "to_state": to_state,
                },
                f"state of {entity_id}",
                event.context,
            )

        return async_track_target_selector_state_change_event(
            self._hass, self._target, state_change_listener, self.entity_filter
        )


class EntityTargetStateTriggerBase(EntityTriggerBase):
    """Trigger for entity state changes to a specific state."""

    _to_states: set[str]

    def is_valid_transition(self, from_state: State, to_state: State) -> bool:
        """Check if the origin state is valid and the state has changed."""
        if from_state.state in (STATE_UNAVAILABLE, STATE_UNKNOWN):
            return False

        return (
            from_state.state != to_state.state
            and from_state.state not in self._to_states
        )

    def is_valid_state(self, state: State) -> bool:
        """Check if the new state matches the expected state."""
        return state.state in self._to_states


class EntityTransitionTriggerBase(EntityTriggerBase):
    """Trigger for entity state changes between specific states."""

    _from_states: set[str]
    _to_states: set[str]

    def is_valid_transition(self, from_state: State, to_state: State) -> bool:
        """Check if the origin state matches the expected ones."""
        if not super().is_valid_transition(from_state, to_state):
            return False

        return from_state.state in self._from_states

    def is_valid_state(self, state: State) -> bool:
        """Check if the new state matches the expected states."""
        return state.state in self._to_states


class EntityOriginStateTriggerBase(EntityTriggerBase):
    """Trigger for entity state changes from a specific state."""

    _from_state: str

    def is_valid_transition(self, from_state: State, to_state: State) -> bool:
        """Check if the origin state matches the expected one and that the state changed."""
        return (
            from_state.state == self._from_state and to_state.state != self._from_state
        )

    def is_valid_state(self, state: State) -> bool:
        """Check if the new state is not the same as the expected origin state."""
        return state.state != self._from_state


class EntityTargetStateAttributeTriggerBase(EntityTriggerBase):
    """Trigger for entity state attribute changes to a specific state."""

    _attribute: str
    _attribute_to_state: str

    def is_valid_transition(self, from_state: State, to_state: State) -> bool:
        """Check if the origin state is valid and the state has changed."""
        if from_state.state in (STATE_UNAVAILABLE, STATE_UNKNOWN):
            return False

        return from_state.attributes.get(self._attribute) != to_state.attributes.get(
            self._attribute
        )

    def is_valid_state(self, state: State) -> bool:
        """Check if the new state attribute matches the expected one."""
        return state.attributes.get(self._attribute) == self._attribute_to_state


def _validate_range[_T: dict[str, Any]](
    lower_limit: str, upper_limit: str
) -> Callable[[_T], _T]:
    """Generate range validator."""

    def _validate_range(value: _T) -> _T:
        above = value.get(lower_limit)
        below = value.get(upper_limit)

        if above is None or below is None:
            return value

        if isinstance(above, str) or isinstance(below, str):
            return value

        if above > below:
            raise vol.Invalid(
                (
                    f"A value can never be above {above} and below {below} at the same"
                    " time. You probably want two different triggers."
                ),
            )

        return value

    return _validate_range


_NUMBER_OR_ENTITY_CHOOSE_SCHEMA = vol.Schema(
    {
        vol.Required("active_choice"): vol.In(["number", "entity"]),
        vol.Optional("entity"): cv.entity_id,
        vol.Optional("number"): vol.Coerce(float),
    }
)


def _validate_number_or_entity(value: dict | float | str) -> float | str:
    """Validate number or entity selector result."""
    if isinstance(value, dict):
        _NUMBER_OR_ENTITY_CHOOSE_SCHEMA(value)
        return value[value["active_choice"]]  # type: ignore[no-any-return]
    return value


_number_or_entity = vol.All(
    _validate_number_or_entity, vol.Any(vol.Coerce(float), cv.entity_id)
)

NUMERICAL_ATTRIBUTE_CHANGED_TRIGGER_SCHEMA = ENTITY_STATE_TRIGGER_SCHEMA.extend(
    {
        vol.Required(CONF_OPTIONS): vol.All(
            {
                vol.Optional(CONF_ABOVE): _number_or_entity,
                vol.Optional(CONF_BELOW): _number_or_entity,
            },
            _validate_range(CONF_ABOVE, CONF_BELOW),
        )
    }
)


def _get_numerical_value(
    hass: HomeAssistant, entity_or_float: float | str
) -> float | None:
    """Get numerical value from float or entity state."""
    if isinstance(entity_or_float, str):
        if not (state := hass.states.get(entity_or_float)):
            # Entity not found
            return None
        try:
            return float(state.state)
        except (TypeError, ValueError):
            # Entity state is not a valid number
            return None
    return entity_or_float


class EntityNumericalStateAttributeChangedTriggerBase(EntityTriggerBase):
    """Trigger for numerical state attribute changes."""

    _attribute: str
    _schema = NUMERICAL_ATTRIBUTE_CHANGED_TRIGGER_SCHEMA

    _above: None | float | str
    _below: None | float | str

    _converter: Callable[[Any], float] = float

    def __init__(self, hass: HomeAssistant, config: TriggerConfig) -> None:
        """Initialize the state trigger."""
        super().__init__(hass, config)
        self._above = self._options.get(CONF_ABOVE)
        self._below = self._options.get(CONF_BELOW)

    def is_valid_transition(self, from_state: State, to_state: State) -> bool:
        """Check if the origin state is valid and the state has changed."""
        if from_state.state in (STATE_UNAVAILABLE, STATE_UNKNOWN):
            return False

        return from_state.attributes.get(self._attribute) != to_state.attributes.get(
            self._attribute
        )

    def is_valid_state(self, state: State) -> bool:
        """Check if the new state attribute matches the expected one."""
        # Handle missing or None attribute case first to avoid expensive exceptions
        if (_attribute_value := state.attributes.get(self._attribute)) is None:
            return False

        try:
            current_value = self._converter(_attribute_value)
        except (TypeError, ValueError):
            # Attribute is not a valid number, don't trigger
            return False

        if self._above is not None:
            if (above := _get_numerical_value(self._hass, self._above)) is None:
                # Entity not found or invalid number, don't trigger
                return False
            if current_value <= above:
                # The number is not above the limit, don't trigger
                return False

        if self._below is not None:
            if (below := _get_numerical_value(self._hass, self._below)) is None:
                # Entity not found or invalid number, don't trigger
                return False
            if current_value >= below:
                # The number is not below the limit, don't trigger
                return False

        return True


CONF_LOWER_LIMIT = "lower_limit"
CONF_UPPER_LIMIT = "upper_limit"
CONF_THRESHOLD_TYPE = "threshold_type"


class ThresholdType(StrEnum):
    """Numerical threshold types."""

    ABOVE = "above"
    BELOW = "below"
    BETWEEN = "between"
    OUTSIDE = "outside"


def _validate_limits_for_threshold_type(value: dict[str, Any]) -> dict[str, Any]:
    """Validate that the correct limits are provided for the selected threshold type."""
    threshold_type = value.get(CONF_THRESHOLD_TYPE)

    if threshold_type == ThresholdType.ABOVE:
        if CONF_LOWER_LIMIT not in value:
            raise vol.Invalid("lower_limit is required for threshold_type 'above'")
    elif threshold_type == ThresholdType.BELOW:
        if CONF_UPPER_LIMIT not in value:
            raise vol.Invalid("upper_limit is required for threshold_type 'below'")
    elif threshold_type in (ThresholdType.BETWEEN, ThresholdType.OUTSIDE):
        if CONF_LOWER_LIMIT not in value or CONF_UPPER_LIMIT not in value:
            raise vol.Invalid(
                "Both lower_limit and upper_limit are required for"
                f" threshold_type '{threshold_type}'"
            )

    return value


NUMERICAL_ATTRIBUTE_CROSSED_THRESHOLD_SCHEMA = ENTITY_STATE_TRIGGER_SCHEMA.extend(
    {
        vol.Required(CONF_OPTIONS): vol.All(
            {
                vol.Required(ATTR_BEHAVIOR, default=BEHAVIOR_ANY): vol.In(
                    [BEHAVIOR_FIRST, BEHAVIOR_LAST, BEHAVIOR_ANY]
                ),
                vol.Optional(CONF_LOWER_LIMIT): _number_or_entity,
                vol.Optional(CONF_UPPER_LIMIT): _number_or_entity,
                vol.Required(CONF_THRESHOLD_TYPE): vol.Coerce(ThresholdType),
            },
            _validate_range(CONF_LOWER_LIMIT, CONF_UPPER_LIMIT),
            _validate_limits_for_threshold_type,
        )
    }
)


class EntityNumericalStateAttributeCrossedThresholdTriggerBase(EntityTriggerBase):
    """Trigger for numerical state attribute changes.

    This trigger only fires when the observed attribute changes from not within to within
    the defined threshold.
    """

    _attribute: str
    _schema = NUMERICAL_ATTRIBUTE_CROSSED_THRESHOLD_SCHEMA

    _lower_limit: float | str | None = None
    _upper_limit: float | str | None = None
    _threshold_type: ThresholdType

    _converter: Callable[[Any], float] = float

    def __init__(self, hass: HomeAssistant, config: TriggerConfig) -> None:
        """Initialize the state trigger."""
        super().__init__(hass, config)
        self._lower_limit = self._options.get(CONF_LOWER_LIMIT)
        self._upper_limit = self._options.get(CONF_UPPER_LIMIT)
        self._threshold_type = self._options[CONF_THRESHOLD_TYPE]

    def is_valid_transition(self, from_state: State, to_state: State) -> bool:
        """Check if the origin state is valid and the state has changed."""
        if from_state.state in (STATE_UNAVAILABLE, STATE_UNKNOWN):
            return False

        return not self.is_valid_state(from_state)

    def is_valid_state(self, state: State) -> bool:
        """Check if the new state attribute matches the expected one."""
        if self._lower_limit is not None:
            if (
                lower_limit := _get_numerical_value(self._hass, self._lower_limit)
            ) is None:
                # Entity not found or invalid number, don't trigger
                return False

        if self._upper_limit is not None:
            if (
                upper_limit := _get_numerical_value(self._hass, self._upper_limit)
            ) is None:
                # Entity not found or invalid number, don't trigger
                return False

        # Handle missing or None attribute case first to avoid expensive exceptions
        if (_attribute_value := state.attributes.get(self._attribute)) is None:
            return False

        try:
            current_value = self._converter(_attribute_value)
        except (TypeError, ValueError):
            # Attribute is not a valid number, don't trigger
            return False

        # Note: We do not need to check for lower_limit/upper_limit being None here
        # because of the validation done in the schema.
        if self._threshold_type == ThresholdType.ABOVE:
            return current_value > lower_limit  # type: ignore[operator]
        if self._threshold_type == ThresholdType.BELOW:
            return current_value < upper_limit  # type: ignore[operator]

        # Mode is BETWEEN or OUTSIDE
        between = lower_limit < current_value < upper_limit  # type: ignore[operator]
        if self._threshold_type == ThresholdType.BETWEEN:
            return between
        return not between


def make_entity_target_state_trigger(
    domain: str, to_states: str | set[str]
) -> type[EntityTargetStateTriggerBase]:
    """Create a trigger for entity state changes to specific state(s)."""

    if isinstance(to_states, str):
        to_states_set = {to_states}
    else:
        to_states_set = to_states

    class CustomTrigger(EntityTargetStateTriggerBase):
        """Trigger for entity state changes."""

        _domain = domain
        _to_states = to_states_set

    return CustomTrigger


def make_entity_transition_trigger(
    domain: str, *, from_states: set[str], to_states: set[str]
) -> type[EntityTransitionTriggerBase]:
    """Create a trigger for entity state changes between specific states."""

    class CustomTrigger(EntityTransitionTriggerBase):
        """Trigger for conditional entity state changes."""

        _domain = domain
        _from_states = from_states
        _to_states = to_states

    return CustomTrigger


def make_entity_origin_state_trigger(
    domain: str, *, from_state: str
) -> type[EntityOriginStateTriggerBase]:
    """Create a trigger for entity state changes from a specific state."""

    class CustomTrigger(EntityOriginStateTriggerBase):
        """Trigger for entity "from state" changes."""

        _domain = domain
        _from_state = from_state

    return CustomTrigger


def make_entity_numerical_state_attribute_changed_trigger(
    domain: str, attribute: str
) -> type[EntityNumericalStateAttributeChangedTriggerBase]:
    """Create a trigger for numerical state attribute change."""

    class CustomTrigger(EntityNumericalStateAttributeChangedTriggerBase):
        """Trigger for numerical state attribute changes."""

        _domain = domain
        _attribute = attribute

    return CustomTrigger


def make_entity_numerical_state_attribute_crossed_threshold_trigger(
    domain: str, attribute: str
) -> type[EntityNumericalStateAttributeCrossedThresholdTriggerBase]:
    """Create a trigger for numerical state attribute change."""

    class CustomTrigger(EntityNumericalStateAttributeCrossedThresholdTriggerBase):
        """Trigger for numerical state attribute changes."""

        _domain = domain
        _attribute = attribute

    return CustomTrigger


def make_entity_target_state_attribute_trigger(
    domain: str, attribute: str, to_state: str
) -> type[EntityTargetStateAttributeTriggerBase]:
    """Create a trigger for entity state attribute changes to a specific state."""

    class CustomTrigger(EntityTargetStateAttributeTriggerBase):
        """Trigger for entity state changes."""

        _domain = domain
        _attribute = attribute
        _attribute_to_state = to_state

    return CustomTrigger


class TriggerProtocol(Protocol):
    """Define the format of trigger modules.

    New implementations should only implement async_get_triggers.
    """

    async def async_get_triggers(self, hass: HomeAssistant) -> dict[str, type[Trigger]]:
        """Return the triggers provided by this integration."""

    TRIGGER_SCHEMA: vol.Schema

    async def async_validate_trigger_config(
        self, hass: HomeAssistant, config: ConfigType
    ) -> ConfigType:
        """Validate config."""

    async def async_attach_trigger(
        self,
        hass: HomeAssistant,
        config: ConfigType,
        action: TriggerActionType,
        trigger_info: TriggerInfo,
    ) -> CALLBACK_TYPE:
        """Attach a trigger."""


@dataclass(slots=True, frozen=True)
class TriggerConfig:
    """Trigger config."""

    key: str  # The key used to identify the trigger, e.g. "zwave.event"
    target: dict[str, Any] | None = None
    options: dict[str, Any] | None = None


class TriggerActionRunner(Protocol):
    """Protocol type for the trigger action runner helper callback."""

    @callback
    def __call__(
        self,
        extra_trigger_payload: dict[str, Any],
        description: str,
        context: Context | None = None,
    ) -> asyncio.Task[Any]:
        """Define trigger action runner type.

        Returns:
            A Task that allows awaiting for the action to finish.
        """


class TriggerActionPayloadBuilder(Protocol):
    """Protocol type for the trigger action payload builder."""

    def __call__(
        self, extra_trigger_payload: dict[str, Any], description: str
    ) -> dict[str, Any]:
        """Define trigger action payload builder type."""


class TriggerAction(Protocol):
    """Protocol type for trigger action callback."""

    async def __call__(
        self, run_variables: dict[str, Any], context: Context | None = None
    ) -> Any:
        """Define action callback type."""


class TriggerActionType(Protocol):
    """Protocol type for trigger action callback.

    Contrary to TriggerAction, this type supports both sync and async callables.
    """

    def __call__(
        self,
        run_variables: dict[str, Any],
        context: Context | None = None,
    ) -> Coroutine[Any, Any, Any] | Any:
        """Define action callback type."""


class TriggerData(TypedDict):
    """Trigger data."""

    id: str
    idx: str
    alias: str | None


class TriggerInfo(TypedDict):
    """Information about trigger."""

    domain: str
    name: str
    home_assistant_start: bool
    variables: TemplateVarsType
    trigger_data: TriggerData


@dataclass(slots=True)
class PluggableActionsEntry:
    """Holder to keep track of all plugs and actions for a given trigger."""

    plugs: set[PluggableAction] = field(default_factory=set)
    actions: dict[
        object,
        tuple[
            HassJob[[dict[str, Any], Context | None], Coroutine[Any, Any, None] | Any],
            dict[str, Any],
        ],
    ] = field(default_factory=dict)


class PluggableAction:
    """A pluggable action handler."""

    _entry: PluggableActionsEntry | None = None

    def __init__(self, update: CALLBACK_TYPE | None = None) -> None:
        """Initialize a pluggable action.

        :param update: callback triggered whenever triggers are attached or removed.
        """
        self._update = update

    def __bool__(self) -> bool:
        """Return if we have something attached."""
        return bool(self._entry and self._entry.actions)

    @callback
    def async_run_update(self) -> None:
        """Run update function if one exists."""
        if self._update:
            self._update()

    @staticmethod
    @callback
    def async_get_registry(hass: HomeAssistant) -> dict[tuple, PluggableActionsEntry]:
        """Return the pluggable actions registry."""
        if data := hass.data.get(DATA_PLUGGABLE_ACTIONS):
            return data
        data = hass.data[DATA_PLUGGABLE_ACTIONS] = defaultdict(PluggableActionsEntry)
        return data

    @staticmethod
    @callback
    def async_attach_trigger(
        hass: HomeAssistant,
        trigger: dict[str, str],
        action: TriggerActionType,
        variables: dict[str, Any],
    ) -> CALLBACK_TYPE:
        """Attach an action to a trigger entry.

        Existing or future plugs registered will be attached.
        """
        reg = PluggableAction.async_get_registry(hass)
        key = tuple(sorted(trigger.items()))
        entry = reg[key]

        def _update() -> None:
            for plug in entry.plugs:
                plug.async_run_update()

        @callback
        def _remove() -> None:
            """Remove this action attachment, and disconnect all plugs."""
            del entry.actions[_remove]
            _update()
            if not entry.actions and not entry.plugs:
                del reg[key]

        job = HassJob(action, f"trigger {trigger} {variables}")
        entry.actions[_remove] = (job, variables)
        _update()

        return _remove

    @callback
    def async_register(
        self, hass: HomeAssistant, trigger: dict[str, str]
    ) -> CALLBACK_TYPE:
        """Register plug in the global plugs dictionary."""

        reg = PluggableAction.async_get_registry(hass)
        key = tuple(sorted(trigger.items()))
        self._entry = reg[key]
        self._entry.plugs.add(self)

        @callback
        def _remove() -> None:
            """Remove plug from registration.

            Clean up entry if there are no actions or plugs registered.
            """
            assert self._entry
            self._entry.plugs.remove(self)
            if not self._entry.actions and not self._entry.plugs:
                del reg[key]
            self._entry = None

        return _remove

    async def async_run(
        self, hass: HomeAssistant, context: Context | None = None
    ) -> None:
        """Run all actions."""
        assert self._entry
        for job, variables in self._entry.actions.values():
            task = hass.async_run_hass_job(job, variables, context)
            if task:
                await task


async def _async_get_trigger_platform(
    hass: HomeAssistant, trigger_key: str
) -> tuple[str, TriggerProtocol]:
    from homeassistant.components import automation  # noqa: PLC0415

    platform_and_sub_type = trigger_key.split(".")
    platform = platform_and_sub_type[0]
    platform = _PLATFORM_ALIASES.get(platform, platform)

    if automation.is_disabled_experimental_trigger(hass, platform):
        raise vol.Invalid(
            f"Trigger '{trigger_key}' requires the experimental 'New triggers and "
            "conditions' feature to be enabled in Home Assistant Labs settings "
            f"(feature flag: '{automation.NEW_TRIGGERS_CONDITIONS_FEATURE_FLAG}')"
        )

    try:
        integration = await async_get_integration(hass, platform)
    except IntegrationNotFound:
        raise vol.Invalid(f"Invalid trigger '{trigger_key}' specified") from None
    try:
        return platform, await integration.async_get_platform("trigger")
    except ImportError:
        raise vol.Invalid(
            f"Integration '{platform}' does not provide trigger support"
        ) from None


async def async_validate_trigger_config(
    hass: HomeAssistant, trigger_config: list[ConfigType]
) -> list[ConfigType]:
    """Validate triggers."""
    config = []
    for conf in trigger_config:
        trigger_key: str = conf[CONF_PLATFORM]
        platform_domain, platform = await _async_get_trigger_platform(hass, trigger_key)
        if hasattr(platform, "async_get_triggers"):
            trigger_descriptors = await platform.async_get_triggers(hass)
            relative_trigger_key = get_relative_description_key(
                platform_domain, trigger_key
            )
            if not (trigger := trigger_descriptors.get(relative_trigger_key)):
                raise vol.Invalid(f"Invalid trigger '{trigger_key}' specified")
            conf = await trigger.async_validate_complete_config(hass, conf)
        elif hasattr(platform, "async_validate_trigger_config"):
            conf = move_options_fields_to_top_level(conf, cv.TRIGGER_BASE_SCHEMA)
            conf = await platform.async_validate_trigger_config(hass, conf)
        else:
            conf = move_options_fields_to_top_level(conf, cv.TRIGGER_BASE_SCHEMA)
            conf = platform.TRIGGER_SCHEMA(conf)
        config.append(conf)
    return config


def _trigger_action_wrapper(
    hass: HomeAssistant, action: Callable, conf: ConfigType
) -> Callable:
    """Wrap trigger action with extra vars if configured.

    If action is a coroutine function, a coroutine function will be returned.
    If action is a callback, a callback will be returned.
    """
    if CONF_VARIABLES not in conf:
        return action

    # Check for partials to properly determine if coroutine function
    check_func = action
    while isinstance(check_func, functools.partial):
        check_func = check_func.func

    wrapper_func: Callable[..., Any] | Callable[..., Coroutine[Any, Any, Any]]
    if inspect.iscoroutinefunction(check_func):
        async_action = cast(Callable[..., Coroutine[Any, Any, Any]], action)

        @functools.wraps(async_action)
        async def async_with_vars(
            run_variables: dict[str, Any], context: Context | None = None
        ) -> Any:
            """Wrap action with extra vars."""
            trigger_variables = conf[CONF_VARIABLES]
            run_variables.update(trigger_variables.async_render(hass, run_variables))
            return await action(run_variables, context)

        wrapper_func = async_with_vars

    else:

        @functools.wraps(action)
        def with_vars(
            run_variables: dict[str, Any], context: Context | None = None
        ) -> Any:
            """Wrap action with extra vars."""
            trigger_variables = conf[CONF_VARIABLES]
            run_variables.update(trigger_variables.async_render(hass, run_variables))
            return action(run_variables, context)

        if is_callback(check_func):
            with_vars = callback(with_vars)

        wrapper_func = with_vars

    return wrapper_func


async def _async_attach_trigger_cls(
    hass: HomeAssistant,
    trigger_cls: type[Trigger],
    trigger_key: str,
    conf: ConfigType,
    action: Callable,
    trigger_info: TriggerInfo,
) -> CALLBACK_TYPE:
    """Initialize a new Trigger class and attach it."""

    def action_payload_builder(
        extra_trigger_payload: dict[str, Any], description: str
    ) -> dict[str, Any]:
        """Build action variables."""
        payload = {
            "trigger": {
                **trigger_info["trigger_data"],
                CONF_PLATFORM: trigger_key,
                "description": description,
                **extra_trigger_payload,
            }
        }
        if CONF_VARIABLES in conf:
            trigger_variables = conf[CONF_VARIABLES]
            payload.update(trigger_variables.async_render(hass, payload))
        return payload

    # Wrap sync action so that it is always async.
    # This simplifies the Trigger action runner interface by always returning a coroutine,
    # removing the need for integrations to check for the return type when awaiting the action.
    match get_hassjob_callable_job_type(action):
        case HassJobType.Executor:
            original_action = action

            async def wrapped_executor_action(
                run_variables: dict[str, Any], context: Context | None = None
            ) -> Any:
                """Wrap sync action to be called in executor."""
                return await hass.async_add_executor_job(
                    original_action, run_variables, context
                )

            action = wrapped_executor_action

        case HassJobType.Callback:
            original_action = action

            async def wrapped_callback_action(
                run_variables: dict[str, Any], context: Context | None = None
            ) -> Any:
                """Wrap callback action to be awaitable."""
                return original_action(run_variables, context)

            action = wrapped_callback_action

    trigger = trigger_cls(
        hass,
        TriggerConfig(
            key=trigger_key,
            target=conf.get(CONF_TARGET),
            options=conf.get(CONF_OPTIONS),
        ),
    )
    return await trigger.async_attach_action(action, action_payload_builder)


async def async_initialize_triggers(
    hass: HomeAssistant,
    trigger_config: list[ConfigType],
    action: Callable,
    domain: str,
    name: str,
    log_cb: Callable,
    home_assistant_start: bool = False,
    variables: TemplateVarsType = None,
) -> CALLBACK_TYPE | None:
    """Initialize triggers."""
    triggers: list[asyncio.Task[CALLBACK_TYPE]] = []
    for idx, conf in enumerate(trigger_config):
        # Skip triggers that are not enabled
        if CONF_ENABLED in conf:
            enabled = conf[CONF_ENABLED]
            if isinstance(enabled, Template):
                try:
                    enabled = enabled.async_render(variables, limited=True)
                except TemplateError as err:
                    log_cb(logging.ERROR, f"Error rendering enabled template: {err}")
                    continue
            if not enabled:
                continue

        trigger_key: str = conf[CONF_PLATFORM]
        platform_domain, platform = await _async_get_trigger_platform(hass, trigger_key)
        trigger_id = conf.get(CONF_ID, f"{idx}")
        trigger_idx = f"{idx}"
        trigger_alias = conf.get(CONF_ALIAS)
        trigger_data = TriggerData(id=trigger_id, idx=trigger_idx, alias=trigger_alias)
        info = TriggerInfo(
            domain=domain,
            name=name,
            home_assistant_start=home_assistant_start,
            variables=variables,
            trigger_data=trigger_data,
        )

        if hasattr(platform, "async_get_triggers"):
            trigger_descriptors = await platform.async_get_triggers(hass)
            relative_trigger_key = get_relative_description_key(
                platform_domain, trigger_key
            )
            trigger_cls = trigger_descriptors[relative_trigger_key]
            coro = _async_attach_trigger_cls(
                hass, trigger_cls, trigger_key, conf, action, info
            )
        else:
            action_wrapper = _trigger_action_wrapper(hass, action, conf)
            coro = platform.async_attach_trigger(hass, conf, action_wrapper, info)

        triggers.append(create_eager_task(coro))

    attach_results = await asyncio.gather(*triggers, return_exceptions=True)
    removes: list[Callable[[], None]] = []

    for result in attach_results:
        if isinstance(result, HomeAssistantError):
            log_cb(logging.ERROR, f"Got error '{result}' when setting up triggers for")
        elif isinstance(result, Exception):
            log_cb(logging.ERROR, "Error setting up trigger", exc_info=result)
        elif isinstance(result, BaseException):
            raise result from None
        elif result is None:
            log_cb(  # type: ignore[unreachable]
                logging.ERROR, "Unknown error while setting up trigger (empty result)"
            )
        else:
            removes.append(result)

    if not removes:
        return None

    log_cb(logging.INFO, "Initialized trigger")

    @callback
    def remove_triggers() -> None:
        """Remove triggers."""
        for remove in removes:
            remove()

    return remove_triggers


def _load_triggers_file(integration: Integration) -> dict[str, Any]:
    """Load triggers file for an integration."""
    try:
        return cast(
            dict[str, Any],
            _TRIGGERS_DESCRIPTION_SCHEMA(
                load_yaml_dict(str(integration.file_path / "triggers.yaml"))
            ),
        )
    except FileNotFoundError:
        _LOGGER.warning(
            "Unable to find triggers.yaml for the %s integration", integration.domain
        )
        return {}
    except (HomeAssistantError, vol.Invalid) as ex:
        _LOGGER.warning(
            "Unable to parse triggers.yaml for the %s integration: %s",
            integration.domain,
            ex,
        )
        return {}


def _load_triggers_files(
    integrations: Iterable[Integration],
) -> dict[str, dict[str, Any]]:
    """Load trigger files for multiple integrations."""
    return {
        integration.domain: {
            get_absolute_description_key(integration.domain, key): value
            for key, value in _load_triggers_file(integration).items()
        }
        for integration in integrations
    }


async def async_get_all_descriptions(
    hass: HomeAssistant,
) -> dict[str, dict[str, Any] | None]:
    """Return descriptions (i.e. user documentation) for all triggers."""
    from homeassistant.components import automation  # noqa: PLC0415

    descriptions_cache = hass.data[TRIGGER_DESCRIPTION_CACHE]

    triggers = hass.data[TRIGGERS]
    # See if there are new triggers not seen before.
    # Any trigger that we saw before already has an entry in description_cache.
    all_triggers = set(triggers)
    previous_all_triggers = set(descriptions_cache)
    # If the triggers are the same, we can return the cache

    # mypy complains: Invalid index type "HassKey[set[str]]" for "HassDict"
    if previous_all_triggers | hass.data[TRIGGER_DISABLED_TRIGGERS] == all_triggers:  # type: ignore[index]
        return descriptions_cache

    # Files we loaded for missing descriptions
    new_triggers_descriptions: dict[str, dict[str, Any]] = {}
    # We try to avoid making a copy in the event the cache is good,
    # but now we must make a copy in case new triggers get added
    # while we are loading the missing ones so we do not
    # add the new ones to the cache without their descriptions
    triggers = triggers.copy()

    if missing_triggers := all_triggers.difference(descriptions_cache):
        domains_with_missing_triggers = {
            triggers[missing_trigger] for missing_trigger in missing_triggers
        }
        ints_or_excs = await async_get_integrations(hass, domains_with_missing_triggers)
        integrations: list[Integration] = []
        for domain, int_or_exc in ints_or_excs.items():
            if type(int_or_exc) is Integration and int_or_exc.has_triggers:
                integrations.append(int_or_exc)
                continue
            if TYPE_CHECKING:
                assert isinstance(int_or_exc, Exception)
            _LOGGER.debug(
                "Failed to load triggers.yaml for integration: %s",
                domain,
                exc_info=int_or_exc,
            )

        if integrations:
            new_triggers_descriptions = await hass.async_add_executor_job(
                _load_triggers_files, integrations
            )

    # Make a copy of the old cache and add missing descriptions to it
    new_descriptions_cache = descriptions_cache.copy()
    for missing_trigger in missing_triggers:
        domain = triggers[missing_trigger]
        if automation.is_disabled_experimental_trigger(hass, domain):
            hass.data[TRIGGER_DISABLED_TRIGGERS].add(missing_trigger)
            continue

        if (
            yaml_description := new_triggers_descriptions.get(domain, {}).get(
                missing_trigger
            )
        ) is None:
            _LOGGER.debug(
                "No trigger descriptions found for trigger %s, skipping",
                missing_trigger,
            )
            new_descriptions_cache[missing_trigger] = None
            continue

        description = {"fields": yaml_description.get("fields", {})}
        if (target := yaml_description.get("target")) is not None:
            description["target"] = target

        new_descriptions_cache[missing_trigger] = description
    hass.data[TRIGGER_DESCRIPTION_CACHE] = new_descriptions_cache
    return new_descriptions_cache
</file>

<file path="typing.py">
"""Typing Helpers for Home Assistant."""

from collections.abc import Mapping
from enum import Enum
from typing import Any, Never

import voluptuous as vol

type GPSType = tuple[float, float]
type ConfigType = dict[str, Any]
type DiscoveryInfoType = dict[str, Any]
type ServiceDataType = dict[str, Any]
type StateType = str | int | float | None
type TemplateVarsType = Mapping[str, Any] | None
type NoEventData = Mapping[str, Never]
type VolSchemaType = vol.Schema | vol.All | vol.Any
type VolDictType = dict[str | vol.Marker, Any]

# Custom type for recorder Queries
type QueryType = Any


class UndefinedType(Enum):
    """Singleton type for use with not set sentinel values."""

    _singleton = 0


UNDEFINED = UndefinedType._singleton  # noqa: SLF001
</file>

<file path="update_coordinator.py">
"""Helpers to help coordinate updates."""

from __future__ import annotations

from abc import abstractmethod
import asyncio
from collections.abc import Awaitable, Callable, Coroutine, Generator
from datetime import datetime, timedelta
from functools import partial
import logging
from random import randint
from time import monotonic
from typing import Any, Generic, Protocol, TypeVar
import urllib.error

import aiohttp
from propcache.api import cached_property
import requests

from homeassistant import config_entries
from homeassistant.const import EVENT_HOMEASSISTANT_STOP
from homeassistant.core import CALLBACK_TYPE, Event, HomeAssistant, callback
from homeassistant.exceptions import (
    ConfigEntryAuthFailed,
    ConfigEntryError,
    ConfigEntryNotReady,
    HomeAssistantError,
)
from homeassistant.util.dt import utcnow

from . import entity, event
from .debounce import Debouncer
from .typing import UNDEFINED, UndefinedType

REQUEST_REFRESH_DEFAULT_COOLDOWN = 10
REQUEST_REFRESH_DEFAULT_IMMEDIATE = True

_DataT = TypeVar("_DataT", default=dict[str, Any])


class UpdateFailed(HomeAssistantError):
    """Raised when an update has failed."""

    def __init__(
        self,
        *args: Any,
        retry_after: float | None = None,
        **kwargs: Any,
    ) -> None:
        """Initialize exception."""
        super().__init__(*args, **kwargs)
        self.retry_after = retry_after


class BaseDataUpdateCoordinatorProtocol(Protocol):
    """Base protocol type for DataUpdateCoordinator."""

    @callback
    def async_add_listener(
        self, update_callback: CALLBACK_TYPE, context: Any = None
    ) -> Callable[[], None]:
        """Listen for data updates."""


class DataUpdateCoordinator(BaseDataUpdateCoordinatorProtocol, Generic[_DataT]):
    """Class to manage fetching data from single endpoint.

    Setting :attr:`always_update` to ``False`` will cause coordinator to only
    callback listeners when data has changed. This requires that the data
    implements ``__eq__`` or uses a python object that already does.
    """

    def __init__(
        self,
        hass: HomeAssistant,
        logger: logging.Logger,
        *,
        config_entry: config_entries.ConfigEntry | None | UndefinedType = UNDEFINED,
        name: str,
        update_interval: timedelta | None = None,
        update_method: Callable[[], Awaitable[_DataT]] | None = None,
        setup_method: Callable[[], Awaitable[None]] | None = None,
        request_refresh_debouncer: Debouncer[Coroutine[Any, Any, None]] | None = None,
        always_update: bool = True,
    ) -> None:
        """Initialize global data updater."""
        self.hass = hass
        self.logger = logger
        self.name = name
        self.update_method = update_method
        self.setup_method = setup_method
        self._update_interval_seconds: float | None = None
        self.update_interval = update_interval
        self._shutdown_requested = False
        if config_entry is UNDEFINED:
            # late import to avoid circular imports
            from . import frame  # noqa: PLC0415

            # It is not planned to enforce this for custom integrations.
            # see https://github.com/home-assistant/core/pull/138161#discussion_r1958184241
            frame.report_usage(
                "relies on ContextVar, but should pass the config entry explicitly.",
                core_behavior=frame.ReportBehavior.ERROR,
                custom_integration_behavior=frame.ReportBehavior.IGNORE,
                breaks_in_ha_version="2026.8",
            )

            self.config_entry = config_entries.current_entry.get()
        else:
            self.config_entry = config_entry
        self.always_update = always_update

        # It's None before the first successful update.
        # Components should call async_config_entry_first_refresh
        # to make sure the first update was successful.
        # Set type to just T to remove annoying checks that data is not None
        # when it was already checked during setup.
        self.data: _DataT = None  # type: ignore[assignment]

        # Pick a random microsecond in range 0.05..0.50 to stagger the refreshes
        # and avoid a thundering herd.
        self._microsecond = (
            randint(event.RANDOM_MICROSECOND_MIN, event.RANDOM_MICROSECOND_MAX) / 10**6
        )

        self._listeners: dict[int, tuple[CALLBACK_TYPE, object | None]] = {}
        self._last_listener_id: int = 0
        self._unsub_refresh: CALLBACK_TYPE | None = None
        self._unsub_shutdown: CALLBACK_TYPE | None = None
        self._request_refresh_task: asyncio.TimerHandle | None = None
        self._retry_after: float | None = None
        self.last_update_success = True
        self.last_exception: BaseException | None = None

        if request_refresh_debouncer is None:
            request_refresh_debouncer = Debouncer(
                hass,
                logger,
                cooldown=REQUEST_REFRESH_DEFAULT_COOLDOWN,
                immediate=REQUEST_REFRESH_DEFAULT_IMMEDIATE,
                function=self._async_refresh,
            )
        else:
            request_refresh_debouncer.function = self._async_refresh

        self._debounced_refresh = request_refresh_debouncer

        if self.config_entry:
            self.config_entry.async_on_unload(self.async_shutdown)

    async def async_register_shutdown(self) -> None:
        """Register shutdown on HomeAssistant stop.

        Should only be used by coordinators that are not linked to a config entry.
        """
        if self.config_entry:
            raise RuntimeError("This should only be used outside of config entries.")

        async def _on_hass_stop(_: Event) -> None:
            """Shutdown coordinator on HomeAssistant stop."""
            # Already cleared on EVENT_HOMEASSISTANT_STOP, via async_fire_internal
            self._unsub_shutdown = None
            await self.async_shutdown()

        self._unsub_shutdown = self.hass.bus.async_listen_once(
            EVENT_HOMEASSISTANT_STOP, _on_hass_stop
        )

    @callback
    def async_add_listener(
        self, update_callback: CALLBACK_TYPE, context: Any = None
    ) -> Callable[[], None]:
        """Listen for data updates."""
        schedule_refresh = not self._listeners
        self._last_listener_id += 1
        self._listeners[self._last_listener_id] = (update_callback, context)

        # This is the first listener, set up interval.
        if schedule_refresh:
            self._schedule_refresh()

        return partial(self.__async_remove_listener_internal, self._last_listener_id)

    @callback
    def __async_remove_listener_internal(self, listener_id: int) -> None:
        """Remove a listener.

        This is an internal function that is not to be overridden
        in subclasses as it may change in the future.
        """
        self._listeners.pop(listener_id)
        if not self._listeners:
            self._unschedule_refresh()
            self._debounced_refresh.async_cancel()

    @callback
    def async_update_listeners(self) -> None:
        """Update all registered listeners."""
        for update_callback, _ in list(self._listeners.values()):
            update_callback()

    async def async_shutdown(self) -> None:
        """Cancel any scheduled call, and ignore new runs."""
        self._shutdown_requested = True
        self._async_unsub_refresh()
        self._async_unsub_shutdown()
        self._debounced_refresh.async_shutdown()

    @callback
    def _unschedule_refresh(self) -> None:
        """Unschedule any pending refresh since there is no longer any listeners."""
        self._async_unsub_refresh()
        self._debounced_refresh.async_cancel()

    def async_contexts(self) -> Generator[Any]:
        """Return all registered contexts."""
        yield from (
            context for _, context in self._listeners.values() if context is not None
        )

    def _async_unsub_refresh(self) -> None:
        """Cancel any scheduled call."""
        if self._unsub_refresh:
            self._unsub_refresh()
            self._unsub_refresh = None

    def _async_unsub_shutdown(self) -> None:
        """Cancel any scheduled call."""
        if self._unsub_shutdown:
            self._unsub_shutdown()
            self._unsub_shutdown = None

    @property
    def update_interval(self) -> timedelta | None:
        """Interval between updates."""
        return self._update_interval

    @update_interval.setter
    def update_interval(self, value: timedelta | None) -> None:
        """Set interval between updates."""
        self._update_interval = value
        self._update_interval_seconds = value.total_seconds() if value else None

    @callback
    def _schedule_refresh(self) -> None:
        """Schedule a refresh."""
        if self._update_interval_seconds is None:
            return

        if self.config_entry and self.config_entry.pref_disable_polling:
            return

        # We do not cancel the debouncer here. If the refresh interval is shorter
        # than the debouncer cooldown, this would cause the debounce to never be called
        self._async_unsub_refresh()

        # We use loop.call_at because DataUpdateCoordinator does
        # not need an exact update interval which also avoids
        # calling dt_util.utcnow() on every update.
        hass = self.hass
        loop = hass.loop

        update_interval = self._update_interval_seconds
        if self._retry_after is not None:
            update_interval = self._retry_after
            self._retry_after = None

        next_refresh = int(loop.time()) + self._microsecond + update_interval
        self._unsub_refresh = loop.call_at(
            next_refresh, self.__wrap_handle_refresh_interval
        ).cancel

    @callback
    def __wrap_handle_refresh_interval(self) -> None:
        """Handle a refresh interval occurrence."""
        if self.config_entry:
            self.config_entry.async_create_background_task(
                self.hass,
                self._handle_refresh_interval(),
                name=f"{self.name} - {self.config_entry.title} - refresh",
                eager_start=True,
            )
        else:
            self.hass.async_create_background_task(
                self._handle_refresh_interval(),
                name=f"{self.name} - refresh",
                eager_start=True,
            )

    async def _handle_refresh_interval(self, _now: datetime | None = None) -> None:
        """Handle a refresh interval occurrence."""
        self._unsub_refresh = None
        async with self._debounced_refresh.async_lock():
            await self._async_refresh(log_failures=True, scheduled=True)

    async def async_request_refresh(self) -> None:
        """Request a refresh.

        Refresh will wait a bit to see if it can batch them.
        """
        await self._debounced_refresh.async_call()

    async def _async_update_data(self) -> _DataT:
        """Fetch the latest data from the source."""
        if self.update_method is None:
            raise NotImplementedError("Update method not implemented")
        return await self.update_method()

    async def async_config_entry_first_refresh(self) -> None:
        """Refresh data for the first time when a config entry is setup.

        Will automatically raise ConfigEntryNotReady if the refresh
        fails. Additionally logging is handled by config entry setup
        to ensure that multiple retries do not cause log spam.
        """
        async with self._debounced_refresh.async_lock():
            await self._async_config_entry_first_refresh()

    async def _async_config_entry_first_refresh(self) -> None:
        """Refresh data for the first time when a config entry is setup.

        Will automatically raise ConfigEntryNotReady if the refresh
        fails. Additionally logging is handled by config entry setup
        to ensure that multiple retries do not cause log spam.
        """
        if self.config_entry is None:
            raise ConfigEntryError(
                "Detected code that uses `async_config_entry_first_refresh`,"
                " which is only supported for coordinators with a config entry"
            )
        if (
            self.config_entry.state
            is not config_entries.ConfigEntryState.SETUP_IN_PROGRESS
        ):
            raise ConfigEntryError(
                f"`async_config_entry_first_refresh` called when config entry state is {self.config_entry.state}, "
                f"but should only be called in state {config_entries.ConfigEntryState.SETUP_IN_PROGRESS}"
            )
        if await self.__wrap_async_setup():
            await self._async_refresh(
                log_failures=False,
                raise_on_auth_failed=True,
                raise_on_entry_error=True,
            )
            if self.last_update_success:
                return
        ex = ConfigEntryNotReady()
        ex.__cause__ = self.last_exception
        raise ex

    async def __wrap_async_setup(self) -> bool:
        """Error handling for _async_setup."""
        try:
            await self._async_setup()
        except (
            TimeoutError,
            requests.exceptions.Timeout,
            aiohttp.ClientError,
            requests.exceptions.RequestException,
            urllib.error.URLError,
            UpdateFailed,
        ) as err:
            self.last_exception = err

        except (ConfigEntryError, ConfigEntryAuthFailed) as err:
            self.last_exception = err
            self.last_update_success = False
            raise

        except Exception as err:  # pylint: disable=broad-except
            self.last_exception = err
            self.logger.exception("Unexpected error fetching %s data", self.name)
        else:
            return True

        self.last_update_success = False
        return False

    async def _async_setup(self) -> None:
        """Set up the coordinator.

        Can be overwritten by integrations to load data or resources
        only once during the first refresh.
        """
        if self.setup_method is None:
            return
        await self.setup_method()

    async def async_refresh(self) -> None:
        """Refresh data and log errors."""
        async with self._debounced_refresh.async_lock():
            await self._async_refresh(log_failures=True)

    async def _async_refresh(  # noqa: C901
        self,
        log_failures: bool = True,
        raise_on_auth_failed: bool = False,
        scheduled: bool = False,
        raise_on_entry_error: bool = False,
    ) -> None:
        """Refresh data."""
        self._async_unsub_refresh()
        self._debounced_refresh.async_cancel()

        if self._shutdown_requested or (scheduled and self.hass.is_stopping):
            return

        if log_timing := self.logger.isEnabledFor(logging.DEBUG):
            start = monotonic()

        auth_failed = False
        previous_update_success = self.last_update_success
        previous_data = self.data

        try:
            self.data = await self._async_update_data()

        except (TimeoutError, requests.exceptions.Timeout) as err:
            self.last_exception = err
            if self.last_update_success:
                if log_failures:
                    self.logger.error("Timeout fetching %s data", self.name)
                self.last_update_success = False

        except (aiohttp.ClientError, requests.exceptions.RequestException) as err:
            self.last_exception = err
            if self.last_update_success:
                if log_failures:
                    self.logger.error("Error requesting %s data: %s", self.name, err)
                self.last_update_success = False

        except urllib.error.URLError as err:
            self.last_exception = err
            if self.last_update_success:
                if log_failures:
                    if err.reason == "timed out":
                        self.logger.error("Timeout fetching %s data", self.name)
                    else:
                        self.logger.error(
                            "Error requesting %s data: %s", self.name, err
                        )
                self.last_update_success = False

        except UpdateFailed as err:
            self.last_exception = err
            # We can only honor a retry_after, after the config entry has been set up
            # Basically meaning that the retry after can't be used when coming
            # from an async_config_entry_first_refresh
            if err.retry_after is not None and not raise_on_entry_error:
                self._retry_after = err.retry_after
                self.logger.debug(
                    "Retry after triggered. Scheduling next update in %s second(s)",
                    err.retry_after,
                )

            if self.last_update_success:
                if log_failures:
                    self.logger.error("Error fetching %s data: %s", self.name, err)
                self.last_update_success = False

        except ConfigEntryError as err:
            self.last_exception = err
            if self.last_update_success:
                if log_failures:
                    self.logger.error(
                        "Config entry setup failed while fetching %s data: %s",
                        self.name,
                        err,
                    )
                self.last_update_success = False
            if raise_on_entry_error:
                raise

        except ConfigEntryAuthFailed as err:
            auth_failed = True
            self.last_exception = err
            if self.last_update_success:
                if log_failures:
                    self.logger.error(
                        "Authentication failed while fetching %s data: %s",
                        self.name,
                        err,
                    )
                self.last_update_success = False
            if raise_on_auth_failed:
                raise

            if self.config_entry:
                self.config_entry.async_start_reauth(self.hass)
        except NotImplementedError as err:
            self.last_exception = err
            self.last_update_success = False
            raise

        except asyncio.CancelledError as err:
            self.last_exception = err
            self.last_update_success = False

            if (task := asyncio.current_task()) and task.cancelling() > 0:
                raise

        except Exception as err:
            self.last_exception = err
            self.last_update_success = False
            self.logger.exception("Unexpected error fetching %s data", self.name)

        else:
            if not self.last_update_success:
                self.last_update_success = True
                self.logger.info("Fetching %s data recovered", self.name)

        finally:
            if log_timing:
                self.logger.debug(
                    "Finished fetching %s data in %.3f seconds (success: %s)",
                    self.name,
                    monotonic() - start,
                    self.last_update_success,
                )
            if not auth_failed and self._listeners and not self.hass.is_stopping:
                self._schedule_refresh()

        self._async_refresh_finished()

        if not self.last_update_success and not previous_update_success:
            return

        if (
            self.always_update
            or self.last_update_success != previous_update_success
            or previous_data != self.data
        ):
            self.async_update_listeners()

    @callback
    def _async_refresh_finished(self) -> None:
        """Handle when a refresh has finished.

        Called when refresh is finished before listeners are updated.

        To be overridden by subclasses.
        """

    @callback
    def async_set_update_error(self, err: Exception) -> None:
        """Manually set an error, log the message and notify listeners."""
        self.last_exception = err
        if self.last_update_success:
            self.logger.error("Error requesting %s data: %s", self.name, err)
            self.last_update_success = False
            self.async_update_listeners()

    @callback
    def async_set_updated_data(self, data: _DataT) -> None:
        """Manually update data, notify listeners and reset refresh interval."""
        self._async_unsub_refresh()
        self._debounced_refresh.async_cancel()

        self.data = data
        self.last_update_success = True
        self.logger.debug(
            "Manually updated %s data",
            self.name,
        )

        if self._listeners:
            self._schedule_refresh()

        self.async_update_listeners()


class TimestampDataUpdateCoordinator(DataUpdateCoordinator[_DataT]):
    """DataUpdateCoordinator which keeps track of the last successful update."""

    last_update_success_time: datetime | None = None

    @callback
    def _async_refresh_finished(self) -> None:
        """Handle when a refresh has finished."""
        if self.last_update_success:
            self.last_update_success_time = utcnow()


class BaseCoordinatorEntity[
    _BaseDataUpdateCoordinatorT: BaseDataUpdateCoordinatorProtocol
](entity.Entity):
    """Base class for all Coordinator entities."""

    def __init__(
        self, coordinator: _BaseDataUpdateCoordinatorT, context: Any = None
    ) -> None:
        """Create the entity with a DataUpdateCoordinator."""
        self.coordinator = coordinator
        self.coordinator_context = context

    @cached_property
    def should_poll(self) -> bool:
        """No need to poll. Coordinator notifies entity of updates."""
        return False

    async def async_added_to_hass(self) -> None:
        """When entity is added to hass."""
        await super().async_added_to_hass()
        self.async_on_remove(
            self.coordinator.async_add_listener(
                self._handle_coordinator_update, self.coordinator_context
            )
        )

    @callback
    def _handle_coordinator_update(self) -> None:
        """Handle updated data from the coordinator."""
        self.async_write_ha_state()

    @abstractmethod
    async def async_update(self) -> None:
        """Update the entity.

        Only used by the generic entity update service.
        """


class CoordinatorEntity[
    _DataUpdateCoordinatorT: DataUpdateCoordinator[Any] = DataUpdateCoordinator[
        dict[str, Any]
    ]
](BaseCoordinatorEntity[_DataUpdateCoordinatorT]):
    """A class for entities using DataUpdateCoordinator."""

    def __init__(
        self, coordinator: _DataUpdateCoordinatorT, context: Any = None
    ) -> None:
        """Create the entity with a DataUpdateCoordinator.

        Passthrough to BaseCoordinatorEntity.

        Necessary to bind TypeVar to correct scope.
        """
        super().__init__(coordinator, context)

    @property
    def available(self) -> bool:
        """Return if entity is available."""
        return self.coordinator.last_update_success

    async def async_update(self) -> None:
        """Update the entity.

        Only used by the generic entity update service.
        """
        # Ignore manual update requests if the entity is disabled
        if not self.enabled:
            return

        await self.coordinator.async_request_refresh()
</file>

</files>
